{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Notability criteria</th>\n",
       "      <th>Notability criteria notes</th>\n",
       "      <th>Model accessibility</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Reference</th>\n",
       "      <th>...</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Batch size notes</th>\n",
       "      <th>Organization categorization</th>\n",
       "      <th>Foundation model</th>\n",
       "      <th>Training compute lower bound</th>\n",
       "      <th>Training compute upper bound</th>\n",
       "      <th>Training chip-hours</th>\n",
       "      <th>Code accessibility</th>\n",
       "      <th>Dataset accessibility</th>\n",
       "      <th>Accessibility notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Gemini Ultra</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Language modelling,Visual question answering,C...</td>\n",
       "      <td>Gemini Team</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>\" Evaluation on a broad range of benchmarks sh...</td>\n",
       "      <td>Hosted access (no API)</td>\n",
       "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
       "      <td>252.0</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Qwen-72B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Chat,Code generation</td>\n",
       "      <td>Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Ka...</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>SOTA on several Chinese benchmarks, with highe...</td>\n",
       "      <td>Permissive license (depr.)</td>\n",
       "      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>Table 1 https://arxiv.org/abs/2309.16609\\n(thi...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Inflection-2</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Significant use</td>\n",
       "      <td>Inflection-2 either already powers Pi or soon ...</td>\n",
       "      <td>API access</td>\n",
       "      <td>https://inflection.ai/inflection-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inflection-2: The Next Step Up</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>checked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Nemotron-3-8B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Chat,Language generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>\"The Nemotron-3-8B-QA model offers state-of-th...</td>\n",
       "      <td>Permissive license (depr.)</td>\n",
       "      <td>https://developer.nvidia.com/blog/nvidia-ai-fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NVIDIA AI Foundation Models: Build Custom Ente...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>CogVLM</td>\n",
       "      <td>Multimodal,Vision,Language</td>\n",
       "      <td>Image captioning,Visual question answering,Chat</td>\n",
       "      <td>Weihan Wang, Qingsong Lv, Wenmeng Yu, Wenyi Ho...</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>\"CogVLM-17B\\nachieves state-of-the-art perform...</td>\n",
       "      <td>Permissive license (depr.)</td>\n",
       "      <td>https://arxiv.org/abs/2311.03079\\nhttps://hugg...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>CogVLM: Visual Expert for Pretrained Language ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Academia,Industry,Academia</td>\n",
       "      <td>checked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>Language</td>\n",
       "      <td>Translation</td>\n",
       "      <td>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1609.08144</td>\n",
       "      <td>6105.0</td>\n",
       "      <td>Google's Neural Machine Translation System: Br...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.nature.com/articles/nature16961</td>\n",
       "      <td>14733.0</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1512.03385</td>\n",
       "      <td>154061.0</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech recognition</td>\n",
       "      <td>Dario Amodei, Rishita Anubhai, Eric Battenberg...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1512.02595</td>\n",
       "      <td>2741.0</td>\n",
       "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>AlphaGo Fan</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.nature.com/articles/nature24270.ep...</td>\n",
       "      <td>14733.0</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System                      Domain  \\\n",
       "39             Gemini Ultra                  Multimodal   \n",
       "46                 Qwen-72B                    Language   \n",
       "54             Inflection-2                    Language   \n",
       "59            Nemotron-3-8B                    Language   \n",
       "76                   CogVLM  Multimodal,Vision,Language   \n",
       "...                     ...                         ...   \n",
       "1095                   GNMT                    Language   \n",
       "1131            AlphaGo Lee                       Games   \n",
       "1135  ResNet-152 (ImageNet)                      Vision   \n",
       "1137  DeepSpeech2 (English)                      Speech   \n",
       "1141            AlphaGo Fan                       Games   \n",
       "\n",
       "                                                   Task  \\\n",
       "39    Language modelling,Visual question answering,C...   \n",
       "46                                 Chat,Code generation   \n",
       "54                                   Language modelling   \n",
       "59                             Chat,Language generation   \n",
       "76      Image captioning,Visual question answering,Chat   \n",
       "...                                                 ...   \n",
       "1095                                        Translation   \n",
       "1131                                                 Go   \n",
       "1135                               Image classification   \n",
       "1137                                 Speech recognition   \n",
       "1141                                                 Go   \n",
       "\n",
       "                                                Authors  \\\n",
       "39                                          Gemini Team   \n",
       "46    Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Ka...   \n",
       "54                                                  NaN   \n",
       "59                                                  NaN   \n",
       "76    Weihan Wang, Qingsong Lv, Wenmeng Yu, Wenyi Ho...   \n",
       "...                                                 ...   \n",
       "1095  Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...   \n",
       "1131  David Silver, Aja Huang, Chris J. Maddison, Ar...   \n",
       "1135  Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun   \n",
       "1137  Dario Amodei, Rishita Anubhai, Eric Battenberg...   \n",
       "1141  David Silver, Aja Huang, Chris J. Maddison, Ar...   \n",
       "\n",
       "                Notability criteria  \\\n",
       "39                 SOTA improvement   \n",
       "46                 SOTA improvement   \n",
       "54                  Significant use   \n",
       "59                 SOTA improvement   \n",
       "76                 SOTA improvement   \n",
       "...                             ...   \n",
       "1095                   Highly cited   \n",
       "1131                   Highly cited   \n",
       "1135                   Highly cited   \n",
       "1137                   Highly cited   \n",
       "1141  Highly cited,SOTA improvement   \n",
       "\n",
       "                              Notability criteria notes  \\\n",
       "39    \" Evaluation on a broad range of benchmarks sh...   \n",
       "46    SOTA on several Chinese benchmarks, with highe...   \n",
       "54    Inflection-2 either already powers Pi or soon ...   \n",
       "59    \"The Nemotron-3-8B-QA model offers state-of-th...   \n",
       "76    \"CogVLM-17B\\nachieves state-of-the-art perform...   \n",
       "...                                                 ...   \n",
       "1095                                                NaN   \n",
       "1131                                                NaN   \n",
       "1135                                                NaN   \n",
       "1137                                                NaN   \n",
       "1141                                                NaN   \n",
       "\n",
       "             Model accessibility  \\\n",
       "39        Hosted access (no API)   \n",
       "46    Permissive license (depr.)   \n",
       "54                    API access   \n",
       "59    Permissive license (depr.)   \n",
       "76    Permissive license (depr.)   \n",
       "...                          ...   \n",
       "1095                         NaN   \n",
       "1131                         NaN   \n",
       "1135                         NaN   \n",
       "1137                         NaN   \n",
       "1141                         NaN   \n",
       "\n",
       "                                                   Link  Citations  \\\n",
       "39    https://storage.googleapis.com/deepmind-media/...      252.0   \n",
       "46                 https://huggingface.co/Qwen/Qwen-72B        NaN   \n",
       "54                   https://inflection.ai/inflection-2        NaN   \n",
       "59    https://developer.nvidia.com/blog/nvidia-ai-fo...        NaN   \n",
       "76    https://arxiv.org/abs/2311.03079\\nhttps://hugg...       43.0   \n",
       "...                                                 ...        ...   \n",
       "1095                   https://arxiv.org/abs/1609.08144     6105.0   \n",
       "1131        https://www.nature.com/articles/nature16961    14733.0   \n",
       "1135                   https://arxiv.org/abs/1512.03385   154061.0   \n",
       "1137                   https://arxiv.org/abs/1512.02595     2741.0   \n",
       "1141  https://www.nature.com/articles/nature24270.ep...    14733.0   \n",
       "\n",
       "                                              Reference  ... Batch size  \\\n",
       "39    Gemini: A Family of Highly Capable Multimodal ...  ...        NaN   \n",
       "46                                                  NaN  ...  4000000.0   \n",
       "54                       Inflection-2: The Next Step Up  ...        NaN   \n",
       "59    NVIDIA AI Foundation Models: Build Custom Ente...  ...        NaN   \n",
       "76    CogVLM: Visual Expert for Pretrained Language ...  ...        NaN   \n",
       "...                                                 ...  ...        ...   \n",
       "1095  Google's Neural Machine Translation System: Br...  ...        NaN   \n",
       "1131  Mastering the game of Go with deep neural netw...  ...        NaN   \n",
       "1135       Deep Residual Learning for Image Recognition  ...        NaN   \n",
       "1137  Deep Speech 2: End-to-End Speech Recognition i...  ...        NaN   \n",
       "1141  Mastering the game of Go with deep neural netw...  ...        NaN   \n",
       "\n",
       "                                       Batch size notes  \\\n",
       "39                                                  NaN   \n",
       "46    Table 1 https://arxiv.org/abs/2309.16609\\n(thi...   \n",
       "54                                                  NaN   \n",
       "59                                                  NaN   \n",
       "76                                                  NaN   \n",
       "...                                                 ...   \n",
       "1095                                                NaN   \n",
       "1131                                                NaN   \n",
       "1135                                                NaN   \n",
       "1137                                                NaN   \n",
       "1141                                                NaN   \n",
       "\n",
       "      Organization categorization Foundation model  \\\n",
       "39                       Industry              NaN   \n",
       "46                       Industry              NaN   \n",
       "54                       Industry          checked   \n",
       "59                       Industry              NaN   \n",
       "76     Academia,Industry,Academia          checked   \n",
       "...                           ...              ...   \n",
       "1095                     Industry              NaN   \n",
       "1131                     Industry              NaN   \n",
       "1135                     Industry              NaN   \n",
       "1137                     Industry              NaN   \n",
       "1141                     Industry              NaN   \n",
       "\n",
       "      Training compute lower bound Training compute upper bound  \\\n",
       "39                             NaN                          NaN   \n",
       "46                             NaN                          NaN   \n",
       "54                             NaN                          NaN   \n",
       "59                             NaN                          NaN   \n",
       "76                             NaN                          NaN   \n",
       "...                            ...                          ...   \n",
       "1095                           NaN                          NaN   \n",
       "1131                           NaN                          NaN   \n",
       "1135                           NaN                          NaN   \n",
       "1137                           NaN                          NaN   \n",
       "1141                           NaN                          NaN   \n",
       "\n",
       "     Training chip-hours Code accessibility  Dataset accessibility  \\\n",
       "39           132000000.0                NaN                    NaN   \n",
       "46                   NaN                NaN                    NaN   \n",
       "54                   NaN                NaN                    NaN   \n",
       "59                   NaN                NaN                    NaN   \n",
       "76                   NaN                NaN                    NaN   \n",
       "...                  ...                ...                    ...   \n",
       "1095            414720.0                NaN                    NaN   \n",
       "1131                 NaN                NaN                    NaN   \n",
       "1135                 NaN                NaN                    NaN   \n",
       "1137               301.0                NaN                    NaN   \n",
       "1141                 NaN                NaN                    NaN   \n",
       "\n",
       "     Accessibility notes  \n",
       "39                   NaN  \n",
       "46                   NaN  \n",
       "54                   NaN  \n",
       "59                   NaN  \n",
       "76                   NaN  \n",
       "...                  ...  \n",
       "1095                 NaN  \n",
       "1131                 NaN  \n",
       "1135                 NaN  \n",
       "1137                 NaN  \n",
       "1141                 NaN  \n",
       "\n",
       "[138 rows x 56 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_pcd_df, hardware_df, price_df = load_data_for_cost_estimation()\n",
    "frontier_pcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU v3: 27\n",
      "A100: 26\n",
      "V100: 24\n",
      "TPU v4: 16\n",
      "P100: 3\n",
      "K80: 3\n",
      "NVIDIA GTX Titan X: 3\n",
      "TPU v2: 2\n",
      "K40: 2\n",
      "TPU v1: 2\n",
      "H100: 1\n",
      "NVIDIA A800: 1\n",
      "Huawei Ascend 910: 1\n",
      "NVIDIA Quadro P600: 1\n",
      "NVIDIA M40,NVIDIA GTX Titan X: 1\n"
     ]
    }
   ],
   "source": [
    "hardware_aliases = ['A100', 'H100', 'P100', 'V100', 'TPU v4', 'TPU v3', 'TPU v2', 'TPU v1', 'K80', 'K40']\n",
    "hardware_counts = defaultdict(int)\n",
    "for hardware in frontier_pcd_df['Training hardware'].dropna():\n",
    "    alias_found = False\n",
    "    for alias in hardware_aliases:\n",
    "        if alias in hardware:\n",
    "            hardware_counts[alias] += 1\n",
    "            alias_found = True\n",
    "    if not alias_found:\n",
    "        hardware_counts[hardware] += 1\n",
    "\n",
    "# Print counts in descending order\n",
    "for hardware, count in sorted(hardware_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{hardware}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A100: 26\n",
      "V100: 24\n",
      "P100: 3\n",
      "K80: 3\n",
      "NVIDIA GTX Titan X: 3\n",
      "K40: 2\n",
      "H100: 1\n",
      "NVIDIA A800: 1\n",
      "Huawei Ascend 910: 1\n",
      "NVIDIA Quadro P600: 1\n",
      "NVIDIA M40,NVIDIA GTX Titan X: 1\n"
     ]
    }
   ],
   "source": [
    "# No TPUs\n",
    "hardware_aliases = ['A100', 'H100', 'P100', 'V100', 'TPU v4', 'TPU v3', 'TPU v2', 'TPU v1', 'K80', 'K40']\n",
    "hardware_counts = defaultdict(int)\n",
    "for hardware in frontier_pcd_df['Training hardware'].dropna():\n",
    "    if 'TPU' in hardware:\n",
    "        continue\n",
    "    alias_found = False\n",
    "    for alias in hardware_aliases:\n",
    "        if alias in hardware:\n",
    "            hardware_counts[alias] += 1\n",
    "            alias_found = True\n",
    "    if not alias_found:\n",
    "        hardware_counts[hardware] += 1\n",
    "\n",
    "# Print counts in descending order\n",
    "for hardware, count in sorted(hardware_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{hardware}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epoch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
