{
    "1": [
        "PaLM (540B)",
        "Gemini Ultra",
        "GPT-4",
        "AlphaGo Zero",
        "GNMT",
        "AlphaGo Master",
        "Megatron-Turing NLG 530B",
        "AlphaGo Lee",
        "Minerva (540B)"
    ],
    "2": [
        "GPT-3 175B (davinci)",
        "NASv3 (CIFAR-10)",
        "U-PaLM (540B)",
        "ERNIE 3.0 Titan",
        "GPT-3.5 (text-davinci-003)",
        "Inflection-2",
        "Yuan 1.0",
        "PaLM 2",
        "Gopher (280B)"
    ],
    "3": [
        "Xception",
        "AlphaZero",
        "GLaM",
        "Claude 2",
        "OpenAI Five",
        "Meena",
        "DeepSpeech2 (English)",
        "Megatron-BERT"
    ],
    "4": [
        "ResNeXt-101 32x48d",
        "Chinchilla",
        "HyperCLOVA",
        "AlphaStar",
        "Falcon-180B"
    ],
    "5": [
        "Libratus",
        "FTW",
        "Megatron-LM (8.3B)",
        "JFT",
        "mT5-XXL",
        "Grok-1",
        "ResNet-152 (ImageNet)",
        "T5-11B",
        "Switch",
        "LaMDA"
    ],
    "6": [
        "OpenAI TI7 DOTA 1v1",
        "ByT5-XXL",
        "PolyNet",
        "OPT-175B"
    ],
    "7": [
        "GPT-2 (1.5B)",
        "Parti",
        "BLOOM-176B",
        "ProtT5-XXL"
    ],
    "8": [
        "MoE",
        "XLNet",
        "BlenderBot 3",
        "GOAT",
        "OpenAI Five Rerun"
    ],
    "9": [
        "RoBERTa Large",
        "Turing-NLG",
        "AlphaCode",
        "DALL-E",
        "BigGAN-deep 512x512",
        "ST-MoE",
        "GLM-130B"
    ],
    "10": [
        "Llama 2-70B",
        "Meta Pseudo Labels",
        "iGPT-XL",
        "xTrimoPGLM -100B",
        "LLaMA-65B",
        "ChatGLM3"
    ],
    "11": [
        "MnasNet-A1 + SSDLite",
        "Qwen-72B",
        "BIDAF",
        "ConvS2S (ensemble of 8 models)",
        "AmoebaNet-A (F=448)"
    ],
    "12": [
        "ViT-22B",
        "PNASNet-5",
        "GPT-NeoX-20B",
        "MnasNet-A3",
        "Flamingo",
        "PanGu-\u03a3",
        "DeepStack"
    ],
    "13": [
        "FLAN 137B",
        "ContextNet + Noisy Student",
        "IMPALA",
        "ProtBERT-BFD",
        "GShard (dense)",
        "PLUG"
    ],
    "14": [
        "iGPT-L",
        "CoAtNet",
        "BERT-Large-CAS (PTB+WT2+WT103)",
        "ProtT5-XXL-BFD",
        "Yi-34B"
    ],
    "15": [],
    "16": [
        "CLIP (ViT L/14@336px)",
        "BERT-Large",
        "Big Transformer for Back-Translation",
        "AlexaTM 20B",
        "Transformer"
    ],
    "17": [
        "Galactica",
        "Part-of-sentence tagging model",
        "UL2",
        "Florence"
    ],
    "18": [
        "Mesh-TensorFlow Transformer 4.9B (language modelling)",
        "ALBERT-xxlarge",
        "Conformer + Wav2vec 2.0 + Noisy Student",
        "T5-3B"
    ],
    "19": [
        "CogView",
        "ELECTRA",
        "Transformer (Adaptive Input Embeddings)",
        "YOLOv3"
    ],
    "20": [
        "Noisy Student (L2)",
        "BASIC-L",
        "Named Entity Recognition model",
        "LSTM (Hebbian, Cache, MbPA)"
    ]
}