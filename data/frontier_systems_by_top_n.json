{
    "1": [
        "AlphaGo Lee",
        "AlphaGo Master",
        "AlphaGo Zero",
        "GNMT",
        "GPT-4",
        "Gemini 1.0 Ultra",
        "Megatron-Turing NLG 530B",
        "Minerva (540B)",
        "PaLM (540B)"
    ],
    "2": [
        "ERNIE 3.0 Titan",
        "GPT-3 175B (davinci)",
        "GPT-3.5 (text-davinci-003)",
        "Gopher (280B)",
        "Inflection-2",
        "NASv3 (CIFAR-10)",
        "PaLM 2",
        "U-PaLM (540B)",
        "Yuan 1.0"
    ],
    "3": [
        "AlphaZero",
        "Claude 2",
        "DeepSpeech2 (English)",
        "GLaM",
        "Meena",
        "Megatron-BERT",
        "OpenAI Five",
        "Xception"
    ],
    "4": [
        "AlphaStar",
        "Chinchilla",
        "Falcon-180B",
        "Flan-PaLM 540B",
        "HyperCLOVA 82B",
        "ResNeXt-101 32x48d"
    ],
    "5": [
        "FTW",
        "Grok-1",
        "JFT",
        "LaMDA",
        "Libratus",
        "Megatron-LM (8.3B)",
        "ResNet-152 (ImageNet)",
        "Switch",
        "T5-11B",
        "mT5-XXL"
    ],
    "6": [
        "OPT-175B",
        "OpenAI TI7 DOTA 1v1",
        "PolyNet"
    ],
    "7": [
        "ByT5-XXL",
        "GPT-2 (1.5B)",
        "Parti",
        "ProtT5-XXL"
    ],
    "8": [
        "BLOOM-176B",
        "BlenderBot 3",
        "GOAT",
        "MoE",
        "OpenAI Five Rerun",
        "XLNet"
    ],
    "9": [
        "AlphaCode",
        "BigGAN-deep 512x512",
        "DALL-E",
        "GLM-130B",
        "RoBERTa Large",
        "ST-MoE",
        "Turing-NLG"
    ],
    "10": [
        "Meta Pseudo Labels",
        "iGPT-XL"
    ],
    "11": [
        "AmoebaNet-A (F=448)",
        "BIDAF",
        "ChatGLM3",
        "ContextNet + Noisy Student",
        "ConvS2S (ensemble of 8 models)",
        "LLaMA-65B",
        "Llama 2-70B",
        "MnasNet-A3",
        "xTrimoPGLM -100B"
    ],
    "12": [
        "DeepStack",
        "Flamingo",
        "GPT-NeoX-20B",
        "MnasNet-A1 + SSDLite",
        "PNASNet-5",
        "Qwen-72B"
    ],
    "13": [
        "FLAN 137B",
        "GShard (dense)",
        "IMPALA",
        "PLUG",
        "PanGu-\u03a3",
        "ProtBERT-BFD",
        "ViT-22B"
    ],
    "14": [
        "BERT-Large-CAS (PTB+WT2+WT103)",
        "CoAtNet",
        "ProtT5-XXL-BFD",
        "iGPT-L"
    ],
    "15": [
        "Yi-34B"
    ],
    "16": [
        "AlexaTM 20B",
        "BERT-Large",
        "Big Transformer for Back-Translation",
        "CLIP (ViT L/14@336px)",
        "Transformer"
    ],
    "17": [
        "Florence",
        "Part-of-sentence tagging model",
        "UL2"
    ],
    "18": [
        "ALBERT-xxlarge",
        "Galactica",
        "Mesh-TensorFlow Transformer 4.9B (language modelling)",
        "T5-3B"
    ],
    "19": [
        "CogView",
        "Conformer + Wav2vec 2.0 + Noisy Student",
        "ELECTRA",
        "Transformer (Adaptive Input Embeddings) WT103",
        "YOLOv3"
    ],
    "20": [
        "BASIC-L",
        "LSTM (Hebbian, Cache, MbPA)",
        "Llama 2-34B",
        "Named Entity Recognition model",
        "Noisy Student (L2)"
    ]
}