{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:30.211131Z",
     "start_time": "2024-02-07T16:04:29.911625700Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:30.226710800Z",
     "start_time": "2024-02-07T16:04:30.020995300Z"
    },
    "id": "qltoZ7TbdkHZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from plotting import *\n",
    "from prices import *\n",
    "from imputation import *\n",
    "from inflation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/refactor_imputation/'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:30.305898500Z",
     "start_time": "2024-02-07T16:04:30.117056900Z"
    },
    "id": "c8uNf70ve1PM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Notability criteria</th>\n",
       "      <th>Notability criteria notes</th>\n",
       "      <th>Open-source</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Reference</th>\n",
       "      <th>...</th>\n",
       "      <th>Organization (from Organization)</th>\n",
       "      <th>Base model</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Finetune compute notes</th>\n",
       "      <th>Authors by country</th>\n",
       "      <th>Hardware quantity</th>\n",
       "      <th>Hardware utilization</th>\n",
       "      <th>Training cost trends</th>\n",
       "      <th>Training cloud compute vendor</th>\n",
       "      <th>Training data center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cohere Command</td>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cohere.com/models/command</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World-class AI, at your command</td>\n",
       "      <td>...</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theseus</td>\n",
       "      <td>Other</td>\n",
       "      <td>Maze solving</td>\n",
       "      <td>Claude Shannon</td>\n",
       "      <td>Historical significance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mighty Mouse</td>\n",
       "      <td>...</td>\n",
       "      <td>Bell Laboratories</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Theseus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNARC</td>\n",
       "      <td>Other</td>\n",
       "      <td>Maze solving</td>\n",
       "      <td>Marvin Minsky</td>\n",
       "      <td>Historical significance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stochastic_neura...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>A Neural-Analogue Calculator Based upon a Prob...</td>\n",
       "      <td>...</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNARC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genetic algorithm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA Barricelli</td>\n",
       "      <td>Historical significance</td>\n",
       "      <td>Possibly first computer simulation of a geneti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://link.springer.com/article/10.1007/BF01...</td>\n",
       "      <td>266.0</td>\n",
       "      <td>Numerical testing of evolution theories</td>\n",
       "      <td>...</td>\n",
       "      <td>Institute for Advanced Study</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Genetic algorithm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sequence-based pattern recognition</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Character recognition</td>\n",
       "      <td>O. G. Selfridge</td>\n",
       "      <td>Historical significance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/1455292.1455310</td>\n",
       "      <td>290.0</td>\n",
       "      <td>Pattern recognition and modern computers</td>\n",
       "      <td>...</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sequence-based pattern recognition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>Mamba-24M (SC09)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Audio generation</td>\n",
       "      <td>Albert Gu, Tri Dao</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"SC09 is a benchmark speech generation dataset...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2312.00752</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Mamba: Linear-Time Sequence Modeling with Sele...</td>\n",
       "      <td>...</td>\n",
       "      <td>Carnegie Mellon University (CMU), Princeton Un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>Mamba-2.8B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language Generation</td>\n",
       "      <td>Albert Gu, Tri Dao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Permissive license</td>\n",
       "      <td>https://arxiv.org/abs/2312.00752</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Mamba: Linear-Time Sequence Modeling with Sele...</td>\n",
       "      <td>...</td>\n",
       "      <td>Carnegie Mellon University (CMU), Princeton Un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>Gemini Ultra</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Language modelling,Visual question answering,C...</td>\n",
       "      <td>Gemini Team</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\" Evaluation on a broad range of benchmarks sh...</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>Phi-2</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language Generation</td>\n",
       "      <td>Marah Abdin, Jyoti Aneja, Sebastien Bubeck, Ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"With only 2.7 billion parameters, Phi-2 surpa...</td>\n",
       "      <td>API accessible</td>\n",
       "      <td>https://www.microsoft.com/en-us/research/blog/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phi-2: The surprising power of small language ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>Gen-2</td>\n",
       "      <td>Text-to-Video</td>\n",
       "      <td>Video generation</td>\n",
       "      <td>Gen-2 authors</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>SOTA improvement over Stable Diffusion and Tex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://research.runwayml.com/gen2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Runway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gen-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1135 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  System         Domain  \\\n",
       "0                         Cohere Command       Language   \n",
       "1                                Theseus          Other   \n",
       "2                                  SNARC          Other   \n",
       "3                      Genetic algorithm            NaN   \n",
       "4     Sequence-based pattern recognition         Vision   \n",
       "...                                  ...            ...   \n",
       "1130                    Mamba-24M (SC09)         Speech   \n",
       "1131                          Mamba-2.8B       Language   \n",
       "1132                        Gemini Ultra     Multimodal   \n",
       "1133                               Phi-2       Language   \n",
       "1134                               Gen-2  Text-to-Video   \n",
       "\n",
       "                                                   Task  \\\n",
       "0                                                   NaN   \n",
       "1                                          Maze solving   \n",
       "2                                          Maze solving   \n",
       "3                                                   NaN   \n",
       "4                                 Character recognition   \n",
       "...                                                 ...   \n",
       "1130                                   Audio generation   \n",
       "1131                                Language Generation   \n",
       "1132  Language modelling,Visual question answering,C...   \n",
       "1133                                Language Generation   \n",
       "1134                                   Video generation   \n",
       "\n",
       "                                                Authors  \\\n",
       "0                                                   NaN   \n",
       "1                                        Claude Shannon   \n",
       "2                                         Marvin Minsky   \n",
       "3                                         NA Barricelli   \n",
       "4                                       O. G. Selfridge   \n",
       "...                                                 ...   \n",
       "1130                                 Albert Gu, Tri Dao   \n",
       "1131                                 Albert Gu, Tri Dao   \n",
       "1132                                        Gemini Team   \n",
       "1133  Marah Abdin, Jyoti Aneja, Sebastien Bubeck, Ca...   \n",
       "1134                                      Gen-2 authors   \n",
       "\n",
       "          Notability criteria  \\\n",
       "0                         NaN   \n",
       "1     Historical significance   \n",
       "2     Historical significance   \n",
       "3     Historical significance   \n",
       "4     Historical significance   \n",
       "...                       ...   \n",
       "1130         SOTA Improvement   \n",
       "1131                      NaN   \n",
       "1132         SOTA Improvement   \n",
       "1133                      NaN   \n",
       "1134         SOTA Improvement   \n",
       "\n",
       "                              Notability criteria notes         Open-source  \\\n",
       "0                                                   NaN                 NaN   \n",
       "1                                                   NaN                 NaN   \n",
       "2                                                   NaN                 NaN   \n",
       "3     Possibly first computer simulation of a geneti...                 NaN   \n",
       "4                                                   NaN                 NaN   \n",
       "...                                                 ...                 ...   \n",
       "1130  \"SC09 is a benchmark speech generation dataset...                 NaN   \n",
       "1131                                                NaN  Permissive license   \n",
       "1132  \" Evaluation on a broad range of benchmarks sh...          Unreleased   \n",
       "1133  \"With only 2.7 billion parameters, Phi-2 surpa...      API accessible   \n",
       "1134  SOTA improvement over Stable Diffusion and Tex...                 NaN   \n",
       "\n",
       "                                                   Link  Citations  \\\n",
       "0                     https://cohere.com/models/command        NaN   \n",
       "1     https://www.technologyreview.com/2018/12/19/13...        0.0   \n",
       "2     https://en.wikipedia.org/wiki/Stochastic_neura...       33.0   \n",
       "3     https://link.springer.com/article/10.1007/BF01...      266.0   \n",
       "4        https://dl.acm.org/doi/10.1145/1455292.1455310      290.0   \n",
       "...                                                 ...        ...   \n",
       "1130                   https://arxiv.org/abs/2312.00752        2.0   \n",
       "1131                   https://arxiv.org/abs/2312.00752        2.0   \n",
       "1132  https://storage.googleapis.com/deepmind-media/...        0.0   \n",
       "1133  https://www.microsoft.com/en-us/research/blog/...        NaN   \n",
       "1134                 https://research.runwayml.com/gen2        0.0   \n",
       "\n",
       "                                              Reference  ...  \\\n",
       "0                       World-class AI, at your command  ...   \n",
       "1                                          Mighty Mouse  ...   \n",
       "2     A Neural-Analogue Calculator Based upon a Prob...  ...   \n",
       "3               Numerical testing of evolution theories  ...   \n",
       "4              Pattern recognition and modern computers  ...   \n",
       "...                                                 ...  ...   \n",
       "1130  Mamba: Linear-Time Sequence Modeling with Sele...  ...   \n",
       "1131  Mamba: Linear-Time Sequence Modeling with Sele...  ...   \n",
       "1132  Gemini: A Family of Highly Capable Multimodal ...  ...   \n",
       "1133  Phi-2: The surprising power of small language ...  ...   \n",
       "1134                                                NaN  ...   \n",
       "\n",
       "                       Organization (from Organization) Base model  \\\n",
       "0                                                Cohere        NaN   \n",
       "1                                     Bell Laboratories        NaN   \n",
       "2                                    Harvard University        NaN   \n",
       "3                          Institute for Advanced Study        NaN   \n",
       "4           Massachusetts Institute of Technology (MIT)        NaN   \n",
       "...                                                 ...        ...   \n",
       "1130  Carnegie Mellon University (CMU), Princeton Un...        NaN   \n",
       "1131  Carnegie Mellon University (CMU), Princeton Un...        NaN   \n",
       "1132                                    Google DeepMind        NaN   \n",
       "1133                                          Microsoft        NaN   \n",
       "1134                                             Runway        NaN   \n",
       "\n",
       "     Finetune compute (FLOP)  Finetune compute notes  \\\n",
       "0                        NaN                     NaN   \n",
       "1                        NaN                     NaN   \n",
       "2                        NaN                     NaN   \n",
       "3                        NaN                     NaN   \n",
       "4                        NaN                     NaN   \n",
       "...                      ...                     ...   \n",
       "1130                     NaN                     NaN   \n",
       "1131                     NaN                     NaN   \n",
       "1132                     NaN                     NaN   \n",
       "1133                     NaN                     NaN   \n",
       "1134                     NaN                     NaN   \n",
       "\n",
       "                      Authors by country  Hardware quantity  \\\n",
       "0                                    NaN                NaN   \n",
       "1                                Theseus                NaN   \n",
       "2                                  SNARC                NaN   \n",
       "3                      Genetic algorithm                NaN   \n",
       "4     Sequence-based pattern recognition                NaN   \n",
       "...                                  ...                ...   \n",
       "1130                                 NaN                NaN   \n",
       "1131                                 NaN                NaN   \n",
       "1132                                 NaN                NaN   \n",
       "1133                                 NaN                NaN   \n",
       "1134                               Gen-2                NaN   \n",
       "\n",
       "     Hardware utilization Training cost trends Training cloud compute vendor  \\\n",
       "0                     NaN                  NaN                           NaN   \n",
       "1                     NaN                  NaN                           NaN   \n",
       "2                     NaN                  NaN                           NaN   \n",
       "3                     NaN                  NaN                           NaN   \n",
       "4                     NaN                  NaN                           NaN   \n",
       "...                   ...                  ...                           ...   \n",
       "1130                  NaN                  NaN                           NaN   \n",
       "1131                  NaN                  NaN                           NaN   \n",
       "1132                  NaN                  NaN                           NaN   \n",
       "1133                  NaN                  NaN                           NaN   \n",
       "1134                  NaN                  NaN                           NaN   \n",
       "\n",
       "      Training data center  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  \n",
       "...                    ...  \n",
       "1130                   NaN  \n",
       "1131                   NaN  \n",
       "1132                   NaN  \n",
       "1133                   NaN  \n",
       "1134                   NaN  \n",
       "\n",
       "[1135 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df = pd.read_csv('data/All ML Systems - full view.csv')\n",
    "pcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:30.451777Z",
     "start_time": "2024-02-07T16:04:30.305898500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Publication date in datetime format\n",
    "pcd_df.dropna(subset=['Publication date'], inplace=True)\n",
    "pcd_df['Publication date'] = pd.to_datetime(pcd_df['Publication date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:30.578536300Z",
     "start_time": "2024-02-07T16:04:30.467646700Z"
    },
    "id": "zHTeCty5dqjn"
   },
   "outputs": [],
   "source": [
    "# Manually copied from \"Training cost trends\" Airtable\n",
    "frontier_systems = [\n",
    "    \"PaLM 2\",\n",
    "    \"GPT-4\",\n",
    "    \"Minerva (540B)\",\n",
    "    \"Megatron-Turing NLG 530B\",\n",
    "    \"GPT-3 175B (davinci)\",\n",
    "    \"Meena\",\n",
    "    \"AlphaStar\",\n",
    "    \"AlphaGo Zero\",\n",
    "    \"AlphaGo Master\",\n",
    "    \"GNMT\",\n",
    "    \"Claude 2\",\n",
    "    \"PaLM (540B)\",\n",
    "#     \"ERNIE 3.0 Titan\",\n",
    "    \"Gopher (280B)\",\n",
    "    \"OpenAI Five\",\n",
    "    \"T5-11B\",\n",
    "    \"Megatron-BERT\",\n",
    "    \"ResNeXt-101 32x48d\",\n",
    "    \"AlphaZero\",\n",
    "    \"Falcon 180B\",\n",
    "    \"GPT-3.5 (text-davinci-003)\",\n",
    "    \"Chinchilla\",\n",
    "    \"Yuan 1.0\",\n",
    "    \"Turing-NLG\",\n",
    "    \"BigGAN-deep 512x512\",\n",
    "    \"NASv3 (CIFAR-10)\",\n",
    "    \"AlphaGo Lee\",\n",
    "    \"AlphaGo Fan\",\n",
    "    \"OPT-175B\",\n",
    "#     \"AlphaCode\",\n",
    "    \"GLaM\",\n",
    "    \"OpenAI Five Rerun\",\n",
    "    \"T5-3B\",\n",
    "    \"Megatron-LM (8.3B)\",\n",
    "    \"FTW\",\n",
    "    \"AmoebaNet-A (F=448)\",\n",
    "    \"OpenAI TI7 DOTA 1v1\",\n",
    "    \"JFT\",\n",
    "    \"Llama 2-70B\",\n",
    "    \"LLaMA-65B\",\n",
    "    \"LaMDA\",\n",
    "    \"ALIGN\",\n",
    "    \"GShard (dense)\",\n",
    "    \"RoBERTa Large\",\n",
    "    \"IMPALA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:30.715236200Z",
     "start_time": "2024-02-07T16:04:30.578536300Z"
    },
    "id": "Nyzyh8IKe0ZK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Notability criteria</th>\n",
       "      <th>Notability criteria notes</th>\n",
       "      <th>Open-source</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Reference</th>\n",
       "      <th>...</th>\n",
       "      <th>Organization (from Organization)</th>\n",
       "      <th>Base model</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Finetune compute notes</th>\n",
       "      <th>Authors by country</th>\n",
       "      <th>Hardware quantity</th>\n",
       "      <th>Hardware utilization</th>\n",
       "      <th>Training cost trends</th>\n",
       "      <th>Training cloud compute vendor</th>\n",
       "      <th>Training data center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>AlphaGo Fan</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.nature.com/articles/nature24270.ep...</td>\n",
       "      <td>14389.0</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaGo Fan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaGo Fan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.nature.com/articles/nature16961</td>\n",
       "      <td>14389.0</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>...</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>Language</td>\n",
       "      <td>Translation</td>\n",
       "      <td>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1609.08144</td>\n",
       "      <td>5948.0</td>\n",
       "      <td>Google's Neural Machine Translation System: Br...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GNMT</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GNMT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barret Zoph, Quoc V. Le</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1611.01578</td>\n",
       "      <td>4569.0</td>\n",
       "      <td>Neural Architecture Search with Reinforcement ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google Brain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>D Silver, J Schrittwieser, K Simonyan, I Anton...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.researchgate.net/publication/32047...</td>\n",
       "      <td>7831.0</td>\n",
       "      <td>Mastering the game of Go without human knowledge</td>\n",
       "      <td>...</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>JFT</td>\n",
       "      <td>Vision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chen Sun, Abhinav Shrivastava, Saurabh Singh, ...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1707.02968</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>Revisiting Unreasonable Effectiveness of Data ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google Research, Carnegie Mellon University (CMU)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JFT</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JFT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>Games</td>\n",
       "      <td>DOTA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTA Improvement,Historical significance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://openai.com/research/dota-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dota 2</td>\n",
       "      <td>...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>AlphaGo Zero</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>D Silver, J Schrittwieser, K Simonyan, I Anton...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.researchgate.net/publication/32047...</td>\n",
       "      <td>7831.0</td>\n",
       "      <td>Mastering the game of Go without human knowledge</td>\n",
       "      <td>...</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaGo Zero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaGo Zero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>AlphaZero</td>\n",
       "      <td>Games</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D Silver, T Hubert, J Schrittwieser, I Antonoglou</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1712.01815</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>Mastering Chess and Shogi by Self-Play with a ...</td>\n",
       "      <td>...</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaZero</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaZero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>AmoebaNet-A (F=448)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Esteban Real, Alok Aggarwal, Yanping Huang, Qu...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1802.01548</td>\n",
       "      <td>2505.0</td>\n",
       "      <td>Regularized Evolution for Image Classifier Arc...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google Brain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AmoebaNet-A (F=448)</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AmoebaNet-A (F=448)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>IMPALA</td>\n",
       "      <td>Games</td>\n",
       "      <td>Atari</td>\n",
       "      <td>Lasse Espeholt, Hubert Soyer, Remi Munos, Kare...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"IMPALA is able to achieve better performance ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1802.01561</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>IMPALA: Scalable Distributed Deep-RL with Impo...</td>\n",
       "      <td>...</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMPALA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMPALA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>ResNeXt-101 32x48d</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Dhruv Mahajan, Ross Girshick, Vignesh Ramanath...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"We show improvements on several image classif...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1805.00932</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>Exploring the Limits of Weakly Supervised Pret...</td>\n",
       "      <td>...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ResNeXt-101 32x48d</td>\n",
       "      <td>336.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ResNeXt-101 32x48d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>FTW</td>\n",
       "      <td>Games</td>\n",
       "      <td>Capture the flag</td>\n",
       "      <td>Max Jaderberg, Wojciech M. Czarnecki, Iain Dun...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"In this work, we demonstrate for the first ti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1807.01281</td>\n",
       "      <td>571.0</td>\n",
       "      <td>Human-level performance in first-person multip...</td>\n",
       "      <td>...</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FTW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FTW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>BigGAN-deep 512x512</td>\n",
       "      <td>Drawing</td>\n",
       "      <td>Image generation</td>\n",
       "      <td>A Brock, J Donahue, K Simonyan</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Permissive license</td>\n",
       "      <td>https://arxiv.org/abs/1809.11096</td>\n",
       "      <td>4163.0</td>\n",
       "      <td>Large Scale GAN Training for High Fidelity Nat...</td>\n",
       "      <td>...</td>\n",
       "      <td>Heriot-Watt University, DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BigGAN-deep 512x512</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BigGAN-deep 512x512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>RoBERTa Large</td>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du,...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1907.11692</td>\n",
       "      <td>15901.0</td>\n",
       "      <td>RoBERTa: A Robustly Optimized BERT Pretraining...</td>\n",
       "      <td>...</td>\n",
       "      <td>Facebook, University of Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RoBERTa Large</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RoBERTa Large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Megatron-BERT</td>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mohammad Shoeybi, Mostofa Patwary, Raul Puri, ...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"Our BERT model achieves SOTA results on the R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1909.08053</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Megatron-LM: Training Multi-Billion Parameter ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Megatron-BERT</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.2269</td>\n",
       "      <td>Megatron-BERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Megatron-LM (8.3B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mohammad Shoeybi, Mostofa Patwary, Raul Puri, ...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"Using the GPT-2 model we achieve SOTA results...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1909.08053</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Megatron-LM: Training Multi-Billion Parameter ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Megatron-LM (8.3B)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>Megatron-LM (8.3B)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>T5-3B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Text autocompletion</td>\n",
       "      <td>Colin Raffel, Noam Shazeer, Adam Roberts, Kath...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1910.10683</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>Exploring the Limits of Transfer Learning with...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T5-3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T5-3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>T5-11B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Text autocompletion</td>\n",
       "      <td>Colin Raffel, Noam Shazeer, Adam Roberts, Kath...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1910.10683</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>Exploring the Limits of Transfer Learning with...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T5-11B</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.3707</td>\n",
       "      <td>T5-11B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>AlphaStar</td>\n",
       "      <td>Games</td>\n",
       "      <td>StarCraft</td>\n",
       "      <td>Oriol Vinyals,Igor Babuschkin,Wojciech M. Czar...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.deepmind.com/blog/alphastar-grandm...</td>\n",
       "      <td>2681.0</td>\n",
       "      <td>Grandmaster level in StarCraft II using multi-...</td>\n",
       "      <td>...</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaStar</td>\n",
       "      <td>384.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlphaStar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>OpenAI Five</td>\n",
       "      <td>Games</td>\n",
       "      <td>Dota 2</td>\n",
       "      <td>Christopher Berner, Greg Brockman, Brooke Chan...</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>\"On April 13th, 2019, OpenAI Five became the f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1912.06680</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>Dota 2 with Large Scale Deep Reinforcement Lea...</td>\n",
       "      <td>...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI Five</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI Five</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>OpenAI Five Rerun</td>\n",
       "      <td>Games</td>\n",
       "      <td>Dota 2</td>\n",
       "      <td>Christopher Berner, Greg Brockman, Brooke Chan...</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>\"On April 13th, 2019, OpenAI Five became the f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cdn.openai.com/dota-2.pdf</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>Dota 2 with Large Scale Deep Reinforcement Lea...</td>\n",
       "      <td>...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI Five Rerun</td>\n",
       "      <td>512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI Five Rerun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Meena</td>\n",
       "      <td>Language</td>\n",
       "      <td>Text autocompletion</td>\n",
       "      <td>Dongling Xiao, Han Zhang, Yukun Li, Yu Sun, Ha...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"We also propose a human evaluation metric cal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2001.09977</td>\n",
       "      <td>747.0</td>\n",
       "      <td>Towards a Human-like Open-Domain Chatbot</td>\n",
       "      <td>...</td>\n",
       "      <td>Google Brain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meena</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.3439</td>\n",
       "      <td>Meena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Turing-NLG</td>\n",
       "      <td>Language</td>\n",
       "      <td>Text autocompletion</td>\n",
       "      <td>Corby Rosset</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>from paper: \"Turing Natural Language Generatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.microsoft.com/en-us/research/blog/...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Turing-NLG: A 17-billion-parameter language mo...</td>\n",
       "      <td>...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turing-NLG</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turing-NLG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>GPT-3 175B (davinci)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Text autocompletion</td>\n",
       "      <td>Tom B. Brown, Benjamin Mann, Nick Ryder, Melan...</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>API accessible</td>\n",
       "      <td>https://arxiv.org/abs/2005.14165</td>\n",
       "      <td>18144.0</td>\n",
       "      <td>Language models are Few-Shot Learners</td>\n",
       "      <td>...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPT-3 175B (davinci)</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>GPT-3 175B (davinci)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>GShard (dense)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Translation</td>\n",
       "      <td>Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu,...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"such a giant model can efficiently be trained...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2006.16668</td>\n",
       "      <td>523.0</td>\n",
       "      <td>GShard: Scaling Giant Models with Conditional ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GShard (dense)</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GShard (dense)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>ALIGN</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Z...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"The aligned visual and language representatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2102.05918</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>Scaling up visual and vision-language represen...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALIGN</td>\n",
       "      <td>512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALIGN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Megatron-Turing NLG 530B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Shaden Smith, Mostofa Patwary, Brandon Norick,...</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>The 105-layer, transformer-based MT-NLG improv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2201.11990</td>\n",
       "      <td>460.0</td>\n",
       "      <td>Using DeepSpeed and Megatron to Train Megatron...</td>\n",
       "      <td>...</td>\n",
       "      <td>Microsoft, NVIDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Megatron-Turing NLG 530B</td>\n",
       "      <td>4480.0</td>\n",
       "      <td>0.3020</td>\n",
       "      <td>Megatron-Turing NLG 530B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Yuan 1.0</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Shaohua Wu, Xudong Zhao, Tong Yu, Rongguo Zhan...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"The zero-shot average scores of both LM and P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2110.04725</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Yuan 1.0: Large-Scale Pre-trained Language Mod...</td>\n",
       "      <td>...</td>\n",
       "      <td>Inspur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yuan 1.0</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>Yuan 1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Gopher (280B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Jack W. Rae, Sebastian Borgeaud, Trevor Cai, K...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"These models are evaluated on 152 diverse tas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2112.11446</td>\n",
       "      <td>736.0</td>\n",
       "      <td>Scaling Language Models: Methods, Analysis &amp; I...</td>\n",
       "      <td>...</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gopher (280B)</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>Gopher (280B)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>GLaM</td>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nan Du, Yanping Huang, Andrew M. Dai, Simon To...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"As shown in Table 5, GLaM (64B/64E) is better...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2112.06905</td>\n",
       "      <td>314.0</td>\n",
       "      <td>GLaM: Efficient Scaling of Language Models wit...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GLaM</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GLaM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>LaMDA</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Romal Thoppilan, Daniel De Freitas, Jamie Hall...</td>\n",
       "      <td>Historical significance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2201.08239</td>\n",
       "      <td>891.0</td>\n",
       "      <td>LaMDA: Language Models for Dialog Applications</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LaMDA</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>LaMDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Chinchilla</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Jordan Hoffmann, Sebastian Borgeaud, Arthur Me...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>Proposes new scaling law, with good empirical ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2203.15556</td>\n",
       "      <td>793.0</td>\n",
       "      <td>Training Compute-Optimal Large Language Models</td>\n",
       "      <td>...</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinchilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinchilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>PaLM (540B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Aakanksha Chowdhery, Sharan Narang, Jacob Devl...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>Demonstrates continued benefits of scaling, as...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2204.02311</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>PaLM: Scaling Language Modeling with Pathways</td>\n",
       "      <td>...</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaLM (540B)</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>PaLM (540B)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>OPT-175B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Susan Zhang, Stephen Roller, Naman Goyal, Mike...</td>\n",
       "      <td>Significant use</td>\n",
       "      <td>https://ai.meta.com/blog/opt-175b-large-langua...</td>\n",
       "      <td>Fully open-source</td>\n",
       "      <td>https://ai.facebook.com/blog/democratizing-acc...</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>OPT: Open Pre-trained Transformer Language Models</td>\n",
       "      <td>...</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OPT-175B</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>OPT-175B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>Minerva (540B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Quantitative Reasoning Problems</td>\n",
       "      <td>Aitor Lewkowycz, Anders Andreassen, David Doha...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2206.14858</td>\n",
       "      <td>307.0</td>\n",
       "      <td>Solving Quantitative Reasoning Problems with L...</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>PaLM (540B)</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minerva (540B)</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minerva (540B)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>GPT-3.5 (text-davinci-003)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTA Improvement,Historical significance,Signi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>API accessible</td>\n",
       "      <td>https://platform.openai.com/docs/models/gpt-3-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPT-3.5 (text-davinci-003)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPT-3.5 (text-davinci-003)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>LLaMA-65B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Hugo Touvron, Thibaut Lavril, Gautier Izacard,...</td>\n",
       "      <td>Historical significance</td>\n",
       "      <td>Widely-used foundation model that has been ada...</td>\n",
       "      <td>Fully open-source</td>\n",
       "      <td>https://arxiv.org/abs/2302.13971</td>\n",
       "      <td>2695.0</td>\n",
       "      <td>LLaMA: Open and Efficient Foundation Language ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LLaMA-65B</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>LLaMA-65B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>See the paper, p.1: \"On a suite of traditional...</td>\n",
       "      <td>API accessible</td>\n",
       "      <td>https://arxiv.org/abs/2303.08774</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Andrew M. Dai, David R. So, Dmitry Lepikhin, J...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>https://ai.google/static/documents/palm2techre...</td>\n",
       "      <td>367.0</td>\n",
       "      <td>PaLM 2 Technical Report</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Claude 2</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historical significance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>API accessible</td>\n",
       "      <td>https://www.anthropic.com/index/claude-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Claude 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Claude 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Llama 2-70B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Hugo Touvron, Louis Martin, Kevin Stone, Peter...</td>\n",
       "      <td>Historical significance,Significant use</td>\n",
       "      <td>Model has been open-sourced and frequently dow...</td>\n",
       "      <td>Fully open-source</td>\n",
       "      <td>https://ai.meta.com/research/publications/llam...</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>Llama 2: Open Foundation and Fine-Tuned Chat M...</td>\n",
       "      <td>...</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Llama 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metaâ€™s Research Super Cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Falcon 180B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"It's currently at the top of the Hugging Face...</td>\n",
       "      <td>Permissive license</td>\n",
       "      <td>https://falconllm.tii.ae/falcon-180b.html</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Falcon LLM - Falcon 180B</td>\n",
       "      <td>...</td>\n",
       "      <td>Technology Innovation Institute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Falcon 180B</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>Falcon 180B</td>\n",
       "      <td>Amazon Web Services</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          System      Domain                             Task  \\\n",
       "265                  AlphaGo Fan       Games                               Go   \n",
       "275                  AlphaGo Lee       Games                               Go   \n",
       "306                         GNMT    Language                      Translation   \n",
       "317             NASv3 (CIFAR-10)      Vision                              NaN   \n",
       "337               AlphaGo Master       Games                               Go   \n",
       "359                          JFT      Vision                              NaN   \n",
       "369          OpenAI TI7 DOTA 1v1       Games                             DOTA   \n",
       "391                 AlphaGo Zero       Games                               Go   \n",
       "403                    AlphaZero       Games                              NaN   \n",
       "411          AmoebaNet-A (F=448)      Vision             Image classification   \n",
       "413                       IMPALA       Games                            Atari   \n",
       "431           ResNeXt-101 32x48d      Vision             Image classification   \n",
       "450                          FTW       Games                 Capture the flag   \n",
       "467          BigGAN-deep 512x512     Drawing                 Image generation   \n",
       "543                RoBERTa Large    Language                              NaN   \n",
       "563                Megatron-BERT    Language                              NaN   \n",
       "564           Megatron-LM (8.3B)    Language                              NaN   \n",
       "580                        T5-3B    Language              Text autocompletion   \n",
       "581                       T5-11B    Language              Text autocompletion   \n",
       "584                    AlphaStar       Games                        StarCraft   \n",
       "600                  OpenAI Five       Games                           Dota 2   \n",
       "601            OpenAI Five Rerun       Games                           Dota 2   \n",
       "607                        Meena    Language              Text autocompletion   \n",
       "613                   Turing-NLG    Language              Text autocompletion   \n",
       "642         GPT-3 175B (davinci)    Language              Text autocompletion   \n",
       "651               GShard (dense)    Language                      Translation   \n",
       "766                        ALIGN  Multimodal          Representation Learning   \n",
       "799     Megatron-Turing NLG 530B    Language               Language modelling   \n",
       "800                     Yuan 1.0    Language               Language modelling   \n",
       "829                Gopher (280B)    Language               Language modelling   \n",
       "834                         GLaM    Language                              NaN   \n",
       "853                        LaMDA    Language               Language modelling   \n",
       "869                   Chinchilla    Language               Language modelling   \n",
       "873                  PaLM (540B)    Language               Language modelling   \n",
       "879                     OPT-175B    Language               Language modelling   \n",
       "918               Minerva (540B)    Language  Quantitative Reasoning Problems   \n",
       "963   GPT-3.5 (text-davinci-003)    Language               Language modelling   \n",
       "992                    LLaMA-65B    Language               Language modelling   \n",
       "1004                       GPT-4  Multimodal               Language modelling   \n",
       "1032                      PaLM 2    Language               Language modelling   \n",
       "1056                    Claude 2    Language               Language modelling   \n",
       "1059                 Llama 2-70B    Language               Language modelling   \n",
       "1083                 Falcon 180B    Language               Language modelling   \n",
       "\n",
       "                                                Authors  \\\n",
       "265   David Silver, Aja Huang, Chris J. Maddison, Ar...   \n",
       "275   David Silver, Aja Huang, Chris J. Maddison, Ar...   \n",
       "306   Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...   \n",
       "317                             Barret Zoph, Quoc V. Le   \n",
       "337   D Silver, J Schrittwieser, K Simonyan, I Anton...   \n",
       "359   Chen Sun, Abhinav Shrivastava, Saurabh Singh, ...   \n",
       "369                                                 NaN   \n",
       "391   D Silver, J Schrittwieser, K Simonyan, I Anton...   \n",
       "403   D Silver, T Hubert, J Schrittwieser, I Antonoglou   \n",
       "411   Esteban Real, Alok Aggarwal, Yanping Huang, Qu...   \n",
       "413   Lasse Espeholt, Hubert Soyer, Remi Munos, Kare...   \n",
       "431   Dhruv Mahajan, Ross Girshick, Vignesh Ramanath...   \n",
       "450   Max Jaderberg, Wojciech M. Czarnecki, Iain Dun...   \n",
       "467                      A Brock, J Donahue, K Simonyan   \n",
       "543   Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du,...   \n",
       "563   Mohammad Shoeybi, Mostofa Patwary, Raul Puri, ...   \n",
       "564   Mohammad Shoeybi, Mostofa Patwary, Raul Puri, ...   \n",
       "580   Colin Raffel, Noam Shazeer, Adam Roberts, Kath...   \n",
       "581   Colin Raffel, Noam Shazeer, Adam Roberts, Kath...   \n",
       "584   Oriol Vinyals,Igor Babuschkin,Wojciech M. Czar...   \n",
       "600   Christopher Berner, Greg Brockman, Brooke Chan...   \n",
       "601   Christopher Berner, Greg Brockman, Brooke Chan...   \n",
       "607   Dongling Xiao, Han Zhang, Yukun Li, Yu Sun, Ha...   \n",
       "613                                        Corby Rosset   \n",
       "642   Tom B. Brown, Benjamin Mann, Nick Ryder, Melan...   \n",
       "651   Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu,...   \n",
       "766   Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Z...   \n",
       "799   Shaden Smith, Mostofa Patwary, Brandon Norick,...   \n",
       "800   Shaohua Wu, Xudong Zhao, Tong Yu, Rongguo Zhan...   \n",
       "829   Jack W. Rae, Sebastian Borgeaud, Trevor Cai, K...   \n",
       "834   Nan Du, Yanping Huang, Andrew M. Dai, Simon To...   \n",
       "853   Romal Thoppilan, Daniel De Freitas, Jamie Hall...   \n",
       "869   Jordan Hoffmann, Sebastian Borgeaud, Arthur Me...   \n",
       "873   Aakanksha Chowdhery, Sharan Narang, Jacob Devl...   \n",
       "879   Susan Zhang, Stephen Roller, Naman Goyal, Mike...   \n",
       "918   Aitor Lewkowycz, Anders Andreassen, David Doha...   \n",
       "963                                                 NaN   \n",
       "992   Hugo Touvron, Thibaut Lavril, Gautier Izacard,...   \n",
       "1004                                             OpenAI   \n",
       "1032  Andrew M. Dai, David R. So, Dmitry Lepikhin, J...   \n",
       "1056                                                NaN   \n",
       "1059  Hugo Touvron, Louis Martin, Kevin Stone, Peter...   \n",
       "1083                                                NaN   \n",
       "\n",
       "                                    Notability criteria  \\\n",
       "265                                    SOTA improvement   \n",
       "275                                        Highly cited   \n",
       "306                                        Highly cited   \n",
       "317                                        Highly cited   \n",
       "337                                        Highly cited   \n",
       "359                                        Highly cited   \n",
       "369            SOTA Improvement,Historical significance   \n",
       "391                                        Highly cited   \n",
       "403                                        Highly cited   \n",
       "411                                        Highly cited   \n",
       "413                                    SOTA Improvement   \n",
       "431                                    SOTA Improvement   \n",
       "450                                    SOTA Improvement   \n",
       "467                                        Highly cited   \n",
       "543                                        Highly cited   \n",
       "563                                    SOTA Improvement   \n",
       "564                                    SOTA Improvement   \n",
       "580                                        Highly cited   \n",
       "581                                        Highly cited   \n",
       "584                                        Highly cited   \n",
       "600                                    SOTA improvement   \n",
       "601                                    SOTA improvement   \n",
       "607                                    SOTA Improvement   \n",
       "613                                    SOTA Improvement   \n",
       "642                                        Highly cited   \n",
       "651                                    SOTA Improvement   \n",
       "766                                    SOTA Improvement   \n",
       "799                                    SOTA improvement   \n",
       "800                                    SOTA Improvement   \n",
       "829                                    SOTA Improvement   \n",
       "834                                    SOTA Improvement   \n",
       "853                             Historical significance   \n",
       "869                                    SOTA Improvement   \n",
       "873                                    SOTA Improvement   \n",
       "879                                     Significant use   \n",
       "918                                    SOTA Improvement   \n",
       "963   SOTA Improvement,Historical significance,Signi...   \n",
       "992                             Historical significance   \n",
       "1004                                   SOTA Improvement   \n",
       "1032                                   SOTA Improvement   \n",
       "1056                            Historical significance   \n",
       "1059            Historical significance,Significant use   \n",
       "1083                                   SOTA Improvement   \n",
       "\n",
       "                              Notability criteria notes         Open-source  \\\n",
       "265                                                 NaN                 NaN   \n",
       "275                                                 NaN                 NaN   \n",
       "306                                                 NaN                 NaN   \n",
       "317                                                 NaN                 NaN   \n",
       "337                                                 NaN                 NaN   \n",
       "359                                                 NaN                 NaN   \n",
       "369                                                 NaN                 NaN   \n",
       "391                                                 NaN                 NaN   \n",
       "403                                                 NaN                 NaN   \n",
       "411                                                 NaN                 NaN   \n",
       "413   \"IMPALA is able to achieve better performance ...                 NaN   \n",
       "431   \"We show improvements on several image classif...                 NaN   \n",
       "450   \"In this work, we demonstrate for the first ti...                 NaN   \n",
       "467                                                 NaN  Permissive license   \n",
       "543                                                 NaN                 NaN   \n",
       "563   \"Our BERT model achieves SOTA results on the R...                 NaN   \n",
       "564   \"Using the GPT-2 model we achieve SOTA results...                 NaN   \n",
       "580                                                 NaN                 NaN   \n",
       "581                                                 NaN                 NaN   \n",
       "584                                                 NaN                 NaN   \n",
       "600   \"On April 13th, 2019, OpenAI Five became the f...                 NaN   \n",
       "601   \"On April 13th, 2019, OpenAI Five became the f...                 NaN   \n",
       "607   \"We also propose a human evaluation metric cal...                 NaN   \n",
       "613   from paper: \"Turing Natural Language Generatio...                 NaN   \n",
       "642                                                 NaN      API accessible   \n",
       "651   \"such a giant model can efficiently be trained...                 NaN   \n",
       "766   \"The aligned visual and language representatio...                 NaN   \n",
       "799   The 105-layer, transformer-based MT-NLG improv...                 NaN   \n",
       "800   \"The zero-shot average scores of both LM and P...                 NaN   \n",
       "829   \"These models are evaluated on 152 diverse tas...                 NaN   \n",
       "834   \"As shown in Table 5, GLaM (64B/64E) is better...                 NaN   \n",
       "853                                                 NaN                 NaN   \n",
       "869   Proposes new scaling law, with good empirical ...                 NaN   \n",
       "873   Demonstrates continued benefits of scaling, as...                 NaN   \n",
       "879   https://ai.meta.com/blog/opt-175b-large-langua...   Fully open-source   \n",
       "918                                                 NaN                 NaN   \n",
       "963                                                 NaN      API accessible   \n",
       "992   Widely-used foundation model that has been ada...   Fully open-source   \n",
       "1004  See the paper, p.1: \"On a suite of traditional...      API accessible   \n",
       "1032                                                NaN          Unreleased   \n",
       "1056                                                NaN      API accessible   \n",
       "1059  Model has been open-sourced and frequently dow...   Fully open-source   \n",
       "1083  \"It's currently at the top of the Hugging Face...  Permissive license   \n",
       "\n",
       "                                                   Link  Citations  \\\n",
       "265   https://www.nature.com/articles/nature24270.ep...    14389.0   \n",
       "275         https://www.nature.com/articles/nature16961    14389.0   \n",
       "306                    https://arxiv.org/abs/1609.08144     5948.0   \n",
       "317                    https://arxiv.org/abs/1611.01578     4569.0   \n",
       "337   https://www.researchgate.net/publication/32047...     7831.0   \n",
       "359                    https://arxiv.org/abs/1707.02968     1923.0   \n",
       "369                  https://openai.com/research/dota-2        0.0   \n",
       "391   https://www.researchgate.net/publication/32047...     7831.0   \n",
       "403                    https://arxiv.org/abs/1712.01815     1343.0   \n",
       "411                    https://arxiv.org/abs/1802.01548     2505.0   \n",
       "413                    https://arxiv.org/abs/1802.01561     1288.0   \n",
       "431                    https://arxiv.org/abs/1805.00932     1176.0   \n",
       "450                    https://arxiv.org/abs/1807.01281      571.0   \n",
       "467                    https://arxiv.org/abs/1809.11096     4163.0   \n",
       "543                    https://arxiv.org/abs/1907.11692    15901.0   \n",
       "563                    https://arxiv.org/abs/1909.08053     1003.0   \n",
       "564                    https://arxiv.org/abs/1909.08053     1003.0   \n",
       "580                    https://arxiv.org/abs/1910.10683    10800.0   \n",
       "581                    https://arxiv.org/abs/1910.10683    10800.0   \n",
       "584   https://www.deepmind.com/blog/alphastar-grandm...     2681.0   \n",
       "600                    https://arxiv.org/abs/1912.06680     1303.0   \n",
       "601                   https://cdn.openai.com/dota-2.pdf     1303.0   \n",
       "607                    https://arxiv.org/abs/2001.09977      747.0   \n",
       "613   https://www.microsoft.com/en-us/research/blog/...      114.0   \n",
       "642                    https://arxiv.org/abs/2005.14165    18144.0   \n",
       "651                    https://arxiv.org/abs/2006.16668      523.0   \n",
       "766                    https://arxiv.org/abs/2102.05918     1766.0   \n",
       "799                    https://arxiv.org/abs/2201.11990      460.0   \n",
       "800                    https://arxiv.org/abs/2110.04725       34.0   \n",
       "829                    https://arxiv.org/abs/2112.11446      736.0   \n",
       "834                    https://arxiv.org/abs/2112.06905      314.0   \n",
       "853                    https://arxiv.org/abs/2201.08239      891.0   \n",
       "869                    https://arxiv.org/abs/2203.15556      793.0   \n",
       "873                    https://arxiv.org/abs/2204.02311     2612.0   \n",
       "879   https://ai.facebook.com/blog/democratizing-acc...     1443.0   \n",
       "918                    https://arxiv.org/abs/2206.14858      307.0   \n",
       "963     https://platform.openai.com/docs/models/gpt-3-5        NaN   \n",
       "992                    https://arxiv.org/abs/2302.13971     2695.0   \n",
       "1004                   https://arxiv.org/abs/2303.08774     1871.0   \n",
       "1032  https://ai.google/static/documents/palm2techre...      367.0   \n",
       "1056           https://www.anthropic.com/index/claude-2        0.0   \n",
       "1059  https://ai.meta.com/research/publications/llam...     1122.0   \n",
       "1083          https://falconllm.tii.ae/falcon-180b.html        0.0   \n",
       "\n",
       "                                              Reference  ...  \\\n",
       "265   Mastering the game of Go with deep neural netw...  ...   \n",
       "275   Mastering the game of Go with deep neural netw...  ...   \n",
       "306   Google's Neural Machine Translation System: Br...  ...   \n",
       "317   Neural Architecture Search with Reinforcement ...  ...   \n",
       "337    Mastering the game of Go without human knowledge  ...   \n",
       "359   Revisiting Unreasonable Effectiveness of Data ...  ...   \n",
       "369                                              Dota 2  ...   \n",
       "391    Mastering the game of Go without human knowledge  ...   \n",
       "403   Mastering Chess and Shogi by Self-Play with a ...  ...   \n",
       "411   Regularized Evolution for Image Classifier Arc...  ...   \n",
       "413   IMPALA: Scalable Distributed Deep-RL with Impo...  ...   \n",
       "431   Exploring the Limits of Weakly Supervised Pret...  ...   \n",
       "450   Human-level performance in first-person multip...  ...   \n",
       "467   Large Scale GAN Training for High Fidelity Nat...  ...   \n",
       "543   RoBERTa: A Robustly Optimized BERT Pretraining...  ...   \n",
       "563   Megatron-LM: Training Multi-Billion Parameter ...  ...   \n",
       "564   Megatron-LM: Training Multi-Billion Parameter ...  ...   \n",
       "580   Exploring the Limits of Transfer Learning with...  ...   \n",
       "581   Exploring the Limits of Transfer Learning with...  ...   \n",
       "584   Grandmaster level in StarCraft II using multi-...  ...   \n",
       "600   Dota 2 with Large Scale Deep Reinforcement Lea...  ...   \n",
       "601   Dota 2 with Large Scale Deep Reinforcement Lea...  ...   \n",
       "607            Towards a Human-like Open-Domain Chatbot  ...   \n",
       "613   Turing-NLG: A 17-billion-parameter language mo...  ...   \n",
       "642               Language models are Few-Shot Learners  ...   \n",
       "651   GShard: Scaling Giant Models with Conditional ...  ...   \n",
       "766   Scaling up visual and vision-language represen...  ...   \n",
       "799   Using DeepSpeed and Megatron to Train Megatron...  ...   \n",
       "800   Yuan 1.0: Large-Scale Pre-trained Language Mod...  ...   \n",
       "829   Scaling Language Models: Methods, Analysis & I...  ...   \n",
       "834   GLaM: Efficient Scaling of Language Models wit...  ...   \n",
       "853      LaMDA: Language Models for Dialog Applications  ...   \n",
       "869      Training Compute-Optimal Large Language Models  ...   \n",
       "873       PaLM: Scaling Language Modeling with Pathways  ...   \n",
       "879   OPT: Open Pre-trained Transformer Language Models  ...   \n",
       "918   Solving Quantitative Reasoning Problems with L...  ...   \n",
       "963                                                 NaN  ...   \n",
       "992   LLaMA: Open and Efficient Foundation Language ...  ...   \n",
       "1004                             GPT-4 Technical Report  ...   \n",
       "1032                            PaLM 2 Technical Report  ...   \n",
       "1056                                                NaN  ...   \n",
       "1059  Llama 2: Open Foundation and Fine-Tuned Chat M...  ...   \n",
       "1083                           Falcon LLM - Falcon 180B  ...   \n",
       "\n",
       "                       Organization (from Organization)   Base model  \\\n",
       "265                                     Google DeepMind          NaN   \n",
       "275                                            DeepMind          NaN   \n",
       "306                                              Google          NaN   \n",
       "317                                        Google Brain          NaN   \n",
       "337                                            DeepMind          NaN   \n",
       "359   Google Research, Carnegie Mellon University (CMU)          NaN   \n",
       "369                                              OpenAI          NaN   \n",
       "391                                            DeepMind          NaN   \n",
       "403                                            DeepMind          NaN   \n",
       "411                                        Google Brain          NaN   \n",
       "413                                            DeepMind          NaN   \n",
       "431                                            Facebook          NaN   \n",
       "450                                            DeepMind          NaN   \n",
       "467                    Heriot-Watt University, DeepMind          NaN   \n",
       "543                  Facebook, University of Washington          NaN   \n",
       "563                                              NVIDIA          NaN   \n",
       "564                                              NVIDIA          NaN   \n",
       "580                                              Google          NaN   \n",
       "581                                              Google          NaN   \n",
       "584                                            DeepMind          NaN   \n",
       "600                                              OpenAI          NaN   \n",
       "601                                              OpenAI          NaN   \n",
       "607                                        Google Brain          NaN   \n",
       "613                                           Microsoft          NaN   \n",
       "642                                              OpenAI          NaN   \n",
       "651                                              Google          NaN   \n",
       "766                                     Google Research          NaN   \n",
       "799                                   Microsoft, NVIDIA          NaN   \n",
       "800                                              Inspur          NaN   \n",
       "829                                            DeepMind          NaN   \n",
       "834                                              Google          NaN   \n",
       "853                                              Google          NaN   \n",
       "869                                            DeepMind          NaN   \n",
       "873                                     Google Research          NaN   \n",
       "879                                             Meta AI          NaN   \n",
       "918                                              Google  PaLM (540B)   \n",
       "963                                              OpenAI          NaN   \n",
       "992                                             Meta AI          NaN   \n",
       "1004                                             OpenAI          NaN   \n",
       "1032                                             Google          NaN   \n",
       "1056                                          Anthropic          NaN   \n",
       "1059                                            Meta AI          NaN   \n",
       "1083                    Technology Innovation Institute          NaN   \n",
       "\n",
       "     Finetune compute (FLOP)  Finetune compute notes  \\\n",
       "265                      NaN                     NaN   \n",
       "275                      NaN                     NaN   \n",
       "306                      NaN                     NaN   \n",
       "317                      NaN                     NaN   \n",
       "337                      NaN                     NaN   \n",
       "359                      NaN                     NaN   \n",
       "369                      NaN                     NaN   \n",
       "391                      NaN                     NaN   \n",
       "403                      NaN                     NaN   \n",
       "411                      NaN                     NaN   \n",
       "413                      NaN                     NaN   \n",
       "431                      NaN                     NaN   \n",
       "450                      NaN                     NaN   \n",
       "467                      NaN                     NaN   \n",
       "543                      NaN                     NaN   \n",
       "563                      NaN                     NaN   \n",
       "564                      NaN                     NaN   \n",
       "580                      NaN                     NaN   \n",
       "581                      NaN                     NaN   \n",
       "584                      NaN                     NaN   \n",
       "600                      NaN                     NaN   \n",
       "601                      NaN                     NaN   \n",
       "607                      NaN                     NaN   \n",
       "613                      NaN                     NaN   \n",
       "642                      NaN                     NaN   \n",
       "651                      NaN                     NaN   \n",
       "766                      NaN                     NaN   \n",
       "799                      NaN                     NaN   \n",
       "800                      NaN                     NaN   \n",
       "829                      NaN                     NaN   \n",
       "834                      NaN                     NaN   \n",
       "853                      NaN                     NaN   \n",
       "869                      NaN                     NaN   \n",
       "873                      NaN                     NaN   \n",
       "879                      NaN                     NaN   \n",
       "918                        2                     NaN   \n",
       "963                      NaN                     NaN   \n",
       "992                      NaN                     NaN   \n",
       "1004                     NaN                     NaN   \n",
       "1032                     NaN                     NaN   \n",
       "1056                     NaN                     NaN   \n",
       "1059                     NaN                     NaN   \n",
       "1083                     NaN                     NaN   \n",
       "\n",
       "              Authors by country  Hardware quantity Hardware utilization  \\\n",
       "265                  AlphaGo Fan                NaN                  NaN   \n",
       "275                  AlphaGo Lee                NaN                  NaN   \n",
       "306                         GNMT               96.0                  NaN   \n",
       "317             NASv3 (CIFAR-10)              800.0                  NaN   \n",
       "337               AlphaGo Master                NaN                  NaN   \n",
       "359                          JFT               50.0                  NaN   \n",
       "369          OpenAI TI7 DOTA 1v1                NaN                  NaN   \n",
       "391                 AlphaGo Zero                NaN                  NaN   \n",
       "403                    AlphaZero               64.0                  NaN   \n",
       "411          AmoebaNet-A (F=448)              450.0                  NaN   \n",
       "413                       IMPALA                1.0                  NaN   \n",
       "431           ResNeXt-101 32x48d              336.0                  NaN   \n",
       "450                          FTW                NaN                  NaN   \n",
       "467          BigGAN-deep 512x512              256.0                  NaN   \n",
       "543                RoBERTa Large             1024.0                  NaN   \n",
       "563                Megatron-BERT              512.0               0.2269   \n",
       "564           Megatron-LM (8.3B)              512.0               0.1162   \n",
       "580                        T5-3B                NaN                  NaN   \n",
       "581                       T5-11B              512.0               0.3707   \n",
       "584                    AlphaStar              384.0                  NaN   \n",
       "600                  OpenAI Five             1536.0                  NaN   \n",
       "601            OpenAI Five Rerun              512.0                  NaN   \n",
       "607                        Meena             1024.0               0.3439   \n",
       "613                   Turing-NLG              256.0                  NaN   \n",
       "642         GPT-3 175B (davinci)            10000.0               0.2196   \n",
       "651               GShard (dense)             1024.0                  NaN   \n",
       "766                        ALIGN              512.0                  NaN   \n",
       "799     Megatron-Turing NLG 530B             4480.0               0.3020   \n",
       "800                     Yuan 1.0             2128.0               0.4500   \n",
       "829                Gopher (280B)             4096.0               0.3780   \n",
       "834                         GLaM             1024.0                  NaN   \n",
       "853                        LaMDA             1024.0               0.5650   \n",
       "869                   Chinchilla                NaN                  NaN   \n",
       "873                  PaLM (540B)             6144.0               0.4620   \n",
       "879                     OPT-175B             1024.0               0.4712   \n",
       "918               Minerva (540B)             1024.0                  NaN   \n",
       "963   GPT-3.5 (text-davinci-003)                NaN                  NaN   \n",
       "992                    LLaMA-65B             2048.0               0.4746   \n",
       "1004                       GPT-4            25000.0               0.3400   \n",
       "1032                      PaLM 2                NaN                  NaN   \n",
       "1056                    Claude 2                NaN                  NaN   \n",
       "1059                     Llama 2                NaN                  NaN   \n",
       "1083                 Falcon 180B             4096.0               0.1876   \n",
       "\n",
       "            Training cost trends Training cloud compute vendor  \\\n",
       "265                  AlphaGo Fan                           NaN   \n",
       "275                  AlphaGo Lee                           NaN   \n",
       "306                         GNMT                           NaN   \n",
       "317             NASv3 (CIFAR-10)                           NaN   \n",
       "337               AlphaGo Master                           NaN   \n",
       "359                          JFT                           NaN   \n",
       "369          OpenAI TI7 DOTA 1v1                           NaN   \n",
       "391                 AlphaGo Zero                           NaN   \n",
       "403                    AlphaZero                           NaN   \n",
       "411          AmoebaNet-A (F=448)                           NaN   \n",
       "413                       IMPALA                           NaN   \n",
       "431           ResNeXt-101 32x48d                           NaN   \n",
       "450                          FTW                           NaN   \n",
       "467          BigGAN-deep 512x512                           NaN   \n",
       "543                RoBERTa Large                           NaN   \n",
       "563                Megatron-BERT                           NaN   \n",
       "564           Megatron-LM (8.3B)                           NaN   \n",
       "580                        T5-3B                           NaN   \n",
       "581                       T5-11B                           NaN   \n",
       "584                    AlphaStar                           NaN   \n",
       "600                  OpenAI Five                           NaN   \n",
       "601            OpenAI Five Rerun                           NaN   \n",
       "607                        Meena                           NaN   \n",
       "613                   Turing-NLG                           NaN   \n",
       "642         GPT-3 175B (davinci)                           NaN   \n",
       "651               GShard (dense)                           NaN   \n",
       "766                        ALIGN                           NaN   \n",
       "799     Megatron-Turing NLG 530B                           NaN   \n",
       "800                     Yuan 1.0                           NaN   \n",
       "829                Gopher (280B)                           NaN   \n",
       "834                         GLaM                           NaN   \n",
       "853                        LaMDA                           NaN   \n",
       "869                   Chinchilla                           NaN   \n",
       "873                  PaLM (540B)                           NaN   \n",
       "879                     OPT-175B                           NaN   \n",
       "918               Minerva (540B)                           NaN   \n",
       "963   GPT-3.5 (text-davinci-003)                           NaN   \n",
       "992                    LLaMA-65B                           NaN   \n",
       "1004                       GPT-4                           NaN   \n",
       "1032                      PaLM 2                           NaN   \n",
       "1056                    Claude 2                           NaN   \n",
       "1059                     Llama 2                           NaN   \n",
       "1083                 Falcon 180B           Amazon Web Services   \n",
       "\n",
       "               Training data center  \n",
       "265                             NaN  \n",
       "275                             NaN  \n",
       "306                             NaN  \n",
       "317                             NaN  \n",
       "337                             NaN  \n",
       "359                             NaN  \n",
       "369                             NaN  \n",
       "391                             NaN  \n",
       "403                             NaN  \n",
       "411                             NaN  \n",
       "413                             NaN  \n",
       "431                             NaN  \n",
       "450                             NaN  \n",
       "467                             NaN  \n",
       "543                             NaN  \n",
       "563                             NaN  \n",
       "564                             NaN  \n",
       "580                             NaN  \n",
       "581                             NaN  \n",
       "584                             NaN  \n",
       "600                             NaN  \n",
       "601                             NaN  \n",
       "607                             NaN  \n",
       "613                             NaN  \n",
       "642                             NaN  \n",
       "651                             NaN  \n",
       "766                             NaN  \n",
       "799                             NaN  \n",
       "800                             NaN  \n",
       "829                             NaN  \n",
       "834                             NaN  \n",
       "853                             NaN  \n",
       "869                             NaN  \n",
       "873                             NaN  \n",
       "879                             NaN  \n",
       "918                             NaN  \n",
       "963                             NaN  \n",
       "992                             NaN  \n",
       "1004                            NaN  \n",
       "1032                            NaN  \n",
       "1056                            NaN  \n",
       "1059  Metaâ€™s Research Super Cluster  \n",
       "1083                            NaN  \n",
       "\n",
       "[43 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_pcd_df = pcd_df[pcd_df['System'].isin(frontier_systems)]\n",
    "frontier_pcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:30.873449800Z",
     "start_time": "2024-02-07T16:04:30.715236200Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(frontier_pcd_df) == len(frontier_systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:31.015263500Z",
     "start_time": "2024-02-07T16:04:30.825450800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price source</th>\n",
       "      <th>Price date</th>\n",
       "      <th>Hardware model</th>\n",
       "      <th>Manufacturer (from Hardware model)</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Location</th>\n",
       "      <th>Price per chip-hour (on-demand)</th>\n",
       "      <th>Price per chip-hour (1-year CUD)</th>\n",
       "      <th>Price per chip-hour (3-year CUD)</th>\n",
       "      <th>Price (hardware purchase)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://web.archive.org/web/20181009102635/htt...</td>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>Google TPU v2</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google Cloud</td>\n",
       "      <td>US</td>\n",
       "      <td>$1.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://web.archive.org/web/20181011013513/htt...</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google Cloud</td>\n",
       "      <td>US</td>\n",
       "      <td>$2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://web.archive.org/web/20181011013513/htt...</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google Cloud</td>\n",
       "      <td>Europe</td>\n",
       "      <td>$2.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://web.archive.org/web/20190701021000/htt...</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google Cloud</td>\n",
       "      <td>Iowa (us-central1)</td>\n",
       "      <td>$2.00</td>\n",
       "      <td>$1.26</td>\n",
       "      <td>$0.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://web.archive.org/web/20190728061708/htt...</td>\n",
       "      <td>2019-07-28</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google Cloud</td>\n",
       "      <td>Netherlands (europe-west4)</td>\n",
       "      <td>$2.00</td>\n",
       "      <td>$1.26</td>\n",
       "      <td>$0.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Price source  Price date  \\\n",
       "0  https://web.archive.org/web/20181009102635/htt...  2018-10-09   \n",
       "1  https://web.archive.org/web/20181011013513/htt...  2018-10-11   \n",
       "2  https://web.archive.org/web/20181011013513/htt...  2018-10-11   \n",
       "3  https://web.archive.org/web/20190701021000/htt...  2019-07-01   \n",
       "4  https://web.archive.org/web/20190728061708/htt...  2019-07-28   \n",
       "\n",
       "  Hardware model Manufacturer (from Hardware model)        Vendor  \\\n",
       "0  Google TPU v2                             Google  Google Cloud   \n",
       "1  Google TPU v3                             Google  Google Cloud   \n",
       "2  Google TPU v3                             Google  Google Cloud   \n",
       "3  Google TPU v3                             Google  Google Cloud   \n",
       "4  Google TPU v3                             Google  Google Cloud   \n",
       "\n",
       "                     Location Price per chip-hour (on-demand)  \\\n",
       "0                          US                           $1.13   \n",
       "1                          US                           $2.00   \n",
       "2                      Europe                           $2.20   \n",
       "3          Iowa (us-central1)                           $2.00   \n",
       "4  Netherlands (europe-west4)                           $2.00   \n",
       "\n",
       "  Price per chip-hour (1-year CUD) Price per chip-hour (3-year CUD)  \\\n",
       "0                              NaN                              NaN   \n",
       "1                              NaN                              NaN   \n",
       "2                              NaN                              NaN   \n",
       "3                            $1.26                            $0.90   \n",
       "4                            $1.26                            $0.90   \n",
       "\n",
       "   Price (hardware purchase)  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df = pd.read_csv('data/Hardware prices.csv')\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:31.172888400Z",
     "start_time": "2024-02-07T16:04:31.015263500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Price date in datetime format\n",
    "price_df.dropna(subset=['Price date'], inplace=True)\n",
    "price_df['Price date'] = pd.to_datetime(price_df['Price date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:31.282985500Z",
     "start_time": "2024-02-07T16:04:31.141530400Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_hardware_model_colname = 'Name of the hardware (from Training hardware)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:31.460215300Z",
     "start_time": "2024-02-07T16:04:31.282985500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the hardware</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Type</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Release price (USD)</th>\n",
       "      <th>FP64 (double precision) Performance (FLOP/s)</th>\n",
       "      <th>FP32 (single precision) Performance (FLOP/s)</th>\n",
       "      <th>FP16 (half precision) Performance (FLOP/s)</th>\n",
       "      <th>Tensor Float 32 (TF32)</th>\n",
       "      <th>FP16 Tensor Core</th>\n",
       "      <th>...</th>\n",
       "      <th>Foundry</th>\n",
       "      <th>Number of transistors in million</th>\n",
       "      <th>Prominent Years of usage</th>\n",
       "      <th>Google Cloud pricing ($ per hour) data from 17 dec 2022</th>\n",
       "      <th>Link to datasheet</th>\n",
       "      <th>Source for the Price</th>\n",
       "      <th>ALL ML SYSTEMS</th>\n",
       "      <th>All ML Systems copy</th>\n",
       "      <th>All ML Systems copy.1</th>\n",
       "      <th>Hardware prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3dfx Spectre 1000</td>\n",
       "      <td>Other</td>\n",
       "      <td>GPU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TSMC</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3dfx Spectre 2000</td>\n",
       "      <td>Other</td>\n",
       "      <td>GPU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TSMC</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3dfx Spectre 3000</td>\n",
       "      <td>Other</td>\n",
       "      <td>GPU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TSMC</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3dfx Voodoo4 4000 AGP</td>\n",
       "      <td>Other</td>\n",
       "      <td>GPU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TSMC</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3dfx Voodoo4 4500 AGP</td>\n",
       "      <td>Other</td>\n",
       "      <td>GPU</td>\n",
       "      <td>2000-10-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>TSMC</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name of the hardware Manufacturer Type Release date Release price (USD)  \\\n",
       "0      3dfx Spectre 1000        Other  GPU          NaN                 NaN   \n",
       "1      3dfx Spectre 2000        Other  GPU          NaN                 NaN   \n",
       "2      3dfx Spectre 3000        Other  GPU          NaN                 NaN   \n",
       "3  3dfx Voodoo4 4000 AGP        Other  GPU          NaN                 NaN   \n",
       "4  3dfx Voodoo4 4500 AGP        Other  GPU   2000-10-13                 NaN   \n",
       "\n",
       "   FP64 (double precision) Performance (FLOP/s)  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "   FP32 (single precision) Performance (FLOP/s)  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "   FP16 (half precision) Performance (FLOP/s)  Tensor Float 32 (TF32)  \\\n",
       "0                                         NaN                     NaN   \n",
       "1                                         NaN                     NaN   \n",
       "2                                         NaN                     NaN   \n",
       "3                                         NaN                     NaN   \n",
       "4                                         NaN                     NaN   \n",
       "\n",
       "   FP16 Tensor Core  ...  Foundry  Number of transistors in million  \\\n",
       "0               NaN  ...     TSMC                              30.0   \n",
       "1               NaN  ...     TSMC                              30.0   \n",
       "2               NaN  ...     TSMC                              30.0   \n",
       "3               NaN  ...     TSMC                              14.0   \n",
       "4               NaN  ...     TSMC                              14.0   \n",
       "\n",
       "   Prominent Years of usage  \\\n",
       "0                       NaN   \n",
       "1                       NaN   \n",
       "2                       NaN   \n",
       "3                       NaN   \n",
       "4                       NaN   \n",
       "\n",
       "   Google Cloud pricing ($ per hour) data from 17 dec 2022  Link to datasheet  \\\n",
       "0                                                NaN                      NaN   \n",
       "1                                                NaN                      NaN   \n",
       "2                                                NaN                      NaN   \n",
       "3                                                NaN                      NaN   \n",
       "4                                                NaN                      NaN   \n",
       "\n",
       "   Source for the Price  ALL ML SYSTEMS  All ML Systems copy  \\\n",
       "0                   NaN             NaN                  NaN   \n",
       "1                   NaN             NaN                  NaN   \n",
       "2                   NaN             NaN                  NaN   \n",
       "3                   NaN             NaN                  NaN   \n",
       "4                   NaN             NaN                  NaN   \n",
       "\n",
       "   All ML Systems copy.1  Hardware prices  \n",
       "0                    NaN              NaN  \n",
       "1                    NaN              NaN  \n",
       "2                    NaN              NaN  \n",
       "3                    NaN              NaN  \n",
       "4                    NaN              NaN  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hardware_df = pd.read_csv('data/Chip dataset-Grid view.csv')\n",
    "hardware_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Training hardware</th>\n",
       "      <th>Training time (hours)</th>\n",
       "      <th>Hardware quantity</th>\n",
       "      <th>Hardware utilization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>AlphaGo Fan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>NVIDIA Tesla K80</td>\n",
       "      <td>4320.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>Google TPU v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>JFT</td>\n",
       "      <td>NVIDIA Tesla K80</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>AlphaGo Zero</td>\n",
       "      <td>Google TPU v1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>AlphaZero</td>\n",
       "      <td>Google TPU v2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>AmoebaNet-A (F=448)</td>\n",
       "      <td>NVIDIA Tesla K40s</td>\n",
       "      <td>168.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>IMPALA</td>\n",
       "      <td>NVIDIA P100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>ResNeXt-101 32x48d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>FTW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>BigGAN-deep 512x512</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>RoBERTa Large</td>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Megatron-BERT</td>\n",
       "      <td>NVIDIA Tesla V100S PCIe 32 GB</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.2269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Megatron-LM (8.3B)</td>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>327.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>T5-3B</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>T5-11B</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>481.9</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.3707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>AlphaStar</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>OpenAI Five</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7104.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>OpenAI Five Rerun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Meena</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Turing-NLG</td>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>GPT-3 175B (davinci)</td>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>355.2</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>GShard (dense)</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>ALIGN</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>347.3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Megatron-Turing NLG 530B</td>\n",
       "      <td>NVIDIA A100 SXM4 80 GB</td>\n",
       "      <td>770.0</td>\n",
       "      <td>4480.0</td>\n",
       "      <td>0.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Yuan 1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Gopher (280B)</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>920.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>GLaM</td>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>LaMDA</td>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Chinchilla</td>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>PaLM (540B)</td>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>0.4620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>OPT-175B</td>\n",
       "      <td>NVIDIA A100 SXM4 80 GB</td>\n",
       "      <td>793.5</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.4712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>Minerva (540B)</td>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>696.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>GPT-3.5 (text-davinci-003)</td>\n",
       "      <td>NVIDIA A100 SXM4 40 GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>LLaMA-65B</td>\n",
       "      <td>NVIDIA A100</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>NVIDIA A100 SXM4 40 GB</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Claude 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Llama 2-70B</td>\n",
       "      <td>NVIDIA A100 SXM4 80 GB</td>\n",
       "      <td>4320.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Falcon 180B</td>\n",
       "      <td>NVIDIA A100 SXM4 40 GB</td>\n",
       "      <td>4320.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.1876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          System              Training hardware  \\\n",
       "265                  AlphaGo Fan                            NaN   \n",
       "275                  AlphaGo Lee                            NaN   \n",
       "306                         GNMT               NVIDIA Tesla K80   \n",
       "317             NASv3 (CIFAR-10)                            NaN   \n",
       "337               AlphaGo Master                  Google TPU v1   \n",
       "359                          JFT               NVIDIA Tesla K80   \n",
       "369          OpenAI TI7 DOTA 1v1                            NaN   \n",
       "391                 AlphaGo Zero                  Google TPU v1   \n",
       "403                    AlphaZero                  Google TPU v2   \n",
       "411          AmoebaNet-A (F=448)              NVIDIA Tesla K40s   \n",
       "413                       IMPALA                    NVIDIA P100   \n",
       "431           ResNeXt-101 32x48d                            NaN   \n",
       "450                          FTW                            NaN   \n",
       "467          BigGAN-deep 512x512                  Google TPU v3   \n",
       "543                RoBERTa Large   NVIDIA Tesla V100 DGXS 32 GB   \n",
       "563                Megatron-BERT  NVIDIA Tesla V100S PCIe 32 GB   \n",
       "564           Megatron-LM (8.3B)   NVIDIA Tesla V100 DGXS 32 GB   \n",
       "580                        T5-3B                  Google TPU v3   \n",
       "581                       T5-11B                  Google TPU v3   \n",
       "584                    AlphaStar                  Google TPU v3   \n",
       "600                  OpenAI Five                            NaN   \n",
       "601            OpenAI Five Rerun                            NaN   \n",
       "607                        Meena                  Google TPU v3   \n",
       "613                   Turing-NLG   NVIDIA Tesla V100 DGXS 32 GB   \n",
       "642         GPT-3 175B (davinci)   NVIDIA Tesla V100 DGXS 32 GB   \n",
       "651               GShard (dense)                  Google TPU v3   \n",
       "766                        ALIGN                  Google TPU v3   \n",
       "799     Megatron-Turing NLG 530B         NVIDIA A100 SXM4 80 GB   \n",
       "800                     Yuan 1.0                            NaN   \n",
       "829                Gopher (280B)                  Google TPU v3   \n",
       "834                         GLaM                  Google TPU v4   \n",
       "853                        LaMDA                  Google TPU v3   \n",
       "869                   Chinchilla                  Google TPU v4   \n",
       "873                  PaLM (540B)                  Google TPU v4   \n",
       "879                     OPT-175B         NVIDIA A100 SXM4 80 GB   \n",
       "918               Minerva (540B)                  Google TPU v4   \n",
       "963   GPT-3.5 (text-davinci-003)         NVIDIA A100 SXM4 40 GB   \n",
       "992                    LLaMA-65B                    NVIDIA A100   \n",
       "1004                       GPT-4         NVIDIA A100 SXM4 40 GB   \n",
       "1032                      PaLM 2                  Google TPU v4   \n",
       "1056                    Claude 2                            NaN   \n",
       "1059                 Llama 2-70B         NVIDIA A100 SXM4 80 GB   \n",
       "1083                 Falcon 180B         NVIDIA A100 SXM4 40 GB   \n",
       "\n",
       "      Training time (hours)  Hardware quantity  Hardware utilization  \n",
       "265                     NaN                NaN                   NaN  \n",
       "275                     NaN                NaN                   NaN  \n",
       "306                  4320.0               96.0                   NaN  \n",
       "317                     NaN              800.0                   NaN  \n",
       "337                     NaN                NaN                   NaN  \n",
       "359                  1440.0               50.0                   NaN  \n",
       "369                     NaN                NaN                   NaN  \n",
       "391                   480.0                NaN                   NaN  \n",
       "403                     NaN               64.0                   NaN  \n",
       "411                   168.0              450.0                   NaN  \n",
       "413                   100.0                1.0                   NaN  \n",
       "431                     NaN              336.0                   NaN  \n",
       "450                     NaN                NaN                   NaN  \n",
       "467                    48.0              256.0                   NaN  \n",
       "543                   120.0             1024.0                   NaN  \n",
       "563                  1392.0              512.0                0.2269  \n",
       "564                   327.0              512.0                0.1162  \n",
       "580                     NaN                NaN                   NaN  \n",
       "581                   481.9              512.0                0.3707  \n",
       "584                  1056.0              384.0                   NaN  \n",
       "600                  7104.0             1536.0                   NaN  \n",
       "601                     NaN              512.0                   NaN  \n",
       "607                   720.0             1024.0                0.3439  \n",
       "613                     NaN              256.0                   NaN  \n",
       "642                   355.2            10000.0                0.2196  \n",
       "651                  1008.0             1024.0                   NaN  \n",
       "766                   347.3              512.0                   NaN  \n",
       "799                   770.0             4480.0                0.3020  \n",
       "800                     NaN             2128.0                0.4500  \n",
       "829                   920.0             4096.0                0.3780  \n",
       "834                  1366.0             1024.0                   NaN  \n",
       "853                  1385.0             1024.0                0.5650  \n",
       "869                     NaN                NaN                   NaN  \n",
       "873                  1368.0             6144.0                0.4620  \n",
       "879                   793.5             1024.0                0.4712  \n",
       "918                   696.0             1024.0                   NaN  \n",
       "963                     NaN                NaN                   NaN  \n",
       "992                   500.0             2048.0                0.4746  \n",
       "1004                 2280.0            25000.0                0.3400  \n",
       "1032                    NaN                NaN                   NaN  \n",
       "1056                    NaN                NaN                   NaN  \n",
       "1059                 4320.0                NaN                   NaN  \n",
       "1083                 4320.0             4096.0                0.1876  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check original data with missing values\n",
    "frontier_pcd_df[['System', 'Training hardware', 'Training time (hours)', 'Hardware quantity', 'Hardware utilization']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:31.601924200Z",
     "start_time": "2024-02-07T16:04:31.460215300Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop unneeded columns from frontier_pcd_df\n",
    "irrelevant_columns = ['Notability criteria', 'Notability criteria notes', 'Link', 'Citations', 'Parameters notes',\n",
    "                      'Training compute notes', 'Training dataset notes', 'Dataset size notes',\n",
    "                      'Inference compute notes', 'Approach', 'Confidence', 'Last modified', 'Created By', 'Benchmark data',\n",
    "                      'Exclude', 'Authors by country', 'Training cost trends', 'Abstract', 'Compute cost notes',\n",
    "                      'Training time notes', 'Authors', 'Name of the hardware (from Training hardware)',\n",
    "                      'Training compute cost (2020 USD)', 'Organization categorization',\n",
    "                      'Training dataset', 'Inference compute (FLOP)', 'Compute sponsor categorization',\n",
    "                      'Finetune compute notes']\n",
    "frontier_pcd_df = frontier_pcd_df.drop(columns=irrelevant_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill column 'Training cloud compute vendor' using org_to_cloud_vendor dictionary\n",
    "org_to_cloud_vendor = {\n",
    "    'Google': 'Google Cloud',\n",
    "    'DeepMind': 'Google Cloud',\n",
    "    'Google DeepMind': 'Google Cloud',\n",
    "    'Google Brain': 'Google Cloud',\n",
    "    'Microsoft': 'Microsoft Azure',\n",
    "    'OpenAI': 'Microsoft Azure',\n",
    "}\n",
    "frontier_pcd_df['Training cloud compute vendor'] = frontier_pcd_df['Organization (from Organization)'].map(org_to_cloud_vendor)\n",
    "frontier_pcd_df['Training cloud compute vendor'] = frontier_pcd_df['Training cloud compute vendor'].fillna('Amazon Web Services')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: logarithmic scaling of big-valued columns (just copy this from validate_imputation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime to float so that it can be used in kNN\n",
    "frontier_pcd_df['Publication date'] = datetime_to_float(pcd_df['Publication date'])\n",
    "\n",
    "# set the System column as the index for formatting purposes\n",
    "frontier_pcd_df = frontier_pcd_df.set_index('System')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN parameters\n",
    "num_neighbors_general = 5  # for training time, hardware quantity, utilization\n",
    "num_neighbors_training_hardware = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:31.808389300Z",
     "start_time": "2024-02-07T16:04:31.601924200Z"
    }
   },
   "outputs": [],
   "source": [
    "imputed_pcd_df = knn_impute_numerical_pcd_data(frontier_pcd_df, num_neighbors=num_neighbors_general)\n",
    "\n",
    "# Impute training hardware separately, because it is a categorical variable\n",
    "# There could be a better solution to this, but it seems complicated no matter what - see https://stackoverflow.com/questions/64900801/implementing-knn-imputation-on-categorical-variables-in-an-sklearn-pipeline\n",
    "imputed_pcd_df = knn_impute_categorical_column(\n",
    "    imputed_pcd_df,\n",
    "    num_neighbors=num_neighbors_training_hardware,\n",
    "    target_col='Training hardware'\n",
    ")\n",
    "\n",
    "# Restore the System column\n",
    "imputed_pcd_df['System'] = frontier_pcd_df.index\n",
    "\n",
    "# set the System column as the index\n",
    "imputed_pcd_df = imputed_pcd_df.set_index('System')\n",
    "\n",
    "# insert imputed values into frontier_pcd_df\n",
    "frontier_pcd_df['Training hardware'] = imputed_pcd_df['Training hardware']\n",
    "frontier_pcd_df['Hardware quantity'] = imputed_pcd_df['Hardware quantity']\n",
    "frontier_pcd_df['Hardware utilization'] = imputed_pcd_df['Hardware utilization']\n",
    "frontier_pcd_df['Training time (hours)'] = imputed_pcd_df['Training time (hours)']\n",
    "# calculate training time (chip hours) from training time and hardware quantity\n",
    "# TODO: try estimating this from compute and FLOP/s instead. Compare the results.\n",
    "frontier_pcd_df['Training time (chip hours)'] = frontier_pcd_df['Training time (hours)'] * frontier_pcd_df['Hardware quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training hardware</th>\n",
       "      <th>Training time (hours)</th>\n",
       "      <th>Hardware quantity</th>\n",
       "      <th>Hardware utilization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AlphaGo Fan</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>311.4</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaGo Lee</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>311.4</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GNMT</th>\n",
       "      <td>NVIDIA Tesla K80</td>\n",
       "      <td>4320.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NASv3 (CIFAR-10)</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaGo Master</th>\n",
       "      <td>Google TPU v1</td>\n",
       "      <td>2073.98</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JFT</th>\n",
       "      <td>NVIDIA Tesla K80</td>\n",
       "      <td>1440.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI TI7 DOTA 1v1</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>311.4</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaGo Zero</th>\n",
       "      <td>Google TPU v1</td>\n",
       "      <td>480.00</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>0.43608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaZero</th>\n",
       "      <td>Google TPU v2</td>\n",
       "      <td>1306.44</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmoebaNet-A (F=448)</th>\n",
       "      <td>NVIDIA Tesla K40s</td>\n",
       "      <td>168.00</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMPALA</th>\n",
       "      <td>NVIDIA P100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResNeXt-101 32x48d</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>1251.00</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTW</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1251.00</td>\n",
       "      <td>444.8</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigGAN-deep 512x512</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>48.00</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa Large</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>120.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Megatron-BERT</th>\n",
       "      <td>NVIDIA Tesla V100S PCIe 32 GB</td>\n",
       "      <td>1392.00</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.22690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Megatron-LM (8.3B)</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>327.00</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.11620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5-3B</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>311.4</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5-11B</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>481.90</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.37070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaStar</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1056.00</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI Five</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>7104.00</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI Five Rerun</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>1251.00</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meena</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>720.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.34390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turing-NLG</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>1032.46</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3 175B (davinci)</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>355.20</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.21960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GShard (dense)</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1008.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALIGN</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>347.30</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Megatron-Turing NLG 530B</th>\n",
       "      <td>NVIDIA A100 SXM4 80 GB</td>\n",
       "      <td>770.00</td>\n",
       "      <td>4480.0</td>\n",
       "      <td>0.30200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yuan 1.0</th>\n",
       "      <td>Google TPU v1</td>\n",
       "      <td>875.94</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gopher (280B)</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>920.00</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.37800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLaM</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>1366.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.43608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LaMDA</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1385.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.56500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinchilla</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>994.30</td>\n",
       "      <td>1740.8</td>\n",
       "      <td>0.42314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaLM (540B)</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>0.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPT-175B</th>\n",
       "      <td>NVIDIA A100 SXM4 80 GB</td>\n",
       "      <td>793.50</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.47120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minerva (540B)</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>696.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.31130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3.5 (text-davinci-003)</th>\n",
       "      <td>NVIDIA A100 SXM4 40 GB</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>0.31130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-65B</th>\n",
       "      <td>NVIDIA A100</td>\n",
       "      <td>500.00</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.47460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4</th>\n",
       "      <td>NVIDIA A100 SXM4 40 GB</td>\n",
       "      <td>2280.00</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaLM 2</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>0.31130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claude 2</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>0.31130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama 2-70B</th>\n",
       "      <td>NVIDIA A100 SXM4 80 GB</td>\n",
       "      <td>4320.00</td>\n",
       "      <td>2432.0</td>\n",
       "      <td>0.37054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falcon 180B</th>\n",
       "      <td>NVIDIA A100 SXM4 40 GB</td>\n",
       "      <td>4320.00</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.18760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Training hardware  \\\n",
       "System                                                      \n",
       "AlphaGo Fan                                 Google TPU v3   \n",
       "AlphaGo Lee                                 Google TPU v3   \n",
       "GNMT                                     NVIDIA Tesla K80   \n",
       "NASv3 (CIFAR-10)                            Google TPU v3   \n",
       "AlphaGo Master                              Google TPU v1   \n",
       "JFT                                      NVIDIA Tesla K80   \n",
       "OpenAI TI7 DOTA 1v1                         Google TPU v3   \n",
       "AlphaGo Zero                                Google TPU v1   \n",
       "AlphaZero                                   Google TPU v2   \n",
       "AmoebaNet-A (F=448)                     NVIDIA Tesla K40s   \n",
       "IMPALA                                        NVIDIA P100   \n",
       "ResNeXt-101 32x48d           NVIDIA Tesla V100 DGXS 32 GB   \n",
       "FTW                                         Google TPU v3   \n",
       "BigGAN-deep 512x512                         Google TPU v3   \n",
       "RoBERTa Large                NVIDIA Tesla V100 DGXS 32 GB   \n",
       "Megatron-BERT               NVIDIA Tesla V100S PCIe 32 GB   \n",
       "Megatron-LM (8.3B)           NVIDIA Tesla V100 DGXS 32 GB   \n",
       "T5-3B                                       Google TPU v3   \n",
       "T5-11B                                      Google TPU v3   \n",
       "AlphaStar                                   Google TPU v3   \n",
       "OpenAI Five                                 Google TPU v3   \n",
       "OpenAI Five Rerun            NVIDIA Tesla V100 DGXS 32 GB   \n",
       "Meena                                       Google TPU v3   \n",
       "Turing-NLG                   NVIDIA Tesla V100 DGXS 32 GB   \n",
       "GPT-3 175B (davinci)         NVIDIA Tesla V100 DGXS 32 GB   \n",
       "GShard (dense)                              Google TPU v3   \n",
       "ALIGN                                       Google TPU v3   \n",
       "Megatron-Turing NLG 530B           NVIDIA A100 SXM4 80 GB   \n",
       "Yuan 1.0                                    Google TPU v1   \n",
       "Gopher (280B)                               Google TPU v3   \n",
       "GLaM                                        Google TPU v4   \n",
       "LaMDA                                       Google TPU v3   \n",
       "Chinchilla                                  Google TPU v4   \n",
       "PaLM (540B)                                 Google TPU v4   \n",
       "OPT-175B                           NVIDIA A100 SXM4 80 GB   \n",
       "Minerva (540B)                              Google TPU v4   \n",
       "GPT-3.5 (text-davinci-003)         NVIDIA A100 SXM4 40 GB   \n",
       "LLaMA-65B                                     NVIDIA A100   \n",
       "GPT-4                              NVIDIA A100 SXM4 40 GB   \n",
       "PaLM 2                                      Google TPU v4   \n",
       "Claude 2                                    Google TPU v4   \n",
       "Llama 2-70B                        NVIDIA A100 SXM4 80 GB   \n",
       "Falcon 180B                        NVIDIA A100 SXM4 40 GB   \n",
       "\n",
       "                            Training time (hours)  Hardware quantity  \\\n",
       "System                                                                 \n",
       "AlphaGo Fan                                375.20              311.4   \n",
       "AlphaGo Lee                                375.20              311.4   \n",
       "GNMT                                      4320.00               96.0   \n",
       "NASv3 (CIFAR-10)                           375.20              800.0   \n",
       "AlphaGo Master                            2073.98              896.0   \n",
       "JFT                                       1440.00               50.0   \n",
       "OpenAI TI7 DOTA 1v1                        375.20              311.4   \n",
       "AlphaGo Zero                               480.00             3040.0   \n",
       "AlphaZero                                 1306.44               64.0   \n",
       "AmoebaNet-A (F=448)                        168.00              450.0   \n",
       "IMPALA                                     100.00                1.0   \n",
       "ResNeXt-101 32x48d                        1251.00              336.0   \n",
       "FTW                                       1251.00              444.8   \n",
       "BigGAN-deep 512x512                         48.00              256.0   \n",
       "RoBERTa Large                              120.00             1024.0   \n",
       "Megatron-BERT                             1392.00              512.0   \n",
       "Megatron-LM (8.3B)                         327.00              512.0   \n",
       "T5-3B                                      375.20              311.4   \n",
       "T5-11B                                     481.90              512.0   \n",
       "AlphaStar                                 1056.00              384.0   \n",
       "OpenAI Five                               7104.00             1536.0   \n",
       "OpenAI Five Rerun                         1251.00              512.0   \n",
       "Meena                                      720.00             1024.0   \n",
       "Turing-NLG                                1032.46              256.0   \n",
       "GPT-3 175B (davinci)                       355.20            10000.0   \n",
       "GShard (dense)                            1008.00             1024.0   \n",
       "ALIGN                                      347.30              512.0   \n",
       "Megatron-Turing NLG 530B                   770.00             4480.0   \n",
       "Yuan 1.0                                   875.94             2128.0   \n",
       "Gopher (280B)                              920.00             4096.0   \n",
       "GLaM                                      1366.00             1024.0   \n",
       "LaMDA                                     1385.00             1024.0   \n",
       "Chinchilla                                 994.30             1740.8   \n",
       "PaLM (540B)                               1368.00             6144.0   \n",
       "OPT-175B                                   793.50             1024.0   \n",
       "Minerva (540B)                             696.00             1024.0   \n",
       "GPT-3.5 (text-davinci-003)                2294.80             3968.0   \n",
       "LLaMA-65B                                  500.00             2048.0   \n",
       "GPT-4                                     2280.00            25000.0   \n",
       "PaLM 2                                    2294.80             3968.0   \n",
       "Claude 2                                  2294.80             3968.0   \n",
       "Llama 2-70B                               4320.00             2432.0   \n",
       "Falcon 180B                               4320.00             4096.0   \n",
       "\n",
       "                            Hardware utilization  \n",
       "System                                            \n",
       "AlphaGo Fan                              0.30008  \n",
       "AlphaGo Lee                              0.30008  \n",
       "GNMT                                     0.32308  \n",
       "NASv3 (CIFAR-10)                         0.30008  \n",
       "AlphaGo Master                           0.30008  \n",
       "JFT                                      0.32308  \n",
       "OpenAI TI7 DOTA 1v1                      0.30008  \n",
       "AlphaGo Zero                             0.43608  \n",
       "AlphaZero                                0.30008  \n",
       "AmoebaNet-A (F=448)                      0.32308  \n",
       "IMPALA                                   0.32308  \n",
       "ResNeXt-101 32x48d                       0.30008  \n",
       "FTW                                      0.30008  \n",
       "BigGAN-deep 512x512                      0.32308  \n",
       "RoBERTa Large                            0.32308  \n",
       "Megatron-BERT                            0.22690  \n",
       "Megatron-LM (8.3B)                       0.11620  \n",
       "T5-3B                                    0.30008  \n",
       "T5-11B                                   0.37070  \n",
       "AlphaStar                                0.32308  \n",
       "OpenAI Five                              0.30008  \n",
       "OpenAI Five Rerun                        0.30008  \n",
       "Meena                                    0.34390  \n",
       "Turing-NLG                               0.30008  \n",
       "GPT-3 175B (davinci)                     0.21960  \n",
       "GShard (dense)                           0.30008  \n",
       "ALIGN                                    0.32308  \n",
       "Megatron-Turing NLG 530B                 0.30200  \n",
       "Yuan 1.0                                 0.45000  \n",
       "Gopher (280B)                            0.37800  \n",
       "GLaM                                     0.43608  \n",
       "LaMDA                                    0.56500  \n",
       "Chinchilla                               0.42314  \n",
       "PaLM (540B)                              0.46200  \n",
       "OPT-175B                                 0.47120  \n",
       "Minerva (540B)                           0.31130  \n",
       "GPT-3.5 (text-davinci-003)               0.31130  \n",
       "LLaMA-65B                                0.47460  \n",
       "GPT-4                                    0.34000  \n",
       "PaLM 2                                   0.31130  \n",
       "Claude 2                                 0.31130  \n",
       "Llama 2-70B                              0.37054  \n",
       "Falcon 180B                              0.18760  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_pcd_df[['Training hardware', 'Training time (hours)', 'Hardware quantity', 'Hardware utilization']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training hardware</th>\n",
       "      <th>Training time (hours)</th>\n",
       "      <th>Hardware quantity</th>\n",
       "      <th>Hardware utilization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AlphaGo Fan</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>311.4</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaGo Lee</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>311.4</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GNMT</th>\n",
       "      <td>NVIDIA Tesla K80</td>\n",
       "      <td>4320.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NASv3 (CIFAR-10)</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaGo Master</th>\n",
       "      <td>Google TPU v1</td>\n",
       "      <td>2073.98</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JFT</th>\n",
       "      <td>NVIDIA Tesla K80</td>\n",
       "      <td>1440.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI TI7 DOTA 1v1</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>311.4</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaGo Zero</th>\n",
       "      <td>Google TPU v1</td>\n",
       "      <td>480.00</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>0.43608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaZero</th>\n",
       "      <td>Google TPU v2</td>\n",
       "      <td>1306.44</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmoebaNet-A (F=448)</th>\n",
       "      <td>NVIDIA Tesla K40s</td>\n",
       "      <td>168.00</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMPALA</th>\n",
       "      <td>NVIDIA P100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResNeXt-101 32x48d</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>1251.00</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTW</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1251.00</td>\n",
       "      <td>444.8</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigGAN-deep 512x512</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>48.00</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa Large</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>120.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Megatron-BERT</th>\n",
       "      <td>NVIDIA Tesla V100S PCIe 32 GB</td>\n",
       "      <td>1392.00</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.22690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Megatron-LM (8.3B)</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>327.00</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.11620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5-3B</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>375.20</td>\n",
       "      <td>311.4</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5-11B</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>481.90</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.37070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlphaStar</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1056.00</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI Five</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>7104.00</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI Five Rerun</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>1251.00</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meena</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>720.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.34390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turing-NLG</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>1032.46</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3 175B (davinci)</th>\n",
       "      <td>NVIDIA Tesla V100 DGXS 32 GB</td>\n",
       "      <td>355.20</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.21960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GShard (dense)</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1008.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.30008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALIGN</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>347.30</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.32308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Megatron-Turing NLG 530B</th>\n",
       "      <td>NVIDIA A100 SXM4 80 GB</td>\n",
       "      <td>770.00</td>\n",
       "      <td>4480.0</td>\n",
       "      <td>0.30200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yuan 1.0</th>\n",
       "      <td>Google TPU v1</td>\n",
       "      <td>875.94</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gopher (280B)</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>920.00</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.37800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLaM</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>1366.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.43608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LaMDA</th>\n",
       "      <td>Google TPU v3</td>\n",
       "      <td>1385.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.56500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinchilla</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>994.30</td>\n",
       "      <td>1740.8</td>\n",
       "      <td>0.42314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaLM (540B)</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>0.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPT-175B</th>\n",
       "      <td>NVIDIA A100 SXM4 80 GB</td>\n",
       "      <td>793.50</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.47120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minerva (540B)</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>696.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.31130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3.5 (text-davinci-003)</th>\n",
       "      <td>NVIDIA A100 SXM4 40 GB</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>0.31130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-65B</th>\n",
       "      <td>NVIDIA A100</td>\n",
       "      <td>500.00</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.47460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4</th>\n",
       "      <td>NVIDIA A100 SXM4 40 GB</td>\n",
       "      <td>2280.00</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaLM 2</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>0.31130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claude 2</th>\n",
       "      <td>Google TPU v4</td>\n",
       "      <td>2294.80</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>0.31130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama 2-70B</th>\n",
       "      <td>NVIDIA A100 SXM4 80 GB</td>\n",
       "      <td>4320.00</td>\n",
       "      <td>2432.0</td>\n",
       "      <td>0.37054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falcon 180B</th>\n",
       "      <td>NVIDIA A100 SXM4 40 GB</td>\n",
       "      <td>4320.00</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.18760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Training hardware  \\\n",
       "System                                                      \n",
       "AlphaGo Fan                                 Google TPU v3   \n",
       "AlphaGo Lee                                 Google TPU v3   \n",
       "GNMT                                     NVIDIA Tesla K80   \n",
       "NASv3 (CIFAR-10)                            Google TPU v3   \n",
       "AlphaGo Master                              Google TPU v1   \n",
       "JFT                                      NVIDIA Tesla K80   \n",
       "OpenAI TI7 DOTA 1v1                         Google TPU v3   \n",
       "AlphaGo Zero                                Google TPU v1   \n",
       "AlphaZero                                   Google TPU v2   \n",
       "AmoebaNet-A (F=448)                     NVIDIA Tesla K40s   \n",
       "IMPALA                                        NVIDIA P100   \n",
       "ResNeXt-101 32x48d           NVIDIA Tesla V100 DGXS 32 GB   \n",
       "FTW                                         Google TPU v3   \n",
       "BigGAN-deep 512x512                         Google TPU v3   \n",
       "RoBERTa Large                NVIDIA Tesla V100 DGXS 32 GB   \n",
       "Megatron-BERT               NVIDIA Tesla V100S PCIe 32 GB   \n",
       "Megatron-LM (8.3B)           NVIDIA Tesla V100 DGXS 32 GB   \n",
       "T5-3B                                       Google TPU v3   \n",
       "T5-11B                                      Google TPU v3   \n",
       "AlphaStar                                   Google TPU v3   \n",
       "OpenAI Five                                 Google TPU v3   \n",
       "OpenAI Five Rerun            NVIDIA Tesla V100 DGXS 32 GB   \n",
       "Meena                                       Google TPU v3   \n",
       "Turing-NLG                   NVIDIA Tesla V100 DGXS 32 GB   \n",
       "GPT-3 175B (davinci)         NVIDIA Tesla V100 DGXS 32 GB   \n",
       "GShard (dense)                              Google TPU v3   \n",
       "ALIGN                                       Google TPU v3   \n",
       "Megatron-Turing NLG 530B           NVIDIA A100 SXM4 80 GB   \n",
       "Yuan 1.0                                    Google TPU v1   \n",
       "Gopher (280B)                               Google TPU v3   \n",
       "GLaM                                        Google TPU v4   \n",
       "LaMDA                                       Google TPU v3   \n",
       "Chinchilla                                  Google TPU v4   \n",
       "PaLM (540B)                                 Google TPU v4   \n",
       "OPT-175B                           NVIDIA A100 SXM4 80 GB   \n",
       "Minerva (540B)                              Google TPU v4   \n",
       "GPT-3.5 (text-davinci-003)         NVIDIA A100 SXM4 40 GB   \n",
       "LLaMA-65B                                     NVIDIA A100   \n",
       "GPT-4                              NVIDIA A100 SXM4 40 GB   \n",
       "PaLM 2                                      Google TPU v4   \n",
       "Claude 2                                    Google TPU v4   \n",
       "Llama 2-70B                        NVIDIA A100 SXM4 80 GB   \n",
       "Falcon 180B                        NVIDIA A100 SXM4 40 GB   \n",
       "\n",
       "                            Training time (hours)  Hardware quantity  \\\n",
       "System                                                                 \n",
       "AlphaGo Fan                                375.20              311.4   \n",
       "AlphaGo Lee                                375.20              311.4   \n",
       "GNMT                                      4320.00               96.0   \n",
       "NASv3 (CIFAR-10)                           375.20              800.0   \n",
       "AlphaGo Master                            2073.98              896.0   \n",
       "JFT                                       1440.00               50.0   \n",
       "OpenAI TI7 DOTA 1v1                        375.20              311.4   \n",
       "AlphaGo Zero                               480.00             3040.0   \n",
       "AlphaZero                                 1306.44               64.0   \n",
       "AmoebaNet-A (F=448)                        168.00              450.0   \n",
       "IMPALA                                     100.00                1.0   \n",
       "ResNeXt-101 32x48d                        1251.00              336.0   \n",
       "FTW                                       1251.00              444.8   \n",
       "BigGAN-deep 512x512                         48.00              256.0   \n",
       "RoBERTa Large                              120.00             1024.0   \n",
       "Megatron-BERT                             1392.00              512.0   \n",
       "Megatron-LM (8.3B)                         327.00              512.0   \n",
       "T5-3B                                      375.20              311.4   \n",
       "T5-11B                                     481.90              512.0   \n",
       "AlphaStar                                 1056.00              384.0   \n",
       "OpenAI Five                               7104.00             1536.0   \n",
       "OpenAI Five Rerun                         1251.00              512.0   \n",
       "Meena                                      720.00             1024.0   \n",
       "Turing-NLG                                1032.46              256.0   \n",
       "GPT-3 175B (davinci)                       355.20            10000.0   \n",
       "GShard (dense)                            1008.00             1024.0   \n",
       "ALIGN                                      347.30              512.0   \n",
       "Megatron-Turing NLG 530B                   770.00             4480.0   \n",
       "Yuan 1.0                                   875.94             2128.0   \n",
       "Gopher (280B)                              920.00             4096.0   \n",
       "GLaM                                      1366.00             1024.0   \n",
       "LaMDA                                     1385.00             1024.0   \n",
       "Chinchilla                                 994.30             1740.8   \n",
       "PaLM (540B)                               1368.00             6144.0   \n",
       "OPT-175B                                   793.50             1024.0   \n",
       "Minerva (540B)                             696.00             1024.0   \n",
       "GPT-3.5 (text-davinci-003)                2294.80             3968.0   \n",
       "LLaMA-65B                                  500.00             2048.0   \n",
       "GPT-4                                     2280.00            25000.0   \n",
       "PaLM 2                                    2294.80             3968.0   \n",
       "Claude 2                                  2294.80             3968.0   \n",
       "Llama 2-70B                               4320.00             2432.0   \n",
       "Falcon 180B                               4320.00             4096.0   \n",
       "\n",
       "                            Hardware utilization  \n",
       "System                                            \n",
       "AlphaGo Fan                              0.30008  \n",
       "AlphaGo Lee                              0.30008  \n",
       "GNMT                                     0.32308  \n",
       "NASv3 (CIFAR-10)                         0.30008  \n",
       "AlphaGo Master                           0.30008  \n",
       "JFT                                      0.32308  \n",
       "OpenAI TI7 DOTA 1v1                      0.30008  \n",
       "AlphaGo Zero                             0.43608  \n",
       "AlphaZero                                0.30008  \n",
       "AmoebaNet-A (F=448)                      0.32308  \n",
       "IMPALA                                   0.32308  \n",
       "ResNeXt-101 32x48d                       0.30008  \n",
       "FTW                                      0.30008  \n",
       "BigGAN-deep 512x512                      0.32308  \n",
       "RoBERTa Large                            0.32308  \n",
       "Megatron-BERT                            0.22690  \n",
       "Megatron-LM (8.3B)                       0.11620  \n",
       "T5-3B                                    0.30008  \n",
       "T5-11B                                   0.37070  \n",
       "AlphaStar                                0.32308  \n",
       "OpenAI Five                              0.30008  \n",
       "OpenAI Five Rerun                        0.30008  \n",
       "Meena                                    0.34390  \n",
       "Turing-NLG                               0.30008  \n",
       "GPT-3 175B (davinci)                     0.21960  \n",
       "GShard (dense)                           0.30008  \n",
       "ALIGN                                    0.32308  \n",
       "Megatron-Turing NLG 530B                 0.30200  \n",
       "Yuan 1.0                                 0.45000  \n",
       "Gopher (280B)                            0.37800  \n",
       "GLaM                                     0.43608  \n",
       "LaMDA                                    0.56500  \n",
       "Chinchilla                               0.42314  \n",
       "PaLM (540B)                              0.46200  \n",
       "OPT-175B                                 0.47120  \n",
       "Minerva (540B)                           0.31130  \n",
       "GPT-3.5 (text-davinci-003)               0.31130  \n",
       "LLaMA-65B                                0.47460  \n",
       "GPT-4                                    0.34000  \n",
       "PaLM 2                                   0.31130  \n",
       "Claude 2                                 0.31130  \n",
       "Llama 2-70B                              0.37054  \n",
       "Falcon 180B                              0.18760  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_pcd_df[['Training hardware', 'Training time (hours)', 'Hardware quantity', 'Hardware utilization']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(frontier_pcd_df['Training time (chip hours)'].notna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use a fixed mapping from Organization to cloud provider. If no mapping found, default to \"Amazon Web Services\".\n",
    "2. If there's a match for the hardware model, use that. Else, discard the ML system from the dataset.\n",
    "3. Use the price that is nearest to, but prior to, training time + 2 months before the publication date\n",
    "4. If there are no prices prior to that time, use the nearest price after that time\n",
    "5. If there are no prices for that hardware model and cloud provider at all, repeat steps 3 and 4 for \"Microsoft Azure\", then \"Google Cloud\" as the cloud provider.\n",
    "6. If there are no prices found from step 5, discard the ML system from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:32.075933800Z",
     "start_time": "2024-02-07T16:04:31.950006600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price date: 2019-07-01 00:00:00\n",
      "Price: $1.26\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "example_vendor = \"Google Cloud\"\n",
    "example_hardware_model = \"Google TPU v3\"\n",
    "example_date = \"2019-07-15\" # Example date, format should be YYYY-MM-DD\n",
    "\n",
    "# Find the row\n",
    "closest_row_df = find_closest_price_dates(example_vendor, example_hardware_model, example_date, price_df)\n",
    "\n",
    "for i, row in closest_row_df.iterrows():\n",
    "    if row['Price date'] <= pd.to_datetime(example_date):\n",
    "        print(f\"Price date: {row['Price date']}\")\n",
    "        print(f\"Price: {row['Price per chip-hour (1-year CUD)']}\")\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:32.189553500Z",
     "start_time": "2024-02-07T16:04:32.075933800Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: use the vendor mapping from imputation to reduce repetition\n",
    "org_to_cloud_vendor = {\n",
    "    'google': 'Google Cloud',\n",
    "    'deepmind': 'Google Cloud',\n",
    "    'microsoft': 'Microsoft Azure',\n",
    "    'openai': 'Microsoft Azure',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:32.284443400Z",
     "start_time": "2024-02-07T16:04:32.189553500Z"
    }
   },
   "outputs": [],
   "source": [
    "frontier_pcd_df['System'] = frontier_pcd_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:32.395189900Z",
     "start_time": "2024-02-07T16:04:32.284443400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert float year to datetime\n",
    "def float_year_to_datetime(float_year):\n",
    "    year = int(float_year)\n",
    "    remainder = float_year - year\n",
    "    days_in_year = 365 + int(pd.Timestamp(year=year, month=12, day=31).is_leap_year)\n",
    "    day_of_year = int(remainder * days_in_year)\n",
    "    return pd.Timestamp(year=year, month=1, day=1) + pd.to_timedelta(day_of_year, unit='D')\n",
    "\n",
    "frontier_pcd_df['Publication date'] = frontier_pcd_df['Publication date'].apply(float_year_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:32.504756500Z",
     "start_time": "2024-02-07T16:04:32.395189900Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_hardware_model_colname = 'Training hardware'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:32.814131500Z",
     "start_time": "2024-02-07T16:04:32.504756500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== System: AlphaGo Fan ====\n",
      "Trying Google TPU v3 at 2015-07-17 09:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: AlphaGo Lee ====\n",
      "Trying Google TPU v3 at 2015-11-12 09:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: GNMT ====\n",
      "Trying NVIDIA Tesla K80 at 2016-01-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 1.4\n",
      "\n",
      "==== System: NASv3 (CIFAR-10) ====\n",
      "Trying Google TPU v3 at 2016-08-21 09:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: AlphaGo Master ====\n",
      "Trying Google TPU v1 at 2016-08-07 15:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v1\n",
      "==== System: JFT ====\n",
      "Trying NVIDIA Tesla K80 at 2017-03-13 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 1.4\n",
      "\n",
      "==== System: OpenAI TI7 DOTA 1v1 ====\n",
      "Trying Google TPU v3 at 2017-05-27 09:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v3\n",
      "==== System: AlphaGo Zero ====\n",
      "Trying Google TPU v1 at 2017-07-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v1\n",
      "==== System: AlphaZero ====\n",
      "Trying Google TPU v2 at 2017-08-12 14:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 1.13\n",
      "\n",
      "==== System: AmoebaNet-A (F=448) ====\n",
      "Trying NVIDIA Tesla K40s at 2017-11-29 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Estimated price: 0.052760065856088875\n",
      "\n",
      "==== System: IMPALA ====\n",
      "Trying NVIDIA P100 at 2017-12-01 20:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 1.46\n",
      "\n",
      "==== System: ResNeXt-101 32x48d ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2018-01-10 21:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: FTW ====\n",
      "Trying Google TPU v3 at 2018-03-13 21:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: BigGAN-deep 512x512 ====\n",
      "Trying Google TPU v3 at 2018-07-28 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: RoBERTa Large ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-04-28 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: Megatron-BERT ====\n",
      "Trying NVIDIA Tesla V100S PCIe 32 GB at 2019-05-22 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Estimated price: 0.1051277082983274\n",
      "\n",
      "==== System: Megatron-LM (8.3B) ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-07-05 09:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: T5-3B ====\n",
      "Trying Google TPU v3 at 2019-08-08 09:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: T5-11B ====\n",
      "Trying Google TPU v3 at 2019-08-03 23:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: AlphaStar ====\n",
      "Trying Google TPU v3 at 2019-07-18 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: OpenAI Five ====\n",
      "Trying Google TPU v3 at 2018-12-22 00:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v3\n",
      "==== System: OpenAI Five Rerun ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-08-22 21:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: Meena ====\n",
      "Trying Google TPU v3 at 2019-10-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: Turing-NLG ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-11-01 00:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: GPT-3 175B (davinci) ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2020-03-15 05:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: GShard (dense) ====\n",
      "Trying Google TPU v3 at 2020-03-20 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: ALIGN ====\n",
      "Trying Google TPU v3 at 2021-03-29 13:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: Megatron-Turing NLG 530B ====\n",
      "Trying NVIDIA A100 SXM4 80 GB at 2021-07-10 22:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.62\n",
      "\n",
      "==== System: Yuan 1.0 ====\n",
      "Trying Google TPU v1 at 2021-07-07 13:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v1\n",
      "==== System: Gopher (280B) ====\n",
      "Trying Google TPU v3 at 2021-08-31 16:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: GLaM ====\n",
      "Trying Google TPU v4 at 2021-08-18 02:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: LaMDA ====\n",
      "Trying Google TPU v3 at 2021-10-14 07:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: Chinchilla ====\n",
      "Trying Google TPU v4 at 2021-12-18 14:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: PaLM (540B) ====\n",
      "Trying Google TPU v4 at 2021-12-09 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: OPT-175B ====\n",
      "Trying NVIDIA A100 SXM4 80 GB at 2022-01-29 23:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 3.0\n",
      "\n",
      "==== System: Minerva (540B) ====\n",
      "Trying Google TPU v4 at 2022-04-02 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: GPT-3.5 (text-davinci-003) ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2022-06-25 10:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.4\n",
      "\n",
      "==== System: LLaMA-65B ====\n",
      "Trying NVIDIA A100 at 2022-12-04 04:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.35\n",
      "\n",
      "==== System: GPT-4 ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2022-10-12 00:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.4\n",
      "\n",
      "==== System: PaLM 2 ====\n",
      "Trying Google TPU v4 at 2022-12-06 10:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: Claude 2 ====\n",
      "Trying Google TPU v4 at 2023-02-06 10:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v4\n",
      "==== System: Llama 2-70B ====\n",
      "Trying NVIDIA A100 SXM4 80 GB at 2022-11-21 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 3.0\n",
      "\n",
      "==== System: Falcon 180B ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2023-01-09 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AlphaGo Fan': 2.0,\n",
       " 'AlphaGo Lee': 2.0,\n",
       " 'GNMT': 1.4,\n",
       " 'NASv3 (CIFAR-10)': 2.0,\n",
       " 'JFT': 1.4,\n",
       " 'AlphaZero': 1.13,\n",
       " 'AmoebaNet-A (F=448)': 0.052760065856088875,\n",
       " 'IMPALA': 1.46,\n",
       " 'ResNeXt-101 32x48d': 2.29,\n",
       " 'FTW': 2.0,\n",
       " 'BigGAN-deep 512x512': 2.0,\n",
       " 'RoBERTa Large': 2.29,\n",
       " 'Megatron-BERT': 0.1051277082983274,\n",
       " 'Megatron-LM (8.3B)': 2.29,\n",
       " 'T5-3B': 1.26,\n",
       " 'T5-11B': 1.26,\n",
       " 'AlphaStar': 1.26,\n",
       " 'OpenAI Five Rerun': 2.29,\n",
       " 'Meena': 1.26,\n",
       " 'Turing-NLG': 2.29,\n",
       " 'GPT-3 175B (davinci)': 2.29,\n",
       " 'GShard (dense)': 1.26,\n",
       " 'ALIGN': 1.26,\n",
       " 'Megatron-Turing NLG 530B': 2.62,\n",
       " 'Gopher (280B)': 1.26,\n",
       " 'GLaM': 2.03,\n",
       " 'LaMDA': 1.26,\n",
       " 'Chinchilla': 2.03,\n",
       " 'PaLM (540B)': 2.03,\n",
       " 'OPT-175B': 3.0,\n",
       " 'Minerva (540B)': 2.03,\n",
       " 'GPT-3.5 (text-davinci-003)': 2.4,\n",
       " 'LLaMA-65B': 2.35,\n",
       " 'GPT-4': 2.4,\n",
       " 'PaLM 2': 2.03,\n",
       " 'Llama 2-70B': 3.0,\n",
       " 'Falcon 180B': 2.4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_colname = 'Price per chip-hour (1-year CUD)'\n",
    "system_to_price = {}\n",
    "\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    price = find_price(row, price_df, hardware_df, pcd_hardware_model_colname, price_colname, org_to_cloud_vendor)\n",
    "    if price is None:\n",
    "        continue\n",
    "    else:\n",
    "        system_to_price[row['System']] = price\n",
    "\n",
    "system_to_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: inflation adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost = price_per_chip_hour * chip_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:32.923721100Z",
     "start_time": "2024-02-07T16:04:32.814131500Z"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_cost(row, system_to_price):\n",
    "    system = row['System']\n",
    "    price = system_to_price.get(system)\n",
    "    if price is None:\n",
    "        return None\n",
    "\n",
    "    chip_hours = row['Training time (chip hours)']\n",
    "    if np.isnan(chip_hours):\n",
    "        return None\n",
    "\n",
    "    cost = price * chip_hours\n",
    "\n",
    "    # Check for base model\n",
    "    if not pd.isna(row['Base model']):\n",
    "        base_model_name = row['Base model']\n",
    "        base_model = frontier_pcd_df[frontier_pcd_df['System'] == base_model_name].squeeze()\n",
    "        base_cost = estimate_cost(base_model, system_to_price)\n",
    "        if base_cost is None:\n",
    "            return None\n",
    "        else:\n",
    "            cost += base_cost\n",
    "\n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:33.033231700Z",
     "start_time": "2024-02-07T16:04:32.923721100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AlphaGo Fan': 233674.55999999997,\n",
       " 'AlphaGo Lee': 233674.55999999997,\n",
       " 'GNMT': 580608.0,\n",
       " 'NASv3 (CIFAR-10)': 600320.0,\n",
       " 'JFT': 100800.0,\n",
       " 'AlphaZero': 94481.7408,\n",
       " 'AmoebaNet-A (F=448)': 3988.660978720319,\n",
       " 'IMPALA': 146.0,\n",
       " 'ResNeXt-101 32x48d': 962569.4400000001,\n",
       " 'FTW': 1112889.6,\n",
       " 'BigGAN-deep 512x512': 24576.0,\n",
       " 'RoBERTa Large': 281395.2,\n",
       " 'Megatron-BERT': 74924.93821505114,\n",
       " 'Megatron-LM (8.3B)': 383400.96,\n",
       " 'T5-3B': 147214.9728,\n",
       " 'T5-11B': 310883.328,\n",
       " 'AlphaStar': 510935.04,\n",
       " 'OpenAI Five Rerun': 1466772.48,\n",
       " 'Meena': 928972.8,\n",
       " 'Turing-NLG': 605269.3504,\n",
       " 'GPT-3 175B (davinci)': 8134080.0,\n",
       " 'GShard (dense)': 1300561.92,\n",
       " 'ALIGN': 224050.176,\n",
       " 'Megatron-Turing NLG 530B': 9037952.0,\n",
       " 'Gopher (280B)': 4748083.2,\n",
       " 'GLaM': 2839531.5199999996,\n",
       " 'LaMDA': 1786982.4,\n",
       " 'Chinchilla': 3513681.2031999994,\n",
       " 'PaLM (540B)': 17062133.759999998,\n",
       " 'OPT-175B': 2437632.0,\n",
       " 'Minerva (540B)': 18508922.88,\n",
       " 'GPT-3.5 (text-davinci-003)': 21853839.36,\n",
       " 'LLaMA-65B': 2406400.0,\n",
       " 'GPT-4': 136800000.0,\n",
       " 'PaLM 2': 18484705.792,\n",
       " 'Llama 2-70B': 31518720.0,\n",
       " 'Falcon 180B': 42467328.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_to_cost = {}\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    cost = estimate_cost(row, system_to_price)\n",
    "    if cost is None:\n",
    "        continue\n",
    "    system_to_cost[row['System']] = cost\n",
    "\n",
    "system_to_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:33.143342700Z",
     "start_time": "2024-02-07T16:04:33.033231700Z"
    }
   },
   "outputs": [],
   "source": [
    "for system, cost in system_to_cost.items():\n",
    "    frontier_pcd_df.loc[system, 'Cost'] = cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply inflation adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:33.405367600Z",
     "start_time": "2024-02-07T16:04:33.290732900Z"
    }
   },
   "outputs": [],
   "source": [
    "from_year_month = frontier_pcd_df['Publication date'].apply(str)\n",
    "frontier_pcd_df['Publication date'] = from_year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:33.499948700Z",
     "start_time": "2024-02-07T16:04:33.405367600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "System\n",
       "AlphaGo Fan                   2015-10-01 00:00:00\n",
       "AlphaGo Lee                   2016-01-27 00:00:00\n",
       "GNMT                          2016-09-26 00:00:00\n",
       "NASv3 (CIFAR-10)              2016-11-05 00:00:00\n",
       "AlphaGo Master                2017-01-01 00:00:00\n",
       "JFT                           2017-07-11 00:00:00\n",
       "OpenAI TI7 DOTA 1v1           2017-08-11 00:00:00\n",
       "AlphaGo Zero                  2017-10-18 00:00:00\n",
       "AlphaZero                     2017-12-05 00:00:00\n",
       "AmoebaNet-A (F=448)           2018-02-04 00:00:00\n",
       "IMPALA                        2018-02-04 00:00:00\n",
       "ResNeXt-101 32x48d            2018-05-03 00:00:00\n",
       "FTW                           2018-07-04 00:00:00\n",
       "BigGAN-deep 512x512           2018-09-28 00:00:00\n",
       "RoBERTa Large                 2019-07-02 00:00:00\n",
       "Megatron-BERT                 2019-09-17 00:00:00\n",
       "Megatron-LM (8.3B)            2019-09-17 00:00:00\n",
       "T5-3B                         2019-10-23 00:00:00\n",
       "T5-11B                        2019-10-23 00:00:00\n",
       "AlphaStar                     2019-10-30 00:00:00\n",
       "OpenAI Five                   2019-12-13 00:00:00\n",
       "OpenAI Five Rerun             2019-12-13 00:00:00\n",
       "Meena                         2020-01-28 00:00:00\n",
       "Turing-NLG                    2020-02-12 00:00:00\n",
       "GPT-3 175B (davinci)          2020-05-29 00:00:00\n",
       "GShard (dense)                2020-06-30 00:00:00\n",
       "ALIGN                         2021-06-12 00:00:00\n",
       "Megatron-Turing NLG 530B      2021-10-11 00:00:00\n",
       "Yuan 1.0                      2021-10-12 00:00:00\n",
       "Gopher (280B)                 2021-12-08 00:00:00\n",
       "GLaM                          2021-12-13 00:00:00\n",
       "LaMDA                         2022-02-09 00:00:00\n",
       "Chinchilla                    2022-03-30 00:00:00\n",
       "PaLM (540B)                   2022-04-05 00:00:00\n",
       "OPT-175B                      2022-05-03 00:00:00\n",
       "Minerva (540B)                2022-06-30 00:00:00\n",
       "GPT-3.5 (text-davinci-003)    2022-11-28 00:00:00\n",
       "LLaMA-65B                     2023-02-23 00:00:00\n",
       "GPT-4                         2023-03-16 00:00:00\n",
       "PaLM 2                        2023-05-11 00:00:00\n",
       "Claude 2                      2023-07-12 00:00:00\n",
       "Llama 2-70B                   2023-07-19 00:00:00\n",
       "Falcon 180B                   2023-09-06 00:00:00\n",
       "Name: Publication date, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_pcd_df['Publication date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:53.202236900Z",
     "start_time": "2024-02-07T16:04:52.976107600Z"
    }
   },
   "outputs": [],
   "source": [
    "frontier_pcd_df = adjust_column_for_inflation(frontier_pcd_df, 'Cost', 'data/PCU518210518210.csv', '2023-12-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:33.660916400Z",
     "start_time": "2024-02-07T16:04:33.645130900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:38.651688600Z",
     "start_time": "2024-02-07T16:04:33.660916400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaGo Fan",
         "text": "AlphaGo Fan",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2015-10-01 00:00:00"
         ],
         "y": [
          233674.55999999997
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaGo Lee",
         "text": "AlphaGo Lee",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2016-01-27 00:00:00"
         ],
         "y": [
          233674.55999999997
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GNMT",
         "text": "GNMT",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2016-09-26 00:00:00"
         ],
         "y": [
          580608
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "NASv3 (CIFAR-10)",
         "text": "NASv3 (CIFAR-10)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2016-11-05 00:00:00"
         ],
         "y": [
          600320
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "JFT",
         "text": "JFT",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2017-07-11 00:00:00"
         ],
         "y": [
          100800
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaZero",
         "text": "AlphaZero",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2017-12-05 00:00:00"
         ],
         "y": [
          94481.7408
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AmoebaNet-A (F=448)",
         "text": "AmoebaNet-A (F=448)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-02-04 00:00:00"
         ],
         "y": [
          3988.660978720319
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "IMPALA",
         "text": "IMPALA",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-02-04 00:00:00"
         ],
         "y": [
          146
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "ResNeXt-101 32x48d",
         "text": "ResNeXt-101 32x48d",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-05-03 00:00:00"
         ],
         "y": [
          962569.4400000001
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "FTW",
         "text": "FTW",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-07-04 00:00:00"
         ],
         "y": [
          1112889.6
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "BigGAN-deep 512x512",
         "text": "BigGAN-deep 512x512",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-09-28 00:00:00"
         ],
         "y": [
          24576
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "RoBERTa Large",
         "text": "RoBERTa Large",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-07-02 00:00:00"
         ],
         "y": [
          281395.2
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Megatron-BERT",
         "text": "Megatron-BERT",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-09-17 00:00:00"
         ],
         "y": [
          74924.93821505114
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Megatron-LM (8.3B)",
         "text": "Megatron-LM (8.3B)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-09-17 00:00:00"
         ],
         "y": [
          383400.96
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "T5-3B",
         "text": "T5-3B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-10-23 00:00:00"
         ],
         "y": [
          147214.9728
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "T5-11B",
         "text": "T5-11B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-10-23 00:00:00"
         ],
         "y": [
          310883.328
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaStar",
         "text": "AlphaStar",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-10-30 00:00:00"
         ],
         "y": [
          510935.04
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "OpenAI Five Rerun",
         "text": "OpenAI Five Rerun",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-12-13 00:00:00"
         ],
         "y": [
          1466772.48
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Meena",
         "text": "Meena",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2020-01-28 00:00:00"
         ],
         "y": [
          928972.8
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Turing-NLG",
         "text": "Turing-NLG",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2020-02-12 00:00:00"
         ],
         "y": [
          605269.3504
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GPT-3 175B (davinci)",
         "text": "GPT-3 175B (davinci)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2020-05-29 00:00:00"
         ],
         "y": [
          8134080
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GShard (dense)",
         "text": "GShard (dense)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2020-06-30 00:00:00"
         ],
         "y": [
          1300561.92
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "ALIGN",
         "text": "ALIGN",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-06-12 00:00:00"
         ],
         "y": [
          224050.176
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Megatron-Turing NLG 530B",
         "text": "Megatron-Turing NLG 530B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-10-11 00:00:00"
         ],
         "y": [
          9037952
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Gopher (280B)",
         "text": "Gopher (280B)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-12-08 00:00:00"
         ],
         "y": [
          4748083.2
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GLaM",
         "text": "GLaM",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-12-13 00:00:00"
         ],
         "y": [
          2839531.5199999996
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "LaMDA",
         "text": "LaMDA",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-02-09 00:00:00"
         ],
         "y": [
          1786982.4
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Chinchilla",
         "text": "Chinchilla",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-03-30 00:00:00"
         ],
         "y": [
          3513681.2031999994
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "PaLM (540B)",
         "text": "PaLM (540B)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-04-05 00:00:00"
         ],
         "y": [
          17062133.759999998
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "OPT-175B",
         "text": "OPT-175B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-05-03 00:00:00"
         ],
         "y": [
          2437632
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Minerva (540B)",
         "text": "Minerva (540B)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-06-30 00:00:00"
         ],
         "y": [
          18508922.88
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GPT-3.5 (text-davinci-003)",
         "text": "GPT-3.5 (text-davinci-003)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-11-28 00:00:00"
         ],
         "y": [
          21853839.36
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "LLaMA-65B",
         "text": "LLaMA-65B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-02-23 00:00:00"
         ],
         "y": [
          2406400
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GPT-4",
         "text": "GPT-4",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-03-16 00:00:00"
         ],
         "y": [
          136800000
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "PaLM 2",
         "text": "PaLM 2",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-05-11 00:00:00"
         ],
         "y": [
          18484705.792
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Llama 2-70B",
         "text": "Llama 2-70B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-07-19 00:00:00"
         ],
         "y": [
          31518720
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Falcon 180B",
         "text": "Falcon 180B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-09-06 00:00:00"
         ],
         "y": [
          42467328
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "font": {
         "size": 14
        },
        "height": 600,
        "margin": {
         "b": 10,
         "l": 10,
         "r": 10,
         "t": 40
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost of cloud compute to train frontier ML systems"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "Publication date"
         }
        },
        "yaxis": {
         "title": {
          "text": "Cost (USD, nominal)"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    system = row['System']\n",
    "    cost = system_to_cost.get(system)\n",
    "    if cost is None:\n",
    "        continue\n",
    "    publication_date = row['Publication date']\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[publication_date],\n",
    "        y=[cost],\n",
    "        name=system,\n",
    "        text=system,\n",
    "        textposition='top center',\n",
    "        line=dict(color='#034752'),\n",
    "        mode='markers+text',\n",
    "    ))\n",
    "\n",
    "# log y axis\n",
    "fig.update_yaxes(type=\"log\")\n",
    "# no legend\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# axis labels\n",
    "fig.update_xaxes(title_text='Publication date')\n",
    "fig.update_yaxes(title_text='Cost (USD, nominal)')\n",
    "\n",
    "# title\n",
    "fig.update_layout(title_text='Cost of cloud compute to train frontier ML systems')\n",
    "\n",
    "# update size\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# font size\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=14,\n",
    "    )\n",
    ")\n",
    "\n",
    "# axis limits\n",
    "# fig.update_xaxes(range=['2017-01-01', '2025-01-01'])\n",
    "# fig.update_yaxes(range=[5, 8])\n",
    "\n",
    "# margins\n",
    "fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "save_plot(fig, results_dir, 'cost_scatter')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:38.651688600Z",
     "start_time": "2024-02-07T16:04:33.660916400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaGo Fan",
         "text": "AlphaGo Fan",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2015-10-01 00:00:00"
         ],
         "y": [
          260433.36026966287
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaGo Lee",
         "text": "AlphaGo Lee",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2016-01-27 00:00:00"
         ],
         "y": [
          260921.97820637896
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GNMT",
         "text": "GNMT",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2016-09-26 00:00:00"
         ],
         "y": [
          634034.5893577982
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "NASv3 (CIFAR-10)",
         "text": "NASv3 (CIFAR-10)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2016-11-05 00:00:00"
         ],
         "y": [
          655560.4550458716
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaGo Master",
         "text": "AlphaGo Master",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2017-01-01 00:00:00"
         ],
         "y": [
          null
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "JFT",
         "text": "JFT",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2017-07-11 00:00:00"
         ],
         "y": [
          108876.80580762251
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "OpenAI TI7 DOTA 1v1",
         "text": "OpenAI TI7 DOTA 1v1",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2017-08-11 00:00:00"
         ],
         "y": [
          null
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaGo Zero",
         "text": "AlphaGo Zero",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2017-10-18 00:00:00"
         ],
         "y": [
          null
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaZero",
         "text": "AlphaZero",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2017-12-05 00:00:00"
         ],
         "y": [
          102144.97372773843
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AmoebaNet-A (F=448)",
         "text": "AmoebaNet-A (F=448)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-02-04 00:00:00"
         ],
         "y": [
          4304.354635512961
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "IMPALA",
         "text": "IMPALA",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-02-04 00:00:00"
         ],
         "y": [
          157.5555757026292
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "ResNeXt-101 32x48d",
         "text": "ResNeXt-101 32x48d",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-05-03 00:00:00"
         ],
         "y": [
          1037813.7721304349
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "FTW",
         "text": "FTW",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-07-04 00:00:00"
         ],
         "y": [
          1198798.634280543
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "BigGAN-deep 512x512",
         "text": "BigGAN-deep 512x512",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2018-09-28 00:00:00"
         ],
         "y": [
          26473.13375565611
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "RoBERTa Large",
         "text": "RoBERTa Large",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-07-02 00:00:00"
         ],
         "y": [
          302843.3151537071
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Megatron-BERT",
         "text": "Megatron-BERT",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-09-17 00:00:00"
         ],
         "y": [
          79913.22039191342
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Megatron-LM (8.3B)",
         "text": "Megatron-LM (8.3B)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-09-17 00:00:00"
         ],
         "y": [
          408926.66907526884
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "T5-3B",
         "text": "T5-3B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-10-23 00:00:00"
         ],
         "y": [
          156875.54353074305
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "T5-11B",
         "text": "T5-11B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-10-23 00:00:00"
         ],
         "y": [
          331284.1766503133
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "AlphaStar",
         "text": "AlphaStar",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-10-30 00:00:00"
         ],
         "y": [
          544463.7225711728
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "OpenAI Five",
         "text": "OpenAI Five",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-12-13 00:00:00"
         ],
         "y": [
          null
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "OpenAI Five Rerun",
         "text": "OpenAI Five Rerun",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2019-12-13 00:00:00"
         ],
         "y": [
          1558838.6454857143
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Meena",
         "text": "Meena",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2020-01-28 00:00:00"
         ],
         "y": [
          975954.3899735217
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Turing-NLG",
         "text": "Turing-NLG",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2020-02-12 00:00:00"
         ],
         "y": [
          634759.566326978
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GPT-3 175B (davinci)",
         "text": "GPT-3 175B (davinci)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2020-05-29 00:00:00"
         ],
         "y": [
          8537914.835978836
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GShard (dense)",
         "text": "GShard (dense)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2020-06-30 00:00:00"
         ],
         "y": [
          1356756.2255705523
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "ALIGN",
         "text": "ALIGN",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-06-12 00:00:00"
         ],
         "y": [
          231700.1950415291
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Megatron-Turing NLG 530B",
         "text": "Megatron-Turing NLG 530B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-10-11 00:00:00"
         ],
         "y": [
          9323783.175392829
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Yuan 1.0",
         "text": "Yuan 1.0",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-10-12 00:00:00"
         ],
         "y": [
          null
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Gopher (280B)",
         "text": "Gopher (280B)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-12-08 00:00:00"
         ],
         "y": [
          4899730.751790266
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GLaM",
         "text": "GLaM",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-12-13 00:00:00"
         ],
         "y": [
          2930222.4335963097
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "LaMDA",
         "text": "LaMDA",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-02-09 00:00:00"
         ],
         "y": [
          1847419.7042801555
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Chinchilla",
         "text": "Chinchilla",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-03-30 00:00:00"
         ],
         "y": [
          3652885.510305308
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "PaLM (540B)",
         "text": "PaLM (540B)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-04-05 00:00:00"
         ],
         "y": [
          17344678.766538847
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "OPT-175B",
         "text": "OPT-175B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-05-03 00:00:00"
         ],
         "y": [
          2476201.0732573224
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Minerva (540B)",
         "text": "Minerva (540B)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-06-30 00:00:00"
         ],
         "y": [
          18858267.411995716
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GPT-3.5 (text-davinci-003)",
         "text": "GPT-3.5 (text-davinci-003)",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2022-11-28 00:00:00"
         ],
         "y": [
          22293223.569819342
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "LLaMA-65B",
         "text": "LLaMA-65B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-02-23 00:00:00"
         ],
         "y": [
          2437132.894859992
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "GPT-4",
         "text": "GPT-4",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-03-16 00:00:00"
         ],
         "y": [
          138268294.7540037
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "PaLM 2",
         "text": "PaLM 2",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-05-11 00:00:00"
         ],
         "y": [
          18674858.93854725
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Claude 2",
         "text": "Claude 2",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-07-12 00:00:00"
         ],
         "y": [
          null
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Llama 2-70B",
         "text": "Llama 2-70B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-07-19 00:00:00"
         ],
         "y": [
          31698476.968442395
         ]
        },
        {
         "line": {
          "color": "#034752"
         },
         "mode": "markers+text",
         "name": "Falcon 180B",
         "text": "Falcon 180B",
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2023-09-06 00:00:00"
         ],
         "y": [
          42730466.97583202
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "font": {
         "size": 14
        },
        "height": 600,
        "margin": {
         "b": 10,
         "l": 10,
         "r": 10,
         "t": 40
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost of cloud compute to train frontier ML systems"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "Publication date"
         }
        },
        "yaxis": {
         "title": {
          "text": "Cost (2023 USD)"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    system = row['System']\n",
    "    cost = row['Cost (inflation-adjusted)']\n",
    "    if cost is None:\n",
    "        continue\n",
    "    publication_date = row['Publication date']\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[publication_date],\n",
    "        y=[cost],\n",
    "        name=system,\n",
    "        text=system,\n",
    "        textposition='top center',\n",
    "        line=dict(color='#034752'),\n",
    "        mode='markers+text',\n",
    "    ))\n",
    "\n",
    "# log y axis\n",
    "fig.update_yaxes(type=\"log\")\n",
    "# no legend\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# axis labels\n",
    "fig.update_xaxes(title_text='Publication date')\n",
    "fig.update_yaxes(title_text='Cost (2023 USD)')\n",
    "\n",
    "# title\n",
    "fig.update_layout(title_text='Cost of cloud compute to train frontier ML systems')\n",
    "\n",
    "# update size\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# font size\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=14,\n",
    "    )\n",
    ")\n",
    "\n",
    "# axis limits\n",
    "# fig.update_xaxes(range=['2017-01-01', '2025-01-01'])\n",
    "# fig.update_yaxes(range=[5, 8])\n",
    "\n",
    "# margins\n",
    "fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "save_plot(fig, results_dir, 'cost_scatter-inflation_adjusted')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:39.597618200Z",
     "start_time": "2024-02-07T16:04:38.651688600Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaGo Fan",
         "type": "bar",
         "x": [
          "AlphaGo Fan"
         ],
         "y": [
          233674.55999999997
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaGo Lee",
         "type": "bar",
         "x": [
          "AlphaGo Lee"
         ],
         "y": [
          233674.55999999997
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GNMT",
         "type": "bar",
         "x": [
          "GNMT"
         ],
         "y": [
          580608
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "NASv3 (CIFAR-10)",
         "type": "bar",
         "x": [
          "NASv3 (CIFAR-10)"
         ],
         "y": [
          600320
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "JFT",
         "type": "bar",
         "x": [
          "JFT"
         ],
         "y": [
          100800
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaZero",
         "type": "bar",
         "x": [
          "AlphaZero"
         ],
         "y": [
          94481.7408
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AmoebaNet-A (F=448)",
         "type": "bar",
         "x": [
          "AmoebaNet-A (F=448)"
         ],
         "y": [
          3988.660978720319
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "IMPALA",
         "type": "bar",
         "x": [
          "IMPALA"
         ],
         "y": [
          146
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "ResNeXt-101 32x48d",
         "type": "bar",
         "x": [
          "ResNeXt-101 32x48d"
         ],
         "y": [
          962569.4400000001
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "FTW",
         "type": "bar",
         "x": [
          "FTW"
         ],
         "y": [
          1112889.6
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "BigGAN-deep 512x512",
         "type": "bar",
         "x": [
          "BigGAN-deep 512x512"
         ],
         "y": [
          24576
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "RoBERTa Large",
         "type": "bar",
         "x": [
          "RoBERTa Large"
         ],
         "y": [
          281395.2
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Megatron-BERT",
         "type": "bar",
         "x": [
          "Megatron-BERT"
         ],
         "y": [
          74924.93821505114
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Megatron-LM (8.3B)",
         "type": "bar",
         "x": [
          "Megatron-LM (8.3B)"
         ],
         "y": [
          383400.96
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "T5-3B",
         "type": "bar",
         "x": [
          "T5-3B"
         ],
         "y": [
          147214.9728
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "T5-11B",
         "type": "bar",
         "x": [
          "T5-11B"
         ],
         "y": [
          310883.328
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaStar",
         "type": "bar",
         "x": [
          "AlphaStar"
         ],
         "y": [
          510935.04
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "OpenAI Five Rerun",
         "type": "bar",
         "x": [
          "OpenAI Five Rerun"
         ],
         "y": [
          1466772.48
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Meena",
         "type": "bar",
         "x": [
          "Meena"
         ],
         "y": [
          928972.8
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Turing-NLG",
         "type": "bar",
         "x": [
          "Turing-NLG"
         ],
         "y": [
          605269.3504
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GPT-3 175B (davinci)",
         "type": "bar",
         "x": [
          "GPT-3 175B (davinci)"
         ],
         "y": [
          8134080
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GShard (dense)",
         "type": "bar",
         "x": [
          "GShard (dense)"
         ],
         "y": [
          1300561.92
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "ALIGN",
         "type": "bar",
         "x": [
          "ALIGN"
         ],
         "y": [
          224050.176
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Megatron-Turing NLG 530B",
         "type": "bar",
         "x": [
          "Megatron-Turing NLG 530B"
         ],
         "y": [
          9037952
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Gopher (280B)",
         "type": "bar",
         "x": [
          "Gopher (280B)"
         ],
         "y": [
          4748083.2
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GLaM",
         "type": "bar",
         "x": [
          "GLaM"
         ],
         "y": [
          2839531.5199999996
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "LaMDA",
         "type": "bar",
         "x": [
          "LaMDA"
         ],
         "y": [
          1786982.4
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Chinchilla",
         "type": "bar",
         "x": [
          "Chinchilla"
         ],
         "y": [
          3513681.2031999994
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "PaLM (540B)",
         "type": "bar",
         "x": [
          "PaLM (540B)"
         ],
         "y": [
          17062133.759999998
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "OPT-175B",
         "type": "bar",
         "x": [
          "OPT-175B"
         ],
         "y": [
          2437632
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Minerva (540B)",
         "type": "bar",
         "x": [
          "Minerva (540B)"
         ],
         "y": [
          18508922.88
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GPT-3.5 (text-davinci-003)",
         "type": "bar",
         "x": [
          "GPT-3.5 (text-davinci-003)"
         ],
         "y": [
          21853839.36
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "LLaMA-65B",
         "type": "bar",
         "x": [
          "LLaMA-65B"
         ],
         "y": [
          2406400
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GPT-4",
         "type": "bar",
         "x": [
          "GPT-4"
         ],
         "y": [
          136800000
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "PaLM 2",
         "type": "bar",
         "x": [
          "PaLM 2"
         ],
         "y": [
          18484705.792
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Llama 2-70B",
         "type": "bar",
         "x": [
          "Llama 2-70B"
         ],
         "y": [
          31518720
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Falcon 180B",
         "type": "bar",
         "x": [
          "Falcon 180B"
         ],
         "y": [
          42467328
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "font": {
         "size": 14
        },
        "height": 600,
        "margin": {
         "b": 10,
         "l": 10,
         "r": 10,
         "t": 40
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost of cloud compute to train frontier ML systems"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "System"
         }
        },
        "yaxis": {
         "range": [
          0,
          8
         ],
         "title": {
          "text": "Cost (USD, nominal)"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    system = row['System']\n",
    "    cost = system_to_cost.get(system)\n",
    "    if cost is None:\n",
    "        continue\n",
    "    publication_date = row['Publication date']\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[system],\n",
    "        y=[cost],\n",
    "        name=system,\n",
    "        # nice blue color\n",
    "        marker_color='#034752',\n",
    "        # text=system,\n",
    "        # textposition='auto',\n",
    "    ))\n",
    "\n",
    "# log y axis\n",
    "fig.update_yaxes(type=\"log\")\n",
    "# no legend\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# axis labels\n",
    "fig.update_xaxes(title_text='System')\n",
    "fig.update_yaxes(title_text='Cost (USD, nominal)')\n",
    "\n",
    "# title\n",
    "fig.update_layout(title_text='Cost of cloud compute to train frontier ML systems')\n",
    "\n",
    "# update size\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# font size\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=14,\n",
    "    )\n",
    ")\n",
    "\n",
    "# axis limits\n",
    "fig.update_yaxes(range=[0, 8])\n",
    "\n",
    "# margins\n",
    "fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:39.597618200Z",
     "start_time": "2024-02-07T16:04:38.651688600Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaGo Fan",
         "type": "bar",
         "x": [
          "AlphaGo Fan"
         ],
         "y": [
          260433.36026966287
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaGo Lee",
         "type": "bar",
         "x": [
          "AlphaGo Lee"
         ],
         "y": [
          260921.97820637896
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GNMT",
         "type": "bar",
         "x": [
          "GNMT"
         ],
         "y": [
          634034.5893577982
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "NASv3 (CIFAR-10)",
         "type": "bar",
         "x": [
          "NASv3 (CIFAR-10)"
         ],
         "y": [
          655560.4550458716
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaGo Master",
         "type": "bar",
         "x": [
          "AlphaGo Master"
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "JFT",
         "type": "bar",
         "x": [
          "JFT"
         ],
         "y": [
          108876.80580762251
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "OpenAI TI7 DOTA 1v1",
         "type": "bar",
         "x": [
          "OpenAI TI7 DOTA 1v1"
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaGo Zero",
         "type": "bar",
         "x": [
          "AlphaGo Zero"
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaZero",
         "type": "bar",
         "x": [
          "AlphaZero"
         ],
         "y": [
          102144.97372773843
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AmoebaNet-A (F=448)",
         "type": "bar",
         "x": [
          "AmoebaNet-A (F=448)"
         ],
         "y": [
          4304.354635512961
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "IMPALA",
         "type": "bar",
         "x": [
          "IMPALA"
         ],
         "y": [
          157.5555757026292
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "ResNeXt-101 32x48d",
         "type": "bar",
         "x": [
          "ResNeXt-101 32x48d"
         ],
         "y": [
          1037813.7721304349
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "FTW",
         "type": "bar",
         "x": [
          "FTW"
         ],
         "y": [
          1198798.634280543
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "BigGAN-deep 512x512",
         "type": "bar",
         "x": [
          "BigGAN-deep 512x512"
         ],
         "y": [
          26473.13375565611
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "RoBERTa Large",
         "type": "bar",
         "x": [
          "RoBERTa Large"
         ],
         "y": [
          302843.3151537071
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Megatron-BERT",
         "type": "bar",
         "x": [
          "Megatron-BERT"
         ],
         "y": [
          79913.22039191342
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Megatron-LM (8.3B)",
         "type": "bar",
         "x": [
          "Megatron-LM (8.3B)"
         ],
         "y": [
          408926.66907526884
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "T5-3B",
         "type": "bar",
         "x": [
          "T5-3B"
         ],
         "y": [
          156875.54353074305
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "T5-11B",
         "type": "bar",
         "x": [
          "T5-11B"
         ],
         "y": [
          331284.1766503133
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "AlphaStar",
         "type": "bar",
         "x": [
          "AlphaStar"
         ],
         "y": [
          544463.7225711728
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "OpenAI Five",
         "type": "bar",
         "x": [
          "OpenAI Five"
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "OpenAI Five Rerun",
         "type": "bar",
         "x": [
          "OpenAI Five Rerun"
         ],
         "y": [
          1558838.6454857143
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Meena",
         "type": "bar",
         "x": [
          "Meena"
         ],
         "y": [
          975954.3899735217
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Turing-NLG",
         "type": "bar",
         "x": [
          "Turing-NLG"
         ],
         "y": [
          634759.566326978
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GPT-3 175B (davinci)",
         "type": "bar",
         "x": [
          "GPT-3 175B (davinci)"
         ],
         "y": [
          8537914.835978836
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GShard (dense)",
         "type": "bar",
         "x": [
          "GShard (dense)"
         ],
         "y": [
          1356756.2255705523
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "ALIGN",
         "type": "bar",
         "x": [
          "ALIGN"
         ],
         "y": [
          231700.1950415291
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Megatron-Turing NLG 530B",
         "type": "bar",
         "x": [
          "Megatron-Turing NLG 530B"
         ],
         "y": [
          9323783.175392829
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Yuan 1.0",
         "type": "bar",
         "x": [
          "Yuan 1.0"
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Gopher (280B)",
         "type": "bar",
         "x": [
          "Gopher (280B)"
         ],
         "y": [
          4899730.751790266
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GLaM",
         "type": "bar",
         "x": [
          "GLaM"
         ],
         "y": [
          2930222.4335963097
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "LaMDA",
         "type": "bar",
         "x": [
          "LaMDA"
         ],
         "y": [
          1847419.7042801555
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Chinchilla",
         "type": "bar",
         "x": [
          "Chinchilla"
         ],
         "y": [
          3652885.510305308
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "PaLM (540B)",
         "type": "bar",
         "x": [
          "PaLM (540B)"
         ],
         "y": [
          17344678.766538847
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "OPT-175B",
         "type": "bar",
         "x": [
          "OPT-175B"
         ],
         "y": [
          2476201.0732573224
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Minerva (540B)",
         "type": "bar",
         "x": [
          "Minerva (540B)"
         ],
         "y": [
          18858267.411995716
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GPT-3.5 (text-davinci-003)",
         "type": "bar",
         "x": [
          "GPT-3.5 (text-davinci-003)"
         ],
         "y": [
          22293223.569819342
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "LLaMA-65B",
         "type": "bar",
         "x": [
          "LLaMA-65B"
         ],
         "y": [
          2437132.894859992
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "GPT-4",
         "type": "bar",
         "x": [
          "GPT-4"
         ],
         "y": [
          138268294.7540037
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "PaLM 2",
         "type": "bar",
         "x": [
          "PaLM 2"
         ],
         "y": [
          18674858.93854725
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Claude 2",
         "type": "bar",
         "x": [
          "Claude 2"
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Llama 2-70B",
         "type": "bar",
         "x": [
          "Llama 2-70B"
         ],
         "y": [
          31698476.968442395
         ]
        },
        {
         "marker": {
          "color": "#034752"
         },
         "name": "Falcon 180B",
         "type": "bar",
         "x": [
          "Falcon 180B"
         ],
         "y": [
          42730466.97583202
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "font": {
         "size": 14
        },
        "height": 600,
        "margin": {
         "b": 10,
         "l": 10,
         "r": 10,
         "t": 40
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost of cloud compute to train frontier ML systems"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "System"
         }
        },
        "yaxis": {
         "range": [
          0,
          8
         ],
         "title": {
          "text": "Cost (2023 USD)"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    system = row['System']\n",
    "    cost = row['Cost (inflation-adjusted)']\n",
    "    if cost is None:\n",
    "        continue\n",
    "    publication_date = row['Publication date']\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[system],\n",
    "        y=[cost],\n",
    "        name=system,\n",
    "        # nice blue color\n",
    "        marker_color='#034752',\n",
    "        # text=system,\n",
    "        # textposition='auto',\n",
    "    ))\n",
    "\n",
    "# log y axis\n",
    "fig.update_yaxes(type=\"log\")\n",
    "# no legend\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# axis labels\n",
    "fig.update_xaxes(title_text='System')\n",
    "fig.update_yaxes(title_text='Cost (2023 USD)')\n",
    "\n",
    "# title\n",
    "fig.update_layout(title_text='Cost of cloud compute to train frontier ML systems')\n",
    "\n",
    "# update size\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# font size\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=14,\n",
    "    )\n",
    ")\n",
    "\n",
    "# axis limits\n",
    "fig.update_yaxes(range=[0, 8])\n",
    "\n",
    "# margins\n",
    "fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "save_plot(fig, results_dir, 'costs-inflation_adjusted')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:39.616432900Z",
     "start_time": "2024-02-07T16:04:38.761334900Z"
    }
   },
   "outputs": [],
   "source": [
    "frontier_pcd_df.drop('Megatron-BERT', inplace=True)\n",
    "frontier_pcd_df.drop('IMPALA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:39.616432900Z",
     "start_time": "2024-02-07T16:04:38.857238300Z"
    }
   },
   "outputs": [],
   "source": [
    "frontier_pcd_df.to_csv(results_dir + 'price dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
