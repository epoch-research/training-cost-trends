{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:24.360542700Z",
     "start_time": "2024-02-06T13:29:23.963965200Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qltoZ7TbdkHZ",
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:30.173748300Z",
     "start_time": "2024-02-06T13:29:24.062197Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from plotting import *\n",
    "from prices import *\n",
    "from inflation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "c8uNf70ve1PM",
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:30.379462500Z",
     "start_time": "2024-02-06T13:29:30.173748300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                               System    Domain                   Task  \\\n0                      Cohere Command  Language                    NaN   \n1                             Theseus     Other           Maze solving   \n2                               SNARC     Other           Maze solving   \n3                   Genetic algorithm       NaN                    NaN   \n4  Sequence-based pattern recognition    Vision  Character recognition   \n\n           Authors      Notability criteria  \\\n0              NaN                      NaN   \n1   Claude Shannon  Historical significance   \n2    Marvin Minsky  Historical significance   \n3    NA Barricelli  Historical significance   \n4  O. G. Selfridge  Historical significance   \n\n                           Notability criteria notes Open-source  \\\n0                                                NaN         NaN   \n1                                                NaN         NaN   \n2                                                NaN         NaN   \n3  Possibly first computer simulation of a geneti...         NaN   \n4                                                NaN         NaN   \n\n                                                Link  Citations  \\\n0                  https://cohere.com/models/command        NaN   \n1  https://www.technologyreview.com/2018/12/19/13...        0.0   \n2  https://en.wikipedia.org/wiki/Stochastic_neura...       33.0   \n3  https://link.springer.com/article/10.1007/BF01...      266.0   \n4     https://dl.acm.org/doi/10.1145/1455292.1455310      290.0   \n\n                                           Reference  ...  \\\n0                    World-class AI, at your command  ...   \n1                                       Mighty Mouse  ...   \n2  A Neural-Analogue Calculator Based upon a Prob...  ...   \n3            Numerical testing of evolution theories  ...   \n4           Pattern recognition and modern computers  ...   \n\n              Organization (from Organization) Base model  \\\n0                                       Cohere        NaN   \n1                            Bell Laboratories        NaN   \n2                           Harvard University        NaN   \n3                 Institute for Advanced Study        NaN   \n4  Massachusetts Institute of Technology (MIT)        NaN   \n\n  Finetune compute (FLOP)  Finetune compute notes  \\\n0                     NaN                     NaN   \n1                     NaN                     NaN   \n2                     NaN                     NaN   \n3                     NaN                     NaN   \n4                     NaN                     NaN   \n\n                   Authors by country  Hardware quantity Hardware utilization  \\\n0                                 NaN                NaN                  NaN   \n1                             Theseus                NaN                  NaN   \n2                               SNARC                NaN                  NaN   \n3                   Genetic algorithm                NaN                  NaN   \n4  Sequence-based pattern recognition                NaN                  NaN   \n\n  Training cost trends Training cloud compute vendor  Training data center  \n0                  NaN                           NaN                   NaN  \n1                  NaN                           NaN                   NaN  \n2                  NaN                           NaN                   NaN  \n3                  NaN                           NaN                   NaN  \n4                  NaN                           NaN                   NaN  \n\n[5 rows x 49 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>System</th>\n      <th>Domain</th>\n      <th>Task</th>\n      <th>Authors</th>\n      <th>Notability criteria</th>\n      <th>Notability criteria notes</th>\n      <th>Open-source</th>\n      <th>Link</th>\n      <th>Citations</th>\n      <th>Reference</th>\n      <th>...</th>\n      <th>Organization (from Organization)</th>\n      <th>Base model</th>\n      <th>Finetune compute (FLOP)</th>\n      <th>Finetune compute notes</th>\n      <th>Authors by country</th>\n      <th>Hardware quantity</th>\n      <th>Hardware utilization</th>\n      <th>Training cost trends</th>\n      <th>Training cloud compute vendor</th>\n      <th>Training data center</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cohere Command</td>\n      <td>Language</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://cohere.com/models/command</td>\n      <td>NaN</td>\n      <td>World-class AI, at your command</td>\n      <td>...</td>\n      <td>Cohere</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Theseus</td>\n      <td>Other</td>\n      <td>Maze solving</td>\n      <td>Claude Shannon</td>\n      <td>Historical significance</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n      <td>0.0</td>\n      <td>Mighty Mouse</td>\n      <td>...</td>\n      <td>Bell Laboratories</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Theseus</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SNARC</td>\n      <td>Other</td>\n      <td>Maze solving</td>\n      <td>Marvin Minsky</td>\n      <td>Historical significance</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://en.wikipedia.org/wiki/Stochastic_neura...</td>\n      <td>33.0</td>\n      <td>A Neural-Analogue Calculator Based upon a Prob...</td>\n      <td>...</td>\n      <td>Harvard University</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>SNARC</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Genetic algorithm</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NA Barricelli</td>\n      <td>Historical significance</td>\n      <td>Possibly first computer simulation of a geneti...</td>\n      <td>NaN</td>\n      <td>https://link.springer.com/article/10.1007/BF01...</td>\n      <td>266.0</td>\n      <td>Numerical testing of evolution theories</td>\n      <td>...</td>\n      <td>Institute for Advanced Study</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Genetic algorithm</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sequence-based pattern recognition</td>\n      <td>Vision</td>\n      <td>Character recognition</td>\n      <td>O. G. Selfridge</td>\n      <td>Historical significance</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://dl.acm.org/doi/10.1145/1455292.1455310</td>\n      <td>290.0</td>\n      <td>Pattern recognition and modern computers</td>\n      <td>...</td>\n      <td>Massachusetts Institute of Technology (MIT)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Sequence-based pattern recognition</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 49 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df = pd.read_csv('data/All ML Systems - full view.csv')\n",
    "pcd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:30.531106100Z",
     "start_time": "2024-02-06T13:29:30.379462500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Publication date in datetime format\n",
    "pcd_df.dropna(subset=['Publication date'], inplace=True)\n",
    "pcd_df['Publication date'] = pd.to_datetime(pcd_df['Publication date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zHTeCty5dqjn",
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:30.630955400Z",
     "start_time": "2024-02-06T13:29:30.515123200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manually copied from \"Training cost trends\" Airtable\n",
    "frontier_systems = [\n",
    "    \"PaLM 2\",\n",
    "    \"GPT-4\",\n",
    "    \"Minerva (540B)\",\n",
    "    \"Megatron-Turing NLG 530B\",\n",
    "    \"GPT-3 175B (davinci)\",\n",
    "    \"Meena\",\n",
    "    \"AlphaStar\",\n",
    "    \"AlphaGo Zero\",\n",
    "    \"AlphaGo Master\",\n",
    "    \"GNMT\",\n",
    "    \"Claude 2\",\n",
    "    \"PaLM (540B)\",\n",
    "#     \"ERNIE 3.0 Titan\",\n",
    "    \"Gopher (280B)\",\n",
    "    \"OpenAI Five\",\n",
    "    \"T5-11B\",\n",
    "    \"Megatron-BERT\",\n",
    "    \"ResNeXt-101 32x48d\",\n",
    "    \"AlphaZero\",\n",
    "    \"Falcon 180B\",\n",
    "    \"GPT-3.5 (text-davinci-003)\",\n",
    "    \"Chinchilla\",\n",
    "    \"Yuan 1.0\",\n",
    "    \"Turing-NLG\",\n",
    "    \"BigGAN-deep 512x512\",\n",
    "    \"NASv3 (CIFAR-10)\",\n",
    "    \"AlphaGo Lee\",\n",
    "    \"AlphaGo Fan\",\n",
    "    \"OPT-175B\",\n",
    "#     \"AlphaCode\",\n",
    "    \"GLaM\",\n",
    "    \"OpenAI Five Rerun\",\n",
    "    \"T5-3B\",\n",
    "    \"Megatron-LM (8.3B)\",\n",
    "    \"FTW\",\n",
    "    \"AmoebaNet-A (F=448)\",\n",
    "    \"OpenAI TI7 DOTA 1v1\",\n",
    "    \"JFT\",\n",
    "    \"Llama 2-70B\",\n",
    "    \"LLaMA-65B\",\n",
    "    \"LaMDA\",\n",
    "    \"ALIGN\",\n",
    "    \"GShard (dense)\",\n",
    "    \"RoBERTa Large\",\n",
    "    \"IMPALA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Nyzyh8IKe0ZK",
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:30.757068800Z",
     "start_time": "2024-02-06T13:29:30.633395800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               System    Domain         Task  \\\n265       AlphaGo Fan     Games           Go   \n275       AlphaGo Lee     Games           Go   \n306              GNMT  Language  Translation   \n317  NASv3 (CIFAR-10)    Vision          NaN   \n337    AlphaGo Master     Games           Go   \n\n                                               Authors Notability criteria  \\\n265  David Silver, Aja Huang, Chris J. Maddison, Ar...    SOTA improvement   \n275  David Silver, Aja Huang, Chris J. Maddison, Ar...        Highly cited   \n306  Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...        Highly cited   \n317                            Barret Zoph, Quoc V. Le        Highly cited   \n337  D Silver, J Schrittwieser, K Simonyan, I Anton...        Highly cited   \n\n    Notability criteria notes Open-source  \\\n265                       NaN         NaN   \n275                       NaN         NaN   \n306                       NaN         NaN   \n317                       NaN         NaN   \n337                       NaN         NaN   \n\n                                                  Link  Citations  \\\n265  https://www.nature.com/articles/nature24270.ep...    14389.0   \n275        https://www.nature.com/articles/nature16961    14389.0   \n306                   https://arxiv.org/abs/1609.08144     5948.0   \n317                   https://arxiv.org/abs/1611.01578     4569.0   \n337  https://www.researchgate.net/publication/32047...     7831.0   \n\n                                             Reference  ...  \\\n265  Mastering the game of Go with deep neural netw...  ...   \n275  Mastering the game of Go with deep neural netw...  ...   \n306  Google's Neural Machine Translation System: Br...  ...   \n317  Neural Architecture Search with Reinforcement ...  ...   \n337   Mastering the game of Go without human knowledge  ...   \n\n    Organization (from Organization) Base model Finetune compute (FLOP)  \\\n265                  Google DeepMind        NaN                     NaN   \n275                         DeepMind        NaN                     NaN   \n306                           Google        NaN                     NaN   \n317                     Google Brain        NaN                     NaN   \n337                         DeepMind        NaN                     NaN   \n\n     Finetune compute notes Authors by country  Hardware quantity  \\\n265                     NaN        AlphaGo Fan                NaN   \n275                     NaN        AlphaGo Lee                NaN   \n306                     NaN               GNMT               96.0   \n317                     NaN   NASv3 (CIFAR-10)              800.0   \n337                     NaN     AlphaGo Master                NaN   \n\n    Hardware utilization Training cost trends Training cloud compute vendor  \\\n265                  NaN          AlphaGo Fan                           NaN   \n275                  NaN          AlphaGo Lee                           NaN   \n306                  NaN                 GNMT                           NaN   \n317                  NaN     NASv3 (CIFAR-10)                           NaN   \n337                  NaN       AlphaGo Master                           NaN   \n\n     Training data center  \n265                   NaN  \n275                   NaN  \n306                   NaN  \n317                   NaN  \n337                   NaN  \n\n[5 rows x 49 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>System</th>\n      <th>Domain</th>\n      <th>Task</th>\n      <th>Authors</th>\n      <th>Notability criteria</th>\n      <th>Notability criteria notes</th>\n      <th>Open-source</th>\n      <th>Link</th>\n      <th>Citations</th>\n      <th>Reference</th>\n      <th>...</th>\n      <th>Organization (from Organization)</th>\n      <th>Base model</th>\n      <th>Finetune compute (FLOP)</th>\n      <th>Finetune compute notes</th>\n      <th>Authors by country</th>\n      <th>Hardware quantity</th>\n      <th>Hardware utilization</th>\n      <th>Training cost trends</th>\n      <th>Training cloud compute vendor</th>\n      <th>Training data center</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>265</th>\n      <td>AlphaGo Fan</td>\n      <td>Games</td>\n      <td>Go</td>\n      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n      <td>SOTA improvement</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://www.nature.com/articles/nature24270.ep...</td>\n      <td>14389.0</td>\n      <td>Mastering the game of Go with deep neural netw...</td>\n      <td>...</td>\n      <td>Google DeepMind</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AlphaGo Fan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AlphaGo Fan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>AlphaGo Lee</td>\n      <td>Games</td>\n      <td>Go</td>\n      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n      <td>Highly cited</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://www.nature.com/articles/nature16961</td>\n      <td>14389.0</td>\n      <td>Mastering the game of Go with deep neural netw...</td>\n      <td>...</td>\n      <td>DeepMind</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AlphaGo Lee</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AlphaGo Lee</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>GNMT</td>\n      <td>Language</td>\n      <td>Translation</td>\n      <td>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...</td>\n      <td>Highly cited</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://arxiv.org/abs/1609.08144</td>\n      <td>5948.0</td>\n      <td>Google's Neural Machine Translation System: Br...</td>\n      <td>...</td>\n      <td>Google</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>GNMT</td>\n      <td>96.0</td>\n      <td>NaN</td>\n      <td>GNMT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>317</th>\n      <td>NASv3 (CIFAR-10)</td>\n      <td>Vision</td>\n      <td>NaN</td>\n      <td>Barret Zoph, Quoc V. Le</td>\n      <td>Highly cited</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://arxiv.org/abs/1611.01578</td>\n      <td>4569.0</td>\n      <td>Neural Architecture Search with Reinforcement ...</td>\n      <td>...</td>\n      <td>Google Brain</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NASv3 (CIFAR-10)</td>\n      <td>800.0</td>\n      <td>NaN</td>\n      <td>NASv3 (CIFAR-10)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>AlphaGo Master</td>\n      <td>Games</td>\n      <td>Go</td>\n      <td>D Silver, J Schrittwieser, K Simonyan, I Anton...</td>\n      <td>Highly cited</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://www.researchgate.net/publication/32047...</td>\n      <td>7831.0</td>\n      <td>Mastering the game of Go without human knowledge</td>\n      <td>...</td>\n      <td>DeepMind</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AlphaGo Master</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AlphaGo Master</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 49 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_pcd_df = pcd_df[pcd_df['System'].isin(frontier_systems)]\n",
    "frontier_pcd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:30.913313500Z",
     "start_time": "2024-02-06T13:29:30.757068800Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(frontier_pcd_df) == len(frontier_systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:31.040180800Z",
     "start_time": "2024-02-06T13:29:30.866431800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                        Price source  Price date  \\\n0  https://web.archive.org/web/20181009102635/htt...  2018-10-09   \n1  https://web.archive.org/web/20181011013513/htt...  2018-10-11   \n2  https://web.archive.org/web/20181011013513/htt...  2018-10-11   \n3  https://web.archive.org/web/20190701021000/htt...  2019-07-01   \n4  https://web.archive.org/web/20190728061708/htt...  2019-07-28   \n\n  Hardware model Manufacturer (from Hardware model)        Vendor  \\\n0  Google TPU v2                             Google  Google Cloud   \n1  Google TPU v3                             Google  Google Cloud   \n2  Google TPU v3                             Google  Google Cloud   \n3  Google TPU v3                             Google  Google Cloud   \n4  Google TPU v3                             Google  Google Cloud   \n\n                     Location Price per chip-hour (on-demand)  \\\n0                          US                           $1.13   \n1                          US                           $2.00   \n2                      Europe                           $2.20   \n3          Iowa (us-central1)                           $2.00   \n4  Netherlands (europe-west4)                           $2.00   \n\n  Price per chip-hour (1-year CUD) Price per chip-hour (3-year CUD)  \\\n0                              NaN                              NaN   \n1                              NaN                              NaN   \n2                              NaN                              NaN   \n3                            $1.26                            $0.90   \n4                            $1.26                            $0.90   \n\n   Price (hardware purchase)  \n0                        NaN  \n1                        NaN  \n2                        NaN  \n3                        NaN  \n4                        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price source</th>\n      <th>Price date</th>\n      <th>Hardware model</th>\n      <th>Manufacturer (from Hardware model)</th>\n      <th>Vendor</th>\n      <th>Location</th>\n      <th>Price per chip-hour (on-demand)</th>\n      <th>Price per chip-hour (1-year CUD)</th>\n      <th>Price per chip-hour (3-year CUD)</th>\n      <th>Price (hardware purchase)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://web.archive.org/web/20181009102635/htt...</td>\n      <td>2018-10-09</td>\n      <td>Google TPU v2</td>\n      <td>Google</td>\n      <td>Google Cloud</td>\n      <td>US</td>\n      <td>$1.13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://web.archive.org/web/20181011013513/htt...</td>\n      <td>2018-10-11</td>\n      <td>Google TPU v3</td>\n      <td>Google</td>\n      <td>Google Cloud</td>\n      <td>US</td>\n      <td>$2.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://web.archive.org/web/20181011013513/htt...</td>\n      <td>2018-10-11</td>\n      <td>Google TPU v3</td>\n      <td>Google</td>\n      <td>Google Cloud</td>\n      <td>Europe</td>\n      <td>$2.20</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://web.archive.org/web/20190701021000/htt...</td>\n      <td>2019-07-01</td>\n      <td>Google TPU v3</td>\n      <td>Google</td>\n      <td>Google Cloud</td>\n      <td>Iowa (us-central1)</td>\n      <td>$2.00</td>\n      <td>$1.26</td>\n      <td>$0.90</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://web.archive.org/web/20190728061708/htt...</td>\n      <td>2019-07-28</td>\n      <td>Google TPU v3</td>\n      <td>Google</td>\n      <td>Google Cloud</td>\n      <td>Netherlands (europe-west4)</td>\n      <td>$2.00</td>\n      <td>$1.26</td>\n      <td>$0.90</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df = pd.read_csv('data/Hardware prices.csv')\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:31.198446100Z",
     "start_time": "2024-02-06T13:29:31.040180800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Price date in datetime format\n",
    "price_df.dropna(subset=['Price date'], inplace=True)\n",
    "price_df['Price date'] = pd.to_datetime(price_df['Price date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:31.318001500Z",
     "start_time": "2024-02-06T13:29:31.166614700Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_hardware_model_colname = 'Name of the hardware (from Training hardware)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:31.466696600Z",
     "start_time": "2024-02-06T13:29:31.318001500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Name of the hardware Manufacturer Type Release date Release price (USD)  \\\n0      3dfx Spectre 1000        Other  GPU          NaN                 NaN   \n1      3dfx Spectre 2000        Other  GPU          NaN                 NaN   \n2      3dfx Spectre 3000        Other  GPU          NaN                 NaN   \n3  3dfx Voodoo4 4000 AGP        Other  GPU          NaN                 NaN   \n4  3dfx Voodoo4 4500 AGP        Other  GPU   2000-10-13                 NaN   \n\n   FP64 (double precision) Performance (FLOP/s)  \\\n0                                           NaN   \n1                                           NaN   \n2                                           NaN   \n3                                           NaN   \n4                                           NaN   \n\n   FP32 (single precision) Performance (FLOP/s)  \\\n0                                           NaN   \n1                                           NaN   \n2                                           NaN   \n3                                           NaN   \n4                                           NaN   \n\n   FP16 (half precision) Performance (FLOP/s)  Tensor Float 32 (TF32)  \\\n0                                         NaN                     NaN   \n1                                         NaN                     NaN   \n2                                         NaN                     NaN   \n3                                         NaN                     NaN   \n4                                         NaN                     NaN   \n\n   FP16 Tensor Core  ...  Foundry  Number of transistors in million  \\\n0               NaN  ...     TSMC                              30.0   \n1               NaN  ...     TSMC                              30.0   \n2               NaN  ...     TSMC                              30.0   \n3               NaN  ...     TSMC                              14.0   \n4               NaN  ...     TSMC                              14.0   \n\n   Prominent Years of usage  \\\n0                       NaN   \n1                       NaN   \n2                       NaN   \n3                       NaN   \n4                       NaN   \n\n   Google Cloud pricing ($ per hour) data from 17 dec 2022  Link to datasheet  \\\n0                                                NaN                      NaN   \n1                                                NaN                      NaN   \n2                                                NaN                      NaN   \n3                                                NaN                      NaN   \n4                                                NaN                      NaN   \n\n   Source for the Price  ALL ML SYSTEMS  All ML Systems copy  \\\n0                   NaN             NaN                  NaN   \n1                   NaN             NaN                  NaN   \n2                   NaN             NaN                  NaN   \n3                   NaN             NaN                  NaN   \n4                   NaN             NaN                  NaN   \n\n   All ML Systems copy.1  Hardware prices  \n0                    NaN              NaN  \n1                    NaN              NaN  \n2                    NaN              NaN  \n3                    NaN              NaN  \n4                    NaN              NaN  \n\n[5 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name of the hardware</th>\n      <th>Manufacturer</th>\n      <th>Type</th>\n      <th>Release date</th>\n      <th>Release price (USD)</th>\n      <th>FP64 (double precision) Performance (FLOP/s)</th>\n      <th>FP32 (single precision) Performance (FLOP/s)</th>\n      <th>FP16 (half precision) Performance (FLOP/s)</th>\n      <th>Tensor Float 32 (TF32)</th>\n      <th>FP16 Tensor Core</th>\n      <th>...</th>\n      <th>Foundry</th>\n      <th>Number of transistors in million</th>\n      <th>Prominent Years of usage</th>\n      <th>Google Cloud pricing ($ per hour) data from 17 dec 2022</th>\n      <th>Link to datasheet</th>\n      <th>Source for the Price</th>\n      <th>ALL ML SYSTEMS</th>\n      <th>All ML Systems copy</th>\n      <th>All ML Systems copy.1</th>\n      <th>Hardware prices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3dfx Spectre 1000</td>\n      <td>Other</td>\n      <td>GPU</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>TSMC</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3dfx Spectre 2000</td>\n      <td>Other</td>\n      <td>GPU</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>TSMC</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3dfx Spectre 3000</td>\n      <td>Other</td>\n      <td>GPU</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>TSMC</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3dfx Voodoo4 4000 AGP</td>\n      <td>Other</td>\n      <td>GPU</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>TSMC</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3dfx Voodoo4 4500 AGP</td>\n      <td>Other</td>\n      <td>GPU</td>\n      <td>2000-10-13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>TSMC</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 38 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hardware_df = pd.read_csv('data/Chip dataset-Grid view.csv')\n",
    "hardware_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training hardware: k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:31.607623800Z",
     "start_time": "2024-02-06T13:29:31.466696600Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop unneeded columns from frontier_pcd_df\n",
    "irrelevant_columns = ['Notability criteria', 'Notability criteria notes', 'Link', 'Citations', 'Parameters notes',\n",
    "                      'Training compute notes', 'Training dataset notes', 'Dataset size notes',\n",
    "                      'Inference compute notes', 'Approach', 'Confidence', 'Last modified', 'Created By', 'Benchmark data',\n",
    "                      'Exclude', 'Authors by country', 'Training cost trends', 'Abstract', 'Compute cost notes',\n",
    "                      'Training time notes', 'Authors', 'Name of the hardware (from Training hardware)',\n",
    "                      'Training compute cost (2020 USD)', 'Organization categorization',\n",
    "                      'Training dataset', 'Inference compute (FLOP)', 'Compute sponsor categorization',\n",
    "                      'Finetune compute notes']\n",
    "frontier_pcd_df = frontier_pcd_df.drop(columns=irrelevant_columns)\n",
    "\n",
    "# fill column 'Training cloud compute vendor' using org_to_cloud_vendor dictionary\n",
    "org_to_cloud_vendor = {\n",
    "    'Google': 'Google Cloud',\n",
    "    'DeepMind': 'Google Cloud',\n",
    "    'Google DeepMind': 'Google Cloud',\n",
    "    'Google Brain': 'Google Cloud',\n",
    "    'Microsoft': 'Microsoft Azure',\n",
    "    'OpenAI': 'Microsoft Azure',\n",
    "}\n",
    "frontier_pcd_df['Training cloud compute vendor'] = frontier_pcd_df['Organization (from Organization)'].map(org_to_cloud_vendor)\n",
    "frontier_pcd_df['Training cloud compute vendor'] = frontier_pcd_df['Training cloud compute vendor'].fillna('Amazon Web Services')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:33.231060800Z",
     "start_time": "2024-02-06T13:29:31.607623800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "2\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Import KNNImputer from sklearn\n",
    "from sklearn.impute import KNNImputer\n",
    "# instantiate the imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# convert datetime to float\n",
    "frontier_pcd_df['Publication date'] = frontier_pcd_df['Publication date'].dt.year + (frontier_pcd_df['Publication date'].dt.month-1) / 12 + (frontier_pcd_df['Publication date'].dt.day-1) / 365\n",
    "\n",
    "# set the System column as the index\n",
    "frontier_pcd_df = frontier_pcd_df.set_index('System')\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = frontier_pcd_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# one-hot encode all categorical columns\n",
    "one_hot_pcd_df = pd.get_dummies(frontier_pcd_df, columns=categorical_cols)\n",
    "\n",
    "# impute the missing values in Training hardware, hardware quantity, Training time (hours)\n",
    "imputed = imputer.fit_transform(one_hot_pcd_df)\n",
    "\n",
    "# convert the numpy array back to a dataframe\n",
    "imputed_pcd_df = pd.DataFrame(imputed, columns=one_hot_pcd_df.columns)\n",
    "\n",
    "# convert Training hardware back to categorical\n",
    "imputed_pcd_df['Training hardware'] = ''\n",
    "for col in imputed_pcd_df.columns:\n",
    "    if col.startswith('Training hardware_'):\n",
    "        training_hardware = col.split('Training hardware_')[1]\n",
    "        imputed_pcd_df['Training hardware'] = imputed_pcd_df['Training hardware'] + pd.Series([int(_) * training_hardware for _ in imputed_pcd_df[col]])\n",
    "\n",
    "# replace all '' with np.nan\n",
    "imputed_pcd_df['Training hardware'] = imputed_pcd_df['Training hardware'].replace('', np.nan)\n",
    "\n",
    "def impute_training_hardware(dataframe, n=5):\n",
    "    # use KNeighborsClassifier to impute the missing values in Training hardware\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # Separate the target and features\n",
    "    target_col = 'Training hardware'\n",
    "    features = dataframe.drop(target_col, axis=1)\n",
    "    target = dataframe[target_col]\n",
    "\n",
    "    # Encode the target column\n",
    "    label_encoder = LabelEncoder()\n",
    "    target_filled = target.fillna('Unknown')  # Temporarily fill missing values\n",
    "    target_encoded = label_encoder.fit_transform(target_filled)\n",
    "\n",
    "    # Train a KNeighborsClassifier\n",
    "    knc = KNeighborsClassifier(n_neighbors=n)\n",
    "    knc.fit(features, target_encoded)\n",
    "\n",
    "    # Predict the missing values\n",
    "    missing_values = features[target.isna()]\n",
    "    predicted = knc.predict(missing_values)\n",
    "\n",
    "    # Decode the predictions\n",
    "    predicted_labels = label_encoder.inverse_transform(predicted)\n",
    "\n",
    "    # Replace the missing values with the predictions\n",
    "    dataframe.loc[target.isna(), target_col] = predicted_labels\n",
    "\n",
    "    # replace all 'Unknown' with np.nan\n",
    "    dataframe['Training hardware'] = dataframe['Training hardware'].replace('Unknown', np.nan)\n",
    "\n",
    "missing_values = imputed_pcd_df['Training hardware'].isna().sum()\n",
    "N = 5\n",
    "while missing_values > 0:\n",
    "    impute_training_hardware(imputed_pcd_df, n=N)\n",
    "    print(imputed_pcd_df['Training hardware'].isna().sum())\n",
    "    if imputed_pcd_df['Training hardware'].isna().sum() == missing_values:\n",
    "        N += 5\n",
    "    else:\n",
    "        missing_values = imputed_pcd_df['Training hardware'].isna().sum()\n",
    "\n",
    "# restore the System column\n",
    "imputed_pcd_df['System'] = one_hot_pcd_df.index\n",
    "\n",
    "# set the System column as the index\n",
    "imputed_pcd_df = imputed_pcd_df.set_index('System')\n",
    "\n",
    "# insert imputed values into frontier_pcd_df\n",
    "frontier_pcd_df['Training hardware'] = imputed_pcd_df['Training hardware']\n",
    "frontier_pcd_df['Hardware quantity'] = imputed_pcd_df['Hardware quantity']\n",
    "frontier_pcd_df['Hardware utilization'] = imputed_pcd_df['Hardware utilization']\n",
    "frontier_pcd_df['Training time (hours)'] = imputed_pcd_df['Training time (hours)']\n",
    "frontier_pcd_df['Training time (chip hours)'] = frontier_pcd_df['Training time (hours)'] * frontier_pcd_df['Hardware quantity']\n",
    "\n",
    "# calculate training time (chip hours) from training time and hardware quantity\n",
    "frontier_pcd_df['Training time (chip hours)'] = frontier_pcd_df['Training time (hours)'] * frontier_pcd_df['Hardware quantity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLOP/second (flops) utilization: mean of known values\n",
    "\n",
    "TODO: random sample from distribution, combined with bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:33.293976200Z",
     "start_time": "2024-02-06T13:29:33.231060800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of chip-hours\n",
    "\n",
    "If num_chips AND training_time_hours known: chip_hours = num_chips * training_time_hours\n",
    "\n",
    "Else if num_chips unknown: \n",
    "\n",
    "Else if training_time_hours unknown: \n",
    "\n",
    "Else (both unknown): chip_hours = training_compute_flop / (chip_flops * flops_utilization * SECONDS_PER_HOUR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:33.389347400Z",
     "start_time": "2024-02-06T13:29:33.247089Z"
    }
   },
   "outputs": [],
   "source": [
    "chip_hours = []\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    if pd.isna(row['Hardware quantity']) or pd.isna(row['Training time (hours)']):\n",
    "        # TODO impute missing values\n",
    "        chip_hours.append(np.nan)\n",
    "    else:\n",
    "        chip_hours.append(row['Hardware quantity'] * row['Training time (hours)'])\n",
    "\n",
    "frontier_pcd_df['Training time (chip hours)'] = chip_hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use a fixed mapping from Organization to cloud provider. If no mapping found, default to \"Amazon Web Services\".\n",
    "2. If there's a match for the hardware model, use that. Else, discard the ML system from the dataset.\n",
    "3. Use the price that is nearest to, but prior to, training time + 2 months before the publication date\n",
    "4. If there are no prices prior to that time, use the nearest price after that time\n",
    "5. If there are no prices for that hardware model and cloud provider at all, repeat steps 3 and 4 for \"Microsoft Azure\", then \"Google Cloud\" as the cloud provider.\n",
    "6. If there are no prices found from step 5, discard the ML system from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:33.514742500Z",
     "start_time": "2024-02-06T13:29:33.389347400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price date: 2019-07-01 00:00:00\n",
      "Price: $1.26\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "example_vendor = \"Google Cloud\"\n",
    "example_hardware_model = \"Google TPU v3\"\n",
    "example_date = \"2019-07-15\" # Example date, format should be YYYY-MM-DD\n",
    "\n",
    "# Find the row\n",
    "closest_row_df = find_closest_price_dates(example_vendor, example_hardware_model, example_date, price_df)\n",
    "\n",
    "for i, row in closest_row_df.iterrows():\n",
    "    if row['Price date'] <= pd.to_datetime(example_date):\n",
    "        print(f\"Price date: {row['Price date']}\")\n",
    "        print(f\"Price: {row['Price per chip-hour (1-year CUD)']}\")\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:33.644617200Z",
     "start_time": "2024-02-06T13:29:33.514742500Z"
    }
   },
   "outputs": [],
   "source": [
    "org_to_cloud_vendor = {\n",
    "    'google': 'Google Cloud',\n",
    "    'deepmind': 'Google Cloud',\n",
    "    'microsoft': 'Microsoft Azure',\n",
    "    'openai': 'Microsoft Azure',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:33.755108400Z",
     "start_time": "2024-02-06T13:29:33.644617200Z"
    }
   },
   "outputs": [],
   "source": [
    "frontier_pcd_df['System'] = frontier_pcd_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:33.869879900Z",
     "start_time": "2024-02-06T13:29:33.755108400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert float year to datetime\n",
    "def float_year_to_datetime(float_year):\n",
    "    year = int(float_year)\n",
    "    remainder = float_year - year\n",
    "    days_in_year = 365 + int(pd.Timestamp(year=year, month=12, day=31).is_leap_year)\n",
    "    day_of_year = int(remainder * days_in_year)\n",
    "    return pd.Timestamp(year=year, month=1, day=1) + pd.to_timedelta(day_of_year, unit='D')\n",
    "\n",
    "frontier_pcd_df['Publication date'] = frontier_pcd_df['Publication date'].apply(float_year_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:33.982359900Z",
     "start_time": "2024-02-06T13:29:33.869879900Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_hardware_model_colname = 'Training hardware'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:34.357949200Z",
     "start_time": "2024-02-06T13:29:33.984481300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== System: AlphaGo Fan ====\n",
      "Trying Google TPU v3 at 2015-07-17 09:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: AlphaGo Lee ====\n",
      "Trying Google TPU v3 at 2015-11-12 09:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: GNMT ====\n",
      "Trying NVIDIA Tesla K80 at 2016-01-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 1.4\n",
      "\n",
      "==== System: NASv3 (CIFAR-10) ====\n",
      "Trying Google TPU v3 at 2016-08-21 09:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: AlphaGo Master ====\n",
      "Trying Google TPU v1 at 2016-08-07 15:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v1\n",
      "==== System: JFT ====\n",
      "Trying NVIDIA Tesla K80 at 2017-03-13 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 1.4\n",
      "\n",
      "==== System: OpenAI TI7 DOTA 1v1 ====\n",
      "Trying Google TPU v3 at 2017-05-27 09:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v3\n",
      "==== System: AlphaGo Zero ====\n",
      "Trying Google TPU v1 at 2017-07-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v1\n",
      "==== System: AlphaZero ====\n",
      "Trying Google TPU v2 at 2017-08-12 14:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 1.13\n",
      "\n",
      "==== System: AmoebaNet-A (F=448) ====\n",
      "Trying NVIDIA Tesla K40s at 2017-11-29 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Estimated price: 0.052760065856088875\n",
      "\n",
      "==== System: IMPALA ====\n",
      "Trying NVIDIA P100 at 2017-12-01 20:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 1.46\n",
      "\n",
      "==== System: ResNeXt-101 32x48d ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2018-01-10 21:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: FTW ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2018-03-13 21:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: BigGAN-deep 512x512 ====\n",
      "Trying Google TPU v3 at 2018-07-28 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: RoBERTa Large ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-04-28 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: Megatron-BERT ====\n",
      "Trying NVIDIA Tesla V100S PCIe 32 GB at 2019-05-22 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Estimated price: 0.1051277082983274\n",
      "\n",
      "==== System: Megatron-LM (8.3B) ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-07-05 09:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: T5-3B ====\n",
      "Trying Google TPU v3 at 2019-08-08 09:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: T5-11B ====\n",
      "Trying Google TPU v3 at 2019-08-03 23:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: AlphaStar ====\n",
      "Trying Google TPU v3 at 2019-07-18 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: OpenAI Five ====\n",
      "Trying Google TPU v3 at 2018-12-22 00:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v3\n",
      "==== System: OpenAI Five Rerun ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-08-22 21:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: Meena ====\n",
      "Trying Google TPU v3 at 2019-10-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: Turing-NLG ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-11-01 00:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: GPT-3 175B (davinci) ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2020-03-15 05:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.29\n",
      "\n",
      "==== System: GShard (dense) ====\n",
      "Trying Google TPU v3 at 2020-03-20 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: ALIGN ====\n",
      "Trying Google TPU v3 at 2021-03-29 13:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: Megatron-Turing NLG 530B ====\n",
      "Trying NVIDIA A100 SXM4 80 GB at 2021-07-10 22:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.62\n",
      "\n",
      "==== System: Yuan 1.0 ====\n",
      "Trying Google TPU v1 at 2021-07-07 13:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v1\n",
      "==== System: Gopher (280B) ====\n",
      "Trying Google TPU v3 at 2021-08-31 16:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: GLaM ====\n",
      "Trying Google TPU v4 at 2021-08-18 02:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: LaMDA ====\n",
      "Trying Google TPU v3 at 2021-10-14 07:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 1.26\n",
      "\n",
      "==== System: Chinchilla ====\n",
      "Trying Google TPU v4 at 2021-12-18 14:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: PaLM (540B) ====\n",
      "Trying Google TPU v4 at 2021-12-09 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: OPT-175B ====\n",
      "Trying NVIDIA A100 SXM4 80 GB at 2022-01-29 23:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 3.0\n",
      "\n",
      "==== System: Minerva (540B) ====\n",
      "Trying Google TPU v4 at 2022-04-02 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: GPT-3.5 (text-davinci-003) ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2022-06-25 10:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.4\n",
      "\n",
      "==== System: LLaMA-65B ====\n",
      "Trying NVIDIA A100 at 2022-12-04 04:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.35\n",
      "\n",
      "==== System: GPT-4 ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2022-10-12 00:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.4\n",
      "\n",
      "==== System: PaLM 2 ====\n",
      "Trying Google TPU v4 at 2022-12-06 10:00:00\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.03\n",
      "\n",
      "==== System: Claude 2 ====\n",
      "Trying Google TPU v4 at 2023-02-06 10:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Estimating price from FLOP/s and FLOP/$ trend\n",
      "Could not find FLOP/s for Google TPU v4\n",
      "==== System: Llama 2-70B ====\n",
      "Trying NVIDIA A100 SXM4 80 GB at 2022-11-21 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 3.0\n",
      "\n",
      "==== System: Falcon 180B ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2023-01-09 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Found price: 2.4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'AlphaGo Fan': 2.0,\n 'AlphaGo Lee': 2.0,\n 'GNMT': 1.4,\n 'NASv3 (CIFAR-10)': 2.0,\n 'JFT': 1.4,\n 'AlphaZero': 1.13,\n 'AmoebaNet-A (F=448)': 0.052760065856088875,\n 'IMPALA': 1.46,\n 'ResNeXt-101 32x48d': 2.29,\n 'FTW': 2.29,\n 'BigGAN-deep 512x512': 2.0,\n 'RoBERTa Large': 2.29,\n 'Megatron-BERT': 0.1051277082983274,\n 'Megatron-LM (8.3B)': 2.29,\n 'T5-3B': 1.26,\n 'T5-11B': 1.26,\n 'AlphaStar': 1.26,\n 'OpenAI Five Rerun': 2.29,\n 'Meena': 1.26,\n 'Turing-NLG': 2.29,\n 'GPT-3 175B (davinci)': 2.29,\n 'GShard (dense)': 1.26,\n 'ALIGN': 1.26,\n 'Megatron-Turing NLG 530B': 2.62,\n 'Gopher (280B)': 1.26,\n 'GLaM': 2.03,\n 'LaMDA': 1.26,\n 'Chinchilla': 2.03,\n 'PaLM (540B)': 2.03,\n 'OPT-175B': 3.0,\n 'Minerva (540B)': 2.03,\n 'GPT-3.5 (text-davinci-003)': 2.4,\n 'LLaMA-65B': 2.35,\n 'GPT-4': 2.4,\n 'PaLM 2': 2.03,\n 'Llama 2-70B': 3.0,\n 'Falcon 180B': 2.4}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_colname = 'Price per chip-hour (1-year CUD)'\n",
    "system_to_price = {}\n",
    "\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    price = find_price(row, price_df, hardware_df, pcd_hardware_model_colname, price_colname, org_to_cloud_vendor)\n",
    "    if price is None:\n",
    "        continue\n",
    "    else:\n",
    "        system_to_price[row['System']] = price\n",
    "\n",
    "system_to_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: inflation adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost = price_per_chip_hour * chip_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:34.492912Z",
     "start_time": "2024-02-06T13:29:34.357949200Z"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_cost(row, system_to_price):\n",
    "    system = row['System']\n",
    "    price = system_to_price.get(system)\n",
    "    if price is None:\n",
    "        return None\n",
    "\n",
    "    chip_hours = row['Training time (chip hours)']\n",
    "    if np.isnan(chip_hours):\n",
    "        return None\n",
    "\n",
    "    cost = price * chip_hours\n",
    "\n",
    "    # Check for base model\n",
    "    if not pd.isna(row['Base model']):\n",
    "        base_model_name = row['Base model']\n",
    "        base_model = frontier_pcd_df[frontier_pcd_df['System'] == base_model_name].squeeze()\n",
    "        base_cost = estimate_cost(base_model, system_to_price)\n",
    "        if base_cost is None:\n",
    "            return None\n",
    "        else:\n",
    "            cost += base_cost\n",
    "\n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:34.601374400Z",
     "start_time": "2024-02-06T13:29:34.492912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'AlphaGo Fan': 233674.55999999997,\n 'AlphaGo Lee': 233674.55999999997,\n 'GNMT': 580608.0,\n 'NASv3 (CIFAR-10)': 600320.0,\n 'JFT': 100800.0,\n 'AlphaZero': 94481.7408,\n 'AmoebaNet-A (F=448)': 3988.660978720319,\n 'IMPALA': 146.0,\n 'ResNeXt-101 32x48d': 962569.4400000001,\n 'FTW': 1274258.5920000002,\n 'BigGAN-deep 512x512': 24576.0,\n 'RoBERTa Large': 281395.2,\n 'Megatron-BERT': 74924.93821505114,\n 'Megatron-LM (8.3B)': 383400.96,\n 'T5-3B': 147214.9728,\n 'T5-11B': 310883.328,\n 'AlphaStar': 510935.04,\n 'OpenAI Five Rerun': 1466772.48,\n 'Meena': 928972.8,\n 'Turing-NLG': 605269.3504,\n 'GPT-3 175B (davinci)': 8134080.0,\n 'GShard (dense)': 1300561.92,\n 'ALIGN': 224050.176,\n 'Megatron-Turing NLG 530B': 9037952.0,\n 'Gopher (280B)': 4748083.2,\n 'GLaM': 2839531.5199999996,\n 'LaMDA': 1786982.4,\n 'Chinchilla': 3513681.2031999994,\n 'PaLM (540B)': 17062133.759999998,\n 'OPT-175B': 2437632.0,\n 'Minerva (540B)': 18508922.88,\n 'GPT-3.5 (text-davinci-003)': 21853839.36,\n 'LLaMA-65B': 2406400.0,\n 'GPT-4': 136800000.0,\n 'PaLM 2': 18484705.792,\n 'Llama 2-70B': 31518720.0,\n 'Falcon 180B': 42467328.0}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_to_cost = {}\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    cost = estimate_cost(row, system_to_price)\n",
    "    if cost is None:\n",
    "        continue\n",
    "    system_to_cost[row['System']] = cost\n",
    "\n",
    "system_to_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:34.716758200Z",
     "start_time": "2024-02-06T13:29:34.601374400Z"
    }
   },
   "outputs": [],
   "source": [
    "for system, cost in system_to_cost.items():\n",
    "    frontier_pcd_df.loc[system, 'Cost'] = cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply inflation adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:34.826641900Z",
     "start_time": "2024-02-06T13:29:34.716758200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Domain', 'Task', 'Open-source', 'Reference', 'Publication date',\n       'Organization', 'Parameters', 'Training compute (FLOP)',\n       'Training dataset size (datapoints)', 'Epochs', 'Training time (hours)',\n       'Training hardware', 'Country (from Organization)',\n       'Organization (from Organization)', 'Base model',\n       'Finetune compute (FLOP)', 'Hardware quantity', 'Hardware utilization',\n       'Training cloud compute vendor', 'Training data center',\n       'Training time (chip hours)', 'System', 'Cost'],\n      dtype='object')"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_pcd_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:34.938170700Z",
     "start_time": "2024-02-06T13:29:34.826641900Z"
    }
   },
   "outputs": [],
   "source": [
    "from_year_month = frontier_pcd_df['Publication date'].apply(str)\n",
    "frontier_pcd_df['Publication date'] = from_year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T13:29:35.050503400Z",
     "start_time": "2024-02-06T13:29:34.938170700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "System\nAlphaGo Fan                   2015-10-01 00:00:00\nAlphaGo Lee                   2016-01-27 00:00:00\nGNMT                          2016-09-26 00:00:00\nNASv3 (CIFAR-10)              2016-11-05 00:00:00\nAlphaGo Master                2017-01-01 00:00:00\nJFT                           2017-07-11 00:00:00\nOpenAI TI7 DOTA 1v1           2017-08-11 00:00:00\nAlphaGo Zero                  2017-10-18 00:00:00\nAlphaZero                     2017-12-05 00:00:00\nAmoebaNet-A (F=448)           2018-02-04 00:00:00\nIMPALA                        2018-02-04 00:00:00\nResNeXt-101 32x48d            2018-05-03 00:00:00\nFTW                           2018-07-04 00:00:00\nBigGAN-deep 512x512           2018-09-28 00:00:00\nRoBERTa Large                 2019-07-02 00:00:00\nMegatron-BERT                 2019-09-17 00:00:00\nMegatron-LM (8.3B)            2019-09-17 00:00:00\nT5-3B                         2019-10-23 00:00:00\nT5-11B                        2019-10-23 00:00:00\nAlphaStar                     2019-10-30 00:00:00\nOpenAI Five                   2019-12-13 00:00:00\nOpenAI Five Rerun             2019-12-13 00:00:00\nMeena                         2020-01-28 00:00:00\nTuring-NLG                    2020-02-12 00:00:00\nGPT-3 175B (davinci)          2020-05-29 00:00:00\nGShard (dense)                2020-06-30 00:00:00\nALIGN                         2021-06-12 00:00:00\nMegatron-Turing NLG 530B      2021-10-11 00:00:00\nYuan 1.0                      2021-10-12 00:00:00\nGopher (280B)                 2021-12-08 00:00:00\nGLaM                          2021-12-13 00:00:00\nLaMDA                         2022-02-09 00:00:00\nChinchilla                    2022-03-30 00:00:00\nPaLM (540B)                   2022-04-05 00:00:00\nOPT-175B                      2022-05-03 00:00:00\nMinerva (540B)                2022-06-30 00:00:00\nGPT-3.5 (text-davinci-003)    2022-11-28 00:00:00\nLLaMA-65B                     2023-02-23 00:00:00\nGPT-4                         2023-03-16 00:00:00\nPaLM 2                        2023-05-11 00:00:00\nClaude 2                      2023-07-12 00:00:00\nLlama 2-70B                   2023-07-19 00:00:00\nFalcon 180B                   2023-09-06 00:00:00\nName: Publication date, dtype: object"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_pcd_df['Publication date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "frontier_pcd_df = adjust_column_for_inflation(frontier_pcd_df, 'Cost', 'data/PCU518210518210.csv', '2023-12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    system = row['System']\n",
    "    cost = system_to_cost.get(system)\n",
    "    if cost is None:\n",
    "        continue\n",
    "    publication_date = row['Publication date']\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[publication_date],\n",
    "        y=[cost],\n",
    "        name=system,\n",
    "        text=system,\n",
    "        textposition='top center',\n",
    "        line=dict(color='#034752'),\n",
    "        mode='markers+text',\n",
    "    ))\n",
    "\n",
    "# log y axis\n",
    "fig.update_yaxes(type=\"log\")\n",
    "# no legend\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# axis labels\n",
    "fig.update_xaxes(title_text='Publication date')\n",
    "fig.update_yaxes(title_text='Cost (USD, nominal)')\n",
    "\n",
    "# title\n",
    "fig.update_layout(title_text='Cost of cloud compute to train frontier ML systems')\n",
    "\n",
    "# update size\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# font size\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=14,\n",
    "    )\n",
    ")\n",
    "\n",
    "# axis limits\n",
    "# fig.update_xaxes(range=['2017-01-01', '2025-01-01'])\n",
    "# fig.update_yaxes(range=[5, 8])\n",
    "\n",
    "# margins\n",
    "fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "save_plot(fig, 'results/', 'cost_scatter')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, row in frontier_pcd_df.iterrows():\n",
    "    system = row['System']\n",
    "    cost = system_to_cost.get(system)\n",
    "    if cost is None:\n",
    "        continue\n",
    "    publication_date = row['Publication date']\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[system],\n",
    "        y=[cost],\n",
    "        name=system,\n",
    "        # nice blue color\n",
    "        marker_color='#034752',\n",
    "        # text=system,\n",
    "        # textposition='auto',\n",
    "    ))\n",
    "\n",
    "# log y axis\n",
    "fig.update_yaxes(type=\"log\")\n",
    "# no legend\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# axis labels\n",
    "fig.update_xaxes(title_text='System')\n",
    "fig.update_yaxes(title_text='Cost (USD, nominal)')\n",
    "\n",
    "# title\n",
    "fig.update_layout(title_text='Cost of cloud compute to train frontier ML systems')\n",
    "\n",
    "# update size\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# font size\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=14,\n",
    "    )\n",
    ")\n",
    "\n",
    "# axis limits\n",
    "fig.update_yaxes(range=[0, 8])\n",
    "\n",
    "# margins\n",
    "fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_pcd_df.drop('Megatron-BERT', inplace=True)\n",
    "frontier_pcd_df.drop('IMPALA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_pcd_df.to_csv('results/price dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
