{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:30.211131Z",
     "start_time": "2024-02-07T16:04:29.911625700Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:30.226710800Z",
     "start_time": "2024-02-07T16:04:30.020995300Z"
    },
    "id": "qltoZ7TbdkHZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from cost import *\n",
    "from plotting import *\n",
    "from prices import *\n",
    "from imputation import *\n",
    "from inflation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/new-models/'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bencottier/Projects/training_cost_2/training-cost-trends/cost.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  frontier_pcd_df['Training compute (FLOP)'] = pd.to_numeric(frontier_pcd_df['Training compute (FLOP)'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "frontier_pcd_df, hardware_df, price_df = load_data_for_cost_estimation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 5508, 69)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frontier_pcd_df), len(hardware_df), len(price_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Gemini Ultra\n",
    "# frontier_pcd_df = frontier_pcd_df[frontier_pcd_df['System'] != 'Gemini Ultra']\n",
    "# frontier_pcd_df = frontier_pcd_df[frontier_pcd_df['System'] != 'GPT-4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== System: Yuan 1.0 ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: OpenAI TI7 DOTA 1v1 ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Claude 2 ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Turing-NLG ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: GPT-3.5 (text-davinci-003) ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: AlphaGo Master ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Minerva (540B) ====\n",
      "Trying Google TPU v4 at 2022-04-01 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "==== System: FTW ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: AlphaGo Zero ====\n",
      "Trying Google TPU v1 at 2017-07-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "==== System: NASv3 (CIFAR-10) ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: AlphaZero ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: PaLM (540B) ====\n",
      "Trying Google TPU v4 at 2021-12-08 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "==== System: OPT-175B ====\n",
      "Trying NVIDIA A100 SXM4 80 GB at 2022-01-28 23:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.81\n",
      "\n",
      "==== System: ALIGN ====\n",
      "Trying Google TPU v3 at 2021-03-28 13:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.9\n",
      "\n",
      "==== System: AlphaGo Fan ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: GPT-4 ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2022-10-11 00:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "==== System: GLaM ====\n",
      "Trying Google TPU v4 at 2021-08-18 02:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "==== System: AlphaGo Lee ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: AlphaStar ====\n",
      "Trying Google TPU v3 at 2019-07-18 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.9\n",
      "\n",
      "==== System: OpenAI Five ====\n",
      "Could not find hardware model for OpenAI Five\n",
      "\n",
      "==== System: RoBERTa Large ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-04-27 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.21\n",
      "\n",
      "==== System: OpenAI Five Rerun ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: GNMT ====\n",
      "Trying NVIDIA Tesla K80 at 2016-01-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.43\n",
      "\n",
      "==== System: GShard (dense) ====\n",
      "Trying Google TPU v3 at 2020-03-20 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.9\n",
      "\n",
      "==== System: AlphaCode ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Megatron-LM (8.3B) ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2019-07-05 09:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.21\n",
      "\n",
      "==== System: Gopher (280B) ====\n",
      "Trying Google TPU v3 at 2021-08-31 16:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.9\n",
      "\n",
      "==== System: Meena ====\n",
      "Trying Google TPU v3 at 2019-10-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.9\n",
      "\n",
      "==== System: IMPALA ====\n",
      "Trying NVIDIA P100 at 2017-12-02 20:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.28\n",
      "\n",
      "==== System: PaLM 2 ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Megatron-BERT ====\n",
      "Trying NVIDIA Tesla V100S PCIe 32 GB at 2019-05-22 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "==== System: Falcon 180B ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2023-01-09 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "==== System: JFT ====\n",
      "Trying NVIDIA Tesla K80 at 2017-03-12 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.43\n",
      "\n",
      "==== System: AmoebaNet-A (F=448) ====\n",
      "Trying NVIDIA Tesla K40s at 2017-11-30 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "==== System: Megatron-Turing NLG 530B ====\n",
      "Trying NVIDIA A100 SXM4 80 GB at 2021-07-10 22:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.8\n",
      "\n",
      "==== System: T5-3B ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: LaMDA ====\n",
      "Trying Google TPU v3 at 2021-10-15 07:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.9\n",
      "\n",
      "==== System: T5-11B ====\n",
      "Trying Google TPU v3 at 2019-08-03 23:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.9\n",
      "\n",
      "==== System: BigGAN-deep 512x512 ====\n",
      "Trying Google TPU v3 at 2018-07-28 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 2.0\n",
      "\n",
      "==== System: ResNeXt-101 32x48d ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Chinchilla ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: ERNIE 3.0 Titan ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: LLaMA-65B ====\n",
      "Trying NVIDIA A100 at 2022-12-05 04:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.36\n",
      "\n",
      "==== System: DALL-E ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: GPT-2 (1.5B) ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: GOAT ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Switch ====\n",
      "Trying Google TPU v3 at 2020-10-16 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.9\n",
      "\n",
      "==== System: iGPT-XL ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Parti ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: mT5-XXL ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: ByT5-XXL ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: BlenderBot 3 ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: ChatGLM3 ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Yi-34B ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Qwen-72B ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: Gemini Ultra ====\n",
      "Trying Google TPU v4 at 2023-06-29 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "==== System: ProtT5-XXL ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: GPT-3 175B (davinci) ====\n",
      "Trying NVIDIA Tesla V100 DGXS 32 GB at 2020-03-14 05:00:00\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.21\n",
      "\n",
      "==== System: Inflection-2 ====\n",
      "Training time is required but no value found\n",
      "\n",
      "==== System: BERT-Large ====\n",
      "Trying Google TPU v2 at 2018-08-08 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Found price: 1.13\n",
      "\n",
      "==== System: Meta Pseudo Labels ====\n",
      "Trying Google TPU v3 at 2020-12-20 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 0.9\n",
      "\n",
      "==== System: Llama 2-70B ====\n",
      "Trying NVIDIA A100 SXM4 80 GB at 2022-11-20 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.81\n",
      "\n",
      "==== System: U-PaLM (540B) ====\n",
      "Trying Google TPU v4 at 2022-08-16 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "==== System: HyperClova ====\n",
      "Trying NVIDIA A100 at 2021-06-15 05:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.44\n",
      "\n",
      "==== System: PanGu-Σ ====\n",
      "Trying Huawei Ascend 910 at 2022-10-11 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (1-year CUD)\n",
      "Could not find price\n",
      "Trying Amazon Web Services, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Microsoft Azure, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "Trying Google Cloud, Price per chip-hour (on-demand)\n",
      "Could not find price\n",
      "==== System: GLM-130B ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2022-04-06 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "==== System: Flamingo ====\n",
      "Trying Google TPU v4 at 2022-02-13 00:00:00\n",
      "Trying Google Cloud, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "==== System: GPT-NeoX-20B ====\n",
      "Trying NVIDIA A100 SXM4 40 GB at 2021-09-12 00:00:00\n",
      "Trying Amazon Web Services, Price per chip-hour (3-year CUD)\n",
      "Found price: 1.45\n",
      "\n",
      "{'Minerva (540B)': 13220659.200000001, 'PaLM (540B)': 12187238.4, 'OPT-175B': 1470704.6400000001, 'ALIGN': 160035.84, 'GPT-4': 82650000.0, 'GLaM': 2028236.8, 'AlphaStar': 364953.60000000003, 'RoBERTa Large': 148684.8, 'GNMT': 178329.6, 'GShard (dense)': 928972.8, 'Megatron-LM (8.3B)': 202583.04, 'Gopher (280B)': 3391488.0, 'Meena': 663552.0, 'IMPALA': 128.0, 'Falcon 180B': 25657344.0, 'JFT': 30960.0, 'Megatron-Turing NLG 530B': 6209280.0, 'LaMDA': 1276416.0, 'T5-11B': 222059.52, 'BigGAN-deep 512x512': 24576.0, 'LLaMA-65B': 1392640.0, 'Switch': 597196.8, 'Gemini Ultra': 191400000.0, 'GPT-3 175B (davinci)': 4297920.0, 'BERT-Large': 6942.719999999999, 'Meta Pseudo Labels': 243302.4, 'Llama 2-70B': 3127680.0, 'U-PaLM (540B)': 12276326.4, 'HyperClova': 948436.9920000001, 'GLM-130B': 1603584.0, 'Flamingo': 801792.0, 'GPT-NeoX-20B': 300672.0}\n"
     ]
    }
   ],
   "source": [
    "cost_df = estimate_costs(frontier_pcd_df, hardware_df, price_df, impute_pcd_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Notability criteria</th>\n",
       "      <th>Notability criteria notes</th>\n",
       "      <th>Open-source</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>...</th>\n",
       "      <th>Training cloud compute vendor</th>\n",
       "      <th>Training data center</th>\n",
       "      <th>Archived links</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Batch size notes</th>\n",
       "      <th>Datasets</th>\n",
       "      <th>Organization categorization</th>\n",
       "      <th>System</th>\n",
       "      <th>Training time (chip hours)</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yuan 1.0</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Shaohua Wu, Xudong Zhao, Tong Yu, Rongguo Zhan...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"The zero-shot average scores of both LM and P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2110.04725</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Yuan 1.0: Large-Scale Pre-trained Language Mod...</td>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6881280.0</td>\n",
       "      <td>Table 2. Batch size 3360, sequence length 2048...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Yuan 1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI TI7 DOTA 1v1</th>\n",
       "      <td>Games</td>\n",
       "      <td>DOTA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTA Improvement,Historical significance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://openai.com/research/dota-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dota 2</td>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claude 2</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historical significance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>API accessible</td>\n",
       "      <td>https://www.anthropic.com/index/claude-2, http...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Claude 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turing-NLG</th>\n",
       "      <td>Language</td>\n",
       "      <td>Text autocompletion</td>\n",
       "      <td>Corby Rosset</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>from paper: \"Turing Natural Language Generatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.microsoft.com/en-us/research/blog/...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Turing-NLG: A 17-billion-parameter language mo...</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Turing-NLG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3.5 (text-davinci-003)</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTA Improvement,Historical significance,Signi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>API accessible</td>\n",
       "      <td>https://platform.openai.com/docs/models/gpt-3-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>GPT-3.5 (text-davinci-003)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HyperClova</th>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boseop Kim, HyoungSeok Kim, Sang-Woo Lee, Gich...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"HyperCLOVA with our training configuration sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2109.04650</td>\n",
       "      <td>79.0</td>\n",
       "      <td>What Changes Can Large-scale Language Models B...</td>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"All models use the mini-batch size of 1,024\"....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry,Industry</td>\n",
       "      <td>HyperClova</td>\n",
       "      <td>658636.8</td>\n",
       "      <td>948436.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PanGu-Σ</th>\n",
       "      <td>Language</td>\n",
       "      <td>Code generation,Language modelling</td>\n",
       "      <td>Xiaozhe Ren, Pingyi Zhou, Xinfan Meng, Xinjing...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"Our experimental findings show that PanGu-{\\S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2303.10845</td>\n",
       "      <td>28.0</td>\n",
       "      <td>PanGu-Σ: Towards Trillion Parameter Language M...</td>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>524288.0</td>\n",
       "      <td>\"We train PanGu-Σ with global batch size of 51...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>PanGu-Σ</td>\n",
       "      <td>1228800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM-130B</th>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"GLM-130B achieves an accuracy of 80.2% on zer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://keg.cs.tsinghua.edu.cn/glm-130b/posts/...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>GLM-130B: An open bilingual pre-trained model</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Academia</td>\n",
       "      <td>GLM-130B</td>\n",
       "      <td>1105920.0</td>\n",
       "      <td>1603584.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flamingo</th>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Visual question answering,Image captioning</td>\n",
       "      <td>Jean-Baptiste Alayrac, Jeff Donahue, Pauline L...</td>\n",
       "      <td>SOTA Improvement</td>\n",
       "      <td>\"For tasks lying anywhere on this spectrum, a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/2204.14198</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>Flamingo: a Visual Language Model for Few-Shot...</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"MultiModal MassiveWeb, LTIP, VTP, ALIGN\"</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Flamingo</td>\n",
       "      <td>552960.0</td>\n",
       "      <td>801792.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-NeoX-20B</th>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sid Black, Stella Biderman, Eric Hallahan, Que...</td>\n",
       "      <td>Historical significance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fully open-source</td>\n",
       "      <td>https://arxiv.org/abs/2204.06745</td>\n",
       "      <td>436.0</td>\n",
       "      <td>GPT-NeoX-20B: An Open-Source Autoregressive La...</td>\n",
       "      <td>2022-02-09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3150000.0</td>\n",
       "      <td>\"we opt to use the same batch size as OpenAI’s...</td>\n",
       "      <td>The Pile</td>\n",
       "      <td>Research collective</td>\n",
       "      <td>GPT-NeoX-20B</td>\n",
       "      <td>207360.0</td>\n",
       "      <td>300672.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Domain  \\\n",
       "System                                   \n",
       "Yuan 1.0                      Language   \n",
       "OpenAI TI7 DOTA 1v1              Games   \n",
       "Claude 2                      Language   \n",
       "Turing-NLG                    Language   \n",
       "GPT-3.5 (text-davinci-003)    Language   \n",
       "...                                ...   \n",
       "HyperClova                    Language   \n",
       "PanGu-Σ                       Language   \n",
       "GLM-130B                      Language   \n",
       "Flamingo                    Multimodal   \n",
       "GPT-NeoX-20B                  Language   \n",
       "\n",
       "                                                                  Task  \\\n",
       "System                                                                   \n",
       "Yuan 1.0                                            Language modelling   \n",
       "OpenAI TI7 DOTA 1v1                                               DOTA   \n",
       "Claude 2                                            Language modelling   \n",
       "Turing-NLG                                         Text autocompletion   \n",
       "GPT-3.5 (text-davinci-003)                          Language modelling   \n",
       "...                                                                ...   \n",
       "HyperClova                                                         NaN   \n",
       "PanGu-Σ                             Code generation,Language modelling   \n",
       "GLM-130B                                                           NaN   \n",
       "Flamingo                    Visual question answering,Image captioning   \n",
       "GPT-NeoX-20B                                                       NaN   \n",
       "\n",
       "                                                                      Authors  \\\n",
       "System                                                                          \n",
       "Yuan 1.0                    Shaohua Wu, Xudong Zhao, Tong Yu, Rongguo Zhan...   \n",
       "OpenAI TI7 DOTA 1v1                                                       NaN   \n",
       "Claude 2                                                                  NaN   \n",
       "Turing-NLG                                                       Corby Rosset   \n",
       "GPT-3.5 (text-davinci-003)                                                NaN   \n",
       "...                                                                       ...   \n",
       "HyperClova                  Boseop Kim, HyoungSeok Kim, Sang-Woo Lee, Gich...   \n",
       "PanGu-Σ                     Xiaozhe Ren, Pingyi Zhou, Xinfan Meng, Xinjing...   \n",
       "GLM-130B                                                                  NaN   \n",
       "Flamingo                    Jean-Baptiste Alayrac, Jeff Donahue, Pauline L...   \n",
       "GPT-NeoX-20B                Sid Black, Stella Biderman, Eric Hallahan, Que...   \n",
       "\n",
       "                                                          Notability criteria  \\\n",
       "System                                                                          \n",
       "Yuan 1.0                                                     SOTA Improvement   \n",
       "OpenAI TI7 DOTA 1v1                  SOTA Improvement,Historical significance   \n",
       "Claude 2                                              Historical significance   \n",
       "Turing-NLG                                                   SOTA Improvement   \n",
       "GPT-3.5 (text-davinci-003)  SOTA Improvement,Historical significance,Signi...   \n",
       "...                                                                       ...   \n",
       "HyperClova                                                   SOTA Improvement   \n",
       "PanGu-Σ                                                      SOTA Improvement   \n",
       "GLM-130B                                                     SOTA Improvement   \n",
       "Flamingo                                                     SOTA Improvement   \n",
       "GPT-NeoX-20B                                          Historical significance   \n",
       "\n",
       "                                                    Notability criteria notes  \\\n",
       "System                                                                          \n",
       "Yuan 1.0                    \"The zero-shot average scores of both LM and P...   \n",
       "OpenAI TI7 DOTA 1v1                                                       NaN   \n",
       "Claude 2                                                                  NaN   \n",
       "Turing-NLG                  from paper: \"Turing Natural Language Generatio...   \n",
       "GPT-3.5 (text-davinci-003)                                                NaN   \n",
       "...                                                                       ...   \n",
       "HyperClova                  \"HyperCLOVA with our training configuration sh...   \n",
       "PanGu-Σ                     \"Our experimental findings show that PanGu-{\\S...   \n",
       "GLM-130B                    \"GLM-130B achieves an accuracy of 80.2% on zer...   \n",
       "Flamingo                    \"For tasks lying anywhere on this spectrum, a ...   \n",
       "GPT-NeoX-20B                                                              NaN   \n",
       "\n",
       "                                  Open-source  \\\n",
       "System                                          \n",
       "Yuan 1.0                                  NaN   \n",
       "OpenAI TI7 DOTA 1v1                       NaN   \n",
       "Claude 2                       API accessible   \n",
       "Turing-NLG                                NaN   \n",
       "GPT-3.5 (text-davinci-003)     API accessible   \n",
       "...                                       ...   \n",
       "HyperClova                                NaN   \n",
       "PanGu-Σ                                   NaN   \n",
       "GLM-130B                                  NaN   \n",
       "Flamingo                                  NaN   \n",
       "GPT-NeoX-20B                Fully open-source   \n",
       "\n",
       "                                                                         Link  \\\n",
       "System                                                                          \n",
       "Yuan 1.0                                     https://arxiv.org/abs/2110.04725   \n",
       "OpenAI TI7 DOTA 1v1                        https://openai.com/research/dota-2   \n",
       "Claude 2                    https://www.anthropic.com/index/claude-2, http...   \n",
       "Turing-NLG                  https://www.microsoft.com/en-us/research/blog/...   \n",
       "GPT-3.5 (text-davinci-003)    https://platform.openai.com/docs/models/gpt-3-5   \n",
       "...                                                                       ...   \n",
       "HyperClova                                   https://arxiv.org/abs/2109.04650   \n",
       "PanGu-Σ                                      https://arxiv.org/abs/2303.10845   \n",
       "GLM-130B                    https://keg.cs.tsinghua.edu.cn/glm-130b/posts/...   \n",
       "Flamingo                                     https://arxiv.org/abs/2204.14198   \n",
       "GPT-NeoX-20B                                 https://arxiv.org/abs/2204.06745   \n",
       "\n",
       "                            Citations  \\\n",
       "System                                  \n",
       "Yuan 1.0                         37.0   \n",
       "OpenAI TI7 DOTA 1v1               0.0   \n",
       "Claude 2                          0.0   \n",
       "Turing-NLG                      114.0   \n",
       "GPT-3.5 (text-davinci-003)        NaN   \n",
       "...                               ...   \n",
       "HyperClova                       79.0   \n",
       "PanGu-Σ                          28.0   \n",
       "GLM-130B                         60.0   \n",
       "Flamingo                       1320.0   \n",
       "GPT-NeoX-20B                    436.0   \n",
       "\n",
       "                                                                    Reference  \\\n",
       "System                                                                          \n",
       "Yuan 1.0                    Yuan 1.0: Large-Scale Pre-trained Language Mod...   \n",
       "OpenAI TI7 DOTA 1v1                                                    Dota 2   \n",
       "Claude 2                                                                  NaN   \n",
       "Turing-NLG                  Turing-NLG: A 17-billion-parameter language mo...   \n",
       "GPT-3.5 (text-davinci-003)                                                NaN   \n",
       "...                                                                       ...   \n",
       "HyperClova                  What Changes Can Large-scale Language Models B...   \n",
       "PanGu-Σ                     PanGu-Σ: Towards Trillion Parameter Language M...   \n",
       "GLM-130B                        GLM-130B: An open bilingual pre-trained model   \n",
       "Flamingo                    Flamingo: a Visual Language Model for Few-Shot...   \n",
       "GPT-NeoX-20B                GPT-NeoX-20B: An Open-Source Autoregressive La...   \n",
       "\n",
       "                           Publication date  ...  \\\n",
       "System                                       ...   \n",
       "Yuan 1.0                         2021-10-12  ...   \n",
       "OpenAI TI7 DOTA 1v1              2017-08-11  ...   \n",
       "Claude 2                         2023-07-11  ...   \n",
       "Turing-NLG                       2020-02-13  ...   \n",
       "GPT-3.5 (text-davinci-003)       2022-11-28  ...   \n",
       "...                                     ...  ...   \n",
       "HyperClova                       2021-09-10  ...   \n",
       "PanGu-Σ                          2023-03-20  ...   \n",
       "GLM-130B                         2022-08-04  ...   \n",
       "Flamingo                         2022-04-29  ...   \n",
       "GPT-NeoX-20B                     2022-02-09  ...   \n",
       "\n",
       "                           Training cloud compute vendor  \\\n",
       "System                                                     \n",
       "Yuan 1.0                                             NaN   \n",
       "OpenAI TI7 DOTA 1v1                                  NaN   \n",
       "Claude 2                                             NaN   \n",
       "Turing-NLG                                           NaN   \n",
       "GPT-3.5 (text-davinci-003)                           NaN   \n",
       "...                                                  ...   \n",
       "HyperClova                                           NaN   \n",
       "PanGu-Σ                                              NaN   \n",
       "GLM-130B                                             NaN   \n",
       "Flamingo                                             NaN   \n",
       "GPT-NeoX-20B                                         NaN   \n",
       "\n",
       "                            Training data center Archived links  Batch size  \\\n",
       "System                                                                        \n",
       "Yuan 1.0                                     NaN            NaN   6881280.0   \n",
       "OpenAI TI7 DOTA 1v1                          NaN            NaN         NaN   \n",
       "Claude 2                                     NaN            NaN         NaN   \n",
       "Turing-NLG                                   NaN            NaN         NaN   \n",
       "GPT-3.5 (text-davinci-003)                   NaN            NaN         NaN   \n",
       "...                                          ...            ...         ...   \n",
       "HyperClova                                   NaN            NaN         NaN   \n",
       "PanGu-Σ                                      NaN            NaN    524288.0   \n",
       "GLM-130B                                     NaN            NaN         NaN   \n",
       "Flamingo                                     NaN            NaN         NaN   \n",
       "GPT-NeoX-20B                                 NaN            NaN   3150000.0   \n",
       "\n",
       "                                                             Batch size notes  \\\n",
       "System                                                                          \n",
       "Yuan 1.0                    Table 2. Batch size 3360, sequence length 2048...   \n",
       "OpenAI TI7 DOTA 1v1                                                       NaN   \n",
       "Claude 2                                                                  NaN   \n",
       "Turing-NLG                                                                NaN   \n",
       "GPT-3.5 (text-davinci-003)                                                NaN   \n",
       "...                                                                       ...   \n",
       "HyperClova                  \"All models use the mini-batch size of 1,024\"....   \n",
       "PanGu-Σ                     \"We train PanGu-Σ with global batch size of 51...   \n",
       "GLM-130B                                                                  NaN   \n",
       "Flamingo                                                                  NaN   \n",
       "GPT-NeoX-20B                \"we opt to use the same batch size as OpenAI’s...   \n",
       "\n",
       "                                                             Datasets  \\\n",
       "System                                                                  \n",
       "Yuan 1.0                                                          NaN   \n",
       "OpenAI TI7 DOTA 1v1                                               NaN   \n",
       "Claude 2                                                          NaN   \n",
       "Turing-NLG                                                        NaN   \n",
       "GPT-3.5 (text-davinci-003)                                        NaN   \n",
       "...                                                               ...   \n",
       "HyperClova                                                        NaN   \n",
       "PanGu-Σ                                                           NaN   \n",
       "GLM-130B                                                          NaN   \n",
       "Flamingo                    \"MultiModal MassiveWeb, LTIP, VTP, ALIGN\"   \n",
       "GPT-NeoX-20B                                                 The Pile   \n",
       "\n",
       "                           Organization categorization  \\\n",
       "System                                                   \n",
       "Yuan 1.0                                      Industry   \n",
       "OpenAI TI7 DOTA 1v1                           Industry   \n",
       "Claude 2                                      Industry   \n",
       "Turing-NLG                                    Industry   \n",
       "GPT-3.5 (text-davinci-003)                    Industry   \n",
       "...                                                ...   \n",
       "HyperClova                           Industry,Industry   \n",
       "PanGu-Σ                                       Industry   \n",
       "GLM-130B                                      Academia   \n",
       "Flamingo                                      Industry   \n",
       "GPT-NeoX-20B                       Research collective   \n",
       "\n",
       "                                                System  \\\n",
       "System                                                   \n",
       "Yuan 1.0                                      Yuan 1.0   \n",
       "OpenAI TI7 DOTA 1v1                OpenAI TI7 DOTA 1v1   \n",
       "Claude 2                                      Claude 2   \n",
       "Turing-NLG                                  Turing-NLG   \n",
       "GPT-3.5 (text-davinci-003)  GPT-3.5 (text-davinci-003)   \n",
       "...                                                ...   \n",
       "HyperClova                                  HyperClova   \n",
       "PanGu-Σ                                        PanGu-Σ   \n",
       "GLM-130B                                      GLM-130B   \n",
       "Flamingo                                      Flamingo   \n",
       "GPT-NeoX-20B                              GPT-NeoX-20B   \n",
       "\n",
       "                           Training time (chip hours)         Cost  \n",
       "System                                                              \n",
       "Yuan 1.0                                          NaN          NaN  \n",
       "OpenAI TI7 DOTA 1v1                               NaN          NaN  \n",
       "Claude 2                                          NaN          NaN  \n",
       "Turing-NLG                                        NaN          NaN  \n",
       "GPT-3.5 (text-davinci-003)                        NaN          NaN  \n",
       "...                                               ...          ...  \n",
       "HyperClova                                   658636.8   948436.992  \n",
       "PanGu-Σ                                     1228800.0          NaN  \n",
       "GLM-130B                                    1105920.0  1603584.000  \n",
       "Flamingo                                     552960.0   801792.000  \n",
       "GPT-NeoX-20B                                 207360.0   300672.000  \n",
       "\n",
       "[68 rows x 53 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Cost'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: nan\n",
      "Training hardware: nan\n",
      "Training time (hours): nan\n",
      "Hardware quantity: nan\n",
      "Hardware utilization: nan\n"
     ]
    }
   ],
   "source": [
    "system = 'AlphaGo Fan'\n",
    "print('Cost:', cost_df.loc[system, 'Cost'])\n",
    "print('Training hardware:', cost_df.loc[system, 'Training hardware'])\n",
    "print('Training time (hours):', cost_df.loc[system, 'Training time (hours)'])\n",
    "print('Hardware quantity:', cost_df.loc[system, 'Hardware quantity'])\n",
    "print('Hardware utilization:', cost_df.loc[system, 'Hardware utilization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply inflation adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "System\n",
       "Yuan 1.0                     2021-10-12\n",
       "OpenAI TI7 DOTA 1v1          2017-08-11\n",
       "Claude 2                     2023-07-11\n",
       "Turing-NLG                   2020-02-13\n",
       "GPT-3.5 (text-davinci-003)   2022-11-28\n",
       "                                ...    \n",
       "HyperClova                   2021-09-10\n",
       "PanGu-Σ                      2023-03-20\n",
       "GLM-130B                     2022-08-04\n",
       "Flamingo                     2022-04-29\n",
       "GPT-NeoX-20B                 2022-02-09\n",
       "Name: Publication date, Length: 68, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Publication date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:33.405367600Z",
     "start_time": "2024-02-07T16:04:33.290732900Z"
    }
   },
   "outputs": [],
   "source": [
    "from_year_month = cost_df['Publication date'].apply(str)\n",
    "cost_df['Publication date'] = from_year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:33.499948700Z",
     "start_time": "2024-02-07T16:04:33.405367600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "System\n",
       "Yuan 1.0                      2021-10-12 00:00:00\n",
       "OpenAI TI7 DOTA 1v1           2017-08-11 00:00:00\n",
       "Claude 2                      2023-07-11 00:00:00\n",
       "Turing-NLG                    2020-02-13 00:00:00\n",
       "GPT-3.5 (text-davinci-003)    2022-11-28 00:00:00\n",
       "                                     ...         \n",
       "HyperClova                    2021-09-10 00:00:00\n",
       "PanGu-Σ                       2023-03-20 00:00:00\n",
       "GLM-130B                      2022-08-04 00:00:00\n",
       "Flamingo                      2022-04-29 00:00:00\n",
       "GPT-NeoX-20B                  2022-02-09 00:00:00\n",
       "Name: Publication date, Length: 68, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Publication date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:53.202236900Z",
     "start_time": "2024-02-07T16:04:52.976107600Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_df = adjust_column_for_inflation(cost_df, 'Cost', 'data/PCU518210518210.csv', '2023-12-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "System\n",
       "Minerva (540B)              1.347019e+07\n",
       "PaLM (540B)                 1.238906e+07\n",
       "OPT-175B                    1.493975e+06\n",
       "ALIGN                       1.655001e+05\n",
       "GPT-4                       8.353709e+07\n",
       "GLaM                        2.093016e+06\n",
       "AlphaStar                   3.889027e+05\n",
       "RoBERTa Large               1.600176e+05\n",
       "GNMT                        1.947392e+05\n",
       "GShard (dense)              9.691116e+05\n",
       "Megatron-LM (8.3B)          2.160704e+05\n",
       "Gopher (280B)               3.499808e+06\n",
       "Meena                       6.971103e+05\n",
       "IMPALA                      1.381309e+02\n",
       "Falcon 180B                 2.581632e+07\n",
       "JFT                         3.344073e+04\n",
       "Megatron-Turing NLG 530B    6.405653e+06\n",
       "LaMDA                       1.319586e+06\n",
       "T5-11B                      2.366316e+05\n",
       "BigGAN-deep 512x512         2.647313e+04\n",
       "LLaMA-65B                   1.410426e+06\n",
       "Switch                      6.197414e+05\n",
       "Gemini Ultra                1.914000e+08\n",
       "GPT-3 175B (davinci)        4.511300e+06\n",
       "BERT-Large                  7.471898e+03\n",
       "Meta Pseudo Labels          2.513914e+05\n",
       "Llama 2-70B                 3.145518e+06\n",
       "U-PaLM (540B)               1.252379e+07\n",
       "HyperClova                  9.801649e+05\n",
       "GLM-130B                    1.635573e+06\n",
       "Flamingo                    8.150695e+05\n",
       "GPT-NeoX-20B                3.108410e+05\n",
       "Name: Cost (inflation-adjusted), dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Cost (inflation-adjusted)'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Cost (inflation-adjusted)'].notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:33.660916400Z",
     "start_time": "2024-02-07T16:04:33.645130900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Publication date=%{x}<br>Cost=%{y}<br>System=%{text}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          "Yuan 1.0",
          "OpenAI TI7 DOTA 1v1",
          "Claude 2",
          "Turing-NLG",
          "GPT-3.5 (text-davinci-003)",
          "AlphaGo Master",
          "Minerva (540B)",
          "FTW",
          "AlphaGo Zero",
          "NASv3 (CIFAR-10)",
          "AlphaZero",
          "PaLM (540B)",
          "OPT-175B",
          "ALIGN",
          "AlphaGo Fan",
          "GPT-4",
          "GLaM",
          "AlphaGo Lee",
          "AlphaStar",
          "OpenAI Five",
          "RoBERTa Large",
          "OpenAI Five Rerun",
          "GNMT",
          "GShard (dense)",
          "AlphaCode",
          "Megatron-LM (8.3B)",
          "Gopher (280B)",
          "Meena",
          "IMPALA",
          "PaLM 2",
          "Megatron-BERT",
          "Falcon 180B",
          "JFT",
          "AmoebaNet-A (F=448)",
          "Megatron-Turing NLG 530B",
          "T5-3B",
          "LaMDA",
          "T5-11B",
          "BigGAN-deep 512x512",
          "ResNeXt-101 32x48d",
          "Chinchilla",
          "ERNIE 3.0 Titan",
          "LLaMA-65B",
          "DALL-E",
          "GPT-2 (1.5B)",
          "GOAT",
          "Switch",
          "iGPT-XL",
          "Parti",
          "mT5-XXL",
          "ByT5-XXL",
          "BlenderBot 3",
          "ChatGLM3",
          "Yi-34B",
          "Qwen-72B",
          "Gemini Ultra",
          "ProtT5-XXL",
          "GPT-3 175B (davinci)",
          "Inflection-2",
          "BERT-Large",
          "Meta Pseudo Labels",
          "Llama 2-70B",
          "U-PaLM (540B)",
          "HyperClova",
          "PanGu-Σ",
          "GLM-130B",
          "Flamingo",
          "GPT-NeoX-20B"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-10-12 00:00:00",
          "2017-08-11 00:00:00",
          "2023-07-11 00:00:00",
          "2020-02-13 00:00:00",
          "2022-11-28 00:00:00",
          "2017-01-01 00:00:00",
          "2022-06-29 00:00:00",
          "2018-07-03 00:00:00",
          "2017-10-18 00:00:00",
          "2016-11-05 00:00:00",
          "2017-12-05 00:00:00",
          "2022-04-04 00:00:00",
          "2022-05-02 00:00:00",
          "2021-06-11 00:00:00",
          "2015-10-01 00:00:00",
          "2023-03-15 00:00:00",
          "2021-12-13 00:00:00",
          "2016-01-27 00:00:00",
          "2019-10-30 00:00:00",
          "2019-12-13 00:00:00",
          "2019-07-01 00:00:00",
          "2019-12-13 00:00:00",
          "2016-09-26 00:00:00",
          "2020-06-30 00:00:00",
          "2022-02-02 00:00:00",
          "2019-09-17 00:00:00",
          "2021-12-08 00:00:00",
          "2020-01-28 00:00:00",
          "2018-02-05 00:00:00",
          "2023-05-10 00:00:00",
          "2019-09-17 00:00:00",
          "2023-09-06 00:00:00",
          "2017-07-10 00:00:00",
          "2018-02-05 00:00:00",
          "2021-10-11 00:00:00",
          "2019-10-23 00:00:00",
          "2022-02-10 00:00:00",
          "2019-10-23 00:00:00",
          "2018-09-28 00:00:00",
          "2018-05-02 00:00:00",
          "2022-03-29 00:00:00",
          "2021-12-23 00:00:00",
          "2023-02-24 00:00:00",
          "2021-01-05 00:00:00",
          "2019-02-14 00:00:00",
          "2021-07-27 00:00:00",
          "2021-01-11 00:00:00",
          "2020-06-17 00:00:00",
          "2022-06-22 00:00:00",
          "2020-10-20 00:00:00",
          "2021-05-28 00:00:00",
          "2022-08-10 00:00:00",
          "2023-10-27 00:00:00",
          "2023-11-02 00:00:00",
          "2023-11-30 00:00:00",
          "2023-12-06 00:00:00",
          "2021-05-04 00:00:00",
          "2020-05-28 00:00:00",
          "2023-11-22 00:00:00",
          "2018-10-11 00:00:00",
          "2021-03-01 00:00:00",
          "2023-07-18 00:00:00",
          "2022-10-20 00:00:00",
          "2021-09-10 00:00:00",
          "2023-03-20 00:00:00",
          "2022-08-04 00:00:00",
          "2022-04-29 00:00:00",
          "2022-02-09 00:00:00"
         ],
         "xaxis": "x",
         "y": [
          null,
          null,
          null,
          null,
          null,
          null,
          13220659.200000001,
          null,
          null,
          null,
          null,
          12187238.4,
          1470704.6400000001,
          160035.84,
          null,
          82650000,
          2028236.8,
          null,
          364953.60000000003,
          null,
          148684.8,
          null,
          178329.6,
          928972.8,
          null,
          202583.04,
          3391488,
          663552,
          128,
          null,
          null,
          25657344,
          30960,
          null,
          6209280,
          null,
          1276416,
          222059.52,
          24576,
          null,
          null,
          null,
          1392640,
          null,
          null,
          null,
          597196.8,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          191400000,
          null,
          4297920,
          null,
          6942.719999999999,
          243302.4,
          3127680,
          12276326.4,
          948436.9920000001,
          null,
          1603584,
          801792,
          300672
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": false,
        "font": {
         "size": 14
        },
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "b": 10,
         "l": 10,
         "r": 10,
         "t": 40
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost of cloud compute to train frontier ML systems"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          "2015-01-01",
          "2025-01-01"
         ],
         "title": {
          "text": "Publication date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Cost (USD, nominal)"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(\n",
    "    cost_df,\n",
    "    x='Publication date',\n",
    "    y='Cost',\n",
    "    text='System',\n",
    "    log_y=True,\n",
    ")\n",
    "fig.update_traces(textposition='top center')\n",
    "\n",
    "# no legend\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# axis labels\n",
    "fig.update_xaxes(title_text='Publication date')\n",
    "fig.update_yaxes(title_text='Cost (USD, nominal)')\n",
    "\n",
    "# title\n",
    "fig.update_layout(title_text='Cost of cloud compute to train frontier ML systems')\n",
    "\n",
    "# update size\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# font size\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=14,\n",
    "    )\n",
    ")\n",
    "\n",
    "# axis limits\n",
    "fig.update_xaxes(range=['2015-01-01', '2025-01-01'])\n",
    "\n",
    "# margins\n",
    "fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "save_plot(fig, results_dir, 'cost_scatter')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Publication date=%{x}<br>Cost (inflation-adjusted)=%{y}<br>System=%{text}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          "Yuan 1.0",
          "OpenAI TI7 DOTA 1v1",
          "Claude 2",
          "Turing-NLG",
          "GPT-3.5 (text-davinci-003)",
          "AlphaGo Master",
          "Minerva (540B)",
          "FTW",
          "AlphaGo Zero",
          "NASv3 (CIFAR-10)",
          "AlphaZero",
          "PaLM (540B)",
          "OPT-175B",
          "ALIGN",
          "AlphaGo Fan",
          "GPT-4",
          "GLaM",
          "AlphaGo Lee",
          "AlphaStar",
          "OpenAI Five",
          "RoBERTa Large",
          "OpenAI Five Rerun",
          "GNMT",
          "GShard (dense)",
          "AlphaCode",
          "Megatron-LM (8.3B)",
          "Gopher (280B)",
          "Meena",
          "IMPALA",
          "PaLM 2",
          "Megatron-BERT",
          "Falcon 180B",
          "JFT",
          "AmoebaNet-A (F=448)",
          "Megatron-Turing NLG 530B",
          "T5-3B",
          "LaMDA",
          "T5-11B",
          "BigGAN-deep 512x512",
          "ResNeXt-101 32x48d",
          "Chinchilla",
          "ERNIE 3.0 Titan",
          "LLaMA-65B",
          "DALL-E",
          "GPT-2 (1.5B)",
          "GOAT",
          "Switch",
          "iGPT-XL",
          "Parti",
          "mT5-XXL",
          "ByT5-XXL",
          "BlenderBot 3",
          "ChatGLM3",
          "Yi-34B",
          "Qwen-72B",
          "Gemini Ultra",
          "ProtT5-XXL",
          "GPT-3 175B (davinci)",
          "Inflection-2",
          "BERT-Large",
          "Meta Pseudo Labels",
          "Llama 2-70B",
          "U-PaLM (540B)",
          "HyperClova",
          "PanGu-Σ",
          "GLM-130B",
          "Flamingo",
          "GPT-NeoX-20B"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "2021-10-12 00:00:00",
          "2017-08-11 00:00:00",
          "2023-07-11 00:00:00",
          "2020-02-13 00:00:00",
          "2022-11-28 00:00:00",
          "2017-01-01 00:00:00",
          "2022-06-29 00:00:00",
          "2018-07-03 00:00:00",
          "2017-10-18 00:00:00",
          "2016-11-05 00:00:00",
          "2017-12-05 00:00:00",
          "2022-04-04 00:00:00",
          "2022-05-02 00:00:00",
          "2021-06-11 00:00:00",
          "2015-10-01 00:00:00",
          "2023-03-15 00:00:00",
          "2021-12-13 00:00:00",
          "2016-01-27 00:00:00",
          "2019-10-30 00:00:00",
          "2019-12-13 00:00:00",
          "2019-07-01 00:00:00",
          "2019-12-13 00:00:00",
          "2016-09-26 00:00:00",
          "2020-06-30 00:00:00",
          "2022-02-02 00:00:00",
          "2019-09-17 00:00:00",
          "2021-12-08 00:00:00",
          "2020-01-28 00:00:00",
          "2018-02-05 00:00:00",
          "2023-05-10 00:00:00",
          "2019-09-17 00:00:00",
          "2023-09-06 00:00:00",
          "2017-07-10 00:00:00",
          "2018-02-05 00:00:00",
          "2021-10-11 00:00:00",
          "2019-10-23 00:00:00",
          "2022-02-10 00:00:00",
          "2019-10-23 00:00:00",
          "2018-09-28 00:00:00",
          "2018-05-02 00:00:00",
          "2022-03-29 00:00:00",
          "2021-12-23 00:00:00",
          "2023-02-24 00:00:00",
          "2021-01-05 00:00:00",
          "2019-02-14 00:00:00",
          "2021-07-27 00:00:00",
          "2021-01-11 00:00:00",
          "2020-06-17 00:00:00",
          "2022-06-22 00:00:00",
          "2020-10-20 00:00:00",
          "2021-05-28 00:00:00",
          "2022-08-10 00:00:00",
          "2023-10-27 00:00:00",
          "2023-11-02 00:00:00",
          "2023-11-30 00:00:00",
          "2023-12-06 00:00:00",
          "2021-05-04 00:00:00",
          "2020-05-28 00:00:00",
          "2023-11-22 00:00:00",
          "2018-10-11 00:00:00",
          "2021-03-01 00:00:00",
          "2023-07-18 00:00:00",
          "2022-10-20 00:00:00",
          "2021-09-10 00:00:00",
          "2023-03-20 00:00:00",
          "2022-08-04 00:00:00",
          "2022-04-29 00:00:00",
          "2022-02-09 00:00:00"
         ],
         "xaxis": "x",
         "y": [
          null,
          null,
          null,
          null,
          null,
          null,
          13470191.00856837,
          null,
          null,
          null,
          null,
          12389056.261813464,
          1493974.647531918,
          165500.13931537792,
          null,
          83537094.74721056,
          2093016.0239973643,
          null,
          388902.65897940914,
          null,
          160017.6468716094,
          null,
          194739.1953027523,
          969111.5896932516,
          null,
          216070.42339784946,
          3499807.67985019,
          697110.2785525154,
          138.13091568449684,
          null,
          null,
          25816323.797898512,
          33440.7332123412,
          null,
          6405652.563246981,
          null,
          1319585.503057254,
          236631.5547502238,
          26473.13375565611,
          null,
          null,
          null,
          1410425.8455359954,
          null,
          null,
          null,
          619741.3696948562,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          191400000,
          null,
          4511299.978835979,
          null,
          7471.898386980109,
          251391.36000000002,
          3145517.7254868825,
          12523793.100601656,
          980164.9214492477,
          null,
          1635572.685301023,
          815069.4909087805,
          310840.989438577
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": false,
        "font": {
         "size": 14
        },
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "b": 10,
         "l": 10,
         "r": 10,
         "t": 40
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost of cloud compute to train frontier ML systems"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          "2015-01-01",
          "2025-01-01"
         ],
         "title": {
          "text": "Publication date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Cost (2023 USD)"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(\n",
    "    cost_df,\n",
    "    x='Publication date',\n",
    "    y='Cost (inflation-adjusted)',\n",
    "    text='System',\n",
    "    log_y=True,\n",
    ")\n",
    "fig.update_traces(textposition='top center')\n",
    "\n",
    "# no legend\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# axis labels\n",
    "fig.update_xaxes(title_text='Publication date')\n",
    "fig.update_yaxes(title_text='Cost (2023 USD)')\n",
    "\n",
    "# title\n",
    "fig.update_layout(title_text='Cost of cloud compute to train frontier ML systems')\n",
    "\n",
    "# update size\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# font size\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=14,\n",
    "    )\n",
    ")\n",
    "\n",
    "# axis limits\n",
    "fig.update_xaxes(range=['2015-01-01', '2025-01-01'])\n",
    "\n",
    "# margins\n",
    "fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "save_plot(fig, results_dir, 'cost_scatter')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Open-source</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "      <th>Training dataset size (datapoints)</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>...</th>\n",
       "      <th>Country (from Organization)</th>\n",
       "      <th>Base model</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Hardware quantity</th>\n",
       "      <th>Hardware utilization</th>\n",
       "      <th>Training cloud compute vendor</th>\n",
       "      <th>Training data center</th>\n",
       "      <th>Training time (chip hours)</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Cost (inflation-adjusted)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yuan 1.0</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yuan 1.0: Large-Scale Pre-trained Language Mod...</td>\n",
       "      <td>2021-10-12 00:00:00</td>\n",
       "      <td>Inspur</td>\n",
       "      <td>2.457300e+11</td>\n",
       "      <td>3.538000e+23</td>\n",
       "      <td>1.000000e+12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenAI TI7 DOTA 1v1</th>\n",
       "      <td>Games</td>\n",
       "      <td>DOTA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dota 2</td>\n",
       "      <td>2017-08-11 00:00:00</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.046095e+20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claude 2</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>API accessible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-11 00:00:00</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.866000e+24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turing-NLG</th>\n",
       "      <td>Language</td>\n",
       "      <td>Text autocompletion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turing-NLG: A 17-billion-parameter language mo...</td>\n",
       "      <td>2020-02-13 00:00:00</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>1.700000e+10</td>\n",
       "      <td>1.570000e+22</td>\n",
       "      <td>3.480000e+10</td>\n",
       "      <td>3.39</td>\n",
       "      <td>...</td>\n",
       "      <td>Multinational</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3.5 (text-davinci-003)</th>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>API accessible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-28 00:00:00</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.578000e+24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HyperClova</th>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What Changes Can Large-scale Language Models B...</td>\n",
       "      <td>2021-09-10 00:00:00</td>\n",
       "      <td>NAVER,Search Solutions</td>\n",
       "      <td>8.200000e+10</td>\n",
       "      <td>1.476000e+23</td>\n",
       "      <td>1.900000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Korea (Republic of),Korea (Republic of)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>658636.8</td>\n",
       "      <td>948436.992</td>\n",
       "      <td>9.801649e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PanGu-Σ</th>\n",
       "      <td>Language</td>\n",
       "      <td>Code generation,Language modelling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PanGu-Σ: Towards Trillion Parameter Language M...</td>\n",
       "      <td>2023-03-20 00:00:00</td>\n",
       "      <td>Huawei Noah's Ark Lab</td>\n",
       "      <td>1.085000e+12</td>\n",
       "      <td>4.670000e+23</td>\n",
       "      <td>2.467500e+11</td>\n",
       "      <td>1.84</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1228800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM-130B</th>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GLM-130B: An open bilingual pre-trained model</td>\n",
       "      <td>2022-08-04 00:00:00</td>\n",
       "      <td>Tsinghua University</td>\n",
       "      <td>1.300000e+11</td>\n",
       "      <td>3.778000e+23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1105920.0</td>\n",
       "      <td>1603584.000</td>\n",
       "      <td>1.635573e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flamingo</th>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Visual question answering,Image captioning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flamingo: a Visual Language Model for Few-Shot...</td>\n",
       "      <td>2022-04-29 00:00:00</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>8.000000e+10</td>\n",
       "      <td>2.700000e+23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>United Kingdom of Great Britain and Northern I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>552960.0</td>\n",
       "      <td>801792.000</td>\n",
       "      <td>8.150695e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-NeoX-20B</th>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fully open-source</td>\n",
       "      <td>GPT-NeoX-20B: An Open-Source Autoregressive La...</td>\n",
       "      <td>2022-02-09 00:00:00</td>\n",
       "      <td>EleutherAI</td>\n",
       "      <td>2.000000e+10</td>\n",
       "      <td>9.316270e+22</td>\n",
       "      <td>1.771674e+11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Multinational</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207360.0</td>\n",
       "      <td>300672.000</td>\n",
       "      <td>3.108410e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Domain  \\\n",
       "System                                   \n",
       "Yuan 1.0                      Language   \n",
       "OpenAI TI7 DOTA 1v1              Games   \n",
       "Claude 2                      Language   \n",
       "Turing-NLG                    Language   \n",
       "GPT-3.5 (text-davinci-003)    Language   \n",
       "...                                ...   \n",
       "HyperClova                    Language   \n",
       "PanGu-Σ                       Language   \n",
       "GLM-130B                      Language   \n",
       "Flamingo                    Multimodal   \n",
       "GPT-NeoX-20B                  Language   \n",
       "\n",
       "                                                                  Task  \\\n",
       "System                                                                   \n",
       "Yuan 1.0                                            Language modelling   \n",
       "OpenAI TI7 DOTA 1v1                                               DOTA   \n",
       "Claude 2                                            Language modelling   \n",
       "Turing-NLG                                         Text autocompletion   \n",
       "GPT-3.5 (text-davinci-003)                          Language modelling   \n",
       "...                                                                ...   \n",
       "HyperClova                                                         NaN   \n",
       "PanGu-Σ                             Code generation,Language modelling   \n",
       "GLM-130B                                                           NaN   \n",
       "Flamingo                    Visual question answering,Image captioning   \n",
       "GPT-NeoX-20B                                                       NaN   \n",
       "\n",
       "                                  Open-source  \\\n",
       "System                                          \n",
       "Yuan 1.0                                  NaN   \n",
       "OpenAI TI7 DOTA 1v1                       NaN   \n",
       "Claude 2                       API accessible   \n",
       "Turing-NLG                                NaN   \n",
       "GPT-3.5 (text-davinci-003)     API accessible   \n",
       "...                                       ...   \n",
       "HyperClova                                NaN   \n",
       "PanGu-Σ                                   NaN   \n",
       "GLM-130B                                  NaN   \n",
       "Flamingo                                  NaN   \n",
       "GPT-NeoX-20B                Fully open-source   \n",
       "\n",
       "                                                                    Reference  \\\n",
       "System                                                                          \n",
       "Yuan 1.0                    Yuan 1.0: Large-Scale Pre-trained Language Mod...   \n",
       "OpenAI TI7 DOTA 1v1                                                    Dota 2   \n",
       "Claude 2                                                                  NaN   \n",
       "Turing-NLG                  Turing-NLG: A 17-billion-parameter language mo...   \n",
       "GPT-3.5 (text-davinci-003)                                                NaN   \n",
       "...                                                                       ...   \n",
       "HyperClova                  What Changes Can Large-scale Language Models B...   \n",
       "PanGu-Σ                     PanGu-Σ: Towards Trillion Parameter Language M...   \n",
       "GLM-130B                        GLM-130B: An open bilingual pre-trained model   \n",
       "Flamingo                    Flamingo: a Visual Language Model for Few-Shot...   \n",
       "GPT-NeoX-20B                GPT-NeoX-20B: An Open-Source Autoregressive La...   \n",
       "\n",
       "                               Publication date            Organization  \\\n",
       "System                                                                    \n",
       "Yuan 1.0                    2021-10-12 00:00:00                  Inspur   \n",
       "OpenAI TI7 DOTA 1v1         2017-08-11 00:00:00                  OpenAI   \n",
       "Claude 2                    2023-07-11 00:00:00               Anthropic   \n",
       "Turing-NLG                  2020-02-13 00:00:00               Microsoft   \n",
       "GPT-3.5 (text-davinci-003)  2022-11-28 00:00:00                  OpenAI   \n",
       "...                                         ...                     ...   \n",
       "HyperClova                  2021-09-10 00:00:00  NAVER,Search Solutions   \n",
       "PanGu-Σ                     2023-03-20 00:00:00   Huawei Noah's Ark Lab   \n",
       "GLM-130B                    2022-08-04 00:00:00     Tsinghua University   \n",
       "Flamingo                    2022-04-29 00:00:00                DeepMind   \n",
       "GPT-NeoX-20B                2022-02-09 00:00:00              EleutherAI   \n",
       "\n",
       "                              Parameters  Training compute (FLOP)  \\\n",
       "System                                                              \n",
       "Yuan 1.0                    2.457300e+11             3.538000e+23   \n",
       "OpenAI TI7 DOTA 1v1                  NaN             6.046095e+20   \n",
       "Claude 2                             NaN             3.866000e+24   \n",
       "Turing-NLG                  1.700000e+10             1.570000e+22   \n",
       "GPT-3.5 (text-davinci-003)           NaN             2.578000e+24   \n",
       "...                                  ...                      ...   \n",
       "HyperClova                  8.200000e+10             1.476000e+23   \n",
       "PanGu-Σ                     1.085000e+12             4.670000e+23   \n",
       "GLM-130B                    1.300000e+11             3.778000e+23   \n",
       "Flamingo                    8.000000e+10             2.700000e+23   \n",
       "GPT-NeoX-20B                2.000000e+10             9.316270e+22   \n",
       "\n",
       "                            Training dataset size (datapoints)  Epochs  ...  \\\n",
       "System                                                                  ...   \n",
       "Yuan 1.0                                          1.000000e+12    0.22  ...   \n",
       "OpenAI TI7 DOTA 1v1                                        NaN     NaN  ...   \n",
       "Claude 2                                                   NaN     NaN  ...   \n",
       "Turing-NLG                                        3.480000e+10    3.39  ...   \n",
       "GPT-3.5 (text-davinci-003)                                 NaN     NaN  ...   \n",
       "...                                                        ...     ...  ...   \n",
       "HyperClova                                        1.900000e+11     NaN  ...   \n",
       "PanGu-Σ                                           2.467500e+11    1.84  ...   \n",
       "GLM-130B                                                   NaN    1.00  ...   \n",
       "Flamingo                                                   NaN     NaN  ...   \n",
       "GPT-NeoX-20B                                      1.771674e+11    1.00  ...   \n",
       "\n",
       "                                                  Country (from Organization)  \\\n",
       "System                                                                          \n",
       "Yuan 1.0                                                                China   \n",
       "OpenAI TI7 DOTA 1v1                                  United States of America   \n",
       "Claude 2                                             United States of America   \n",
       "Turing-NLG                                                      Multinational   \n",
       "GPT-3.5 (text-davinci-003)                           United States of America   \n",
       "...                                                                       ...   \n",
       "HyperClova                            Korea (Republic of),Korea (Republic of)   \n",
       "PanGu-Σ                                                                 China   \n",
       "GLM-130B                                                                China   \n",
       "Flamingo                    United Kingdom of Great Britain and Northern I...   \n",
       "GPT-NeoX-20B                                                    Multinational   \n",
       "\n",
       "                           Base model Finetune compute (FLOP)  \\\n",
       "System                                                          \n",
       "Yuan 1.0                          NaN                     NaN   \n",
       "OpenAI TI7 DOTA 1v1               NaN                     NaN   \n",
       "Claude 2                          NaN                     NaN   \n",
       "Turing-NLG                        NaN                     NaN   \n",
       "GPT-3.5 (text-davinci-003)        NaN                     NaN   \n",
       "...                               ...                     ...   \n",
       "HyperClova                        NaN                     NaN   \n",
       "PanGu-Σ                           NaN                     NaN   \n",
       "GLM-130B                          NaN                     NaN   \n",
       "Flamingo                          NaN                     NaN   \n",
       "GPT-NeoX-20B                      NaN                     NaN   \n",
       "\n",
       "                           Hardware quantity Hardware utilization  \\\n",
       "System                                                              \n",
       "Yuan 1.0                              2128.0                0.450   \n",
       "OpenAI TI7 DOTA 1v1                      NaN                  NaN   \n",
       "Claude 2                                 NaN                  NaN   \n",
       "Turing-NLG                             256.0                  NaN   \n",
       "GPT-3.5 (text-davinci-003)               NaN                  NaN   \n",
       "...                                      ...                  ...   \n",
       "HyperClova                            1024.0                0.200   \n",
       "PanGu-Σ                                512.0                  NaN   \n",
       "GLM-130B                               768.0                0.433   \n",
       "Flamingo                              1536.0                  NaN   \n",
       "GPT-NeoX-20B                            96.0                0.375   \n",
       "\n",
       "                            Training cloud compute vendor  \\\n",
       "System                                                      \n",
       "Yuan 1.0                                              NaN   \n",
       "OpenAI TI7 DOTA 1v1                                   NaN   \n",
       "Claude 2                                              NaN   \n",
       "Turing-NLG                                            NaN   \n",
       "GPT-3.5 (text-davinci-003)                            NaN   \n",
       "...                                                   ...   \n",
       "HyperClova                                            NaN   \n",
       "PanGu-Σ                                               NaN   \n",
       "GLM-130B                                              NaN   \n",
       "Flamingo                                              NaN   \n",
       "GPT-NeoX-20B                                          NaN   \n",
       "\n",
       "                            Training data center Training time (chip hours)  \\\n",
       "System                                                                        \n",
       "Yuan 1.0                                     NaN                        NaN   \n",
       "OpenAI TI7 DOTA 1v1                          NaN                        NaN   \n",
       "Claude 2                                     NaN                        NaN   \n",
       "Turing-NLG                                   NaN                        NaN   \n",
       "GPT-3.5 (text-davinci-003)                   NaN                        NaN   \n",
       "...                                          ...                        ...   \n",
       "HyperClova                                   NaN                   658636.8   \n",
       "PanGu-Σ                                      NaN                  1228800.0   \n",
       "GLM-130B                                     NaN                  1105920.0   \n",
       "Flamingo                                     NaN                   552960.0   \n",
       "GPT-NeoX-20B                                 NaN                   207360.0   \n",
       "\n",
       "                                   Cost  Cost (inflation-adjusted)  \n",
       "System                                                              \n",
       "Yuan 1.0                            NaN                        NaN  \n",
       "OpenAI TI7 DOTA 1v1                 NaN                        NaN  \n",
       "Claude 2                            NaN                        NaN  \n",
       "Turing-NLG                          NaN                        NaN  \n",
       "GPT-3.5 (text-davinci-003)          NaN                        NaN  \n",
       "...                                 ...                        ...  \n",
       "HyperClova                   948436.992               9.801649e+05  \n",
       "PanGu-Σ                             NaN                        NaN  \n",
       "GLM-130B                    1603584.000               1.635573e+06  \n",
       "Flamingo                     801792.000               8.150695e+05  \n",
       "GPT-NeoX-20B                 300672.000               3.108410e+05  \n",
       "\n",
       "[68 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_cols = [\n",
    "    'Domain',\n",
    "    'Task',\n",
    "    'Open-source',\n",
    "    'Reference',\n",
    "    'Publication date',\n",
    "    'Organization',\n",
    "    'Parameters',\n",
    "    'Training compute (FLOP)',\n",
    "    'Training dataset size (datapoints)',\n",
    "    'Epochs',\n",
    "    'Training time (hours)',\n",
    "    'Training hardware',\n",
    "    'Country (from Organization)',\n",
    "    'Base model',\n",
    "    'Finetune compute (FLOP)',\n",
    "    'Hardware quantity',\n",
    "    'Hardware utilization',\n",
    "    'Training cloud compute vendor',\n",
    "    'Training data center',\n",
    "    'Training time (chip hours)',\n",
    "    'Cost',\n",
    "    'Cost (inflation-adjusted)',\n",
    "]\n",
    "cost_df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T16:04:39.616432900Z",
     "start_time": "2024-02-07T16:04:38.857238300Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_df[keep_cols].to_csv(results_dir + 'price dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
