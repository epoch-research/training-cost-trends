{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:49.691298800Z",
     "start_time": "2024-03-08T01:54:49.634206900Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:56.468786200Z",
     "start_time": "2024-03-08T01:54:49.695864500Z"
    },
    "id": "qltoZ7TbdkHZ"
   },
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from cost import *\n",
    "from plotting import *\n",
    "from prices import *\n",
    "from inflation import *\n",
    "from regression import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:56.578403700Z",
     "start_time": "2024-03-08T01:54:56.468786200Z"
    }
   },
   "outputs": [],
   "source": [
    "estimation_method = 'hardware-capex-energy'  # hardware-capex-energy, hardware-acquisition, cloud\n",
    "compute_threshold_method = 'top_n'  # top_n, window_percentile\n",
    "compute_threshold = 10  # e.g. 10 to select top 10; 75 to select top 25%\n",
    "variant = '2025-03-17_exclude_finetunes_at_threshold_stage'  # whatever else distinguishes this run, e.g. 'excluding-AlphaGo'\n",
    "exclude_models_containing = []  # ['GNMT', 'AlphaZero', 'AlphaGo Master', 'AlphaGo Zero']\n",
    "\n",
    "estimation_method_lookup = {\n",
    "    'hardware-capex-energy': estimate_hardware_capex_energy,\n",
    "    'hardware-acquisition': estimate_hardware_acquisition_cost,\n",
    "    'cloud': estimate_cloud_costs,\n",
    "}\n",
    "cost_estimation_function = estimation_method_lookup[estimation_method]\n",
    "\n",
    "results_dir = f'results/{estimation_method}-{compute_threshold_method}={compute_threshold}-{variant}/'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:57.129865300Z",
     "start_time": "2024-03-08T01:54:56.872275900Z"
    }
   },
   "outputs": [],
   "source": [
    "frontier_pcd_df, hardware_df, price_df = load_data_for_cost_estimation(\n",
    "    compute_threshold_method=compute_threshold_method, compute_threshold=compute_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:57.278230500Z",
     "start_time": "2024-03-08T01:54:57.129865300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 5775, 590)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frontier_pcd_df), len(hardware_df), len(price_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:57.807954200Z",
     "start_time": "2024-03-08T01:54:57.278230500Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{results_dir}/cost_estimation.out', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        cost_df = cost_estimation_function(frontier_pcd_df, hardware_df, price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if estimation_method == 'hardware-capex-energy':\n",
    "    frontier_pcd_df_copy = frontier_pcd_df.copy()\n",
    "    with open(f'{results_dir}/component_cost_estimation.out', 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            component_cost_df = cost_estimation_function(frontier_pcd_df_copy, hardware_df, price_df, separate_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:57.967995500Z",
     "start_time": "2024-03-08T01:54:57.807954200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Notability criteria</th>\n",
       "      <th>...</th>\n",
       "      <th>Organization categorization (from Organization)</th>\n",
       "      <th>Training compute cost (2023 USD)</th>\n",
       "      <th>Utilization notes</th>\n",
       "      <th>Numerical format</th>\n",
       "      <th>Training power draw (W)</th>\n",
       "      <th>Training compute estimation method</th>\n",
       "      <th>Hugging Face developer id</th>\n",
       "      <th>Post-training compute (FLOP)</th>\n",
       "      <th>Post-training compute notes</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Llama 4 Behemoth (preview)</td>\n",
       "      <td>Multimodal,Language,Vision</td>\n",
       "      <td>Chat,Code generation,Visual question answering...</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>The Llama 4 herd: The beginning of a new era o...</td>\n",
       "      <td>https://ai.meta.com/blog/llama-4-multimodal-in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Operation counting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>GPT-4.5</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Foundational contributors\\r\\nAlex Paino, Ali K...</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>Introducing GPT-4.5</td>\n",
       "      <td>https://openai.com/index/introducing-gpt-4-5/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>https://www.anthropic.com/news/claude-3-7-sonnet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Grok-3</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Chat,Language modeling/generation,Question ans...</td>\n",
       "      <td>xAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Grok 3 Beta â€” The Age of Reasoning Agents</td>\n",
       "      <td>https://x.ai/blog/grok-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.374358e+08</td>\n",
       "      <td>Hardware,Comparison with other models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.014548e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Doubao-pro</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>ByteDance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>Doubao General Model Pro (Doubao-pro)</td>\n",
       "      <td>https://www.volcengine.com/docs/6360/1264663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Operation counting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>ResNet-200</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Microsoft Research Asia</td>\n",
       "      <td>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>Identity Mappings in Deep Residual Networks</td>\n",
       "      <td>https://link.springer.com/chapter/10.1007/978-...</td>\n",
       "      <td>9621.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>https://www.nature.com/articles/nature16961</td>\n",
       "      <td>16057.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comparison with other models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>https://arxiv.org/abs/1512.03385</td>\n",
       "      <td>175697.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FP32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Operation counting,Third-party estimation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech recognition</td>\n",
       "      <td>Baidu Research - Silicon Valley AI Lab</td>\n",
       "      <td>Dario Amodei, Rishita Anubhai, Eric Battenberg...</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
       "      <td>https://arxiv.org/abs/1512.02595</td>\n",
       "      <td>2853.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>$206.31</td>\n",
       "      <td>\"Overall the system sustains approximately 50 ...</td>\n",
       "      <td>FP32</td>\n",
       "      <td>8.463468e+03</td>\n",
       "      <td>Operation counting,Third-party estimation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.854566e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>Inception v3</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Google,University College London (UCL)</td>\n",
       "      <td>Christian Szegedy, Vincent Vanhoucke, Sergey I...</td>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>Rethinking the inception architecture for comp...</td>\n",
       "      <td>https://arxiv.org/abs/1512.00567</td>\n",
       "      <td>25401.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry,Academia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Third-party estimation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model                      Domain  \\\n",
       "52    Llama 4 Behemoth (preview)  Multimodal,Language,Vision   \n",
       "87                       GPT-4.5  Language,Vision,Multimodal   \n",
       "94             Claude 3.7 Sonnet  Language,Vision,Multimodal   \n",
       "101                       Grok-3  Language,Vision,Multimodal   \n",
       "206                   Doubao-pro                    Language   \n",
       "...                          ...                         ...   \n",
       "1632                  ResNet-200                      Vision   \n",
       "1660                 AlphaGo Lee                       Games   \n",
       "1664       ResNet-152 (ImageNet)                      Vision   \n",
       "1665       DeepSpeech2 (English)                      Speech   \n",
       "1667                Inception v3                      Vision   \n",
       "\n",
       "                                                   Task  \\\n",
       "52    Chat,Code generation,Visual question answering...   \n",
       "87    Language modeling/generation,Question answerin...   \n",
       "94    Language modeling/generation,Question answerin...   \n",
       "101   Chat,Language modeling/generation,Question ans...   \n",
       "206   Language modeling/generation,Question answerin...   \n",
       "...                                                 ...   \n",
       "1632                               Image classification   \n",
       "1660                                                 Go   \n",
       "1664                               Image classification   \n",
       "1665                                 Speech recognition   \n",
       "1667                               Image classification   \n",
       "\n",
       "                                Organization  \\\n",
       "52                                   Meta AI   \n",
       "87                                    OpenAI   \n",
       "94                                 Anthropic   \n",
       "101                                      xAI   \n",
       "206                                ByteDance   \n",
       "...                                      ...   \n",
       "1632                 Microsoft Research Asia   \n",
       "1660                                DeepMind   \n",
       "1664                               Microsoft   \n",
       "1665  Baidu Research - Silicon Valley AI Lab   \n",
       "1667  Google,University College London (UCL)   \n",
       "\n",
       "                                                Authors Publication date  \\\n",
       "52                                                  NaN       2025-04-05   \n",
       "87    Foundational contributors\\r\\nAlex Paino, Ali K...       2025-02-27   \n",
       "94                                                  NaN       2025-02-24   \n",
       "101                                                 NaN       2025-02-17   \n",
       "206                                                 NaN       2024-10-28   \n",
       "...                                                 ...              ...   \n",
       "1632  Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun       2016-09-17   \n",
       "1660  David Silver, Aja Huang, Chris J. Maddison, Ar...       2016-01-27   \n",
       "1664  Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun       2015-12-10   \n",
       "1665  Dario Amodei, Rishita Anubhai, Eric Battenberg...       2015-12-08   \n",
       "1667  Christian Szegedy, Vincent Vanhoucke, Sergey I...       2015-12-02   \n",
       "\n",
       "                                              Reference  \\\n",
       "52    The Llama 4 herd: The beginning of a new era o...   \n",
       "87                                  Introducing GPT-4.5   \n",
       "94                                    Claude 3.7 Sonnet   \n",
       "101           Grok 3 Beta â€” The Age of Reasoning Agents   \n",
       "206               Doubao General Model Pro (Doubao-pro)   \n",
       "...                                                 ...   \n",
       "1632        Identity Mappings in Deep Residual Networks   \n",
       "1660  Mastering the game of Go with deep neural netw...   \n",
       "1664       Deep Residual Learning for Image Recognition   \n",
       "1665  Deep Speech 2: End-to-End Speech Recognition i...   \n",
       "1667  Rethinking the inception architecture for comp...   \n",
       "\n",
       "                                                   Link  Citations  \\\n",
       "52    https://ai.meta.com/blog/llama-4-multimodal-in...        NaN   \n",
       "87        https://openai.com/index/introducing-gpt-4-5/        NaN   \n",
       "94     https://www.anthropic.com/news/claude-3-7-sonnet        NaN   \n",
       "101                            https://x.ai/blog/grok-3        NaN   \n",
       "206        https://www.volcengine.com/docs/6360/1264663        NaN   \n",
       "...                                                 ...        ...   \n",
       "1632  https://link.springer.com/chapter/10.1007/978-...     9621.0   \n",
       "1660        https://www.nature.com/articles/nature16961    16057.0   \n",
       "1664                   https://arxiv.org/abs/1512.03385   175697.0   \n",
       "1665                   https://arxiv.org/abs/1512.02595     2853.0   \n",
       "1667                   https://arxiv.org/abs/1512.00567    25401.0   \n",
       "\n",
       "     Notability criteria  ... Organization categorization (from Organization)  \\\n",
       "52         Training cost  ...                                        Industry   \n",
       "87         Training cost  ...                                        Industry   \n",
       "94         Training cost  ...                                        Industry   \n",
       "101        Training cost  ...                                        Industry   \n",
       "206        Training cost  ...                                        Industry   \n",
       "...                  ...  ...                                             ...   \n",
       "1632        Highly cited  ...                                        Industry   \n",
       "1660        Highly cited  ...                                        Industry   \n",
       "1664        Highly cited  ...                                        Industry   \n",
       "1665        Highly cited  ...                                        Industry   \n",
       "1667        Highly cited  ...                               Industry,Academia   \n",
       "\n",
       "      Training compute cost (2023 USD)  \\\n",
       "52                                 NaN   \n",
       "87                                 NaN   \n",
       "94                                 NaN   \n",
       "101                                NaN   \n",
       "206                                NaN   \n",
       "...                                ...   \n",
       "1632                               NaN   \n",
       "1660                               NaN   \n",
       "1664                               NaN   \n",
       "1665                           $206.31   \n",
       "1667                               NaN   \n",
       "\n",
       "                                      Utilization notes  Numerical format  \\\n",
       "52                                                  NaN               NaN   \n",
       "87                                                  NaN               NaN   \n",
       "94                                                  NaN               NaN   \n",
       "101                                                 NaN               NaN   \n",
       "206                                                 NaN               NaN   \n",
       "...                                                 ...               ...   \n",
       "1632                                                NaN               NaN   \n",
       "1660                                                NaN               NaN   \n",
       "1664                                                NaN              FP32   \n",
       "1665  \"Overall the system sustains approximately 50 ...              FP32   \n",
       "1667                                                NaN               NaN   \n",
       "\n",
       "     Training power draw (W)         Training compute estimation method  \\\n",
       "52                       NaN                         Operation counting   \n",
       "87                       NaN                                 Benchmarks   \n",
       "94                       NaN                                        NaN   \n",
       "101             1.374358e+08      Hardware,Comparison with other models   \n",
       "206                      NaN                         Operation counting   \n",
       "...                      ...                                        ...   \n",
       "1632                     NaN                                   Hardware   \n",
       "1660                     NaN               Comparison with other models   \n",
       "1664                     NaN  Operation counting,Third-party estimation   \n",
       "1665            8.463468e+03  Operation counting,Third-party estimation   \n",
       "1667                     NaN                     Third-party estimation   \n",
       "\n",
       "     Hugging Face developer id  Post-training compute (FLOP)  \\\n",
       "52                         NaN                           NaN   \n",
       "87                         NaN                           NaN   \n",
       "94                         NaN                           NaN   \n",
       "101                        NaN                           NaN   \n",
       "206                        NaN                           NaN   \n",
       "...                        ...                           ...   \n",
       "1632                       NaN                           NaN   \n",
       "1660                       NaN                           NaN   \n",
       "1664                       NaN                           NaN   \n",
       "1665                       NaN                           NaN   \n",
       "1667                       NaN                           NaN   \n",
       "\n",
       "     Post-training compute notes          Cost  \n",
       "52                           NaN           NaN  \n",
       "87                           NaN           NaN  \n",
       "94                           NaN           NaN  \n",
       "101                          NaN  3.014548e+08  \n",
       "206                          NaN           NaN  \n",
       "...                          ...           ...  \n",
       "1632                         NaN           NaN  \n",
       "1660                         NaN           NaN  \n",
       "1664                         NaN           NaN  \n",
       "1665                         NaN  1.854566e+02  \n",
       "1667                         NaN           NaN  \n",
       "\n",
       "[89 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:58.104807Z",
     "start_time": "2024-03-08T01:54:57.967995500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Cost'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df.dropna(subset=['Cost'])['Training time (hours)'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df.dropna(subset=['Cost'])['Hardware utilization'].notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>2017-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>AlphaGo Zero</td>\n",
       "      <td>2017-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>Libratus</td>\n",
       "      <td>2017-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>2017-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>JFT</td>\n",
       "      <td>2017-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>MoE-Multi</td>\n",
       "      <td>2017-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>PolyNet</td>\n",
       "      <td>2016-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>2016-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Xception</td>\n",
       "      <td>2016-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>2016-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>ResNet-200</td>\n",
       "      <td>2016-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>2016-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>2015-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>2015-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>Inception v3</td>\n",
       "      <td>2015-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Publication date\n",
       "1566         AlphaGo Master       2017-10-19\n",
       "1567           AlphaGo Zero       2017-10-18\n",
       "1572               Libratus       2017-08-19\n",
       "1577    OpenAI TI7 DOTA 1v1       2017-08-11\n",
       "1584                    JFT       2017-07-10\n",
       "1604              MoE-Multi       2017-01-23\n",
       "1615                PolyNet       2016-11-17\n",
       "1617       NASv3 (CIFAR-10)       2016-11-05\n",
       "1623               Xception       2016-10-07\n",
       "1624                   GNMT       2016-09-26\n",
       "1632             ResNet-200       2016-09-17\n",
       "1660            AlphaGo Lee       2016-01-27\n",
       "1664  ResNet-152 (ImageNet)       2015-12-10\n",
       "1665  DeepSpeech2 (English)       2015-12-08\n",
       "1667           Inception v3       2015-12-02"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df[['Model', 'Publication date']].tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>2017-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>AlphaGo Zero</td>\n",
       "      <td>2017-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>Libratus</td>\n",
       "      <td>2017-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>2017-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>JFT</td>\n",
       "      <td>2017-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>MoE-Multi</td>\n",
       "      <td>2017-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>PolyNet</td>\n",
       "      <td>2016-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>2016-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Xception</td>\n",
       "      <td>2016-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>2016-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>ResNet-200</td>\n",
       "      <td>2016-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>2016-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>2015-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>2015-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>Inception v3</td>\n",
       "      <td>2015-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Publication date\n",
       "1566         AlphaGo Master       2017-10-19\n",
       "1567           AlphaGo Zero       2017-10-18\n",
       "1572               Libratus       2017-08-19\n",
       "1577    OpenAI TI7 DOTA 1v1       2017-08-11\n",
       "1584                    JFT       2017-07-10\n",
       "1604              MoE-Multi       2017-01-23\n",
       "1615                PolyNet       2016-11-17\n",
       "1617       NASv3 (CIFAR-10)       2016-11-05\n",
       "1623               Xception       2016-10-07\n",
       "1624                   GNMT       2016-09-26\n",
       "1632             ResNet-200       2016-09-17\n",
       "1660            AlphaGo Lee       2016-01-27\n",
       "1664  ResNet-152 (ImageNet)       2015-12-10\n",
       "1665  DeepSpeech2 (English)       2015-12-08\n",
       "1667           Inception v3       2015-12-02"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for kw in exclude_models_containing:\n",
    "    cost_df = cost_df[cost_df['Model'].str.contains(kw) == False]\n",
    "cost_df[['Model', 'Publication date']].tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below to check data availability for specific systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:58.418907200Z",
     "start_time": "2024-03-08T01:54:58.109807800Z"
    }
   },
   "outputs": [],
   "source": [
    "# system = 'WizardLM-7B'\n",
    "# row = cost_df.loc[cost_df['Model'] == system]\n",
    "# print('Cost:', row['Cost'].values[0])\n",
    "# print('Training hardware:', row['Training hardware'].values[0])\n",
    "# print('Training time (hours):', row['Training time (hours)'].values[0])\n",
    "# print('Hardware quantity:', row['Hardware quantity'].values[0])\n",
    "# print('Hardware utilization:', row['Hardware utilization'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply inflation adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101     3.014548e+08\n",
       "366     3.060541e+07\n",
       "403     5.126034e+07\n",
       "448     2.057972e+07\n",
       "612     1.179460e+07\n",
       "            ...     \n",
       "1604    3.538189e+03\n",
       "1615    5.635997e+02\n",
       "1623    1.155451e+04\n",
       "1624    1.774592e+05\n",
       "1665    1.854566e+02\n",
       "Name: Cost, Length: 61, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Cost'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.049781600Z",
     "start_time": "2024-03-08T01:54:58.881981400Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_df = adjust_column_for_inflation(cost_df, 'Cost', 'data/PCU518210518210.csv', '2024-12-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.177190500Z",
     "start_time": "2024-03-08T01:54:59.049781600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101     3.008724e+08\n",
       "366     3.049986e+07\n",
       "403     5.104052e+07\n",
       "448     2.052898e+07\n",
       "612     1.180459e+07\n",
       "            ...     \n",
       "1604    3.874123e+03\n",
       "1615    6.171107e+02\n",
       "1623    1.265155e+04\n",
       "1624    1.943081e+05\n",
       "1665    2.068604e+02\n",
       "Name: Cost (inflation-adjusted), Length: 61, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Cost (inflation-adjusted)'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.344452300Z",
     "start_time": "2024-03-08T01:54:59.182457200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Equal number of non-null values\n",
    "assert cost_df['Cost (inflation-adjusted)'].notna().sum() == cost_df['Cost'].notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.490722200Z",
     "start_time": "2024-03-08T01:54:59.337705700Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_df['Publication date (float)'] = datetime_to_float_year(pd.to_datetime(cost_df['Publication date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.700207700Z",
     "start_time": "2024-03-08T01:54:59.462346300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   142.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 30 Jul 2025</td> <th>  Prob (F-statistic):</th> <td>2.36e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:32:48</td>     <th>  Log-Likelihood:    </th> <td> -62.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    61</td>      <th>  AIC:               </th> <td>   128.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    59</td>      <th>  BIC:               </th> <td>   132.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -887.9037</td> <td>   74.944</td> <td>  -11.848</td> <td> 0.000</td> <td>-1037.867</td> <td> -737.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4421</td> <td>    0.037</td> <td>   11.923</td> <td> 0.000</td> <td>    0.368</td> <td>    0.516</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.397</td> <th>  Durbin-Watson:     </th> <td>   1.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.111</td> <th>  Jarque-Bera (JB):  </th> <td>   4.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.630</td> <th>  Prob(JB):          </th> <td>   0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.962</td> <th>  Cond. No.          </th> <td>1.73e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.73e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.707   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.702   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     142.1   \\\\\n",
       "\\textbf{Date:}             & Wed, 30 Jul 2025 & \\textbf{  Prob (F-statistic):} &  2.36e-17   \\\\\n",
       "\\textbf{Time:}             &     15:32:48     & \\textbf{  Log-Likelihood:    } &   -62.231   \\\\\n",
       "\\textbf{No. Observations:} &          61      & \\textbf{  AIC:               } &     128.5   \\\\\n",
       "\\textbf{Df Residuals:}     &          59      & \\textbf{  BIC:               } &     132.7   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    -887.9037  &       74.944     &   -11.848  &         0.000        &    -1037.867    &     -737.940     \\\\\n",
       "\\textbf{x1}    &       0.4421  &        0.037     &    11.923  &         0.000        &        0.368    &        0.516     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  4.397 & \\textbf{  Durbin-Watson:     } &    1.406  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.111 & \\textbf{  Jarque-Bera (JB):  } &    4.037  \\\\\n",
       "\\textbf{Skew:}          &  0.630 & \\textbf{  Prob(JB):          } &    0.133  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.962 & \\textbf{  Cond. No.          } & 1.73e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.73e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.707\n",
       "Model:                            OLS   Adj. R-squared:                  0.702\n",
       "Method:                 Least Squares   F-statistic:                     142.1\n",
       "Date:                Wed, 30 Jul 2025   Prob (F-statistic):           2.36e-17\n",
       "Time:                        15:32:48   Log-Likelihood:                -62.231\n",
       "No. Observations:                  61   AIC:                             128.5\n",
       "Df Residuals:                      59   BIC:                             132.7\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -887.9037     74.944    -11.848      0.000   -1037.867    -737.940\n",
       "x1             0.4421      0.037     11.923      0.000       0.368       0.516\n",
       "==============================================================================\n",
       "Omnibus:                        4.397   Durbin-Watson:                   1.406\n",
       "Prob(Omnibus):                  0.111   Jarque-Bera (JB):                4.037\n",
       "Skew:                           0.630   Prob(JB):                        0.133\n",
       "Kurtosis:                       2.962   Cond. No.                     1.73e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.73e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_results = fit_ols_regression(cost_df, ['Publication date (float)'], 'Cost (inflation-adjusted)', logy=True)\n",
    "reg_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:55:00.548785500Z",
     "start_time": "2024-03-08T01:54:59.700207700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=61.0\n",
      "R^2=0.71\n",
      "0.44209 OOMs/year (90% CI: 0.38012, 0.50405)\n",
      "2.76748x/year (90% CI: 2.3995x, 3.1919x)\n",
      "doubling time of 8.17119 months (90% CI: 7.16669, 9.50317)\n"
     ]
    }
   ],
   "source": [
    "with open(f'{results_dir}/regression_results.out', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        print_growth_rates(reg_results, round_digits=None)\n",
    "print_growth_rates(reg_results, ci=90, round_digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:55:00.548785500Z",
     "start_time": "2024-03-08T01:54:59.809703300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication date (float)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.10101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.20202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.30303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.40404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2024.59596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2024.69697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2024.79798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2024.89899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2025.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Publication date (float)\n",
       "0                 2015.00000\n",
       "1                 2015.10101\n",
       "2                 2015.20202\n",
       "3                 2015.30303\n",
       "4                 2015.40404\n",
       "..                       ...\n",
       "95                2024.59596\n",
       "96                2024.69697\n",
       "97                2024.79798\n",
       "98                2024.89899\n",
       "99                2025.00000\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_start_year = 2015\n",
    "pred_end_year = 2025\n",
    "pred_start_date = f'{pred_start_year}-01-01'\n",
    "pred_end_date = f'{pred_end_year}-01-01'\n",
    "\n",
    "pred_years = pd.DataFrame({'Publication date (float)': np.linspace(pred_start_year, pred_end_year, 100)})\n",
    "pred_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:55:00.564420400Z",
     "start_time": "2024-03-08T01:54:59.920051200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "      <th>Publication date (float)</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.897729</td>\n",
       "      <td>0.244884</td>\n",
       "      <td>2.488505</td>\n",
       "      <td>3.306952</td>\n",
       "      <td>1.686120</td>\n",
       "      <td>4.109338</td>\n",
       "      <td>2015.00000</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.942384</td>\n",
       "      <td>0.241388</td>\n",
       "      <td>2.539001</td>\n",
       "      <td>3.345767</td>\n",
       "      <td>1.732736</td>\n",
       "      <td>4.152032</td>\n",
       "      <td>2015.10101</td>\n",
       "      <td>2015-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.987039</td>\n",
       "      <td>0.237901</td>\n",
       "      <td>2.589484</td>\n",
       "      <td>3.384594</td>\n",
       "      <td>1.779322</td>\n",
       "      <td>4.194756</td>\n",
       "      <td>2015.20202</td>\n",
       "      <td>2015-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.031694</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>2.639954</td>\n",
       "      <td>3.423434</td>\n",
       "      <td>1.825878</td>\n",
       "      <td>4.237510</td>\n",
       "      <td>2015.30303</td>\n",
       "      <td>2015-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.076349</td>\n",
       "      <td>0.230950</td>\n",
       "      <td>2.690410</td>\n",
       "      <td>3.462288</td>\n",
       "      <td>1.872405</td>\n",
       "      <td>4.280293</td>\n",
       "      <td>2015.40404</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7.139960</td>\n",
       "      <td>0.154196</td>\n",
       "      <td>6.882284</td>\n",
       "      <td>7.397636</td>\n",
       "      <td>5.970802</td>\n",
       "      <td>8.309117</td>\n",
       "      <td>2024.59596</td>\n",
       "      <td>2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7.184615</td>\n",
       "      <td>0.157296</td>\n",
       "      <td>6.921758</td>\n",
       "      <td>7.447472</td>\n",
       "      <td>6.014305</td>\n",
       "      <td>8.354925</td>\n",
       "      <td>2024.69697</td>\n",
       "      <td>2024-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.229270</td>\n",
       "      <td>0.160424</td>\n",
       "      <td>6.961186</td>\n",
       "      <td>7.497354</td>\n",
       "      <td>6.057775</td>\n",
       "      <td>8.400765</td>\n",
       "      <td>2024.79798</td>\n",
       "      <td>2024-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7.273925</td>\n",
       "      <td>0.163578</td>\n",
       "      <td>7.000571</td>\n",
       "      <td>7.547279</td>\n",
       "      <td>6.101212</td>\n",
       "      <td>8.446637</td>\n",
       "      <td>2024.89899</td>\n",
       "      <td>2024-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7.318580</td>\n",
       "      <td>0.166756</td>\n",
       "      <td>7.039914</td>\n",
       "      <td>7.597245</td>\n",
       "      <td>6.144618</td>\n",
       "      <td>8.492542</td>\n",
       "      <td>2025.00000</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0   2.897729  0.244884       2.488505       3.306952      1.686120   \n",
       "1   2.942384  0.241388       2.539001       3.345767      1.732736   \n",
       "2   2.987039  0.237901       2.589484       3.384594      1.779322   \n",
       "3   3.031694  0.234421       2.639954       3.423434      1.825878   \n",
       "4   3.076349  0.230950       2.690410       3.462288      1.872405   \n",
       "..       ...       ...            ...            ...           ...   \n",
       "95  7.139960  0.154196       6.882284       7.397636      5.970802   \n",
       "96  7.184615  0.157296       6.921758       7.447472      6.014305   \n",
       "97  7.229270  0.160424       6.961186       7.497354      6.057775   \n",
       "98  7.273925  0.163578       7.000571       7.547279      6.101212   \n",
       "99  7.318580  0.166756       7.039914       7.597245      6.144618   \n",
       "\n",
       "    obs_ci_upper  Publication date (float) Publication date  \n",
       "0       4.109338                2015.00000       2015-01-01  \n",
       "1       4.152032                2015.10101       2015-02-06  \n",
       "2       4.194756                2015.20202       2015-03-15  \n",
       "3       4.237510                2015.30303       2015-04-21  \n",
       "4       4.280293                2015.40404       2015-05-28  \n",
       "..           ...                       ...              ...  \n",
       "95      8.309117                2024.59596       2024-08-06  \n",
       "96      8.354925                2024.69697       2024-09-12  \n",
       "97      8.400765                2024.79798       2024-10-19  \n",
       "98      8.446637                2024.89899       2024-11-25  \n",
       "99      8.492542                2025.00000       2025-01-01  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predicted_cost_df = get_predictions(reg_results, pred_years, ['Publication date (float)'])\n",
    "predicted_cost_df['Publication date'] = predicted_cost_df['Publication date (float)'].apply(float_year_to_datetime)\n",
    "predicted_cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cost_df.to_csv(results_dir + 'predicted_cost_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Model accessibility</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "      <th>Training dataset size (datapoints)</th>\n",
       "      <th>...</th>\n",
       "      <th>Training hardware</th>\n",
       "      <th>Country (of organization)</th>\n",
       "      <th>Base model</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Hardware quantity</th>\n",
       "      <th>Hardware utilization</th>\n",
       "      <th>Training cloud compute vendor</th>\n",
       "      <th>Training data center</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Cost (inflation-adjusted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Llama 4 Behemoth (preview)</td>\n",
       "      <td>Multimodal,Language,Vision</td>\n",
       "      <td>Chat,Code generation,Visual question answering...</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>The Llama 4 herd: The beginning of a new era o...</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2.000000e+12</td>\n",
       "      <td>5.184000e+25</td>\n",
       "      <td>3.000000e+13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>GPT-4.5</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>API access</td>\n",
       "      <td>Introducing GPT-4.5</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.100000e+26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Azure AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>API access</td>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.350000e+25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Grok-3</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Chat,Language modeling/generation,Question ans...</td>\n",
       "      <td>Hosted access (no API)</td>\n",
       "      <td>Grok 3 Beta â€” The Age of Reasoning Agents</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>xAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.640000e+26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NVIDIA H100 SXM5 80GB</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xAI Memphis Colossus</td>\n",
       "      <td>3.014548e+08</td>\n",
       "      <td>3.008724e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Doubao-pro</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>API access</td>\n",
       "      <td>Doubao General Model Pro (Doubao-pro)</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>ByteDance</td>\n",
       "      <td>5.000000e+11</td>\n",
       "      <td>2.505000e+25</td>\n",
       "      <td>8.350000e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There is no paper to reference, also no inform...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>ResNet-200</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>Identity Mappings in Deep Residual Networks</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>Microsoft Research Asia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.974164e+19</td>\n",
       "      <td>1.281167e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.900000e+21</td>\n",
       "      <td>2.940000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom of Great Britain and Northern I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>6.020000e+07</td>\n",
       "      <td>1.041408e+19</td>\n",
       "      <td>1.280000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America,Multinational,India,B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech recognition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>Baidu Research - Silicon Valley AI Lab</td>\n",
       "      <td>3.800000e+07</td>\n",
       "      <td>2.600000e+19</td>\n",
       "      <td>1.633392e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NVIDIA GeForce GTX TITAN X</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.854566e+02</td>\n",
       "      <td>2.068604e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>Inception v3</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rethinking the inception architecture for comp...</td>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>Google,University College London (UCL)</td>\n",
       "      <td>2.362673e+07</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America,United Kingdom of Gre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model                      Domain  \\\n",
       "52    Llama 4 Behemoth (preview)  Multimodal,Language,Vision   \n",
       "87                       GPT-4.5  Language,Vision,Multimodal   \n",
       "94             Claude 3.7 Sonnet  Language,Vision,Multimodal   \n",
       "101                       Grok-3  Language,Vision,Multimodal   \n",
       "206                   Doubao-pro                    Language   \n",
       "...                          ...                         ...   \n",
       "1632                  ResNet-200                      Vision   \n",
       "1660                 AlphaGo Lee                       Games   \n",
       "1664       ResNet-152 (ImageNet)                      Vision   \n",
       "1665       DeepSpeech2 (English)                      Speech   \n",
       "1667                Inception v3                      Vision   \n",
       "\n",
       "                                                   Task  \\\n",
       "52    Chat,Code generation,Visual question answering...   \n",
       "87    Language modeling/generation,Question answerin...   \n",
       "94    Language modeling/generation,Question answerin...   \n",
       "101   Chat,Language modeling/generation,Question ans...   \n",
       "206   Language modeling/generation,Question answerin...   \n",
       "...                                                 ...   \n",
       "1632                               Image classification   \n",
       "1660                                                 Go   \n",
       "1664                               Image classification   \n",
       "1665                                 Speech recognition   \n",
       "1667                               Image classification   \n",
       "\n",
       "         Model accessibility  \\\n",
       "52                Unreleased   \n",
       "87                API access   \n",
       "94                API access   \n",
       "101   Hosted access (no API)   \n",
       "206               API access   \n",
       "...                      ...   \n",
       "1632              Unreleased   \n",
       "1660              Unreleased   \n",
       "1664                     NaN   \n",
       "1665                     NaN   \n",
       "1667                     NaN   \n",
       "\n",
       "                                              Reference Publication date  \\\n",
       "52    The Llama 4 herd: The beginning of a new era o...       2025-04-05   \n",
       "87                                  Introducing GPT-4.5       2025-02-27   \n",
       "94                                    Claude 3.7 Sonnet       2025-02-24   \n",
       "101           Grok 3 Beta â€” The Age of Reasoning Agents       2025-02-17   \n",
       "206               Doubao General Model Pro (Doubao-pro)       2024-10-28   \n",
       "...                                                 ...              ...   \n",
       "1632        Identity Mappings in Deep Residual Networks       2016-09-17   \n",
       "1660  Mastering the game of Go with deep neural netw...       2016-01-27   \n",
       "1664       Deep Residual Learning for Image Recognition       2015-12-10   \n",
       "1665  Deep Speech 2: End-to-End Speech Recognition i...       2015-12-08   \n",
       "1667  Rethinking the inception architecture for comp...       2015-12-02   \n",
       "\n",
       "                                Organization    Parameters  \\\n",
       "52                                   Meta AI  2.000000e+12   \n",
       "87                                    OpenAI           NaN   \n",
       "94                                 Anthropic           NaN   \n",
       "101                                      xAI           NaN   \n",
       "206                                ByteDance  5.000000e+11   \n",
       "...                                      ...           ...   \n",
       "1632                 Microsoft Research Asia           NaN   \n",
       "1660                                DeepMind           NaN   \n",
       "1664                               Microsoft  6.020000e+07   \n",
       "1665  Baidu Research - Silicon Valley AI Lab  3.800000e+07   \n",
       "1667  Google,University College London (UCL)  2.362673e+07   \n",
       "\n",
       "      Training compute (FLOP)  Training dataset size (datapoints)  ...  \\\n",
       "52               5.184000e+25                        3.000000e+13  ...   \n",
       "87               2.100000e+26                                 NaN  ...   \n",
       "94               3.350000e+25                                 NaN  ...   \n",
       "101              4.640000e+26                                 NaN  ...   \n",
       "206              2.505000e+25                        8.350000e+12  ...   \n",
       "...                       ...                                 ...  ...   \n",
       "1632             2.974164e+19                        1.281167e+06  ...   \n",
       "1660             1.900000e+21                        2.940000e+07  ...   \n",
       "1664             1.041408e+19                        1.280000e+06  ...   \n",
       "1665             2.600000e+19                        1.633392e+08  ...   \n",
       "1667             1.000000e+20                        1.200000e+06  ...   \n",
       "\n",
       "               Training hardware  \\\n",
       "52                           NaN   \n",
       "87                           NaN   \n",
       "94                           NaN   \n",
       "101        NVIDIA H100 SXM5 80GB   \n",
       "206                          NaN   \n",
       "...                          ...   \n",
       "1632                         NaN   \n",
       "1660                         NaN   \n",
       "1664                         NaN   \n",
       "1665  NVIDIA GeForce GTX TITAN X   \n",
       "1667                         NaN   \n",
       "\n",
       "                              Country (of organization) Base model  \\\n",
       "52                             United States of America        NaN   \n",
       "87                             United States of America        NaN   \n",
       "94                             United States of America        NaN   \n",
       "101                            United States of America        NaN   \n",
       "206                                               China        NaN   \n",
       "...                                                 ...        ...   \n",
       "1632                                              China        NaN   \n",
       "1660  United Kingdom of Great Britain and Northern I...        NaN   \n",
       "1664  United States of America,Multinational,India,B...        NaN   \n",
       "1665                           United States of America        NaN   \n",
       "1667  United States of America,United Kingdom of Gre...        NaN   \n",
       "\n",
       "     Finetune compute (FLOP) Hardware quantity Hardware utilization  \\\n",
       "52                       NaN           32000.0                  NaN   \n",
       "87                       NaN               NaN                  NaN   \n",
       "94                       NaN               NaN                  NaN   \n",
       "101                      NaN          100000.0                  NaN   \n",
       "206                      NaN               NaN                  NaN   \n",
       "...                      ...               ...                  ...   \n",
       "1632                     NaN               NaN                  NaN   \n",
       "1660                     NaN               NaN                  NaN   \n",
       "1664                     NaN               NaN                  NaN   \n",
       "1665                     NaN              16.0               0.4484   \n",
       "1667                     NaN               NaN                  NaN   \n",
       "\n",
       "      Training cloud compute vendor  \\\n",
       "52                              NaN   \n",
       "87                         Azure AI   \n",
       "94                              NaN   \n",
       "101                             NaN   \n",
       "206                             NaN   \n",
       "...                             ...   \n",
       "1632                            NaN   \n",
       "1660                            NaN   \n",
       "1664                            NaN   \n",
       "1665                            NaN   \n",
       "1667                            NaN   \n",
       "\n",
       "                                   Training data center          Cost  \\\n",
       "52                                                  NaN           NaN   \n",
       "87                                                  NaN           NaN   \n",
       "94                                                  NaN           NaN   \n",
       "101                                xAI Memphis Colossus  3.014548e+08   \n",
       "206   There is no paper to reference, also no inform...           NaN   \n",
       "...                                                 ...           ...   \n",
       "1632                                                NaN           NaN   \n",
       "1660                                                NaN           NaN   \n",
       "1664                                                NaN           NaN   \n",
       "1665                                                NaN  1.854566e+02   \n",
       "1667                                                NaN           NaN   \n",
       "\n",
       "     Cost (inflation-adjusted)  \n",
       "52                         NaN  \n",
       "87                         NaN  \n",
       "94                         NaN  \n",
       "101               3.008724e+08  \n",
       "206                        NaN  \n",
       "...                        ...  \n",
       "1632                       NaN  \n",
       "1660                       NaN  \n",
       "1664                       NaN  \n",
       "1665              2.068604e+02  \n",
       "1667                       NaN  \n",
       "\n",
       "[89 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_cols = [\n",
    "    'Model',\n",
    "    'Domain',\n",
    "    'Task',\n",
    "    'Model accessibility',\n",
    "    'Reference',\n",
    "    'Publication date',\n",
    "    'Organization',\n",
    "    'Parameters',\n",
    "    'Training compute (FLOP)',\n",
    "    'Training dataset size (datapoints)',\n",
    "    'Epochs',\n",
    "    'Training time (hours)',\n",
    "    'Training hardware',\n",
    "    'Country (of organization)',\n",
    "    'Base model',\n",
    "    'Finetune compute (FLOP)',\n",
    "    'Hardware quantity',\n",
    "    'Hardware utilization',\n",
    "    'Training cloud compute vendor',\n",
    "    'Training data center',\n",
    "    # 'Training time (chip hours)',\n",
    "    'Cost',\n",
    "    'Cost (inflation-adjusted)',\n",
    "]\n",
    "cost_df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_df[keep_cols].to_csv(results_dir + 'cost_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:55:04.230921600Z",
     "start_time": "2024-03-08T01:55:00.065485900Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(\n",
    "#     cost_df,\n",
    "#     x='Publication date',\n",
    "#     y='Cost (inflation-adjusted)',\n",
    "#     text='Model',\n",
    "#     log_y=True,\n",
    "# )\n",
    "# fig.update_traces(textposition='top center')\n",
    "\n",
    "# # no legend\n",
    "# fig.update_layout(showlegend=False)\n",
    "\n",
    "# # axis labels\n",
    "# fig.update_xaxes(title_text='Publication date')\n",
    "# fig.update_yaxes(title_text='Cost (2024 USD, log scale)')\n",
    "\n",
    "# # title\n",
    "# fig.update_layout(title_text=get_cost_plot_title(estimation_method, compute_threshold_method, compute_threshold))\n",
    "\n",
    "# # update size\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "#     title_font=dict(\n",
    "#         size=16,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # font size\n",
    "# fig.update_layout(\n",
    "#     font=dict(\n",
    "#         size=14,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # margins\n",
    "# fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "# save_plot(fig, results_dir, 'cost_scatter')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:55:04.855981900Z",
     "start_time": "2024-03-08T01:55:04.230921600Z"
    }
   },
   "outputs": [],
   "source": [
    "label_systems = ['GNMT', 'AlphaGo Zero', 'DALL-E', 'GPT-3 175B (davinci)', 'GPT-4', 'Llama 3.1-405B', 'Grok-2']\n",
    "\n",
    "tpu_mask = cost_df['Training hardware'].str.contains('TPU', na=False)\n",
    "tpu_cost_df = cost_df.loc[tpu_mask]\n",
    "gpu_cost_df = cost_df.loc[~tpu_mask]\n",
    "\n",
    "# fig = go.Figure()\n",
    "\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=gpu_cost_df['Publication date'],\n",
    "#     y=gpu_cost_df['Cost (inflation-adjusted)'],\n",
    "#     text=gpu_cost_df['Model'],\n",
    "#     mode='markers',\n",
    "#     showlegend=False,\n",
    "# ))\n",
    "# fig.update_yaxes(type='log')\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=tpu_cost_df['Publication date'],\n",
    "#     y=tpu_cost_df['Cost (inflation-adjusted)'],\n",
    "#     text=tpu_cost_df['Model'],\n",
    "#     mode='markers',\n",
    "#     marker_symbol='circle-open' if estimation_method != 'cloud' else 'circle',\n",
    "#     name='Using estimated cost of TPU' if estimation_method != 'cloud' else '',\n",
    "#     showlegend=estimation_method != 'cloud',\n",
    "# ))\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=gpu_cost_df.loc[gpu_cost_df['Model'].isin(label_systems)]['Publication date'],\n",
    "#     y=gpu_cost_df.loc[gpu_cost_df['Model'].isin(label_systems)]['Cost (inflation-adjusted)'],\n",
    "#     text=gpu_cost_df.loc[gpu_cost_df['Model'].isin(label_systems)]['Model'],\n",
    "#     mode='text',\n",
    "#     showlegend=False,\n",
    "# ))\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=tpu_cost_df.loc[tpu_cost_df['Model'].isin(label_systems)]['Publication date'],\n",
    "#     y=tpu_cost_df.loc[tpu_cost_df['Model'].isin(label_systems)]['Cost (inflation-adjusted)'],\n",
    "#     text=tpu_cost_df.loc[tpu_cost_df['Model'].isin(label_systems)]['Model'],\n",
    "#     mode='text',\n",
    "#     showlegend=False,\n",
    "# ))\n",
    "\n",
    "# # Marker color\n",
    "# fig.update_traces(\n",
    "#     marker=dict(\n",
    "#         color='rgb(0,100,200)',\n",
    "#     ),\n",
    "#     selector=dict(mode='markers'),\n",
    "# )\n",
    "\n",
    "# # Shade in CI\n",
    "# fig.add_scatter(\n",
    "#     x=predicted_cost_df['Publication date'],\n",
    "#     y=10**predicted_cost_df['mean_ci_lower'],\n",
    "#     mode='lines',\n",
    "#     line=dict(width=0),\n",
    "#     showlegend=False,\n",
    "# )\n",
    "# fig.add_scatter(\n",
    "#     x=predicted_cost_df['Publication date'],\n",
    "#     y=10**predicted_cost_df['mean_ci_upper'],\n",
    "#     mode='lines',\n",
    "#     fill='tonexty',\n",
    "#     fillcolor='rgba(0,100,200,0.2)',\n",
    "#     line=dict(width=0),\n",
    "#     name='90% CI of mean',\n",
    "# )\n",
    "# fig.add_scatter(\n",
    "#     x=predicted_cost_df['Publication date'],\n",
    "#     y=10**predicted_cost_df['mean'],\n",
    "#     mode='lines',\n",
    "#     line=dict(color='rgb(0,100,200)'),\n",
    "#     name=f'Regression mean (growth rate: {10**reg_results.params[1]:.1f}x per year)',\n",
    "# )\n",
    "\n",
    "# fig.update_traces(textposition='top center')\n",
    "\n",
    "# # axis limits\n",
    "# # fig.update_xaxes(range=[pred_start_date, pred_end_date])\n",
    "# fig.update_xaxes(range=['2015-01-01', '2025-06-01'])  #Â manual\n",
    "# if estimation_method == 'hardware-acquisition':\n",
    "#     fig.update_yaxes(range=[4, 10])\n",
    "# else:\n",
    "#     fig.update_yaxes(range=[1, 9])\n",
    "\n",
    "# # legend on bottom-right of the axes\n",
    "# fig.update_layout(\n",
    "#     legend=dict(\n",
    "#         x=0.45,\n",
    "#         y=0.05,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # axis labels\n",
    "# fig.update_xaxes(title_text='Publication date')\n",
    "# fig.update_yaxes(title_text='Cost (2024 USD, log scale)')\n",
    "\n",
    "# # title\n",
    "# fig.update_layout(title_text=get_cost_plot_title(estimation_method, compute_threshold_method, compute_threshold))\n",
    "\n",
    "# # update size\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "#     title_font=dict(\n",
    "#         size=16,\n",
    "#     ),\n",
    "#     title_x=0.5,\n",
    "# )\n",
    "\n",
    "# # font size\n",
    "# fig.update_layout(\n",
    "#     font=dict(\n",
    "#         size=14,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # margins\n",
    "# fig.update_layout(margin=dict(l=10, r=10, t=60, b=10))\n",
    "\n",
    "# save_plot(fig, results_dir, 'cost_regression')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_component_names = [\n",
    "    'AI accelerator chip cost',\n",
    "    'Other server components cost',\n",
    "    'Cluster-level interconnect cost',\n",
    "    'Energy cost',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52            NaN\n",
       "87            NaN\n",
       "94            NaN\n",
       "101     45.507920\n",
       "206           NaN\n",
       "          ...    \n",
       "1632          NaN\n",
       "1660          NaN\n",
       "1664          NaN\n",
       "1665    34.484219\n",
       "1667          NaN\n",
       "Name: AI accelerator chip cost (%), Length: 89, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in cost_component_names:\n",
    "    component_cost_df[f\"{key} (%)\"] = component_cost_df[key] / component_cost_df['Cost'] * 100\n",
    "component_cost_df['AI accelerator chip cost (%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_component_pc_names = [name + ' (%)' for name in cost_component_names]\n",
    "filtered_component_cost_df = component_cost_df.dropna(subset=cost_component_pc_names).sort_values(by='Publication date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked bar chart of cost components, using component_cost_df\n",
    "# fig = px.bar(\n",
    "#     filtered_component_cost_df,\n",
    "#     x='Model',\n",
    "#     y=cost_component_pc_names,\n",
    "#     barmode='stack',\n",
    "# )\n",
    "\n",
    "# # axis labels\n",
    "# fig.update_xaxes(title_text='ML model')\n",
    "# fig.update_yaxes(title_text='% of amortized hardware CapEx + energy')\n",
    "# fig.update_layout(\n",
    "#     legend=dict(\n",
    "#         title_text='Cost component',\n",
    "#         x=0.60,\n",
    "#         y=0.05,\n",
    "#     )\n",
    "# )\n",
    "# # limits 0 to 100\n",
    "# fig.update_yaxes(range=[0, 100])\n",
    "\n",
    "# fig.update_yaxes(tickvals=list(range(0, 101, 10)))\n",
    "\n",
    "# # size\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "# )\n",
    "\n",
    "# # margins\n",
    "# fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "# save_plot(fig, results_dir, 'cost_component_percentage')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Notability criteria</th>\n",
       "      <th>...</th>\n",
       "      <th>Post-training compute notes</th>\n",
       "      <th>Cost</th>\n",
       "      <th>AI accelerator chip cost</th>\n",
       "      <th>Other server components cost</th>\n",
       "      <th>Cluster-level interconnect cost</th>\n",
       "      <th>Energy cost</th>\n",
       "      <th>AI accelerator chip cost (%)</th>\n",
       "      <th>Other server components cost (%)</th>\n",
       "      <th>Cluster-level interconnect cost (%)</th>\n",
       "      <th>Energy cost (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech recognition</td>\n",
       "      <td>Baidu Research - Silicon Valley AI Lab</td>\n",
       "      <td>Dario Amodei, Rishita Anubhai, Eric Battenberg...</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
       "      <td>https://arxiv.org/abs/1512.02595</td>\n",
       "      <td>2853.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185.456639</td>\n",
       "      <td>63.953273</td>\n",
       "      <td>40.930095</td>\n",
       "      <td>24.602271</td>\n",
       "      <td>55.971000</td>\n",
       "      <td>34.484219</td>\n",
       "      <td>22.069900</td>\n",
       "      <td>13.265781</td>\n",
       "      <td>30.180101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>Language</td>\n",
       "      <td>Translation</td>\n",
       "      <td>Google</td>\n",
       "      <td>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>Google's Neural Machine Translation System: Br...</td>\n",
       "      <td>https://arxiv.org/abs/1609.08144</td>\n",
       "      <td>6483.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177459.232941</td>\n",
       "      <td>77894.044829</td>\n",
       "      <td>49852.188691</td>\n",
       "      <td>29965.165887</td>\n",
       "      <td>19747.833534</td>\n",
       "      <td>43.894050</td>\n",
       "      <td>28.092192</td>\n",
       "      <td>16.885662</td>\n",
       "      <td>11.128096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Xception</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Google</td>\n",
       "      <td>FranÃ§ois Chollet</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>Xception: Deep Learning with Depthwise Separab...</td>\n",
       "      <td>https://arxiv.org/abs/1610.02357</td>\n",
       "      <td>13038.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11554.506253</td>\n",
       "      <td>5064.230483</td>\n",
       "      <td>3241.107509</td>\n",
       "      <td>1948.165702</td>\n",
       "      <td>1301.002560</td>\n",
       "      <td>43.829051</td>\n",
       "      <td>28.050593</td>\n",
       "      <td>16.860657</td>\n",
       "      <td>11.259698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>PolyNet</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Chinese University of Hong Kong (CUHK)</td>\n",
       "      <td>X Zhang, Z Li, C Change Loy</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>PolyNet: A Pursuit of Structural Diversity in ...</td>\n",
       "      <td>https://arxiv.org/abs/1611.05725</td>\n",
       "      <td>282.0</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>563.599706</td>\n",
       "      <td>178.564122</td>\n",
       "      <td>114.281038</td>\n",
       "      <td>68.692074</td>\n",
       "      <td>202.062472</td>\n",
       "      <td>31.682792</td>\n",
       "      <td>20.276987</td>\n",
       "      <td>12.188096</td>\n",
       "      <td>35.852125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>MoE-Multi</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modeling,Translation</td>\n",
       "      <td>Jagiellonian University,Google Brain</td>\n",
       "      <td>N Shazeer, A Mirhoseini, K Maziarz, A Davis</td>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>Outrageously Large Neural Networks: The Sparse...</td>\n",
       "      <td>https://arxiv.org/abs/1701.06538</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3538.189418</td>\n",
       "      <td>1519.646471</td>\n",
       "      <td>972.573741</td>\n",
       "      <td>584.594865</td>\n",
       "      <td>461.374341</td>\n",
       "      <td>42.949834</td>\n",
       "      <td>27.487894</td>\n",
       "      <td>16.522430</td>\n",
       "      <td>13.039843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model    Domain                           Task  \\\n",
       "1665  DeepSpeech2 (English)    Speech             Speech recognition   \n",
       "1624                   GNMT  Language                    Translation   \n",
       "1623               Xception    Vision           Image classification   \n",
       "1615                PolyNet    Vision           Image classification   \n",
       "1604              MoE-Multi  Language  Language modeling,Translation   \n",
       "\n",
       "                                Organization  \\\n",
       "1665  Baidu Research - Silicon Valley AI Lab   \n",
       "1624                                  Google   \n",
       "1623                                  Google   \n",
       "1615  Chinese University of Hong Kong (CUHK)   \n",
       "1604    Jagiellonian University,Google Brain   \n",
       "\n",
       "                                                Authors Publication date  \\\n",
       "1665  Dario Amodei, Rishita Anubhai, Eric Battenberg...       2015-12-08   \n",
       "1624  Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...       2016-09-26   \n",
       "1623                                   FranÃ§ois Chollet       2016-10-07   \n",
       "1615                        X Zhang, Z Li, C Change Loy       2016-11-17   \n",
       "1604        N Shazeer, A Mirhoseini, K Maziarz, A Davis       2017-01-23   \n",
       "\n",
       "                                              Reference  \\\n",
       "1665  Deep Speech 2: End-to-End Speech Recognition i...   \n",
       "1624  Google's Neural Machine Translation System: Br...   \n",
       "1623  Xception: Deep Learning with Depthwise Separab...   \n",
       "1615  PolyNet: A Pursuit of Structural Diversity in ...   \n",
       "1604  Outrageously Large Neural Networks: The Sparse...   \n",
       "\n",
       "                                  Link  Citations  \\\n",
       "1665  https://arxiv.org/abs/1512.02595     2853.0   \n",
       "1624  https://arxiv.org/abs/1609.08144     6483.0   \n",
       "1623  https://arxiv.org/abs/1610.02357    13038.0   \n",
       "1615  https://arxiv.org/abs/1611.05725      282.0   \n",
       "1604  https://arxiv.org/abs/1701.06538     2037.0   \n",
       "\n",
       "                Notability criteria  ... Post-training compute notes  \\\n",
       "1665                   Highly cited  ...                         NaN   \n",
       "1624                   Highly cited  ...                         NaN   \n",
       "1623                   Highly cited  ...                         NaN   \n",
       "1615               SOTA improvement  ...                         NaN   \n",
       "1604  Highly cited,SOTA improvement  ...                         NaN   \n",
       "\n",
       "               Cost AI accelerator chip cost  Other server components cost  \\\n",
       "1665     185.456639                63.953273                     40.930095   \n",
       "1624  177459.232941             77894.044829                  49852.188691   \n",
       "1623   11554.506253              5064.230483                   3241.107509   \n",
       "1615     563.599706               178.564122                    114.281038   \n",
       "1604    3538.189418              1519.646471                    972.573741   \n",
       "\n",
       "     Cluster-level interconnect cost   Energy cost  \\\n",
       "1665                       24.602271     55.971000   \n",
       "1624                    29965.165887  19747.833534   \n",
       "1623                     1948.165702   1301.002560   \n",
       "1615                       68.692074    202.062472   \n",
       "1604                      584.594865    461.374341   \n",
       "\n",
       "     AI accelerator chip cost (%)  Other server components cost (%)  \\\n",
       "1665                    34.484219                         22.069900   \n",
       "1624                    43.894050                         28.092192   \n",
       "1623                    43.829051                         28.050593   \n",
       "1615                    31.682792                         20.276987   \n",
       "1604                    42.949834                         27.487894   \n",
       "\n",
       "     Cluster-level interconnect cost (%)  Energy cost (%)  \n",
       "1665                           13.265781        30.180101  \n",
       "1624                           16.885662        11.128096  \n",
       "1623                           16.860657        11.259698  \n",
       "1615                           12.188096        35.852125  \n",
       "1604                           16.522430        13.039843  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_component_cost_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_component_cost_df.to_csv(results_dir + 'cost_components.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AI accelerator chip cost (%)           45.618313\n",
       "Other server components cost (%)       29.544045\n",
       "Cluster-level interconnect cost (%)    17.630677\n",
       "Energy cost (%)                         7.206965\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average percentage for each component\n",
    "filtered_component_cost_df[cost_component_pc_names].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.bar(\n",
    "#     filtered_component_cost_df,\n",
    "#     x='Model',\n",
    "#     y='Energy cost (%)',\n",
    "#     barmode='stack',\n",
    "#     # labels='Cost %',\n",
    "#     # text='Energy cost %',\n",
    "# )\n",
    "# # axis labels\n",
    "# fig.update_xaxes(title_text='Model')\n",
    "# fig.update_yaxes(title_text='Energy cost (% of amortized hardware CapEx + energy)')\n",
    "# # fig.update_layout(\n",
    "# #     legend=dict(\n",
    "# #         title_text='Cost component',\n",
    "# #         x=0.75,\n",
    "# #         y=0.05,\n",
    "# #     )\n",
    "# # )\n",
    "# # limits 0 to 100\n",
    "# fig.update_yaxes(range=[0, 30])\n",
    "# # size\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "# )\n",
    "\n",
    "# # margins\n",
    "# fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "# save_plot(fig, results_dir, 'energy_percentage')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.scatter(\n",
    "#     filtered_component_cost_df,\n",
    "#     x='Publication date',\n",
    "#     y='Energy cost',\n",
    "#     text='Model',\n",
    "# )\n",
    "# # axis labels\n",
    "# fig.update_xaxes(title_text='Model')\n",
    "# fig.update_yaxes(title_text='Energy cost')\n",
    "# # log y\n",
    "# fig.update_yaxes(type='log')\n",
    "# # size\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "# )\n",
    "\n",
    "# # margins\n",
    "# fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "# save_plot(fig, results_dir, 'energy_cost')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from energy import energy_price\n",
    "\n",
    "# Stacked bar chart of cost components, using component_cost_df\n",
    "filtered_component_cost_df.loc[:, 'Energy (kWh)'] = [\n",
    "    row['Energy cost'] / energy_price(row['Publication date'].year) \n",
    "    for _, row in filtered_component_cost_df.iterrows()\n",
    "]\n",
    "# fig = px.scatter(\n",
    "#     filtered_component_cost_df,\n",
    "#     x='Publication date',\n",
    "#     y='Energy (kWh)',\n",
    "#     text='Model',\n",
    "# )\n",
    "# # log y\n",
    "# fig.update_yaxes(type='log')\n",
    "# # size\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "# )\n",
    "\n",
    "# # margins\n",
    "# fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "# save_plot(fig, results_dir, 'energy_kwh')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Model', 'Domain', 'Task', 'Organization', 'Authors',\n",
       "       'Publication date', 'Reference', 'Link', 'Citations',\n",
       "       'Notability criteria', 'Notability criteria notes', 'Parameters',\n",
       "       'Parameters notes', 'Training compute (FLOP)', 'Training compute notes',\n",
       "       'Training dataset', 'Training dataset notes',\n",
       "       'Training dataset size (datapoints)', 'Dataset size notes',\n",
       "       'Training time (hours)', 'Training time notes', 'Training hardware',\n",
       "       'Approach', 'Confidence', 'Abstract', 'Epochs', 'Benchmark data',\n",
       "       'Model accessibility', 'Country (of organization)', 'Base model',\n",
       "       'Finetune compute (FLOP)', 'Finetune compute notes',\n",
       "       'Hardware quantity', 'Hardware utilization', 'Last modified',\n",
       "       'Training cloud compute vendor', 'Training data center',\n",
       "       'Archived links', 'Batch size', 'Batch size notes',\n",
       "       'Organization categorization', 'Foundation model',\n",
       "       'Training compute lower bound', 'Training compute upper bound',\n",
       "       'Training chip-hours', 'Training code accessibility',\n",
       "       'Accessibility notes',\n",
       "       'Organization categorization (from Organization)',\n",
       "       'Training compute cost (2023 USD)', 'Utilization notes',\n",
       "       'Numerical format', 'Training power draw (W)',\n",
       "       'Training compute estimation method', 'Hugging Face developer id',\n",
       "       'Post-training compute (FLOP)', 'Post-training compute notes', 'Cost',\n",
       "       'AI accelerator chip cost', 'Other server components cost',\n",
       "       'Cluster-level interconnect cost', 'Energy cost',\n",
       "       'AI accelerator chip cost (%)', 'Other server components cost (%)',\n",
       "       'Cluster-level interconnect cost (%)', 'Energy cost (%)',\n",
       "       'Energy (kWh)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_component_cost_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_component_cost_df = filtered_component_cost_df.dropna(subset=['Training hardware'])\n",
    "power_col = 'Power capacity for final training run (kW)'\n",
    "filtered_component_cost_df.loc[:, power_col] = [\n",
    "    cluster_power_capacity(row['Training hardware'], row['Hardware quantity'], hardware_df, row['Organization'])\n",
    "    for _, row in filtered_component_cost_df.iterrows()\n",
    "]\n",
    "\n",
    "# fig = px.scatter(\n",
    "#     filtered_component_cost_df,\n",
    "#     x='Publication date',\n",
    "#     y=power_col,\n",
    "#     text='Model',\n",
    "# )\n",
    "# # log y\n",
    "# fig.update_yaxes(type='log')\n",
    "# # size\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "# )\n",
    "\n",
    "# # margins\n",
    "# fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n",
    "\n",
    "# save_plot(fig, results_dir, 'power_capacity_kw')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_component_cost_df['Publication date (float)'] = datetime_to_float_year(\n",
    "    pd.to_datetime(filtered_component_cost_df['Publication date'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   149.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 30 Jul 2025</td> <th>  Prob (F-statistic):</th> <td>2.80e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:32:50</td>     <th>  Log-Likelihood:    </th> <td> -24.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    43</td>      <th>  AIC:               </th> <td>   52.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    41</td>      <th>  BIC:               </th> <td>   55.97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -703.9984</td> <td>   57.729</td> <td>  -12.195</td> <td> 0.000</td> <td> -820.584</td> <td> -587.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.3497</td> <td>    0.029</td> <td>   12.244</td> <td> 0.000</td> <td>    0.292</td> <td>    0.407</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.823</td> <th>  Durbin-Watson:     </th> <td>   1.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.402</td> <th>  Jarque-Bera (JB):  </th> <td>   0.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.327</td> <th>  Prob(JB):          </th> <td>   0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.353</td> <th>  Cond. No.          </th> <td>1.76e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.76e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.785   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.780   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     149.9   \\\\\n",
       "\\textbf{Date:}             & Wed, 30 Jul 2025 & \\textbf{  Prob (F-statistic):} &  2.80e-15   \\\\\n",
       "\\textbf{Time:}             &     15:32:50     & \\textbf{  Log-Likelihood:    } &   -24.222   \\\\\n",
       "\\textbf{No. Observations:} &          43      & \\textbf{  AIC:               } &     52.44   \\\\\n",
       "\\textbf{Df Residuals:}     &          41      & \\textbf{  BIC:               } &     55.97   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    -703.9984  &       57.729     &   -12.195  &         0.000        &     -820.584    &     -587.412     \\\\\n",
       "\\textbf{x1}    &       0.3497  &        0.029     &    12.244  &         0.000        &        0.292    &        0.407     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.823 & \\textbf{  Durbin-Watson:     } &    1.654  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.402 & \\textbf{  Jarque-Bera (JB):  } &    0.989  \\\\\n",
       "\\textbf{Skew:}          &  0.327 & \\textbf{  Prob(JB):          } &    0.610  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.353 & \\textbf{  Cond. No.          } & 1.76e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.76e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.785\n",
       "Model:                            OLS   Adj. R-squared:                  0.780\n",
       "Method:                 Least Squares   F-statistic:                     149.9\n",
       "Date:                Wed, 30 Jul 2025   Prob (F-statistic):           2.80e-15\n",
       "Time:                        15:32:50   Log-Likelihood:                -24.222\n",
       "No. Observations:                  43   AIC:                             52.44\n",
       "Df Residuals:                      41   BIC:                             55.97\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -703.9984     57.729    -12.195      0.000    -820.584    -587.412\n",
       "x1             0.3497      0.029     12.244      0.000       0.292       0.407\n",
       "==============================================================================\n",
       "Omnibus:                        1.823   Durbin-Watson:                   1.654\n",
       "Prob(Omnibus):                  0.402   Jarque-Bera (JB):                0.989\n",
       "Skew:                           0.327   Prob(JB):                        0.610\n",
       "Kurtosis:                       3.353   Cond. No.                     1.76e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.76e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_reg_results = fit_ols_regression(\n",
    "    filtered_component_cost_df,\n",
    "    ['Publication date (float)'],\n",
    "    power_col,\n",
    "    logy=True\n",
    ")\n",
    "power_reg_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=43.0\n",
      "R^2=0.79\n",
      "0.34972925639193325 OOMs/year (90% CI: 0.301660382440203, 0.3977981303436635)\n",
      "2.23732593192286x/year (90% CI: 2.002905146315243x, 2.499183416081074x)\n",
      "doubling time of 10.32901846770145 months (90% CI: 9.08088719483675, 11.974923318556222)\n"
     ]
    }
   ],
   "source": [
    "with open(f'{results_dir}/power_regression_results.out', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        print_growth_rates(power_reg_results)\n",
    "print_growth_rates(power_reg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication date (float)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.10101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.20202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.30303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.40404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2024.59596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2024.69697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2024.79798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2024.89899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2025.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Publication date (float)\n",
       "0                 2015.00000\n",
       "1                 2015.10101\n",
       "2                 2015.20202\n",
       "3                 2015.30303\n",
       "4                 2015.40404\n",
       "..                       ...\n",
       "95                2024.59596\n",
       "96                2024.69697\n",
       "97                2024.79798\n",
       "98                2024.89899\n",
       "99                2025.00000\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_start_year = 2015\n",
    "pred_end_year = 2025\n",
    "pred_start_date = f'{pred_start_year}-01-01'\n",
    "pred_end_date = f'{pred_end_year}-01-01'\n",
    "\n",
    "pred_years = pd.DataFrame({'Publication date (float)': np.linspace(pred_start_year, pred_end_year, 100)})\n",
    "pred_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "      <th>Publication date (float)</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.706065</td>\n",
       "      <td>0.185751</td>\n",
       "      <td>0.393470</td>\n",
       "      <td>1.018661</td>\n",
       "      <td>-0.090333</td>\n",
       "      <td>1.502463</td>\n",
       "      <td>2015.00000</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741392</td>\n",
       "      <td>0.183059</td>\n",
       "      <td>0.433326</td>\n",
       "      <td>1.049457</td>\n",
       "      <td>-0.053239</td>\n",
       "      <td>1.536022</td>\n",
       "      <td>2015.10101</td>\n",
       "      <td>2015-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776718</td>\n",
       "      <td>0.180373</td>\n",
       "      <td>0.473172</td>\n",
       "      <td>1.080264</td>\n",
       "      <td>-0.016172</td>\n",
       "      <td>1.569607</td>\n",
       "      <td>2015.20202</td>\n",
       "      <td>2015-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.812044</td>\n",
       "      <td>0.177694</td>\n",
       "      <td>0.513007</td>\n",
       "      <td>1.111081</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>1.603218</td>\n",
       "      <td>2015.30303</td>\n",
       "      <td>2015-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.847370</td>\n",
       "      <td>0.175020</td>\n",
       "      <td>0.552832</td>\n",
       "      <td>1.141908</td>\n",
       "      <td>0.057885</td>\n",
       "      <td>1.636855</td>\n",
       "      <td>2015.40404</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.062053</td>\n",
       "      <td>0.120531</td>\n",
       "      <td>3.859215</td>\n",
       "      <td>4.264892</td>\n",
       "      <td>3.302002</td>\n",
       "      <td>4.822104</td>\n",
       "      <td>2024.59596</td>\n",
       "      <td>2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.097379</td>\n",
       "      <td>0.122949</td>\n",
       "      <td>3.890471</td>\n",
       "      <td>4.304288</td>\n",
       "      <td>3.336232</td>\n",
       "      <td>4.858527</td>\n",
       "      <td>2024.69697</td>\n",
       "      <td>2024-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.132706</td>\n",
       "      <td>0.125388</td>\n",
       "      <td>3.921693</td>\n",
       "      <td>4.343718</td>\n",
       "      <td>3.370433</td>\n",
       "      <td>4.894978</td>\n",
       "      <td>2024.79798</td>\n",
       "      <td>2024-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.168032</td>\n",
       "      <td>0.127845</td>\n",
       "      <td>3.952885</td>\n",
       "      <td>4.383179</td>\n",
       "      <td>3.404604</td>\n",
       "      <td>4.931459</td>\n",
       "      <td>2024.89899</td>\n",
       "      <td>2024-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.203358</td>\n",
       "      <td>0.130319</td>\n",
       "      <td>3.984047</td>\n",
       "      <td>4.422669</td>\n",
       "      <td>3.438746</td>\n",
       "      <td>4.967970</td>\n",
       "      <td>2025.00000</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0   0.706065  0.185751       0.393470       1.018661     -0.090333   \n",
       "1   0.741392  0.183059       0.433326       1.049457     -0.053239   \n",
       "2   0.776718  0.180373       0.473172       1.080264     -0.016172   \n",
       "3   0.812044  0.177694       0.513007       1.111081      0.020870   \n",
       "4   0.847370  0.175020       0.552832       1.141908      0.057885   \n",
       "..       ...       ...            ...            ...           ...   \n",
       "95  4.062053  0.120531       3.859215       4.264892      3.302002   \n",
       "96  4.097379  0.122949       3.890471       4.304288      3.336232   \n",
       "97  4.132706  0.125388       3.921693       4.343718      3.370433   \n",
       "98  4.168032  0.127845       3.952885       4.383179      3.404604   \n",
       "99  4.203358  0.130319       3.984047       4.422669      3.438746   \n",
       "\n",
       "    obs_ci_upper  Publication date (float) Publication date  \n",
       "0       1.502463                2015.00000       2015-01-01  \n",
       "1       1.536022                2015.10101       2015-02-06  \n",
       "2       1.569607                2015.20202       2015-03-15  \n",
       "3       1.603218                2015.30303       2015-04-21  \n",
       "4       1.636855                2015.40404       2015-05-28  \n",
       "..           ...                       ...              ...  \n",
       "95      4.822104                2024.59596       2024-08-06  \n",
       "96      4.858527                2024.69697       2024-09-12  \n",
       "97      4.894978                2024.79798       2024-10-19  \n",
       "98      4.931459                2024.89899       2024-11-25  \n",
       "99      4.967970                2025.00000       2025-01-01  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_power_df = get_predictions(power_reg_results, pred_years, ['Publication date (float)'])\n",
    "predicted_power_df['Publication date'] = predicted_power_df['Publication date (float)'].apply(float_year_to_datetime)\n",
    "predicted_power_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_systems = ['GNMT', 'AlphaGo Master', 'AlphaGo Zero', 'AlphaZero', 'DALL-E', 'GPT-3 175B (davinci)', 'PaLM (540B)', 'Llama 2-70B', 'Falcon 180B', 'GPT-4', 'Gemini 1.0 Ultra', 'Inflection-2']\n",
    "\n",
    "# fig = px.scatter(\n",
    "#     filtered_component_cost_df,\n",
    "#     x='Publication date',\n",
    "#     y=power_col,\n",
    "#     log_y=True,\n",
    "# )\n",
    "\n",
    "# # Marker color\n",
    "# fig.update_traces(\n",
    "#     marker=dict(\n",
    "#         color='rgb(0,100,200)',\n",
    "#     ),\n",
    "#     selector=dict(mode='markers'),\n",
    "# )\n",
    "\n",
    "# fig.add_scatter(\n",
    "#     x=filtered_component_cost_df.loc[filtered_component_cost_df['Model'].isin(label_systems)]['Publication date'],\n",
    "#     y=filtered_component_cost_df.loc[filtered_component_cost_df['Model'].isin(label_systems)][power_col],\n",
    "#     text=filtered_component_cost_df.loc[filtered_component_cost_df['Model'].isin(label_systems)]['Model'],\n",
    "#     mode='text',\n",
    "#     showlegend=False,\n",
    "# )\n",
    "\n",
    "# # Shade in CI\n",
    "# fig.add_scatter(\n",
    "#     x=predicted_power_df['Publication date'],\n",
    "#     y=10**predicted_power_df['mean_ci_lower'],\n",
    "#     mode='lines',\n",
    "#     line=dict(width=0),\n",
    "#     showlegend=False,\n",
    "# )\n",
    "# fig.add_scatter(\n",
    "#     x=predicted_power_df['Publication date'],\n",
    "#     y=10**predicted_power_df['mean_ci_upper'],\n",
    "#     mode='lines',\n",
    "#     fill='tonexty',\n",
    "#     fillcolor='rgba(0,100,200,0.2)',\n",
    "#     line=dict(width=0),\n",
    "#     name='90% CI of mean',\n",
    "# )\n",
    "# fig.add_scatter(\n",
    "#     x=predicted_power_df['Publication date'],\n",
    "#     y=10**predicted_power_df['mean'],\n",
    "#     mode='lines',\n",
    "#     line=dict(color='rgb(0,100,200)'),\n",
    "#     name=f'Regression mean (growth rate: {10**power_reg_results.params[1]:.1f}x per year)',\n",
    "# )\n",
    "\n",
    "# fig.update_traces(textposition='top center')\n",
    "\n",
    "# # axis limits\n",
    "# fig.update_xaxes(range=[pred_start_date, pred_end_date])\n",
    "# # fig.update_xaxes(range=['2015-01-01', '2025-01-01'])  #Â manual\n",
    "# # fig.update_yaxes(range=[1, 6])\n",
    "\n",
    "# # legend on bottom-right of the axes\n",
    "# fig.update_layout(\n",
    "#     legend=dict(\n",
    "#         x=0.45,\n",
    "#         y=0.05,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # axis labels\n",
    "# fig.update_xaxes(title_text='Publication date')\n",
    "# fig.update_yaxes(title_text='Power (kW, log scale)')\n",
    "\n",
    "# # title\n",
    "# fig.update_layout(title_text='Cluster power required for final training run')\n",
    "\n",
    "# # update size\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "#     title_font=dict(\n",
    "#         size=16,\n",
    "#     ),\n",
    "#     title_x=0.5,\n",
    "# )\n",
    "\n",
    "# # font size\n",
    "# fig.update_layout(\n",
    "#     font=dict(\n",
    "#         size=14,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # margins\n",
    "# fig.update_layout(margin=dict(l=10, r=10, t=60, b=10))\n",
    "\n",
    "# save_plot(fig, results_dir, 'power_regression')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
