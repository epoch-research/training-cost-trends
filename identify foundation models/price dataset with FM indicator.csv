,System,Domain,Task,Open-source,Reference,Publication date,Organization,Parameters,Training compute (FLOP),Training dataset size (datapoints),Epochs,Training time (hours),Training hardware,Country (from Organization),Base model,Finetune compute (FLOP),Hardware quantity,Hardware utilization,Training cloud compute vendor,Training data center,Training time (chip hours),Cost,Cost (inflation-adjusted),Foundation model?
0,Gemini Ultra,Multimodal,"Language modelling,Visual question answering,Chat,Translation",Unreleased,Gemini: A Family of Highly Capable Multimodal Models,2023-12-06 00:00:00,Google DeepMind,,8.00000000001e+25,,,2400.0,Google TPU v4,Multinational,,,55000.0,,,,132000000.0,191400000.0,191400000.0,False
1,Qwen-72B,Language,"Chat,Code generation",Permissive license,,2023-11-30 00:00:00,Alibaba,72000000000.0,1.3e+24,,,,,China,,,,,,,,,,False
2,Inflection-2,Language,Language modelling,API accessible,Inflection-2: The Next Step Up,2023-11-22 00:00:00,Inflection AI,,1.001e+25,,,,NVIDIA H100 SXM5,United States of America,,,5000.0,,,,,,,True
3,Nemotron-3-8B,Language,"Chat,Language Generation",Permissive license,NVIDIA AI Foundation Models: Build Custom Enterprise Chatbots and Co-Pilots with Production-Ready LLMs,2023-11-15 00:00:00,NVIDIA,8000000000.0,1.8e+23,,,456.0,NVIDIA A100,United States of America,,,,,,,,,,False
4,Yi-34B,Language,Chat,Permissive license,,2023-11-02 00:00:00,01.AI,34000000000.0,6.1e+23,,,,,China,,,,,,,,,,False
5,Skywork-13B,Language,Language modelling,Permissive license,Skywork: A More Open Bilingual Foundation Model,2023-10-30 00:00:00,Kunlun Inc.,13000000000.0,2.5e+23,2780000000000.0,1.0,940.0,NVIDIA A800,China,,,,,,,,,,False
6,ChatGLM3,Multimodal,"Chat,Visual question answering",,Zhipu AI launches third-generation base model,2023-10-27 00:00:00,Zhipu AI,130000000000.0,1.09200000000001e+24,1050000000000.0,,,,China,,,,,,,,,,True
7,XGen-7B,Language,Language Generation,Permissive license,XGen-7B Technical Report,2023-09-07 00:00:00,Salesforce,6700000000.0,8.02e+22,1113000000000.0,1.0,,Google TPU v4,United States of America,,,,,,,,,,False
8,Falcon 180B,Language,Language modelling,Permissive license,Falcon LLM - Falcon 180B,2023-09-06 00:00:00,Technology Innovation Institute,180000000000.0,3.76e+24,2625000000000.0,,4320.0,NVIDIA A100 SXM4 40 GB,United Arab Emirates,,,4096.0,0.1876,Amazon Web Services,,17694720.0,25657344.0,25816323.797898512,False
9,Jais,Language,Language modelling,,Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models,2023-08-29 00:00:00,"Cerebras Systems,Mohamed bin Zayed University of Artificial Intelligence,Inception",13000000000.0,3.08e+22,300000000000.0,,600.0,,"Multinational,United Arab Emirates,United States of America",,,,,,,,,,True
10,Llama 2-70B,Language,Language modelling,Fully open-source,Llama 2: Open Foundation and Fine-Tuned Chat Models,2023-07-18 00:00:00,Meta AI,70000000000.0,8.1e+23,1500000000000.0,1.0,2160.0,NVIDIA A100 SXM4 80 GB,Multinational,,,1000.0,0.435,,Meta’s Research Super Cluster,2160000.0,3909600.0,3931897.156858603,False
11,Llama 2-7B,Language,Language modelling,Fully open-source,Llama 2: Open Foundation and Fine-Tuned Chat Models,2023-07-18 00:00:00,Meta AI,70000000000.0,8.4e+22,1500000000000.0,1.0,,NVIDIA A100 SXM4 80 GB,Multinational,,,,,,Meta’s Research Super Cluster,,,,False
12,Claude 2,Language,Language modelling,API accessible,,2023-07-11 00:00:00,Anthropic,,3.866e+24,,,,,United States of America,,,,,,,,,,True
13,PaLM 2,Language,Language modelling,API accessible,PaLM 2 Technical Report,2023-05-10 00:00:00,Google,340000000000.0,7.34e+24,2700000000000.0,,,Google TPU v4,Multinational,,,,,,,,,,True
14,StarCoder,Language,Code generation,Fully open-source,StarCoder: may the source be with you!,2023-05-09 00:00:00,"Hugging Face,ServiceNow,Northeastern University,Mila- Quebec AI,Carnegie Mellon University (CMU),Johns Hopkins University,Leipzig University,ScaDS.AI,Queen Mary University of London,Roblox,Sea AI Lab,Technion - Israel Institute of Technology,Monash University,CSIRO,Data61,McGill University,Saama,University of British Columbia (UBC),Massachusetts Institute of Technology (MIT),Technical University of Munich,IBM,University of Vermont,UnfoldML,SAP,University of Notre Dame,Columbia University,New York University (NYU),University of Allahabad,Discover Dollar,Toloka,Telefonica,Stanford University,Weizmann Institute of Science,Alan Turing Institute,Wellesley College,EleutherAI,Forschungszentrum Julich",15500000000.0,1.12e+23,,1.0,,NVIDIA A100 SXM4 80 GB,"Multinational,United States of America,United States of America,Canada,United States of America,United States of America,Germany,Germany,United Kingdom of Great Britain and Northern Ireland,United States of America,Singapore,Israel,Australia,Australia,Australia,Canada,United States of America,Canada,United States of America,Germany,Multinational,United States of America,Sweden,Multinational,United States of America,United States of America,United States of America,India,India,Multinational,Spain,United States of America,Israel,United Kingdom of Great Britain and Northern Ireland,United States of America,Multinational,Germany",,,,,,,,,,True
15,WizardLM-7B,Language,Language modelling,Fully open-source,WizardLM: Empowering Large Language Models to Follow Complex Instructions,2023-04-24 00:00:00,"Microsoft,Peking University",6700000000.0,4.02e+22,,,,"NVIDIA A100,NVIDIA V100","Multinational,China",,,,,,,,,,False
16,BloombergGPT,Language,Language modelling,,BloombergGPT: A Large Language Model for Finance,2023-03-30 00:00:00,"Bloomberg,Johns Hopkins University",50558868480.0,2.36e+23,532000000000.0,0.8,1270.0,NVIDIA A100,"United States of America,United States of America",,,,,,,,,,True
17,PanGu-Σ,Language,"Code generation,Language modelling",,PanGu-Σ: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing,2023-03-20 00:00:00,Huawei Noah's Ark Lab,1085000000000.0,4.669999999999999e+23,246750000000.0,1.84,2400.0,Huawei Ascend 910,China,,,512.0,,,,1228800.0,,,False
18,GPT-4,Multimodal,Language modelling,API accessible,GPT-4 Technical Report,2023-03-15 00:00:00,OpenAI,,2.1e+25,4900000000000.0,2.0,2280.0,NVIDIA A100 SXM4 40 GB,United States of America,,,25000.0,0.34,,,57000000.0,82650000.0,83537094.74721056,True
19,Falcon-40B,Language,Language modelling,Fully open-source,Abu Dhabi-based Technology Innovation Institute Introduces Falcon LLM: Foundational Large Language Model (LLM) outperforms GPT-3 with 40 Billion Parameters,2023-03-15 00:00:00,Technology Innovation Institute,40000000000.0,2.4e+23,750000000000.0,,1440.0,NVIDIA A100,United Arab Emirates,,,,,,,,,,True
20,LLaMA-65B,Language,Language modelling,Fully open-source,LLaMA: Open and Efficient Foundation Language Models,2023-02-24 00:00:00,Meta AI,65200000000.0,5.5e+23,1050000000000.0,1.09,500.0,NVIDIA A100,Multinational,,,2048.0,0.4746,,,1024000.0,1392640.0,1410425.8455359954,False
21,LLaMA-7B,Language,Language modelling,Fully open-source,LLaMA: Open and Efficient Foundation Language Models,2023-02-24 00:00:00,Meta AI,6700000000.0,2.78e+22,750000000000.0,1.09,,NVIDIA A100,Multinational,,,,,,,,,,False
22,GPT-3.5 (text-davinci-003),Language,Language modelling,API accessible,,2022-11-28 00:00:00,OpenAI,,2.578e+24,,,,NVIDIA A100 SXM4 40 GB,United States of America,,,,,,,,,,False
23,Galactica,"Language,Biology",Language modelling,,Galactica: A Large Language Model for Science,2022-11-16 00:00:00,Meta AI,120000000000.0,3.24e+23,,4.0,,NVIDIA A100 SXM4 80 GB,Multinational,,,,,,,,,,True
24,BLOOM-176B,Language,Language modelling,Permissive license,BigScience Large Open-science Open-access Multilingual Language Model,2022-11-08 00:00:00,"Hugging Face,BigScience",176000000000.0,3.6e+23,262500000000.0,,,,"Multinational,Multinational",,,,,,,,,,False
25,Taiyi-Stable Diffusion,Image generation,Text-to-image,,,2022-10-31 00:00:00,IDEA CCNL,1000000000.0,5.1e+22,,,100.0,NVIDIA A100,China,,,,,,,,,,False
26,U-PaLM (540B),Language,Language Generation,Unreleased,Transcending Scaling Laws with 0.1% Extra Compute,2022-10-20 00:00:00,Google,540000000000.0,2.53e+24,,,120.0,Google TPU v4,Multinational,PaLM (540B),4.0,512.0,,,,61440.0,12276326.4,12523793.100601656,False
27,Whisper,Speech,Audio speech recognition,,Robust Speech Recognition via Large-Scale Weak Supervision,2022-09-21 00:00:00,OpenAI,1550000000.0,4.65e+22,9302400000.0,3.0,,,United States of America,,,,,,,,,,True
28,PaLI,"Language,Vision",,,PaLI: A Jointly-Scaled Multilingual Language-Image Model,2022-09-14 00:00:00,Google,16900000000.0,5.1e+22,,1.0,168.0,Google TPU v4,Multinational,,,,,,,,,,True
29,BlenderBot 3,Language,Chat,Permissive license,BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage,2022-08-10 00:00:00,"McGill University,Meta AI,Mila- Quebec AI",175000000000.0,4.3e+23,,,,NVIDIA A100 SXM4 40 GB,"Canada,Multinational,Canada",OPT-175B,1.0,128.0,,,,,,,False
30,GLM-130B,Language,,,GLM-130B: An open bilingual pre-trained model,2022-08-04 00:00:00,Tsinghua University,130000000000.0,3.778e+23,,1.0,1440.0,NVIDIA A100 SXM4 40 GB,China,,,768.0,0.433,,,1105920.0,1603584.0,1635572.685301023,True
31,AlexaTM 20B,Language,Language modelling,,AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model,2022-08-02 00:00:00,Amazon,19750000000.0,2.04374016e+23,,,2880.0,,Multinational,,,,,,,,,,False
32,ESM2-15B,Biology,"Proteins,general-purpose protein or nucleotide language model (pLM/nLM)",Fully open-source,Evolutionary-scale prediction of atomic-level protein structure with a language model,2022-07-21 00:00:00,"Meta AI,New York University (NYU),Stanford University,Massachusetts Institute of Technology (MIT)",15000000000.0,7.350000000009999e+22,,,1440.0,,"Multinational,United States of America,United States of America,United States of America",,,,,,,,,,False
33,NLLB,Language,Translation,,No Language Left Behind: Scaling Human-Centered Machine Translation,2022-07-06 00:00:00,Meta AI,54500000000.0,1.751113728e+22,360000000000.0,,,,Multinational,,,,,,,,,,False
34,Minerva (540B),Language,Quantitative reasoning,,Solving Quantitative Reasoning Problems with Language Models,2022-06-29 00:00:00,Google,540350000000.0,2.7415e+24,613875000000.0,,696.0,Google TPU v4,Multinational,PaLM (540B),2.0,1024.0,,,,712704.0,13220659.2,13470191.00856837,True
35,Parti,Image generation,Text-to-image,,Scaling Autoregressive Models for Content-Rich Text-to-Image Generation,2022-06-22 00:00:00,Google Research,20000000000.0,3.962895376192635e+23,4800000000.0,,,Google TPU v4,Multinational,,,,,,,,,,True
36,CoCa,Vision,Image classification,,CoCa: Contrastive Captioners are Image-Text Foundation Models,2022-06-14 00:00:00,Google,2100000000.0,7.3e+22,4800000000.0,7.5,120.0,Google TPU v4,Multinational,,,,,,,,,,False
37,Imagen,Image generation,Text-to-image,,Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding,2022-05-23 00:00:00,Google Brain,3000000000.0,1.4600000000000002e+22,860000000.0,,,,Multinational,,,,,,,,,,True
38,UL2,Language,,,Unifying Language Learning Paradigms,2022-05-10 00:00:00,"Google Research,Google Brain",20000000000.0,1.2e+23,,,,,"Multinational,Multinational",,,,,,,,,,True
39,OPT-175B,Language,Language modelling,Fully open-source,OPT: Open Pre-trained Transformer Language Models,2022-05-02 00:00:00,Meta AI,175000000000.0,4.3e+23,135000000000.0,1.67,793.5,NVIDIA A100 SXM4 80 GB,Multinational,,,1024.0,0.4712,,,812544.0,1470704.64,1493974.647531918,False
40,Flamingo,Multimodal,"Visual question answering,Image captioning",,Flamingo: a Visual Language Model for Few-Shot Learning,2022-04-29 00:00:00,DeepMind,80000000000.0,2.7e+23,,,360.0,Google TPU v4,United Kingdom of Great Britain and Northern Ireland,,,1536.0,,,,552960.0,801792.0,815069.4909087805,True
41,Stable Diffusion (LDM-KL-8-G),Image generation,Text-to-image,,High-Resolution Image Synthesis with Latent Diffusion Models,2022-04-13 00:00:00,"Runway,Ludwig Maximilian University",1450000000.0,5e+22,400000000.0,,,,"United States of America,Germany",,,,,,,,,,False
42,PaLM (540B),Language,Language modelling,,PaLM: Scaling Language Modeling with Pathways,2022-04-04 00:00:00,Google Research,540350000000.0,2.5272e+24,585000000000.0,,1368.0,Google TPU v4,Multinational,,,6144.0,0.462,,,8404992.0,12187238.4,12389056.261813464,True
43,Chinchilla,Language,Language modelling,,Training Compute-Optimal Large Language Models,2022-03-29 00:00:00,DeepMind,70000000000.0,5.76e+23,1050000000000.0,1.0,,"Google TPU v4,Google TPU v3",United Kingdom of Great Britain and Northern Ireland,,,,,,,,,,True
44,LaMDA,Language,Language modelling,,LaMDA: Language Models for Dialog Applications,2022-02-10 00:00:00,Google,137000000000.0,3.55e+23,1560000000000.0,,1385.0,Google TPU v3,Multinational,,,1024.0,0.565,,,1418240.0,1276416.0,1319585.503057254,True
45,GPT-NeoX-20B,Language,,Fully open-source,GPT-NeoX-20B: An Open-Source Autoregressive Language Model,2022-02-09 00:00:00,EleutherAI,20000000000.0,9.31627008e+22,177167400000.0,1.0,2160.0,NVIDIA A100 SXM4 40 GB,Multinational,,,96.0,0.375,,,207360.0,300672.0,310840.989438577,False
46,AlphaCode,Language,Code generation,,Competition-Level Code Generation with AlphaCode,2022-02-02 00:00:00,DeepMind,41100000000.0,1.568160000001e+23,,,,"Google TPU v4,Google TPU v4i",United Kingdom of Great Britain and Northern Ireland,,,3750.0,,,,,,,True
47,ERNIE 3.0 Titan,Language,,,ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation,2021-12-23 00:00:00,"Baidu,Peng Cheng Laboratory",260000000000.0,1.0421e+24,668000000000.0,,,"Huawei Ascend 910,NVIDIA Tesla V100 DGXS 32 GB","China,China",,,1920.0,,,,,,,True
48,GLaM,Language,,,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts,2021-12-13 00:00:00,Google,1200000000000.0,3.74e+23,800000000000.0,,1366.0,Google TPU v4,Multinational,,,1024.0,,,,1398784.0,2028236.8,2093016.0239973643,True
49,Gopher (280B),Language,Language modelling,,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",2021-12-08 00:00:00,DeepMind,280000000000.0,6.31e+23,225000000000.0,1.0,920.0,Google TPU v3,United Kingdom of Great Britain and Northern Ireland,,,4096.0,0.378,,,3768320.0,3391488.0,3499807.67985019,False
50,Florence,Vision,,,Florence: A New Foundation Model for Computer Vision,2021-11-22 00:00:00,Microsoft,893000000.0,4.831e+22,900000000.0,,240.0,NVIDIA A100 SXM4 40 GB,Multinational,,,,,,,,,,True
51,BASIC-L,Vision,Image classification,,Combined Scaling for Zero-shot Transfer Learning,2021-11-19 00:00:00,Google,3070000000.0,4.12e+22,6700000000.0,3.0,,Google TPU v4,Multinational,,,,,,,,,,False
52,T0-XXL,Language,Language modelling,,Multitask Prompted Training Enables Zero-Shot Task Generalization,2021-10-15 00:00:00,"Hugging Face,Brown University",11000000000.0,1.792e+22,,,,,"Multinational,United States of America",,,,,,,,,,False
53,Yuan 1.0,Language,Language modelling,,Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and Few-Shot Learning,2021-10-12 00:00:00,Inspur,245730000000.0,3.5380000000001e+23,1000000000000.0,0.22,,,China,,,2128.0,0.45,,,,,,False
54,Megatron-Turing NLG 530B,Language,Language modelling,,"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model",2021-10-11 00:00:00,"Microsoft,NVIDIA",530000000000.0,1.17e+24,202500000000.0,,770.0,NVIDIA A100 SXM4 80 GB,"Multinational,United States of America",,,4480.0,0.302,,,3449600.0,6209280.0,6405652.563246981,True
55,HyperCLOVA,Language,,,What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers,2021-09-10 00:00:00,"NAVER,Search Solutions",82000000000.0,1.476e+23,190000000000.0,,643.2,NVIDIA A100,"Korea (Republic of),Korea (Republic of)",,,1024.0,0.2,,,658636.8,948436.992,980164.9214492476,True
56,FLAN 137B,Language,Language modelling,,Finetuned Language Models Are Zero-Shot Learners,2021-09-03 00:00:00,Google Research,137000000000.0,4.896e+22,1870000000000.0,,,,Multinational,,,,,,,,,,False
57,GOAT,Games,Open ended play,,Open-Ended Learning Leads to Generally Capable Agents,2021-07-27 00:00:00,DeepMind,3500000.0,7.8e+22,390000000000.0,,,Google TPU v3,United Kingdom of Great Britain and Northern Ireland,,,,,,,,,,True
58,ERNIE 3.0,Language,,,ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation,2021-07-05 00:00:00,Baidu,10000000000.0,2.25e+22,668000000000.0,,,,China,,,,,,,,,,False
59,ALIGN,Multimodal,Representation learning,,Scaling up visual and vision-language representation learning with noisy text supervision,2021-06-11 00:00:00,Google Research,820000000.0,2.5986700000009994e+22,1600000000.0,,347.3,Google TPU v3,Multinational,,,512.0,,,,177817.6,160035.84,165500.13931537792,False
60,DeBERTa,Language,,,DeBERTa: Decoding-enhanced BERT with Disentangled Attention,2021-06-10 00:00:00,Microsoft,1500000000.0,6.00000000001e+21,15600000000.0,,,,Multinational,,,,,,,,,,False
61,CoAtNet,Vision,Image classification,,"CoAtNet: Marrying Convolution and Attention
for All Data Sizes",2021-06-09 00:00:00,Google,2440000000.0,4.27e+22,,,,Google TPU v3,Multinational,,,,,,,,,,False
62,ByT5-XXL,Language,Language modelling,Permissive license,ByT5: Towards a token-free future with pre-trained byte-to-byte models,2021-05-28 00:00:00,Google,12900000000.0,8.1e+22,,,,Google TPU v3,Multinational,,,64.0,,,,,,,False
63,CogView,Image generation,Text-to-image,,CogView: Mastering Text-to-Image Generation via Transformers,2021-05-26 00:00:00,"Tsinghua University,DAMO Academy",4000000000.0,2.68e+22,50000000000.0,,,NVIDIA Tesla V100 DGXS 16 GB,"China,China",,,,,,,,,,True
64,ProtT5-XXL,Biology,"Proteins,general-purpose protein or nucleotide language model (pLM/nLM)",,ProtTrans: Towards Cracking the Language of Life’s Code Through Self-Supervised Learning,2021-05-04 00:00:00,"Technical University of Munich,Med AI Technology,NVIDIA,Oak Ridge National Laboratory,Google",11000000000.0,7.370000000000001e+22,393000000000.0,,,Google TPU v3,"Germany,China,United States of America,United States of America,Multinational",,,512.0,,,,,,,False
65,PLUG,Language,,,,2021-04-19 00:00:00,Alibaba,27000000000.0,3.5997696e+22,,,,,China,,,,,,,,,,False
66,M6-T,Multimodal,,,M6-T: Exploring Sparse Expert Models and Beyond,2021-03-05 00:00:00,Alibaba,1000000000000.0,5.5e+21,1900000000000.0,,,NVIDIA Tesla V100 DGXS 32 GB,China,,,,,,,,,,False
67,Meta Pseudo Labels,Vision,Image classification,,Meta pseudo labels,2021-03-01 00:00:00,Google Brain,480000000.0,4.79e+22,130000000.0,,264.0,Google TPU v3,Multinational,,,1024.0,,,,270336.0,243302.4,251391.36,False
68,MSA Transformer,Biology,"Proteins,general-purpose protein or nucleotide language model (pLM/nLM)",Fully open-source,MSA Transformer,2021-02-13 00:00:00,"Facebook AI Research,UC Berkeley,New York University (NYU)",100000000.0,5.49e+21,26000000.0,,,NVIDIA Tesla V100 DGXS 32 GB,"Multinational,United States of America,United States of America",,,32.0,,,,,,,False
69,Switch,Language,Text autocompletion,,Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity,2021-01-11 00:00:00,Google,1600000000000.0,8.22e+22,432000000000.0,,648.0,Google TPU v3,Multinational,,,1024.0,0.28,,,663552.0,597196.8,619741.3696948562,False
70,DALL-E,Image generation,Text-to-image,,Zero-Shot Text-to-Image Generation,2021-01-05 00:00:00,OpenAI,12000000000.0,4.7e+22,250000000.0,,,NVIDIA Tesla V100 DGXS 16 GB,United States of America,,,1024.0,,,,,,,False
71,CLIP (ViT L/14@336px),Multimodal,Zero-shot image classification,,Learning Transferable Visual Models From Natural Language Supervision,2021-01-05 00:00:00,OpenAI,370000000.0,1.05e+22,400000000.0,,,,United States of America,,,,,,,,,,False
72,ViT-Huge/14,Vision,Image representation,,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,2020-10-22 00:00:00,Google Brain,632000000.0,1.2826e+22,1280000.0,,,,Multinational,,,,,,,,,,False
73,Conformer + Wav2vec 2.0 + Noisy Student,Speech,Speech recognition,,Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition,2020-10-20 00:00:00,Google,1000000000.0,7.6e+21,,,168.0,Google TPU v3,Multinational,,,,,,,,,,False
74,mT5-XXL,Language,Language modelling,,mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer,2020-10-20 00:00:00,Google,13000000000.0,7.8e+22,750000000000.0,1.0,,,Multinational,,,,,,,,,,False
75,GShard (dense),Language,Translation,,GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,2020-06-30 00:00:00,Google,600000000000.0,1.28e+22,260000000000.0,,1008.0,Google TPU v3,Multinational,,,1024.0,,,,1032192.0,928972.8,969111.5896932516,False
76,iGPT-XL,"Vision,Image generation",Image completion,,Generative Pretraining from Pixels,2020-06-17 00:00:00,OpenAI,6801000000.0,3.3e+22,9600000.0,,,NVIDIA Tesla V100 DGXS 32 GB,United States of America,,,,,,,,,,False
77,iGPT-L,"Image generation,Vision",Image completion,,Generative Pretraining from Pixels,2020-06-17 00:00:00,OpenAI,1362000000.0,8.91e+21,9600000.0,,,NVIDIA Tesla V100 DGXS 32 GB,United States of America,,,,,,,,,,False
78,GPT-3 175B (davinci),Language,Text autocompletion,API accessible,Language models are Few-Shot Learners,2020-05-28 00:00:00,OpenAI,175000000000.0,3.14e+23,374000000000.0,0.6,355.2,NVIDIA Tesla V100 DGXS 32 GB,United States of America,,,10000.0,0.2196,,,3552000.0,4297920.0,4511299.978835979,True
79,Once for All,Vision,Image classification,,Once for all: Train one network and specialize it for efficient deployment.,2020-04-29 00:00:00,"MIT-IBM Watson AI Lab,Massachusetts Institute of Technology (MIT),IBM",7700000.0,1.7842809599999995e+21,,,,,"United States of America,United States of America,Multinational",,,,,,,,,,False
80,ELECTRA,Language,Text autocompletion,,ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators,2020-03-23 00:00:00,"Stanford University,Google,Google Brain",335000000.0,3.0999999999999995e+21,,,,,"United States of America,Multinational,Multinational",,,,,,,,,,False
81,Turing-NLG,Language,Text autocompletion,,Turing-NLG: A 17-billion-parameter language model by Microsoft,2020-02-13 00:00:00,Microsoft,17000000000.0,1.57e+22,34800000000.0,3.39,,NVIDIA Tesla V100 DGXS 32 GB,Multinational,,,256.0,,,,,,,False
82,ALBERT-xxlarge,Language,,,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.,2020-02-09 00:00:00,"Toyota Technological Institute at Chicago,Google",235000000.0,2.39e+21,3300000000.0,,,,"United States of America,Multinational",,,,,,,,,,False
83,Meena,Language,Text autocompletion,,Towards a Human-like Open-Domain Chatbot,2020-01-28 00:00:00,Google Brain,2600000000.0,1.12e+23,40000000000.0,,720.0,Google TPU v3,Multinational,,,1024.0,0.3439,,,737280.0,663552.0,697110.2785525154,False
84,ContextNet + Noisy Student,Speech,Speech recognition,,Improved Noisy Student Training for Automatic Speech Recognition,2020-01-19 00:00:00,Google,,5.4e+21,,,240.0,Google TPU v3,Multinational,,,,,,,,,,False
85,DD-PPO,Robotics,Object detection,,DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion Frames,2019-12-19 00:00:00,"Georgia Institute of Technology,Facebook AI Research,Oregon State University,Simon Fraser University",,7.8e+20,,,66.0,NVIDIA V100,"United States of America,Multinational,United States of America,Canada",,,,,,,,,,False
86,OpenAI Five,Games,Dota 2,,Dota 2 with Large Scale Deep Reinforcement Learning,2019-12-13 00:00:00,OpenAI,159000000.0,6.7e+22,454321373184.0,,7104.0,,United States of America,,,1536.0,,,,10911744.0,,,False
87,OpenAI Five Rerun,Games,Dota 2,,Dota 2 with Large Scale Deep Reinforcement Learning,2019-12-13 00:00:00,OpenAI,159000000.0,1.3e+22,53084160000.0,,,,United States of America,,,512.0,,,,,,,False
88,Noisy Student (L2),Vision,Image classification,,Self-training with Noisy Student improves ImageNet classification,2019-11-11 00:00:00,"Carnegie Mellon University (CMU),Google",480000000.0,8.4934656e+20,81000000.0,,144.0,,"United States of America,Multinational",,,,,,,,,,False
89,AlphaStar,Games,StarCraft,,Grandmaster level in StarCraft II using multi-agent reinforcement learning,2019-10-30 00:00:00,DeepMind,139000000.0,5.9250000000001e+22,,,1056.0,Google TPU v3,United Kingdom of Great Britain and Northern Ireland,,,384.0,,,,405504.0,364953.6,388902.65897940914,False
90,T5-3B,Language,Text autocompletion,,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,2019-10-23 00:00:00,Google,2800000000.0,8.658654068736e+20,25500000000.0,0.17,,Google TPU v3,Multinational,,,,,,,,,,False
91,T5-11B,Language,Text autocompletion,,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,2019-10-23 00:00:00,Google,11000000000.0,3.3e+22,150000000000.0,,481.9,Google TPU v3,Multinational,,,512.0,0.3707,,,246732.8,222059.52,236631.5547502238,False
92,Megatron-BERT,Language,,,Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism,2019-09-17 00:00:00,NVIDIA,3900000000.0,6.027e+22,34800000000.0,,1392.0,NVIDIA Tesla V100S PCIe 32 GB,United States of America,,,512.0,0.2269,,,712704.0,,,False
93,Megatron-LM (8.3B),Language,,,Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism,2019-09-17 00:00:00,NVIDIA,8300000000.0,9.1e+21,34800000000.0,4.4,327.0,NVIDIA Tesla V100 DGXS 32 GB,United States of America,,,512.0,0.1162,,,167424.0,202583.04,216070.42339784943,False
94,RoBERTa Large,Language,,,RoBERTa: A Robustly Optimized BERT Pretraining Approach,2019-07-01 00:00:00,"Facebook,University of Washington",355000000.0,4.15383552e+21,32000000000.0,,120.0,NVIDIA Tesla V100 DGXS 32 GB,"Multinational,United States of America",,,1024.0,,,,122880.0,148684.8,160017.6468716094,False
95,MnasNet-A3,Vision,"Image classification,Object detection",,MnasNet: Platform-Aware Neural Architecture Search for Mobile,2019-05-29 00:00:00,Google,5200000.0,1.5e+21,1280000.0,,,Google TPU v3,Multinational,,,,,,,,,,False
96,MnasNet-A1 + SSDLite,Vision,"Image classification,Object detection",,MnasNet: Platform-Aware Neural Architecture Search for Mobile,2019-05-29 00:00:00,Google,4900000.0,1.5e+21,118000.0,,,Google TPU v3,Multinational,,,,,,,,,,False
97,BERT-Large-CAS (PTB+WT2+WT103),Language,,,Language Models with Transformers,2019-04-20 00:00:00,Amazon,395000000.0,5.21e+20,,50.0,,,Multinational,,,,,,,,,,False
98,ProxylessNAS,Vision,Image classification,,ProxylessNAS: Direct neural architecture search on target task and hardware,2019-02-23 00:00:00,Massachusetts Institute of Technology (MIT),,3.70656e+19,1280000.0,,,,United States of America,,,,,,,,,,False
99,GPT-2 (1.5B),Language,,,Language Models are Unsupervised Multitask Learners,2019-02-14 00:00:00,OpenAI,1500000000.0,4.3e+21,3000000000.0,20.0,,,United States of America,,,,,,,,,,False
100,BERT-Large,Language,Next sentence prediction,Fully open-source,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,2018-10-11 00:00:00,Google,340000000.0,2.85e+20,3300000000.0,,96.0,Google TPU v2,Multinational,,,64.0,0.29,,,6144.0,6942.719999999999,7471.898386980109,False
101,BigGAN-deep 512x512,Image generation,Image generation,Permissive license,Large Scale GAN Training for High Fidelity Natural Image Synthesis,2018-09-28 00:00:00,"Heriot-Watt University,DeepMind",112694781.0,3.00000000001e+21,292000000.0,,48.0,Google TPU v3,"United Kingdom of Great Britain and Northern Ireland,United Kingdom of Great Britain and Northern Ireland",,,256.0,,,,12288.0,24576.0,26473.13375565611,False
102,Transformer (Adaptive Input Embeddings),Language,,,Adaptive Input Representations for Neural Language Modeling,2018-09-28 00:00:00,Facebook AI Research,247000000.0,7.3e+19,,180.0,67.0,NVIDIA V100,Multinational,,,,,,,,,,False
103,Transformer + Simple Recurrent Unit,Language,Translation,,Simple Recurrent Units for Highly Parallelizable Recurrence,2018-09-17 00:00:00,"ASAPP,Cornell University,Google,Princeton University",90000000.0,1.1e+19,,40.0,84.0,NVIDIA V100,"United States of America,United States of America,Multinational,United States of America",,,,,,,,,,False
104,FTW,Games,Capture the flag,,Human-level performance in first-person multiplayer games with population-based deep reinforcement learning,2018-07-03 00:00:00,DeepMind,126001330.0,7.26e+21,,,,,United Kingdom of Great Britain and Northern Ireland,,,,,,,,,,False
105,Population-based DRL,Games,Capture the flag,,Human-level performance in first-person multiplayer games with population-based deep reinforcement learning,2018-07-03 00:00:00,DeepMind,122000000.0,3.49e+19,,,,,United Kingdom of Great Britain and Northern Ireland,,,,,,,,,,False
106,GPT,Language,,,Improving Language Understanding by Generative Pre-Training,2018-06-01 00:00:00,OpenAI,117000000.0,1.7578125e+19,1000000000.0,,,,United States of America,,,,,,,,,,False
107,ResNeXt-101 32x48d,Vision,Image classification,,Exploring the Limits of Weakly Supervised Pretraining,2018-05-02 00:00:00,Facebook,829000000.0,8.74395e+21,9525000000.0,,,,Multinational,,,336.0,,,,,,,False
108,YOLOv3,Vision,Object detection,,YOLOv3: An Incremental Improvement,2018-04-08 00:00:00,University of Washington,56933216.0,5.093919991999999e+19,1281167.0,,,"NVIDIA M40,NVIDIA GTX Titan X",United States of America,,,,,,,,,,False
109,"LSTM (Hebbian, Cache, MbPA)",Language,,,Fast Parametric Learning with Activation Memorization,2018-03-27 00:00:00,"DeepMind,University College London (UCL)",45200000.0,2.4e+19,,90.0,,,"United Kingdom of Great Britain and Northern Ireland,United Kingdom of Great Britain and Northern Ireland",,,,,,,,,,False
110,AmoebaNet-A (F=448),Vision,Image classification,,Regularized Evolution for Image Classifier Architecture Search,2018-02-05 00:00:00,Google Brain,469000000.0,3.85296912e+20,1280000.0,,168.0,NVIDIA Tesla K40s,Multinational,,,450.0,,,,75600.0,,,False
111,IMPALA,Games,Atari,,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,2018-02-05 00:00:00,DeepMind,1600000.0,1.68e+20,240000000000.0,,100.0,NVIDIA P100,United Kingdom of Great Britain and Northern Ireland,,,1.0,,,,100.0,128.0,138.13091568449684,False
112,AlphaZero,Games,,,Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm,2017-12-05 00:00:00,DeepMind,,3.667927300468287e+22,700000.0,,,Google TPU v2,United Kingdom of Great Britain and Northern Ireland,,,64.0,,,,,,,False
113,PNASNet-5,Vision,Image classification,,Progressive Neural Architecture Search,2017-12-02 00:00:00,"Johns Hopkins University,Google AI,Stanford University",,6.629040000000001e+19,1280000.0,,,,"United States of America,Multinational,United States of America",,,,,,,,,,False
114,AlphaGo Zero,Games,Go,,Mastering the game of Go without human knowledge,2017-10-18 00:00:00,DeepMind,46400244.0,3.41e+23,5800000000.0,,480.0,Google TPU v1,United Kingdom of Great Britain and Northern Ireland,,,,,,,,,,False
115,OpenAI TI7 DOTA 1v1,Games,DOTA,,Dota 2,2017-08-11 00:00:00,OpenAI,,6.046095222592002e+20,,,,,United States of America,,,,,,,,,,False
116,JFT,Vision,"Image classification,Object detection,Semantic segmentation,Pose estimation",,Revisiting Unreasonable Effectiveness of Data in Deep Learning Era.,2017-07-10 00:00:00,"Google Research,Carnegie Mellon University (CMU)",,8.43e+20,300000000.0,,1440.0,NVIDIA Tesla K80,"Multinational,United States of America",,,50.0,,,,72000.0,30960.0,33440.7332123412,False
117,Transformer,Language,Translation,,Attention Is All You Need,2017-06-12 00:00:00,"Google Research,Google Brain",213000000.0,7.4245248e+18,360000000.0,,,NVIDIA P100,"Multinational,Multinational",,,,,,,,,,False
118,MoE,Language,"Language modelling,Translation",,Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer,2017-01-23 00:00:00,"Jagiellonian University,Google Brain",8700000000.0,9.393905664e+19,100000000000.0,,,NVIDIA Tesla K40t,"Poland,Multinational",,,,,,,,,,False
119,DeepStack,Games,Poker,,DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker,2017-01-06 00:00:00,"University of Alberta,Charles University,Czech Technical University",2500000.0,1.446336e+19,10000000.0,,,,"Canada,Czechia,Czechia",,,,,,,,,,False
120,Libratus,Games,Poker,,Libratus: The Superhuman AI for No-Limit Poker,2017-01-01 00:00:00,Carnegie Mellon University (CMU),,5.51e+20,,,,,United States of America,,,,,,,,,,False
121,AlphaGo Master,Games,Go,,Mastering the game of Go without human knowledge,2017-01-01 00:00:00,DeepMind,,1.5e+23,,,,Google TPU v1,United Kingdom of Great Britain and Northern Ireland,,,,,,,,,,False
122,PolyNet,Vision,Image classification,,PolyNet: A Pursuit of Structural Diversity in Very Deep Networks,2016-11-17 00:00:00,Chinese University of Hong Kong,92000000.0,6.4e+19,1280000.0,,,,Hong Kong,,,,,,,,,,False
123,NASv3 (CIFAR-10),Vision,,,Neural Architecture Search with Reinforcement Learning,2016-11-05 00:00:00,Google Brain,37400000.0,2.2e+21,,,,,Multinational,,,800.0,,,,,,,False
124,Xception,Vision,Image classification,,Xception: Deep Learning with Depthwise Separable Convolutions,2016-10-07 00:00:00,Google,22855952.0,4.362336e+19,350000000.0,,,NVIDIA Tesla K80,Multinational,,,,,,,,,,False
125,GNMT,Language,Translation,,Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation,2016-09-26 00:00:00,Google,278000000.0,6.899999999999999e+21,360000000.0,,4320.0,NVIDIA Tesla K80,Multinational,,,96.0,,,,414720.0,178329.6,194739.1953027523,False
126,AlphaGo Lee,Games,Go,,Mastering the game of Go with deep neural networks and tree search,2016-01-27 00:00:00,DeepMind,,1.9e+21,29400000.0,,,,United Kingdom of Great Britain and Northern Ireland,,,,,,,,,,False
127,ResNet-152 (ImageNet),Vision,Image classification,,Deep Residual Learning for Image Recognition,2015-12-10 00:00:00,Microsoft,60000000.0,1.21e+19,1280000.0,,,,Multinational,,,,,,,,,,False
128,DeepSpeech2 (English),Speech,Speech recognition,,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin,2015-12-08 00:00:00,Baidu Research - Silicon Valley AI Lab,38000000.0,2.6e+19,163339200.0,,,"NVIDIA GTX Titan X,NVIDIA Quadro K1200",United States of America,,,,,,,,,,False
129,AlphaGo Fan,Games,Go,,Mastering the game of Go with deep neural networks and tree search,2015-10-01 00:00:00,Google DeepMind,8209984.0,3.8000000000000007e+20,,,,,Multinational,,,,,,,,,,False
130,ProtT5-XXL-BFD,Biology,"Proteins,general-purpose protein or nucleotide language model (pLM/nLM)",Weights available,ProtTrans:Towards Cracking the Language of Life's Code Through Self-Supervised Learning,2021-05-04 00:00:00,,11000000000.0,3.7e+22,,,,,,,,,,,,,,,False
131,ProtBERT-BFD,Biology,"Proteins,general-purpose protein or nucleotide language model (pLM/nLM)",Weights available,ProtTrans:Towards Cracking the Language of Life's Code Through Self-Supervised Learning,2021-05-04 00:00:00,"Technical University of Munich,NVIDIA,Seoul National University,Google,Oak Ridge National Laboratory",420000000.0,3.9e+22,,,,,"Germany,United States of America,Korea (Republic of),Multinational,United States of America",,,,,,,,,,False
132,Understanding Back-Translation at Scale,Language,Translation,,Understanding Back-Translation at Scale,2018-08-28 00:00:00,"Facebook AI Research,Google Brain",,1.080843264e+20,3390000000.0,,27.7,NVIDIA V100,"Multinational,Multinational",,,128.0,,,,3545.6,4112.896,4434.402272463768,False
133,BIDAF,Language,Question answering,Fully open-source,Bidirectional Attention Flow for Machine Comprehension,2016-11-05 00:00:00,"University of Washington,Allen Institute for AI",2600000.0,3.4686144e+18,47160000.0,8.0,60.0,NVIDIA GTX Titan X,"United States of America,United States of America",,,8.0,,,,480.0,,,False
134,Pangu-Weather,Earth science,Weather prediction,,Accurate medium-range global weather forecasting with 3D neural networks,2023-07-05 00:00:00,Huawei,256000000.0,3.98e+22,,100.0,,NVIDIA V100,China,,,192.0,,,,,,,False
135,XGLM-7.5B,Language,"Translation,Question answering,Language modelling/generation",Fully open-source,Few-shot Learning with Multilingual Language Models,2021-12-20 00:00:00,Meta AI,7500000000.0,4.347592704e+22,565367040000.0,1.0,504.0,NVIDIA A100,Multinational,,,256.0,,,,129024.0,175472.64,181077.0060444229,False
136,SciBERT,Language,"Relation extraction,Sentiment classification,Text classification",Fully open-source,SciBERT: A Pretrained Language Model for Scientific Text,2019-03-26 00:00:00,Allen Institute for AI,110000000.0,8.926848e+19,2475000000.0,,168.0,Google TPU v3,United States of America,,,4.0,,,,672.0,1344.0,1451.6907441016335,False
137,CogVLM,"Multimodal,Vision,Language","Image captioning,Visual question answering,Chat",Permissive license,CogVLM: Visual Expert for Pretrained Language Models,2023-11-06 00:00:00,"Tsinghua University,Zhipu AI,Beihang University",17000000000.0,1.988064e+22,,,,,"China,China,China",,,,,,,,,,True
