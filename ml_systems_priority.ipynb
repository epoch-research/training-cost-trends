{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPSm37gghSrl"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8Edmo7vA2Eg1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fXBbtVKi2LmG"
   },
   "outputs": [],
   "source": [
    "data_url = 'https://epochai.org/data/epochdb/all_systems.csv'\n",
    "dtypes = {\n",
    "    'Training compute (FLOP)': np.float64,\n",
    "}\n",
    "pcd_df = pd.read_csv(data_url, dtype=dtypes)\n",
    "pcd_df['Decimal year'] = pd.to_datetime(pcd_df['Publication date']).dt.year + (pd.to_datetime(pcd_df['Publication date']).dt.month - 1) / 12 + (pd.to_datetime(pcd_df['Publication date']).dt.day - 1) / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yyQJeGOA2m7e",
    "outputId": "0fe58fa3-79c0-46d1-f5ff-00802616c0b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training dataset</th>\n",
       "      <th>Training dataset notes</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>Training time notes</th>\n",
       "      <th>Training time (hours)</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Batch size notes</th>\n",
       "      <th>Base model</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Training compute upper bound</th>\n",
       "      <th>Archived links</th>\n",
       "      <th>Benchmark data</th>\n",
       "      <th>Decimal year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen 1.5 110B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>Qwen1.5-110B: The First 100B+ Model of the Qwe...</td>\n",
       "      <td>https://qwenlm.github.io/blog/qwen1.5-110b/?re...</td>\n",
       "      <td>1.100000e+11</td>\n",
       "      <td>Unspecified unreleased</td>\n",
       "      <td>We pretrained the models with a large amount o...</td>\n",
       "      <td>The Qwen1.5-110B is the largest model in the Q...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.315753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phi-3-medium 14B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>Phi-3 Technical Report: A Highly Capable Langu...</td>\n",
       "      <td>https://arxiv.org/abs/2404.14219</td>\n",
       "      <td>1.400000e+10</td>\n",
       "      <td>Unspecified unreleased</td>\n",
       "      <td>we also trained phi-3-medium, a model with 14B...</td>\n",
       "      <td>We introduce phi-3-mini, a 3.8 billion paramet...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.310274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama 3-70B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>Introducing Meta Llama 3: The most capable ope...</td>\n",
       "      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n",
       "      <td>7.000000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.296575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mixtral 8x22B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>Mixtral 8x22B</td>\n",
       "      <td>https://mistral.ai/news/mixtral-8x22b/</td>\n",
       "      <td>1.760000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mixtral 8x22B is our latest open model. It set...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.293836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIMA</td>\n",
       "      <td>Games,Video</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>Scaling Instructable Agents Across Many Simula...</td>\n",
       "      <td>https://arxiv.org/abs/2404.10179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.293836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>Sequence-based pattern recognition</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>1955-03-01</td>\n",
       "      <td>Pattern recognition and modern computers</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/1455292.1455310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1955.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Self Organizing System</td>\n",
       "      <td>Other</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>1955-03-01</td>\n",
       "      <td>Generalization of pattern recognition in a sel...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/1455292.1455309</td>\n",
       "      <td>2.250000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1955.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>Genetic algorithm</td>\n",
       "      <td>Other</td>\n",
       "      <td>Institute for Advanced Study</td>\n",
       "      <td>1954-07-02</td>\n",
       "      <td>Numerical testing of evolution theories</td>\n",
       "      <td>https://link.springer.com/article/10.1007/BF01...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1954.502740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>SNARC</td>\n",
       "      <td>Robotics</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>1952-01-08</td>\n",
       "      <td>A Neural-Analogue Calculator Based upon a Prob...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stochastic_neura...</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1952.019178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>Theseus</td>\n",
       "      <td>Robotics</td>\n",
       "      <td>Bell Laboratories</td>\n",
       "      <td>1950-07-02</td>\n",
       "      <td>Mighty Mouse</td>\n",
       "      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950.502740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1262 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  System       Domain  \\\n",
       "0                          Qwen 1.5 110B     Language   \n",
       "1                       phi-3-medium 14B     Language   \n",
       "2                            Llama 3-70B     Language   \n",
       "3                          Mixtral 8x22B     Language   \n",
       "4                                   SIMA  Games,Video   \n",
       "...                                  ...          ...   \n",
       "1257  Sequence-based pattern recognition       Vision   \n",
       "1258              Self Organizing System        Other   \n",
       "1259                   Genetic algorithm        Other   \n",
       "1260                               SNARC     Robotics   \n",
       "1261                             Theseus     Robotics   \n",
       "\n",
       "                                     Organization Publication date  \\\n",
       "0                                         Alibaba       2024-04-25   \n",
       "1                                       Microsoft       2024-04-23   \n",
       "2                                         Meta AI       2024-04-18   \n",
       "3                                      Mistral AI       2024-04-17   \n",
       "4                                 Google DeepMind       2024-04-17   \n",
       "...                                           ...              ...   \n",
       "1257  Massachusetts Institute of Technology (MIT)       1955-03-01   \n",
       "1258  Massachusetts Institute of Technology (MIT)       1955-03-01   \n",
       "1259                 Institute for Advanced Study       1954-07-02   \n",
       "1260                           Harvard University       1952-01-08   \n",
       "1261                            Bell Laboratories       1950-07-02   \n",
       "\n",
       "                                              Reference  \\\n",
       "0     Qwen1.5-110B: The First 100B+ Model of the Qwe...   \n",
       "1     Phi-3 Technical Report: A Highly Capable Langu...   \n",
       "2     Introducing Meta Llama 3: The most capable ope...   \n",
       "3                                         Mixtral 8x22B   \n",
       "4     Scaling Instructable Agents Across Many Simula...   \n",
       "...                                                 ...   \n",
       "1257           Pattern recognition and modern computers   \n",
       "1258  Generalization of pattern recognition in a sel...   \n",
       "1259            Numerical testing of evolution theories   \n",
       "1260  A Neural-Analogue Calculator Based upon a Prob...   \n",
       "1261                                       Mighty Mouse   \n",
       "\n",
       "                                                   Link    Parameters  \\\n",
       "0     https://qwenlm.github.io/blog/qwen1.5-110b/?re...  1.100000e+11   \n",
       "1                      https://arxiv.org/abs/2404.14219  1.400000e+10   \n",
       "2     https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n",
       "3                https://mistral.ai/news/mixtral-8x22b/  1.760000e+11   \n",
       "4                      https://arxiv.org/abs/2404.10179           NaN   \n",
       "...                                                 ...           ...   \n",
       "1257     https://dl.acm.org/doi/10.1145/1455292.1455310           NaN   \n",
       "1258     https://dl.acm.org/doi/10.1145/1455292.1455309  2.250000e+02   \n",
       "1259  https://link.springer.com/article/10.1007/BF01...           NaN   \n",
       "1260  https://en.wikipedia.org/wiki/Stochastic_neura...  4.000000e+01   \n",
       "1261  https://www.technologyreview.com/2018/12/19/13...  4.000000e+01   \n",
       "\n",
       "            Training dataset  \\\n",
       "0     Unspecified unreleased   \n",
       "1     Unspecified unreleased   \n",
       "2                        NaN   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "...                      ...   \n",
       "1257                     NaN   \n",
       "1258                     NaN   \n",
       "1259                     NaN   \n",
       "1260                     NaN   \n",
       "1261                     NaN   \n",
       "\n",
       "                                 Training dataset notes  \\\n",
       "0     We pretrained the models with a large amount o...   \n",
       "1     we also trained phi-3-medium, a model with 14B...   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1257                                                NaN   \n",
       "1258                                                NaN   \n",
       "1259                                                NaN   \n",
       "1260                                                NaN   \n",
       "1261                                                NaN   \n",
       "\n",
       "                                               Abstract  ...  \\\n",
       "0     The Qwen1.5-110B is the largest model in the Q...  ...   \n",
       "1     We introduce phi-3-mini, a 3.8 billion paramet...  ...   \n",
       "2                                                   NaN  ...   \n",
       "3     Mixtral 8x22B is our latest open model. It set...  ...   \n",
       "4                                                   NaN  ...   \n",
       "...                                                 ...  ...   \n",
       "1257                                                NaN  ...   \n",
       "1258                                                NaN  ...   \n",
       "1259                                                NaN  ...   \n",
       "1260                                                NaN  ...   \n",
       "1261                                                NaN  ...   \n",
       "\n",
       "     Training time notes Training time (hours) Batch size Batch size notes  \\\n",
       "0                    NaN                   NaN        NaN              NaN   \n",
       "1                    NaN                   NaN        NaN              NaN   \n",
       "2                    NaN                   NaN        NaN              NaN   \n",
       "3                    NaN                   NaN        NaN              NaN   \n",
       "4                    NaN                   NaN        NaN              NaN   \n",
       "...                  ...                   ...        ...              ...   \n",
       "1257                 NaN                   NaN        NaN              NaN   \n",
       "1258                 NaN                   NaN        NaN              NaN   \n",
       "1259                 NaN                   NaN        NaN              NaN   \n",
       "1260                 NaN                   NaN        NaN              NaN   \n",
       "1261                 NaN                   NaN        NaN              NaN   \n",
       "\n",
       "     Base model Finetune compute (FLOP) Training compute upper bound  \\\n",
       "0           NaN                     NaN                          NaN   \n",
       "1           NaN                     NaN                          NaN   \n",
       "2           NaN                     NaN                          NaN   \n",
       "3           NaN                     NaN                          NaN   \n",
       "4           NaN                     NaN                          NaN   \n",
       "...         ...                     ...                          ...   \n",
       "1257        NaN                     NaN                          NaN   \n",
       "1258        NaN                     NaN                          NaN   \n",
       "1259        NaN                     NaN                          NaN   \n",
       "1260        NaN                     NaN                          NaN   \n",
       "1261        NaN                     NaN                          NaN   \n",
       "\n",
       "     Archived links  Benchmark data Decimal year  \n",
       "0               NaN             NaN  2024.315753  \n",
       "1               NaN             NaN  2024.310274  \n",
       "2               NaN             NaN  2024.296575  \n",
       "3               NaN             NaN  2024.293836  \n",
       "4               NaN             NaN  2024.293836  \n",
       "...             ...             ...          ...  \n",
       "1257            NaN             NaN  1955.166667  \n",
       "1258            NaN             NaN  1955.166667  \n",
       "1259            NaN             NaN  1954.502740  \n",
       "1260            NaN             NaN  1952.019178  \n",
       "1261            NaN             NaN  1950.502740  \n",
       "\n",
       "[1262 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XZ0FKyaZ3h_W"
   },
   "outputs": [],
   "source": [
    "pcd_df['Publication date'] = pd.to_datetime(pcd_df['Publication date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rcOYiwwg3oVY"
   },
   "outputs": [],
   "source": [
    "pcd_df.sort_values('Publication date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QLUi4aysAXWr"
   },
   "outputs": [],
   "source": [
    "pcd_df.dropna(subset=['Publication date', 'Notability criteria', 'Training compute (FLOP)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wGGuurmk4uZd",
    "outputId": "5d822c9c-67e5-4f2c-ff8b-9418f82d05e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training dataset</th>\n",
       "      <th>Training dataset notes</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>Training time notes</th>\n",
       "      <th>Training time (hours)</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Batch size notes</th>\n",
       "      <th>Base model</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Training compute upper bound</th>\n",
       "      <th>Archived links</th>\n",
       "      <th>Benchmark data</th>\n",
       "      <th>Decimal year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>Theseus</td>\n",
       "      <td>Robotics</td>\n",
       "      <td>Bell Laboratories</td>\n",
       "      <td>1950-07-02</td>\n",
       "      <td>Mighty Mouse</td>\n",
       "      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950.502740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Perceptron Mark I</td>\n",
       "      <td>Other</td>\n",
       "      <td>Cornell Aeronautical Laboratory,Cornell Univer...</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>The Perceptron—a perceiving and recognizing au...</td>\n",
       "      <td>https://blogs.umass.edu/brain-wars/files/2016/...</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1957.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Pandemonium (morse)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>1959-02-01</td>\n",
       "      <td>Pandemonium: A Paradigm for Learning</td>\n",
       "      <td>https://aitopics.org/doc/classics:504E1BAC/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1959.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>Samuel Neural Checkers</td>\n",
       "      <td>Games</td>\n",
       "      <td>IBM</td>\n",
       "      <td>1959-07-01</td>\n",
       "      <td>Some studies in machine learning using the gam...</td>\n",
       "      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1959.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>Perceptron (1960)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Cornell Aeronautical Laboratory</td>\n",
       "      <td>1960-03-30</td>\n",
       "      <td>Perceptron Simulation Experiments</td>\n",
       "      <td>https://www.semanticscholar.org/paper/Perceptr...</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An experimental simulation program, which has ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960.246119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FunSearch</td>\n",
       "      <td>Language,Search</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>2023-12-14</td>\n",
       "      <td>Mathematical discoveries from program search w...</td>\n",
       "      <td>https://www.nature.com/articles/s41586-023-069...</td>\n",
       "      <td>1.500000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"The experiments carried out in this paper do ...</td>\n",
       "      <td>Large language models (LLMs) have demonstrated...</td>\n",
       "      <td>...</td>\n",
       "      <td>Appendix A.5: \"To reproduce admissible set exp...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023.952283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MegaScale (Production)</td>\n",
       "      <td>Language</td>\n",
       "      <td>ByteDance,Peking University</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>MegaScale: Scaling Large Language Model Traini...</td>\n",
       "      <td>https://arxiv.org/abs/2402.15627</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We present the design, implementation and engi...</td>\n",
       "      <td>...</td>\n",
       "      <td>Speculative. Authors state \"several weeks\". Fo...</td>\n",
       "      <td>504.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.143607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Inflection-2.5</td>\n",
       "      <td>Language</td>\n",
       "      <td>Inflection AI</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>Inflection-2.5: meet the world's best personal AI</td>\n",
       "      <td>https://inflection.ai/inflection-2-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>At Inflection, our mission is to create a pers...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.183105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MM1-30B</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>MM1: Methods, Analysis &amp; Insights from Multimo...</td>\n",
       "      <td>https://arxiv.org/abs/2403.09611</td>\n",
       "      <td>3.000000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Text, captioned images. See Table 2</td>\n",
       "      <td>In this work, we discuss building performant M...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.202283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama 3-70B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>Introducing Meta Llama 3: The most capable ope...</td>\n",
       "      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n",
       "      <td>7.000000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.296575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      System           Domain  \\\n",
       "1261                 Theseus         Robotics   \n",
       "1255       Perceptron Mark I            Other   \n",
       "1254     Pandemonium (morse)         Language   \n",
       "1253  Samuel Neural Checkers            Games   \n",
       "1251       Perceptron (1960)           Vision   \n",
       "...                      ...              ...   \n",
       "56                 FunSearch  Language,Search   \n",
       "22    MegaScale (Production)         Language   \n",
       "15            Inflection-2.5         Language   \n",
       "14                   MM1-30B       Multimodal   \n",
       "2                Llama 3-70B         Language   \n",
       "\n",
       "                                           Organization Publication date  \\\n",
       "1261                                  Bell Laboratories       1950-07-02   \n",
       "1255  Cornell Aeronautical Laboratory,Cornell Univer...       1957-01-01   \n",
       "1254        Massachusetts Institute of Technology (MIT)       1959-02-01   \n",
       "1253                                                IBM       1959-07-01   \n",
       "1251                    Cornell Aeronautical Laboratory       1960-03-30   \n",
       "...                                                 ...              ...   \n",
       "56                                      Google DeepMind       2023-12-14   \n",
       "22                          ByteDance,Peking University       2024-02-23   \n",
       "15                                        Inflection AI       2024-03-07   \n",
       "14                                                Apple       2024-03-14   \n",
       "2                                               Meta AI       2024-04-18   \n",
       "\n",
       "                                              Reference  \\\n",
       "1261                                       Mighty Mouse   \n",
       "1255  The Perceptron—a perceiving and recognizing au...   \n",
       "1254               Pandemonium: A Paradigm for Learning   \n",
       "1253  Some studies in machine learning using the gam...   \n",
       "1251                  Perceptron Simulation Experiments   \n",
       "...                                                 ...   \n",
       "56    Mathematical discoveries from program search w...   \n",
       "22    MegaScale: Scaling Large Language Model Traini...   \n",
       "15    Inflection-2.5: meet the world's best personal AI   \n",
       "14    MM1: Methods, Analysis & Insights from Multimo...   \n",
       "2     Introducing Meta Llama 3: The most capable ope...   \n",
       "\n",
       "                                                   Link    Parameters  \\\n",
       "1261  https://www.technologyreview.com/2018/12/19/13...  4.000000e+01   \n",
       "1255  https://blogs.umass.edu/brain-wars/files/2016/...  1.000000e+03   \n",
       "1254        https://aitopics.org/doc/classics:504E1BAC/           NaN   \n",
       "1253  https://ieeexplore.ieee.org/abstract/document/...  1.600000e+01   \n",
       "1251  https://www.semanticscholar.org/paper/Perceptr...  1.000000e+03   \n",
       "...                                                 ...           ...   \n",
       "56    https://www.nature.com/articles/s41586-023-069...  1.500000e+10   \n",
       "22                     https://arxiv.org/abs/2402.15627  5.300000e+11   \n",
       "15                 https://inflection.ai/inflection-2-5           NaN   \n",
       "14                     https://arxiv.org/abs/2403.09611  3.000000e+10   \n",
       "2     https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n",
       "\n",
       "     Training dataset                             Training dataset notes  \\\n",
       "1261              NaN                                                NaN   \n",
       "1255              NaN                                                NaN   \n",
       "1254              NaN                                                NaN   \n",
       "1253              NaN                                                NaN   \n",
       "1251              NaN                                                NaN   \n",
       "...               ...                                                ...   \n",
       "56                NaN  \"The experiments carried out in this paper do ...   \n",
       "22                NaN                                                NaN   \n",
       "15                NaN                                                NaN   \n",
       "14                NaN                Text, captioned images. See Table 2   \n",
       "2                 NaN                                                NaN   \n",
       "\n",
       "                                               Abstract  ...  \\\n",
       "1261                                                NaN  ...   \n",
       "1255                                                NaN  ...   \n",
       "1254                                                NaN  ...   \n",
       "1253                                                NaN  ...   \n",
       "1251  An experimental simulation program, which has ...  ...   \n",
       "...                                                 ...  ...   \n",
       "56    Large language models (LLMs) have demonstrated...  ...   \n",
       "22    We present the design, implementation and engi...  ...   \n",
       "15    At Inflection, our mission is to create a pers...  ...   \n",
       "14    In this work, we discuss building performant M...  ...   \n",
       "2                                                   NaN  ...   \n",
       "\n",
       "                                    Training time notes Training time (hours)  \\\n",
       "1261                                                NaN                   NaN   \n",
       "1255                                                NaN                   NaN   \n",
       "1254                                                NaN                   NaN   \n",
       "1253                                                NaN                   NaN   \n",
       "1251                                                NaN                   NaN   \n",
       "...                                                 ...                   ...   \n",
       "56    Appendix A.5: \"To reproduce admissible set exp...                  48.0   \n",
       "22    Speculative. Authors state \"several weeks\". Fo...                 504.0   \n",
       "15                                                  NaN                   NaN   \n",
       "14                                                  NaN                   NaN   \n",
       "2                                                   NaN                   NaN   \n",
       "\n",
       "     Batch size Batch size notes Base model Finetune compute (FLOP)  \\\n",
       "1261        NaN              NaN        NaN                     NaN   \n",
       "1255        NaN              NaN        NaN                     NaN   \n",
       "1254        NaN              NaN        NaN                     NaN   \n",
       "1253        NaN              NaN        NaN                     NaN   \n",
       "1251        NaN              NaN        NaN                     NaN   \n",
       "...         ...              ...        ...                     ...   \n",
       "56          NaN              NaN     PaLM 2                     0.0   \n",
       "22          NaN              NaN        NaN                     NaN   \n",
       "15          NaN              NaN        NaN                     NaN   \n",
       "14          NaN              NaN        NaN                     NaN   \n",
       "2           NaN              NaN        NaN                     NaN   \n",
       "\n",
       "     Training compute upper bound Archived links  Benchmark data Decimal year  \n",
       "1261                          NaN            NaN             NaN  1950.502740  \n",
       "1255                          NaN            NaN             NaN  1957.000000  \n",
       "1254                          NaN            NaN             NaN  1959.083333  \n",
       "1253                          NaN            NaN             NaN  1959.500000  \n",
       "1251                          NaN            NaN             NaN  1960.246119  \n",
       "...                           ...            ...             ...          ...  \n",
       "56                            NaN            NaN             NaN  2023.952283  \n",
       "22                            NaN            NaN             NaN  2024.143607  \n",
       "15                            NaN            NaN             NaN  2024.183105  \n",
       "14                            NaN            NaN             NaN  2024.202283  \n",
       "2                             NaN            NaN             NaN  2024.296575  \n",
       "\n",
       "[354 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zFUQoG_01L8m"
   },
   "outputs": [],
   "source": [
    "outlier_window_size = 2  # years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_large_scale_era = '2015-10-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrayDGa4hK6X"
   },
   "source": [
    "# Top n all-time most compute-intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, 21):\n",
    "    # Add a column to mark the top n models\n",
    "    pcd_df[f'top_{n}_at_release'] = False\n",
    "    \n",
    "    for row, model in pcd_df.iterrows():\n",
    "        # Filter for models released through the model's release date\n",
    "        yearly_df = pcd_df[pcd_df['Decimal year'] <= model['Decimal year']]\n",
    "        # get the top n models by compute\n",
    "        top_n_models = yearly_df.nlargest(n, 'Training compute (FLOP)')\n",
    "        # mark these models in the original dataframe\n",
    "        pcd_df.loc[top_n_models.index, f'top_{n}_at_release'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['System', 'Domain', 'Organization', 'Publication date', 'Reference',\n",
       "       'Link', 'Parameters', 'Training dataset', 'Training dataset notes',\n",
       "       'Abstract', 'Confidence', 'Model accessibility', 'Last modified',\n",
       "       'Created By', 'Country (from Organization)',\n",
       "       'Organization categorization', 'Authors', 'Parameters notes',\n",
       "       'Training compute (FLOP)', 'Training compute notes',\n",
       "       'Training dataset size (datapoints)', 'Notability criteria',\n",
       "       'Notability criteria notes', 'Training hardware', 'Exclude',\n",
       "       'Hardware quantity', 'Hardware utilization', 'Approach',\n",
       "       'Training compute lower bound', 'Dataset size notes', 'Epochs',\n",
       "       'Foundation model', 'Training data center', 'Finetune compute notes',\n",
       "       'Training cloud compute vendor', 'Citations', 'Training time notes',\n",
       "       'Training time (hours)', 'Batch size', 'Batch size notes', 'Base model',\n",
       "       'Finetune compute (FLOP)', 'Training compute upper bound',\n",
       "       'Archived links', 'Benchmark data', 'Decimal year', 'top_1_at_release',\n",
       "       'top_2_at_release', 'top_3_at_release', 'top_4_at_release',\n",
       "       'top_5_at_release', 'top_6_at_release', 'top_7_at_release',\n",
       "       'top_8_at_release', 'top_9_at_release', 'top_10_at_release',\n",
       "       'top_11_at_release', 'top_12_at_release', 'top_13_at_release',\n",
       "       'top_14_at_release', 'top_15_at_release', 'top_16_at_release',\n",
       "       'top_17_at_release', 'top_18_at_release', 'top_19_at_release',\n",
       "       'top_20_at_release'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pcd_df['top_4_at_release'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_df_n = pcd_df[(pcd_df['Decimal year'] > 2015.75) & (pcd_df['Decimal year'] < 2024)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_n = [np.sum(pcd_df_n[f'top_{n}_at_release']) for n in range(1, 21)]\n",
    "plt.scatter(range(1, 21), top_n)\n",
    "plt.xticks(ticks=range(1, 21))\n",
    "plt.xlabel('n-value for top n')\n",
    "plt.ylabel('Models which have ever been in the top n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_models = {}\n",
    "for n in range(1, 21):\n",
    "    models = pcd_df_n[pcd_df_n[f'top_{n}_at_release']]['System'].values.tolist()\n",
    "    top_n_models[n] = set(models)\n",
    "\n",
    "for n in range(20, 1, -1):\n",
    "    top_n_models[n] = list(top_n_models[n].difference(top_n_models[n-1]))\n",
    "top_n_models[1] = list(top_n_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/frontier_systems_by_top_n.json', 'w') as f:\n",
    "    json.dump(top_n_models, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrayDGa4hK6X"
   },
   "source": [
    "# Default large scale systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ort2OjXauNI-"
   },
   "source": [
    "https://colab.research.google.com/drive/1PLGY5ErysqQMfy7Z08uIR2cTnnDgSaVR?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Xo0BSLmQ4RpG"
   },
   "outputs": [],
   "source": [
    "high_outliers_z_value_threshold = 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sTTmucLNtU8l"
   },
   "outputs": [],
   "source": [
    "large_scale_idx = set()\n",
    "\n",
    "for index, row in pcd_df.iterrows():\n",
    "  # Filter entries in a 2-year window around the paper\n",
    "  window_size = pd.Timedelta(f'{outlier_window_size*52*7} days')\n",
    "  half_window_size = window_size / 2\n",
    "  mask = ( row['Publication date'] - half_window_size <= pcd_df['Publication date'] ) &\\\n",
    "        ( pcd_df['Publication date'] <= row['Publication date'] + half_window_size )\n",
    "  window_df = pcd_df[mask].copy()\n",
    "\n",
    "  if len(window_df) < 2: continue\n",
    "\n",
    "  window_df['Training compute (FLOP) z scores'] = stats.zscore(np.log10(window_df['Training compute (FLOP)'].values))\n",
    "  if window_df.loc[index, 'Training compute (FLOP) z scores'] > high_outliers_z_value_threshold:\n",
    "    large_scale_idx.add(index)\n",
    "\n",
    "large_scale_mask = pcd_df.index.isin(large_scale_idx) & (pcd_df['Publication date'] > start_large_scale_era)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "w2HakL5g4iUq"
   },
   "outputs": [],
   "source": [
    "large_scale_df = pcd_df[large_scale_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y4-TmYMQ7Iex",
    "outputId": "485901a3-4ccd-4956-bba8-e81f64bf5c0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training dataset</th>\n",
       "      <th>Training dataset notes</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>top_11_at_release</th>\n",
       "      <th>top_12_at_release</th>\n",
       "      <th>top_13_at_release</th>\n",
       "      <th>top_14_at_release</th>\n",
       "      <th>top_15_at_release</th>\n",
       "      <th>top_16_at_release</th>\n",
       "      <th>top_17_at_release</th>\n",
       "      <th>top_18_at_release</th>\n",
       "      <th>top_19_at_release</th>\n",
       "      <th>top_20_at_release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>https://www.nature.com/articles/nature16961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The game of Go has long been viewed as the mos...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>Language</td>\n",
       "      <td>Google</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>Google's Neural Machine Translation System: Br...</td>\n",
       "      <td>https://arxiv.org/abs/1609.08144</td>\n",
       "      <td>2.780000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neural Machine Translation (NMT) is an end-to-...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>Xception</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Google</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>Xception: Deep Learning with Depthwise Separab...</td>\n",
       "      <td>https://arxiv.org/abs/1610.02357</td>\n",
       "      <td>2.285595e+07</td>\n",
       "      <td>JFT</td>\n",
       "      <td>Also ImageNet, but JFT is significantly larger</td>\n",
       "      <td>We present an interpretation of Inception modu...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Google Brain</td>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>Neural Architecture Search with Reinforcement ...</td>\n",
       "      <td>https://arxiv.org/abs/1611.01578</td>\n",
       "      <td>3.740000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neural networks are powerful and flexible mode...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>Games</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Mastering the game of Go without human knowledge</td>\n",
       "      <td>https://www.nature.com/articles/nature24270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A long-standing goal of artificial intelligenc...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Qwen-72B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n",
       "      <td>7.200000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"It is pretrained on over 3 trillion tokens, i...</td>\n",
       "      <td>Qwen-72B is the 72B-parameter version of the l...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Gemini Ultra</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Gemini models are trained on a dataset that i...</td>\n",
       "      <td>This report introduces a new family of multimo...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MegaScale (Production)</td>\n",
       "      <td>Language</td>\n",
       "      <td>ByteDance,Peking University</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>MegaScale: Scaling Large Language Model Traini...</td>\n",
       "      <td>https://arxiv.org/abs/2402.15627</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We present the design, implementation and engi...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Inflection-2.5</td>\n",
       "      <td>Language</td>\n",
       "      <td>Inflection AI</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>Inflection-2.5: meet the world's best personal AI</td>\n",
       "      <td>https://inflection.ai/inflection-2-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>At Inflection, our mission is to create a pers...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama 3-70B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>Introducing Meta Llama 3: The most capable ope...</td>\n",
       "      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n",
       "      <td>7.000000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System      Domain                 Organization  \\\n",
       "986             AlphaGo Lee       Games                     DeepMind   \n",
       "953                    GNMT    Language                       Google   \n",
       "952                Xception      Vision                       Google   \n",
       "946        NASv3 (CIFAR-10)      Vision                 Google Brain   \n",
       "931          AlphaGo Master       Games                     DeepMind   \n",
       "..                      ...         ...                          ...   \n",
       "71                 Qwen-72B    Language                      Alibaba   \n",
       "64             Gemini Ultra  Multimodal              Google DeepMind   \n",
       "22   MegaScale (Production)    Language  ByteDance,Peking University   \n",
       "15           Inflection-2.5    Language                Inflection AI   \n",
       "2               Llama 3-70B    Language                      Meta AI   \n",
       "\n",
       "    Publication date                                          Reference  \\\n",
       "986       2016-01-27  Mastering the game of Go with deep neural netw...   \n",
       "953       2016-09-26  Google's Neural Machine Translation System: Br...   \n",
       "952       2016-10-07  Xception: Deep Learning with Depthwise Separab...   \n",
       "946       2016-11-05  Neural Architecture Search with Reinforcement ...   \n",
       "931       2017-01-01   Mastering the game of Go without human knowledge   \n",
       "..               ...                                                ...   \n",
       "71        2023-11-30                                                NaN   \n",
       "64        2023-12-06  Gemini: A Family of Highly Capable Multimodal ...   \n",
       "22        2024-02-23  MegaScale: Scaling Large Language Model Traini...   \n",
       "15        2024-03-07  Inflection-2.5: meet the world's best personal AI   \n",
       "2         2024-04-18  Introducing Meta Llama 3: The most capable ope...   \n",
       "\n",
       "                                                  Link    Parameters  \\\n",
       "986        https://www.nature.com/articles/nature16961           NaN   \n",
       "953                   https://arxiv.org/abs/1609.08144  2.780000e+08   \n",
       "952                   https://arxiv.org/abs/1610.02357  2.285595e+07   \n",
       "946                   https://arxiv.org/abs/1611.01578  3.740000e+07   \n",
       "931        https://www.nature.com/articles/nature24270           NaN   \n",
       "..                                                 ...           ...   \n",
       "71                https://huggingface.co/Qwen/Qwen-72B  7.200000e+10   \n",
       "64   https://storage.googleapis.com/deepmind-media/...           NaN   \n",
       "22                    https://arxiv.org/abs/2402.15627  5.300000e+11   \n",
       "15                https://inflection.ai/inflection-2-5           NaN   \n",
       "2    https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n",
       "\n",
       "    Training dataset                             Training dataset notes  \\\n",
       "986              NaN                                                NaN   \n",
       "953              NaN                                                NaN   \n",
       "952              JFT     Also ImageNet, but JFT is significantly larger   \n",
       "946              NaN                                                NaN   \n",
       "931              NaN                                                NaN   \n",
       "..               ...                                                ...   \n",
       "71               NaN  \"It is pretrained on over 3 trillion tokens, i...   \n",
       "64               NaN  \"Gemini models are trained on a dataset that i...   \n",
       "22               NaN                                                NaN   \n",
       "15               NaN                                                NaN   \n",
       "2                NaN                                                NaN   \n",
       "\n",
       "                                              Abstract  ... top_11_at_release  \\\n",
       "986  The game of Go has long been viewed as the mos...  ...              True   \n",
       "953  Neural Machine Translation (NMT) is an end-to-...  ...              True   \n",
       "952  We present an interpretation of Inception modu...  ...              True   \n",
       "946  Neural networks are powerful and flexible mode...  ...              True   \n",
       "931  A long-standing goal of artificial intelligenc...  ...              True   \n",
       "..                                                 ...  ...               ...   \n",
       "71   Qwen-72B is the 72B-parameter version of the l...  ...              True   \n",
       "64   This report introduces a new family of multimo...  ...              True   \n",
       "22   We present the design, implementation and engi...  ...              True   \n",
       "15   At Inflection, our mission is to create a pers...  ...              True   \n",
       "2                                                  NaN  ...              True   \n",
       "\n",
       "    top_12_at_release top_13_at_release top_14_at_release top_15_at_release  \\\n",
       "986              True              True              True              True   \n",
       "953              True              True              True              True   \n",
       "952              True              True              True              True   \n",
       "946              True              True              True              True   \n",
       "931              True              True              True              True   \n",
       "..                ...               ...               ...               ...   \n",
       "71               True              True              True              True   \n",
       "64               True              True              True              True   \n",
       "22               True              True              True              True   \n",
       "15               True              True              True              True   \n",
       "2                True              True              True              True   \n",
       "\n",
       "    top_16_at_release top_17_at_release top_18_at_release  top_19_at_release  \\\n",
       "986              True              True              True               True   \n",
       "953              True              True              True               True   \n",
       "952              True              True              True               True   \n",
       "946              True              True              True               True   \n",
       "931              True              True              True               True   \n",
       "..                ...               ...               ...                ...   \n",
       "71               True              True              True               True   \n",
       "64               True              True              True               True   \n",
       "22               True              True              True               True   \n",
       "15               True              True              True               True   \n",
       "2                True              True              True               True   \n",
       "\n",
       "    top_20_at_release  \n",
       "986              True  \n",
       "953              True  \n",
       "952              True  \n",
       "946              True  \n",
       "931              True  \n",
       "..                ...  \n",
       "71               True  \n",
       "64               True  \n",
       "22               True  \n",
       "15               True  \n",
       "2                True  \n",
       "\n",
       "[75 rows x 66 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_scale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ngeVX9J-1yx",
    "outputId": "949a42f5-e8c9-4c65-fcc9-c5ae79651d10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3-70B\n",
      "Inflection-2.5\n",
      "MegaScale (Production)\n",
      "Gemini Ultra\n",
      "Qwen-72B\n",
      "Inflection-2\n",
      "Grok-1\n",
      "ChatGLM3\n",
      "Falcon-180B\n",
      "Llama 2-70B\n",
      "Claude 2\n",
      "PaLM 2\n",
      "GPT-4\n",
      "LLaMA-65B\n",
      "ViT-22B\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Galactica\n",
      "BLOOM-176B\n",
      "U-PaLM (540B)\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "Minerva (540B)\n",
      "Parti\n",
      "OPT-175B\n",
      "Flamingo\n",
      "PaLM (540B)\n",
      "Chinchilla\n",
      "ST-MoE\n",
      "LaMDA\n",
      "AlphaCode\n",
      "ERNIE 3.0 Titan\n",
      "GLaM\n",
      "Gopher (280B)\n",
      "Yuan 1.0\n",
      "Megatron-Turing NLG 530B\n",
      "HyperCLOVA\n",
      "GOAT\n",
      "ByT5-XXL\n",
      "ProtT5-XXL\n",
      "Meta Pseudo Labels\n",
      "Switch\n",
      "DALL-E\n",
      "mT5-XXL\n",
      "GShard (dense)\n",
      "iGPT-XL\n",
      "GPT-3 175B (davinci)\n",
      "Turing-NLG\n",
      "Meena\n",
      "ContextNet + Noisy Student\n",
      "OpenAI Five\n",
      "OpenAI Five Rerun\n",
      "AlphaStar\n",
      "T5-11B\n",
      "Megatron-LM (8.3B)\n",
      "Megatron-BERT\n",
      "RoBERTa Large\n",
      "XLNet\n",
      "MnasNet-A3\n",
      "MnasNet-A1 + SSDLite\n",
      "GPT-2 (1.5B)\n",
      "BigGAN-deep 512x512\n",
      "FTW\n",
      "ResNeXt-101 32x48d\n",
      "IMPALA\n",
      "AmoebaNet-A (F=448)\n",
      "AlphaZero\n",
      "AlphaGo Zero\n",
      "OpenAI TI7 DOTA 1v1\n",
      "JFT\n",
      "Libratus\n",
      "AlphaGo Master\n",
      "NASv3 (CIFAR-10)\n",
      "Xception\n",
      "GNMT\n",
      "AlphaGo Lee\n"
     ]
    }
   ],
   "source": [
    "for system in large_scale_df['System'][::-1]:\n",
    "  print(system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1TTIzTQhPan"
   },
   "source": [
    "# Percentiles (CURRENT CHOICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-cxrNxPbW7r",
    "outputId": "1ab54428-dc65-4d79-e6a0-feff77ad6e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "90\n",
      "85\n",
      "80\n",
      "75\n",
      "70\n",
      "65\n",
      "60\n",
      "55\n",
      "50\n",
      "45\n",
      "40\n",
      "35\n",
      "30\n",
      "25\n",
      "20\n",
      "15\n",
      "10\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "frontier_systems_by_percentile = {}\n",
    "percentile_interval = 5\n",
    "for percentile in range(95, -5, -percentile_interval):\n",
    "  print(percentile)\n",
    "  percentile_compute_low = np.zeros(len(pcd_df))\n",
    "  percentile_compute_high = np.zeros(len(pcd_df))\n",
    "  # Iterate through each row and calculate the 2-year moving average for each date\n",
    "  for i, (index, row) in enumerate(pcd_df.iterrows()):\n",
    "    # Define the 2-year window\n",
    "    start_date = row['Publication date'] - pd.DateOffset(years=outlier_window_size/2)\n",
    "    end_date = row['Publication date'] + pd.DateOffset(years=outlier_window_size/2)\n",
    "\n",
    "    # Filter the DataFrame for this window\n",
    "    window_df = pcd_df[(pcd_df['Publication date'] >= start_date) & (pcd_df['Publication date'] <= end_date)]\n",
    "\n",
    "    percentile_compute_low[i] = np.percentile(window_df['Training compute (FLOP)'], percentile)\n",
    "    percentile_compute_high[i] = np.percentile(window_df['Training compute (FLOP)'], percentile + percentile_interval)\n",
    "\n",
    "  frontier_systems_flag = pcd_df['Training compute (FLOP)'] > np.array(percentile_compute_low)\n",
    "  extra_frontier_systems_flag = pcd_df['Training compute (FLOP)'] <= np.array(percentile_compute_high)\n",
    "\n",
    "  # raise Exception(\"Edit the following line if you want to consider models released after 2023-12-31.\")\n",
    "  extra_frontier_systems = pcd_df['System'][frontier_systems_flag & extra_frontier_systems_flag & (pcd_df['Publication date'] > pd.to_datetime('2015-09-30'))].values\n",
    "\n",
    "  frontier_systems_by_percentile[percentile] = list(extra_frontier_systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGXo_vGde5mz",
    "outputId": "6684d0f4-3ec9-40ca-ff4a-94cd73c830d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95: ['GNMT',\n",
       "  'AlphaGo Master',\n",
       "  'AlphaGo Zero',\n",
       "  'AlphaZero',\n",
       "  'ResNeXt-101 32x48d',\n",
       "  'FTW',\n",
       "  'Megatron-BERT',\n",
       "  'OpenAI Five',\n",
       "  'Meena',\n",
       "  'GPT-3 175B (davinci)',\n",
       "  'Megatron-Turing NLG 530B',\n",
       "  'ERNIE 3.0 Titan',\n",
       "  'PaLM (540B)',\n",
       "  'Minerva (540B)',\n",
       "  'GPT-4',\n",
       "  'Gemini Ultra',\n",
       "  'MegaScale (Production)'],\n",
       " 90: ['NASv3 (CIFAR-10)',\n",
       "  'T5-11B',\n",
       "  'AlphaStar',\n",
       "  'mT5-XXL',\n",
       "  'Switch',\n",
       "  'Gopher (280B)',\n",
       "  'Chinchilla',\n",
       "  'U-PaLM (540B)',\n",
       "  'GPT-3.5 (text-davinci-003)',\n",
       "  'PaLM 2',\n",
       "  'Claude 2',\n",
       "  'Inflection-2',\n",
       "  'Inflection-2.5'],\n",
       " 85: ['AlphaGo Fan',\n",
       "  'AlphaGo Lee',\n",
       "  'Megatron-LM (8.3B)',\n",
       "  'OpenAI Five Rerun',\n",
       "  'Turing-NLG',\n",
       "  'Yuan 1.0',\n",
       "  'GLaM',\n",
       "  'LaMDA',\n",
       "  'OPT-175B',\n",
       "  'BLOOM-176B',\n",
       "  'Falcon-180B',\n",
       "  'Grok-1'],\n",
       " 80: ['JFT',\n",
       "  'OpenAI TI7 DOTA 1v1',\n",
       "  'AmoebaNet-A (F=448)',\n",
       "  'IMPALA',\n",
       "  'BigGAN-deep 512x512',\n",
       "  'GPT-2 (1.5B)',\n",
       "  'XLNet',\n",
       "  'iGPT-XL',\n",
       "  'DALL-E',\n",
       "  'ByT5-XXL',\n",
       "  'HyperCLOVA',\n",
       "  'AlphaCode',\n",
       "  'ST-MoE',\n",
       "  'Flamingo',\n",
       "  'Parti',\n",
       "  'GLM-130B',\n",
       "  'BlenderBot 3',\n",
       "  'Llama 2-70B',\n",
       "  'ChatGLM3',\n",
       "  'Qwen-72B',\n",
       "  'Llama 3-70B'],\n",
       " 75: ['DeepSpeech2 (English)',\n",
       "  'Xception',\n",
       "  'Libratus',\n",
       "  'BERT-Large',\n",
       "  'RoBERTa Large',\n",
       "  'ContextNet + Noisy Student',\n",
       "  'Meta Pseudo Labels',\n",
       "  'ProtT5-XXL',\n",
       "  'GOAT',\n",
       "  'GPT-NeoX-20B',\n",
       "  'ViT-22B',\n",
       "  'LLaMA-65B',\n",
       "  'PanGu-Σ',\n",
       "  'xTrimoPGLM -100B',\n",
       "  'Yi-34B'],\n",
       " 70: ['PolyNet',\n",
       "  'MoE',\n",
       "  'Big Transformer for Back-Translation',\n",
       "  'Mesh-TensorFlow Transformer 4.9B (language modelling)',\n",
       "  'MnasNet-A1 + SSDLite',\n",
       "  'MnasNet-A3',\n",
       "  'iGPT-L',\n",
       "  'GShard (dense)',\n",
       "  'CoAtNet',\n",
       "  'FLAN 137B',\n",
       "  'UL2',\n",
       "  'AlexaTM 20B',\n",
       "  'Galactica'],\n",
       " 65: ['ResNet-152 (ImageNet)',\n",
       "  'YOLOv3',\n",
       "  'Transformer (Adaptive Input Embeddings)',\n",
       "  'BERT-Large-CAS (PTB+WT2+WT103)',\n",
       "  'ALBERT-xxlarge',\n",
       "  'ELECTRA',\n",
       "  'Conformer + Wav2vec 2.0 + Noisy Student',\n",
       "  'PLUG',\n",
       "  'ProtT5-XXL-BFD',\n",
       "  'ProtBERT-BFD',\n",
       "  'Florence',\n",
       "  'Stable Diffusion (LDM-KL-8-G)',\n",
       "  'CoCa',\n",
       "  'Falcon-40B',\n",
       "  'FunSearch'],\n",
       " 60: ['ConvS2S (ensemble of 8 models)',\n",
       "  'PNASNet-5',\n",
       "  'Mesh-TensorFlow Transformer 2.9B (translation)',\n",
       "  'T5-3B',\n",
       "  'CLIP (ViT L/14@336px)',\n",
       "  'CogView',\n",
       "  'ALIGN',\n",
       "  'ERNIE 3.0',\n",
       "  'BASIC-L',\n",
       "  'XGLM-7.5B',\n",
       "  'ESM2-15B',\n",
       "  'PaLI',\n",
       "  'Taiyi-Stable Diffusion',\n",
       "  'BloombergGPT',\n",
       "  'StarCoder',\n",
       "  'Skywork-13B',\n",
       "  'MM1-30B'],\n",
       " 55: ['DeepStack',\n",
       "  'LSTM (Hebbian, Cache, MbPA)',\n",
       "  'QT-Opt',\n",
       "  'Population-based DRL',\n",
       "  'SciBERT',\n",
       "  'CamemBERT',\n",
       "  'Noisy Student (L2)',\n",
       "  'Once for All',\n",
       "  'ViT-Huge/14',\n",
       "  'T0-XXL',\n",
       "  'Student of Games',\n",
       "  'Whisper',\n",
       "  'Llama 2-7B',\n",
       "  'Nemotron-3-8B'],\n",
       " 50: ['BIDAF',\n",
       "  'Transformer',\n",
       "  'GPT',\n",
       "  'ProxylessNAS',\n",
       "  'DD-PPO',\n",
       "  'GBERT-Large',\n",
       "  'AlphaFold 2',\n",
       "  'MSA Transformer',\n",
       "  'M6-T',\n",
       "  'DeBERTa',\n",
       "  'XGLM',\n",
       "  'RETRO-7B',\n",
       "  'Imagen',\n",
       "  'NLLB',\n",
       "  'LLaMA-7B'],\n",
       " 45: ['Transformer + Simple Recurrent Unit',\n",
       "  'Sandwich Transformer',\n",
       "  'German ELECTRA Large',\n",
       "  'wave2vec 2.0 LARGE',\n",
       "  'CPM-Large',\n",
       "  'HuBERT',\n",
       "  'ProGen2-xlarge',\n",
       "  'OmegaPLM',\n",
       "  'WizardLM-7B',\n",
       "  'Pangu-Weather',\n",
       "  'Jais',\n",
       "  'CogVLM',\n",
       "  'CogAgent'],\n",
       " 40: ['Part-of-sentence tagging model',\n",
       "  'RetinaNet-R101',\n",
       "  'GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)',\n",
       "  'Transformer-XL (257M)',\n",
       "  'KataGo',\n",
       "  'MuZero',\n",
       "  'AlphaFold',\n",
       "  'DETR',\n",
       "  'ESM1-670M (UR50/D)',\n",
       "  'ViT-G/14',\n",
       "  'SEER',\n",
       "  'NÜWA',\n",
       "  'Gato',\n",
       "  'Tranception',\n",
       "  'Nucleotide Transformer',\n",
       "  'GraphCast'],\n",
       " 35: ['Named Entity Recognition model',\n",
       "  'R-FCN',\n",
       "  'ResNet-152 + ObjectNet',\n",
       "  'Feedback Transformer',\n",
       "  'AlphaFold-Multimer',\n",
       "  'ViT-G (model soup)',\n",
       "  'VideoMAE V2',\n",
       "  'Segment Anything Model',\n",
       "  'DINOv2',\n",
       "  'PeptideBERT'],\n",
       " 30: ['AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)',\n",
       "  'AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)',\n",
       "  'QRNN',\n",
       "  '(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)',\n",
       "  'TrellisNet',\n",
       "  'FAIRSEQ Adaptive Inputs',\n",
       "  'DistilBERT',\n",
       "  'TaLK Convolution',\n",
       "  'ATLAS',\n",
       "  'ERNIE-GEN (large)',\n",
       "  'LUKE',\n",
       "  'ADM',\n",
       "  'EMDR',\n",
       "  'CodeT5-base',\n",
       "  'CodeT5-large',\n",
       "  'EVA-01',\n",
       "  'Ankh_large',\n",
       "  'AudioGen'],\n",
       " 25: ['VD-LSTM+REAL Large',\n",
       "  'Big-Little Net (speech)',\n",
       "  'Hanabi 4 player',\n",
       "  'Transformer-XL Large + Phrase Induction',\n",
       "  'Tensorized Transformer (257M)',\n",
       "  'AlphaX-1',\n",
       "  'KEPLER',\n",
       "  'ViT + DINO',\n",
       "  'Denoising Diffusion Probabilistic Models (LSUN Bedroom)',\n",
       "  'S4',\n",
       "  'Swin Transformer V2',\n",
       "  'PolyCoder',\n",
       "  'GenSLM',\n",
       "  'Ankh_base',\n",
       "  'BLIP-2 (Q-Former)',\n",
       "  'Incoder-6.7B'],\n",
       " 20: ['Zoneout + Variational LSTM (WT2)',\n",
       "  'Fraternal dropout + AWD-LSTM 3-layer (WT2)',\n",
       "  '4 layer QRNN (h=2500)',\n",
       "  'Dropout-LSTM+Noise(Bernoulli) (WT2)',\n",
       "  'Decoupled weight decay regularization',\n",
       "  'Cross-lingual alignment',\n",
       "  'DLRM-2020',\n",
       "  'Base LM + kNN LM + Continuous Cache',\n",
       "  'ConSERT',\n",
       "  'Masked Autoencoders',\n",
       "  'AR-LDM',\n",
       "  'Hybrid H3-2.7B',\n",
       "  'Flan T5-XXL + BLIP-2',\n",
       "  'DiT-XL/2'],\n",
       " 15: ['Variational (untied weights, MC) LSTM (Large)',\n",
       "  'Pointer Sentinel-LSTM (medium)',\n",
       "  'Neural Architecture Search with base 8 and shared embeddings',\n",
       "  'ENAS',\n",
       "  'aLSTM(depth-2)+RecurrentPolicy (WT2)',\n",
       "  'Transformer-XL DeFINE (141M)',\n",
       "  'DeLight',\n",
       "  'ERNIE-Doc (247M)',\n",
       "  'EfficientNetV2',\n",
       "  'Adaptive Input Transformer + RD',\n",
       "  'DNABERT',\n",
       "  'BERT-RBP',\n",
       "  'Fusion in Encoder',\n",
       "  'Discriminator Guidance',\n",
       "  'DDPM-IP (CelebA)',\n",
       "  'ONE-PEACE'],\n",
       " 10: ['EI-REHN-1000D',\n",
       "  'DARTS',\n",
       "  'NAS+ESS (156M)',\n",
       "  'ProBERTa',\n",
       "  'SRU++ Large',\n",
       "  'Transformer local-attention (NesT-B)',\n",
       "  'ProteinBERT',\n",
       "  'BEIT-3',\n",
       "  'DiffDock',\n",
       "  'LLaVA 1.5'],\n",
       " 5: ['VD-RHN',\n",
       "  'ISS',\n",
       "  'AWD-LSTM+WT+Cache+IOG (WT2)',\n",
       "  'AWD-LSTM-DRILL + dynamic evaluation† (WT2)',\n",
       "  'AWD-LSTM + MoS + Partial Shuffled',\n",
       "  'UDSMProt',\n",
       "  'MMLSTM',\n",
       "  'TransformerXL + spectrum control',\n",
       "  'Tensor-Transformer(1core)+PN (WT103)',\n",
       "  'MedBERT',\n",
       "  'Detic',\n",
       "  'Segatron-XL large, M=384 + HCP',\n",
       "  'Sparse all-MLP',\n",
       "  'CaLM',\n",
       "  'LLaVA',\n",
       "  'MultiBand Diffusion'],\n",
       " 0: ['2-layer-LSTM+Deep-Gradient-Compression',\n",
       "  'Fine-tuned-AWD-LSTM-DOC(fin)',\n",
       "  'Multi-cell LSTM',\n",
       "  'Pluribus',\n",
       "  'DensePhrases',\n",
       "  'CT-MoS (WT2)',\n",
       "  'PermuteFormer',\n",
       "  'base LM+GNN+kNN',\n",
       "  'DITTO',\n",
       "  'Mogrifier RLSTM (WT2)',\n",
       "  'VALL-E',\n",
       "  'HyenaDNA',\n",
       "  'CODEFUSION (Python)']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_systems_by_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "with open('data/frontier_systems_by_window_percentile.json', 'w') as f:\n",
    "    json.dump(frontier_systems_by_percentile, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8pzY7skfxkV",
    "outputId": "195c3ec6-c885-4008-ba36-abb60e5dd645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 to 100\n",
      "17 systems\n",
      "Total systems above 95th percentile: 17\n",
      "MegaScale (Production)\n",
      "Gemini Ultra\n",
      "GPT-4\n",
      "Minerva (540B)\n",
      "PaLM (540B)\n",
      "ERNIE 3.0 Titan\n",
      "Megatron-Turing NLG 530B\n",
      "GPT-3 175B (davinci)\n",
      "Meena\n",
      "OpenAI Five\n",
      "Megatron-BERT\n",
      "FTW\n",
      "ResNeXt-101 32x48d\n",
      "AlphaZero\n",
      "AlphaGo Zero\n",
      "AlphaGo Master\n",
      "GNMT\n",
      "\n",
      "90 to 95\n",
      "13 systems\n",
      "Total systems above 90th percentile: 30\n",
      "Inflection-2.5\n",
      "Inflection-2\n",
      "Claude 2\n",
      "PaLM 2\n",
      "GPT-3.5 (text-davinci-003)\n",
      "U-PaLM (540B)\n",
      "Chinchilla\n",
      "Gopher (280B)\n",
      "Switch\n",
      "mT5-XXL\n",
      "AlphaStar\n",
      "T5-11B\n",
      "NASv3 (CIFAR-10)\n",
      "\n",
      "85 to 90\n",
      "12 systems\n",
      "Total systems above 85th percentile: 42\n",
      "Grok-1\n",
      "Falcon-180B\n",
      "BLOOM-176B\n",
      "OPT-175B\n",
      "LaMDA\n",
      "GLaM\n",
      "Yuan 1.0\n",
      "Turing-NLG\n",
      "OpenAI Five Rerun\n",
      "Megatron-LM (8.3B)\n",
      "AlphaGo Lee\n",
      "AlphaGo Fan\n",
      "\n",
      "80 to 85\n",
      "21 systems\n",
      "Total systems above 80th percentile: 63\n",
      "Llama 3-70B\n",
      "Qwen-72B\n",
      "ChatGLM3\n",
      "Llama 2-70B\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "Parti\n",
      "Flamingo\n",
      "ST-MoE\n",
      "AlphaCode\n",
      "HyperCLOVA\n",
      "ByT5-XXL\n",
      "DALL-E\n",
      "iGPT-XL\n",
      "XLNet\n",
      "GPT-2 (1.5B)\n",
      "BigGAN-deep 512x512\n",
      "IMPALA\n",
      "AmoebaNet-A (F=448)\n",
      "OpenAI TI7 DOTA 1v1\n",
      "JFT\n",
      "\n",
      "75 to 80\n",
      "15 systems\n",
      "Total systems above 75th percentile: 78\n",
      "Yi-34B\n",
      "xTrimoPGLM -100B\n",
      "PanGu-Σ\n",
      "LLaMA-65B\n",
      "ViT-22B\n",
      "GPT-NeoX-20B\n",
      "GOAT\n",
      "ProtT5-XXL\n",
      "Meta Pseudo Labels\n",
      "ContextNet + Noisy Student\n",
      "RoBERTa Large\n",
      "BERT-Large\n",
      "Libratus\n",
      "Xception\n",
      "DeepSpeech2 (English)\n",
      "\n",
      "70 to 75\n",
      "13 systems\n",
      "Total systems above 70th percentile: 91\n",
      "Galactica\n",
      "AlexaTM 20B\n",
      "UL2\n",
      "FLAN 137B\n",
      "CoAtNet\n",
      "GShard (dense)\n",
      "iGPT-L\n",
      "MnasNet-A3\n",
      "MnasNet-A1 + SSDLite\n",
      "Mesh-TensorFlow Transformer 4.9B (language modelling)\n",
      "Big Transformer for Back-Translation\n",
      "MoE\n",
      "PolyNet\n",
      "\n",
      "65 to 70\n",
      "15 systems\n",
      "Total systems above 65th percentile: 106\n",
      "FunSearch\n",
      "Falcon-40B\n",
      "CoCa\n",
      "Stable Diffusion (LDM-KL-8-G)\n",
      "Florence\n",
      "ProtBERT-BFD\n",
      "ProtT5-XXL-BFD\n",
      "PLUG\n",
      "Conformer + Wav2vec 2.0 + Noisy Student\n",
      "ELECTRA\n",
      "ALBERT-xxlarge\n",
      "BERT-Large-CAS (PTB+WT2+WT103)\n",
      "Transformer (Adaptive Input Embeddings)\n",
      "YOLOv3\n",
      "ResNet-152 (ImageNet)\n",
      "\n",
      "60 to 65\n",
      "17 systems\n",
      "Total systems above 60th percentile: 123\n",
      "MM1-30B\n",
      "Skywork-13B\n",
      "StarCoder\n",
      "BloombergGPT\n",
      "Taiyi-Stable Diffusion\n",
      "PaLI\n",
      "ESM2-15B\n",
      "XGLM-7.5B\n",
      "BASIC-L\n",
      "ERNIE 3.0\n",
      "ALIGN\n",
      "CogView\n",
      "CLIP (ViT L/14@336px)\n",
      "T5-3B\n",
      "Mesh-TensorFlow Transformer 2.9B (translation)\n",
      "PNASNet-5\n",
      "ConvS2S (ensemble of 8 models)\n",
      "\n",
      "55 to 60\n",
      "14 systems\n",
      "Total systems above 55th percentile: 137\n",
      "Nemotron-3-8B\n",
      "Llama 2-7B\n",
      "Whisper\n",
      "Student of Games\n",
      "T0-XXL\n",
      "ViT-Huge/14\n",
      "Once for All\n",
      "Noisy Student (L2)\n",
      "CamemBERT\n",
      "SciBERT\n",
      "Population-based DRL\n",
      "QT-Opt\n",
      "LSTM (Hebbian, Cache, MbPA)\n",
      "DeepStack\n",
      "\n",
      "50 to 55\n",
      "15 systems\n",
      "Total systems above 50th percentile: 152\n",
      "LLaMA-7B\n",
      "NLLB\n",
      "Imagen\n",
      "RETRO-7B\n",
      "XGLM\n",
      "DeBERTa\n",
      "M6-T\n",
      "MSA Transformer\n",
      "AlphaFold 2\n",
      "GBERT-Large\n",
      "DD-PPO\n",
      "ProxylessNAS\n",
      "GPT\n",
      "Transformer\n",
      "BIDAF\n",
      "\n",
      "45 to 50\n",
      "13 systems\n",
      "Total systems above 45th percentile: 165\n",
      "CogAgent\n",
      "CogVLM\n",
      "Jais\n",
      "Pangu-Weather\n",
      "WizardLM-7B\n",
      "OmegaPLM\n",
      "ProGen2-xlarge\n",
      "HuBERT\n",
      "CPM-Large\n",
      "wave2vec 2.0 LARGE\n",
      "German ELECTRA Large\n",
      "Sandwich Transformer\n",
      "Transformer + Simple Recurrent Unit\n",
      "\n",
      "40 to 45\n",
      "16 systems\n",
      "Total systems above 40th percentile: 181\n",
      "GraphCast\n",
      "Nucleotide Transformer\n",
      "Tranception\n",
      "Gato\n",
      "NÜWA\n",
      "SEER\n",
      "ViT-G/14\n",
      "ESM1-670M (UR50/D)\n",
      "DETR\n",
      "AlphaFold\n",
      "MuZero\n",
      "KataGo\n",
      "Transformer-XL (257M)\n",
      "GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)\n",
      "RetinaNet-R101\n",
      "Part-of-sentence tagging model\n",
      "\n",
      "35 to 40\n",
      "10 systems\n",
      "Total systems above 35th percentile: 191\n",
      "PeptideBERT\n",
      "DINOv2\n",
      "Segment Anything Model\n",
      "VideoMAE V2\n",
      "ViT-G (model soup)\n",
      "AlphaFold-Multimer\n",
      "Feedback Transformer\n",
      "ResNet-152 + ObjectNet\n",
      "R-FCN\n",
      "Named Entity Recognition model\n",
      "\n",
      "30 to 35\n",
      "18 systems\n",
      "Total systems above 30th percentile: 209\n",
      "AudioGen\n",
      "Ankh_large\n",
      "EVA-01\n",
      "CodeT5-large\n",
      "CodeT5-base\n",
      "EMDR\n",
      "ADM\n",
      "LUKE\n",
      "ERNIE-GEN (large)\n",
      "ATLAS\n",
      "TaLK Convolution\n",
      "DistilBERT\n",
      "FAIRSEQ Adaptive Inputs\n",
      "TrellisNet\n",
      "(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)\n",
      "QRNN\n",
      "AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)\n",
      "AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)\n",
      "\n",
      "25 to 30\n",
      "16 systems\n",
      "Total systems above 25th percentile: 225\n",
      "Incoder-6.7B\n",
      "BLIP-2 (Q-Former)\n",
      "Ankh_base\n",
      "GenSLM\n",
      "PolyCoder\n",
      "Swin Transformer V2\n",
      "S4\n",
      "Denoising Diffusion Probabilistic Models (LSUN Bedroom)\n",
      "ViT + DINO\n",
      "KEPLER\n",
      "AlphaX-1\n",
      "Tensorized Transformer (257M)\n",
      "Transformer-XL Large + Phrase Induction\n",
      "Hanabi 4 player\n",
      "Big-Little Net (speech)\n",
      "VD-LSTM+REAL Large\n",
      "\n",
      "20 to 25\n",
      "14 systems\n",
      "Total systems above 20th percentile: 239\n",
      "DiT-XL/2\n",
      "Flan T5-XXL + BLIP-2\n",
      "Hybrid H3-2.7B\n",
      "AR-LDM\n",
      "Masked Autoencoders\n",
      "ConSERT\n",
      "Base LM + kNN LM + Continuous Cache\n",
      "DLRM-2020\n",
      "Cross-lingual alignment\n",
      "Decoupled weight decay regularization\n",
      "Dropout-LSTM+Noise(Bernoulli) (WT2)\n",
      "4 layer QRNN (h=2500)\n",
      "Fraternal dropout + AWD-LSTM 3-layer (WT2)\n",
      "Zoneout + Variational LSTM (WT2)\n",
      "\n",
      "15 to 20\n",
      "16 systems\n",
      "Total systems above 15th percentile: 255\n",
      "ONE-PEACE\n",
      "DDPM-IP (CelebA)\n",
      "Discriminator Guidance\n",
      "Fusion in Encoder\n",
      "BERT-RBP\n",
      "DNABERT\n",
      "Adaptive Input Transformer + RD\n",
      "EfficientNetV2\n",
      "ERNIE-Doc (247M)\n",
      "DeLight\n",
      "Transformer-XL DeFINE (141M)\n",
      "aLSTM(depth-2)+RecurrentPolicy (WT2)\n",
      "ENAS\n",
      "Neural Architecture Search with base 8 and shared embeddings\n",
      "Pointer Sentinel-LSTM (medium)\n",
      "Variational (untied weights, MC) LSTM (Large)\n",
      "\n",
      "10 to 15\n",
      "10 systems\n",
      "Total systems above 10th percentile: 265\n",
      "LLaVA 1.5\n",
      "DiffDock\n",
      "BEIT-3\n",
      "ProteinBERT\n",
      "Transformer local-attention (NesT-B)\n",
      "SRU++ Large\n",
      "ProBERTa\n",
      "NAS+ESS (156M)\n",
      "DARTS\n",
      "EI-REHN-1000D\n",
      "\n",
      "5 to 10\n",
      "16 systems\n",
      "Total systems above 5th percentile: 281\n",
      "MultiBand Diffusion\n",
      "LLaVA\n",
      "CaLM\n",
      "Sparse all-MLP\n",
      "Segatron-XL large, M=384 + HCP\n",
      "Detic\n",
      "MedBERT\n",
      "Tensor-Transformer(1core)+PN (WT103)\n",
      "TransformerXL + spectrum control\n",
      "MMLSTM\n",
      "UDSMProt\n",
      "AWD-LSTM + MoS + Partial Shuffled\n",
      "AWD-LSTM-DRILL + dynamic evaluation† (WT2)\n",
      "AWD-LSTM+WT+Cache+IOG (WT2)\n",
      "ISS\n",
      "VD-RHN\n",
      "\n",
      "0 to 5\n",
      "13 systems\n",
      "Total systems above 0th percentile: 294\n",
      "CODEFUSION (Python)\n",
      "HyenaDNA\n",
      "VALL-E\n",
      "Mogrifier RLSTM (WT2)\n",
      "DITTO\n",
      "base LM+GNN+kNN\n",
      "PermuteFormer\n",
      "CT-MoS (WT2)\n",
      "DensePhrases\n",
      "Pluribus\n",
      "Multi-cell LSTM\n",
      "Fine-tuned-AWD-LSTM-DOC(fin)\n",
      "2-layer-LSTM+Deep-Gradient-Compression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_num_systems = 0\n",
    "for percentile, systems in frontier_systems_by_percentile.items():\n",
    "  total_num_systems += len(systems)\n",
    "  print(percentile, 'to', percentile + percentile_interval)\n",
    "  print(len(systems), \"systems\")\n",
    "  print(f'Total systems above {percentile}th percentile: {total_num_systems}')\n",
    "  for system in systems[::-1]:\n",
    "    print(system)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klMq2PP3f6Xw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TllyX8IqSiG2"
   },
   "source": [
    "# Distance from compute record at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CC8_j5AASl0y"
   },
   "outputs": [],
   "source": [
    "ooms_from_frontier = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N395lGkYSoNU",
    "outputId": "ee6d6df7-3662-4dd8-ce41-b9490a33389a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.00000000e+01, 6.94894938e+05, 6.00000000e+08, 6.00000000e+08,\n",
       "       7.20000000e+08, 7.20000000e+08, 7.20000000e+08, 7.20000000e+08,\n",
       "       7.20000000e+08, 2.76640650e+10, 2.83280026e+10, 2.83280026e+10,\n",
       "       8.11870414e+10, 8.11870414e+10, 1.82321576e+13, 1.82321576e+13,\n",
       "       1.82321576e+13, 2.10080000e+13, 2.10080000e+13, 6.30000000e+13,\n",
       "       1.30389876e+15, 1.30389876e+15, 1.30389876e+15, 1.30389876e+15,\n",
       "       1.30389876e+15, 3.41463600e+15, 6.14400000e+16, 6.14400000e+16,\n",
       "       6.14400000e+16, 2.73196800e+17, 2.73196800e+17, 6.00000000e+17,\n",
       "       6.00000000e+17, 6.00000000e+17, 6.00000000e+17, 6.00000000e+17,\n",
       "       6.00000000e+17, 6.00000000e+17, 1.34092800e+18, 1.34092800e+18,\n",
       "       1.34092800e+18, 1.34092800e+18, 1.34092800e+18, 3.41107200e+18,\n",
       "       3.41107200e+18, 3.41107200e+18, 9.25344000e+18, 9.25344000e+18,\n",
       "       5.60000000e+19, 5.60000000e+19, 5.60000000e+19, 5.60000000e+19,\n",
       "       5.60000000e+19, 5.60000000e+19, 5.60000000e+19, 5.60000000e+19,\n",
       "       3.80000000e+20, 3.80000000e+20, 3.80000000e+20, 3.80000000e+20,\n",
       "       1.90000000e+21, 1.90000000e+21, 1.90000000e+21, 1.90000000e+21,\n",
       "       1.90000000e+21, 1.90000000e+21, 1.90000000e+21, 6.90000000e+21,\n",
       "       6.90000000e+21, 6.90000000e+21, 6.90000000e+21, 6.90000000e+21,\n",
       "       6.90000000e+21, 6.90000000e+21, 6.90000000e+21, 2.00010000e+23,\n",
       "       2.00010000e+23, 2.00010000e+23, 2.00010000e+23, 2.00010000e+23,\n",
       "       2.00010000e+23, 2.00010000e+23, 2.00010000e+23, 2.00010000e+23,\n",
       "       2.00010000e+23, 2.00010000e+23, 2.00010000e+23, 2.00010000e+23,\n",
       "       2.00010000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n",
       "       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n",
       "       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n",
       "       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 5.00000000e+25,\n",
       "       5.00000000e+25, 5.00000000e+25, 5.00000000e+25, 5.00000000e+25,\n",
       "       5.00000000e+25, 5.00000000e+25])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_max = 0\n",
    "running_max = np.zeros(len(pcd_df))\n",
    "for i, compute in enumerate(pcd_df['Training compute (FLOP)']):\n",
    "  if compute > current_max:\n",
    "    running_max[i] = compute\n",
    "    current_max = compute\n",
    "  else:\n",
    "    running_max[i] = current_max\n",
    "running_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SV1tpYgETmYT"
   },
   "outputs": [],
   "source": [
    "pcd_df['Frontier training compute (FLOP)'] = running_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "WdpWpDvvTqOs",
    "outputId": "331ce3ef-cc47-4393-dc7f-98148184fd4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Frontier system</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>Theseus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Perceptron Mark I</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Pandemonium (morse)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>Samuel Neural Checkers</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>Perceptron (1960)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FunSearch</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MegaScale (Production)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Inflection-2.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MM1-30B</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama 3-70B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      System  Frontier system\n",
       "1261                 Theseus            False\n",
       "1255       Perceptron Mark I            False\n",
       "1254     Pandemonium (morse)            False\n",
       "1253  Samuel Neural Checkers            False\n",
       "1251       Perceptron (1960)            False\n",
       "...                      ...              ...\n",
       "56                 FunSearch            False\n",
       "22    MegaScale (Production)             True\n",
       "15            Inflection-2.5             True\n",
       "14                   MM1-30B            False\n",
       "2                Llama 3-70B             True\n",
       "\n",
       "[354 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df['Frontier system'] = (pcd_df['Publication date'] > start_large_scale_era) & (np.log10(pcd_df['Frontier training compute (FLOP)']) - np.log10(pcd_df['Training compute (FLOP)']) <= ooms_from_frontier)\n",
    "pcd_df[['System', 'Frontier system']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yrk0wu7LT6ZK",
    "outputId": "9d95a1fa-1ed8-4c4b-ae94-f9b42a8dddd8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training dataset</th>\n",
       "      <th>Training dataset notes</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>top_13_at_release</th>\n",
       "      <th>top_14_at_release</th>\n",
       "      <th>top_15_at_release</th>\n",
       "      <th>top_16_at_release</th>\n",
       "      <th>top_17_at_release</th>\n",
       "      <th>top_18_at_release</th>\n",
       "      <th>top_19_at_release</th>\n",
       "      <th>top_20_at_release</th>\n",
       "      <th>Frontier training compute (FLOP)</th>\n",
       "      <th>Frontier system</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Baidu Research - Silicon Valley AI Lab</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
       "      <td>https://arxiv.org/abs/1512.02595</td>\n",
       "      <td>3.800000e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We show that an end-to-end deep learning appro...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.800000e+20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>https://arxiv.org/abs/1512.03385</td>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>ILSVRC 2012 subset of ImageNet</td>\n",
       "      <td>They won ILSVRC 2015, but actually the classif...</td>\n",
       "      <td>Deeper neural networks are more difficult to t...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.800000e+20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>https://www.nature.com/articles/nature16961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The game of Go has long been viewed as the mos...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.900000e+21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>Language</td>\n",
       "      <td>Google</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>Google's Neural Machine Translation System: Br...</td>\n",
       "      <td>https://arxiv.org/abs/1609.08144</td>\n",
       "      <td>2.780000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neural Machine Translation (NMT) is an end-to-...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.900000e+21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>Xception</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Google</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>Xception: Deep Learning with Depthwise Separab...</td>\n",
       "      <td>https://arxiv.org/abs/1610.02357</td>\n",
       "      <td>2.285595e+07</td>\n",
       "      <td>JFT</td>\n",
       "      <td>Also ImageNet, but JFT is significantly larger</td>\n",
       "      <td>We present an interpretation of Inception modu...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.900000e+21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Qwen-72B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n",
       "      <td>7.200000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"It is pretrained on over 3 trillion tokens, i...</td>\n",
       "      <td>Qwen-72B is the 72B-parameter version of the l...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.100000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Gemini Ultra</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Gemini models are trained on a dataset that i...</td>\n",
       "      <td>This report introduces a new family of multimo...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MegaScale (Production)</td>\n",
       "      <td>Language</td>\n",
       "      <td>ByteDance,Peking University</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>MegaScale: Scaling Large Language Model Traini...</td>\n",
       "      <td>https://arxiv.org/abs/2402.15627</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We present the design, implementation and engi...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Inflection-2.5</td>\n",
       "      <td>Language</td>\n",
       "      <td>Inflection AI</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>Inflection-2.5: meet the world's best personal AI</td>\n",
       "      <td>https://inflection.ai/inflection-2-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>At Inflection, our mission is to create a pers...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama 3-70B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>Introducing Meta Llama 3: The most capable ope...</td>\n",
       "      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n",
       "      <td>7.000000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System      Domain  \\\n",
       "992   DeepSpeech2 (English)      Speech   \n",
       "990   ResNet-152 (ImageNet)      Vision   \n",
       "986             AlphaGo Lee       Games   \n",
       "953                    GNMT    Language   \n",
       "952                Xception      Vision   \n",
       "..                      ...         ...   \n",
       "71                 Qwen-72B    Language   \n",
       "64             Gemini Ultra  Multimodal   \n",
       "22   MegaScale (Production)    Language   \n",
       "15           Inflection-2.5    Language   \n",
       "2               Llama 3-70B    Language   \n",
       "\n",
       "                               Organization Publication date  \\\n",
       "992  Baidu Research - Silicon Valley AI Lab       2015-12-08   \n",
       "990                               Microsoft       2015-12-10   \n",
       "986                                DeepMind       2016-01-27   \n",
       "953                                  Google       2016-09-26   \n",
       "952                                  Google       2016-10-07   \n",
       "..                                      ...              ...   \n",
       "71                                  Alibaba       2023-11-30   \n",
       "64                          Google DeepMind       2023-12-06   \n",
       "22              ByteDance,Peking University       2024-02-23   \n",
       "15                            Inflection AI       2024-03-07   \n",
       "2                                   Meta AI       2024-04-18   \n",
       "\n",
       "                                             Reference  \\\n",
       "992  Deep Speech 2: End-to-End Speech Recognition i...   \n",
       "990       Deep Residual Learning for Image Recognition   \n",
       "986  Mastering the game of Go with deep neural netw...   \n",
       "953  Google's Neural Machine Translation System: Br...   \n",
       "952  Xception: Deep Learning with Depthwise Separab...   \n",
       "..                                                 ...   \n",
       "71                                                 NaN   \n",
       "64   Gemini: A Family of Highly Capable Multimodal ...   \n",
       "22   MegaScale: Scaling Large Language Model Traini...   \n",
       "15   Inflection-2.5: meet the world's best personal AI   \n",
       "2    Introducing Meta Llama 3: The most capable ope...   \n",
       "\n",
       "                                                  Link    Parameters  \\\n",
       "992                   https://arxiv.org/abs/1512.02595  3.800000e+07   \n",
       "990                   https://arxiv.org/abs/1512.03385  6.000000e+07   \n",
       "986        https://www.nature.com/articles/nature16961           NaN   \n",
       "953                   https://arxiv.org/abs/1609.08144  2.780000e+08   \n",
       "952                   https://arxiv.org/abs/1610.02357  2.285595e+07   \n",
       "..                                                 ...           ...   \n",
       "71                https://huggingface.co/Qwen/Qwen-72B  7.200000e+10   \n",
       "64   https://storage.googleapis.com/deepmind-media/...           NaN   \n",
       "22                    https://arxiv.org/abs/2402.15627  5.300000e+11   \n",
       "15                https://inflection.ai/inflection-2-5           NaN   \n",
       "2    https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n",
       "\n",
       "                   Training dataset  \\\n",
       "992                             NaN   \n",
       "990  ILSVRC 2012 subset of ImageNet   \n",
       "986                             NaN   \n",
       "953                             NaN   \n",
       "952                             JFT   \n",
       "..                              ...   \n",
       "71                              NaN   \n",
       "64                              NaN   \n",
       "22                              NaN   \n",
       "15                              NaN   \n",
       "2                               NaN   \n",
       "\n",
       "                                Training dataset notes  \\\n",
       "992                                                NaN   \n",
       "990  They won ILSVRC 2015, but actually the classif...   \n",
       "986                                                NaN   \n",
       "953                                                NaN   \n",
       "952     Also ImageNet, but JFT is significantly larger   \n",
       "..                                                 ...   \n",
       "71   \"It is pretrained on over 3 trillion tokens, i...   \n",
       "64   \"Gemini models are trained on a dataset that i...   \n",
       "22                                                 NaN   \n",
       "15                                                 NaN   \n",
       "2                                                  NaN   \n",
       "\n",
       "                                              Abstract  ... top_13_at_release  \\\n",
       "992  We show that an end-to-end deep learning appro...  ...              True   \n",
       "990  Deeper neural networks are more difficult to t...  ...              True   \n",
       "986  The game of Go has long been viewed as the mos...  ...              True   \n",
       "953  Neural Machine Translation (NMT) is an end-to-...  ...              True   \n",
       "952  We present an interpretation of Inception modu...  ...              True   \n",
       "..                                                 ...  ...               ...   \n",
       "71   Qwen-72B is the 72B-parameter version of the l...  ...              True   \n",
       "64   This report introduces a new family of multimo...  ...              True   \n",
       "22   We present the design, implementation and engi...  ...              True   \n",
       "15   At Inflection, our mission is to create a pers...  ...              True   \n",
       "2                                                  NaN  ...              True   \n",
       "\n",
       "    top_14_at_release top_15_at_release top_16_at_release top_17_at_release  \\\n",
       "992              True              True              True              True   \n",
       "990              True              True              True              True   \n",
       "986              True              True              True              True   \n",
       "953              True              True              True              True   \n",
       "952              True              True              True              True   \n",
       "..                ...               ...               ...               ...   \n",
       "71               True              True              True              True   \n",
       "64               True              True              True              True   \n",
       "22               True              True              True              True   \n",
       "15               True              True              True              True   \n",
       "2                True              True              True              True   \n",
       "\n",
       "    top_18_at_release top_19_at_release top_20_at_release  \\\n",
       "992              True              True              True   \n",
       "990              True              True              True   \n",
       "986              True              True              True   \n",
       "953              True              True              True   \n",
       "952              True              True              True   \n",
       "..                ...               ...               ...   \n",
       "71               True              True              True   \n",
       "64               True              True              True   \n",
       "22               True              True              True   \n",
       "15               True              True              True   \n",
       "2                True              True              True   \n",
       "\n",
       "     Frontier training compute (FLOP) Frontier system  \n",
       "992                      3.800000e+20            True  \n",
       "990                      3.800000e+20            True  \n",
       "986                      1.900000e+21            True  \n",
       "953                      6.900000e+21            True  \n",
       "952                      6.900000e+21            True  \n",
       "..                                ...             ...  \n",
       "71                       2.100000e+25            True  \n",
       "64                       5.000000e+25            True  \n",
       "22                       5.000000e+25            True  \n",
       "15                       5.000000e+25            True  \n",
       "2                        5.000000e+25            True  \n",
       "\n",
       "[110 rows x 68 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_df = pcd_df[pcd_df['Frontier system']]\n",
    "frontier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjDaQcsVsyYz",
    "outputId": "7aa5fd43-3b36-45f5-997c-d57abd4a94d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3-70B\n",
      "Inflection-2.5\n",
      "MegaScale (Production)\n",
      "Gemini Ultra\n",
      "Qwen-72B\n",
      "Inflection-2\n",
      "Grok-1\n",
      "Yi-34B\n",
      "Skywork-13B\n",
      "ChatGLM3\n",
      "Falcon-180B\n",
      "Llama 2-70B\n",
      "Claude 2\n",
      "xTrimoPGLM -100B\n",
      "PaLM 2\n",
      "BloombergGPT\n",
      "PanGu-Σ\n",
      "GPT-4\n",
      "Falcon-40B\n",
      "LLaMA-7B\n",
      "LLaMA-65B\n",
      "ViT-22B\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Galactica\n",
      "BLOOM-176B\n",
      "Taiyi-Stable Diffusion\n",
      "U-PaLM (540B)\n",
      "Whisper\n",
      "PaLI\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "AlexaTM 20B\n",
      "ESM2-15B\n",
      "Minerva (540B)\n",
      "Parti\n",
      "CoCa\n",
      "UL2\n",
      "OPT-175B\n",
      "Flamingo\n",
      "Stable Diffusion (LDM-KL-8-G)\n",
      "PaLM (540B)\n",
      "Chinchilla\n",
      "ST-MoE\n",
      "LaMDA\n",
      "GPT-NeoX-20B\n",
      "RETRO-7B\n",
      "AlphaCode\n",
      "ERNIE 3.0 Titan\n",
      "XGLM-7.5B\n",
      "XGLM\n",
      "GLaM\n",
      "Gopher (280B)\n",
      "Student of Games\n",
      "Florence\n",
      "BASIC-L\n",
      "T0-XXL\n",
      "Yuan 1.0\n",
      "Megatron-Turing NLG 530B\n",
      "AlphaFold-Multimer\n",
      "HyperCLOVA\n",
      "FLAN 137B\n",
      "SEER\n",
      "GOAT\n",
      "HuBERT\n",
      "ERNIE 3.0\n",
      "ALIGN\n",
      "DeBERTa\n",
      "CoAtNet\n",
      "ByT5-XXL\n",
      "CogView\n",
      "ProtBERT-BFD\n",
      "ProtT5-XXL\n",
      "ProtT5-XXL-BFD\n",
      "PLUG\n",
      "M6-T\n",
      "Meta Pseudo Labels\n",
      "MSA Transformer\n",
      "Switch\n",
      "DALL-E\n",
      "CLIP (ViT L/14@336px)\n",
      "ViT-Huge/14\n",
      "mT5-XXL\n",
      "Conformer + Wav2vec 2.0 + Noisy Student\n",
      "GShard (dense)\n",
      "iGPT-L\n",
      "iGPT-XL\n",
      "GPT-3 175B (davinci)\n",
      "Turing-NLG\n",
      "Meena\n",
      "ContextNet + Noisy Student\n",
      "OpenAI Five\n",
      "OpenAI Five Rerun\n",
      "AlphaStar\n",
      "T5-11B\n",
      "Megatron-LM (8.3B)\n",
      "Megatron-BERT\n",
      "RoBERTa Large\n",
      "XLNet\n",
      "GPT-2 (1.5B)\n",
      "FTW\n",
      "ResNeXt-101 32x48d\n",
      "AlphaZero\n",
      "AlphaGo Zero\n",
      "AlphaGo Master\n",
      "NASv3 (CIFAR-10)\n",
      "Xception\n",
      "GNMT\n",
      "AlphaGo Lee\n",
      "ResNet-152 (ImageNet)\n",
      "DeepSpeech2 (English)\n"
     ]
    }
   ],
   "source": [
    "for system in frontier_df['System'][::-1]:\n",
    "  print(system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ4rEiW4hW6_"
   },
   "source": [
    "# Constant threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "L8IgNL9shAZb"
   },
   "outputs": [],
   "source": [
    "compute_threshold = 1e23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tGPWWQJ6hZCU"
   },
   "outputs": [],
   "source": [
    "above_threshold = pcd_df[pcd_df['Training compute (FLOP)'] > compute_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wB6Qu1pBhd41",
    "outputId": "456309a2-7c4a-4f19-8e18-9922508807b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 systems\n",
      "Llama 3-70B\n",
      "MM1-30B\n",
      "Inflection-2.5\n",
      "MegaScale (Production)\n",
      "FunSearch\n",
      "Gemini Ultra\n",
      "Qwen-72B\n",
      "Inflection-2\n",
      "Nemotron-3-8B\n",
      "Grok-1\n",
      "Yi-34B\n",
      "Skywork-13B\n",
      "ChatGLM3\n",
      "Falcon-180B\n",
      "Llama 2-70B\n",
      "Claude 2\n",
      "xTrimoPGLM -100B\n",
      "PaLM 2\n",
      "BloombergGPT\n",
      "PanGu-Σ\n",
      "GPT-4\n",
      "Falcon-40B\n",
      "LLaMA-65B\n",
      "ViT-22B\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Galactica\n",
      "BLOOM-176B\n",
      "U-PaLM (540B)\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "AlexaTM 20B\n",
      "Minerva (540B)\n",
      "Parti\n",
      "UL2\n",
      "OPT-175B\n",
      "Flamingo\n",
      "PaLM (540B)\n",
      "Chinchilla\n",
      "ST-MoE\n",
      "LaMDA\n",
      "AlphaCode\n",
      "ERNIE 3.0 Titan\n",
      "GLaM\n",
      "Gopher (280B)\n",
      "Yuan 1.0\n",
      "Megatron-Turing NLG 530B\n",
      "HyperCLOVA\n",
      "GPT-3 175B (davinci)\n",
      "Meena\n",
      "AlphaGo Zero\n",
      "AlphaGo Master\n"
     ]
    }
   ],
   "source": [
    "print(len(above_threshold), 'systems')\n",
    "for system in above_threshold['System'][::-1]:\n",
    "  print(system)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
