{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPSm37gghSrl"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8Edmo7vA2Eg1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fXBbtVKi2LmG"
      },
      "outputs": [],
      "source": [
        "data_url = 'https://epochai.org/data/epochdb/all_systems.csv'\n",
        "dtypes = {\n",
        "    'Training compute (FLOP)': np.float64,\n",
        "}\n",
        "pcd_df = pd.read_csv(data_url, dtype=dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yyQJeGOA2m7e",
        "outputId": "0fe58fa3-79c0-46d1-f5ff-00802616c0b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Domain</th>\n",
              "      <th>Organization</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Publication date</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Link</th>\n",
              "      <th>Citations</th>\n",
              "      <th>Notability criteria</th>\n",
              "      <th>Notability criteria notes</th>\n",
              "      <th>...</th>\n",
              "      <th>Training time notes</th>\n",
              "      <th>Hardware quantity</th>\n",
              "      <th>Hardware utilization</th>\n",
              "      <th>Finetune compute (FLOP)</th>\n",
              "      <th>Finetune compute notes</th>\n",
              "      <th>Batch size</th>\n",
              "      <th>Compute cost notes</th>\n",
              "      <th>Training cloud compute vendor</th>\n",
              "      <th>Batch size notes</th>\n",
              "      <th>Training data center</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sparse digit recognition SVM</td>\n",
              "      <td>Vision</td>\n",
              "      <td>University of Lubeck</td>\n",
              "      <td>Kai Labusch, Erhadt Barth, Thomas Martinetz</td>\n",
              "      <td>2008-11-19</td>\n",
              "      <td>Simple method for high-performance digit recog...</td>\n",
              "      <td>https://pubmed.ncbi.nlm.nih.gov/19000969/</td>\n",
              "      <td>124.0</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>\"Finally, we train a support vector machine (S...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Karakuri LM</td>\n",
              "      <td>Language</td>\n",
              "      <td>KARAKURI Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2024-01-26</td>\n",
              "      <td>KARAKURI LM</td>\n",
              "      <td>https://huggingface.co/karakuri-ai/karakuri-lm...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DOT(S)-RNN</td>\n",
              "      <td>Language</td>\n",
              "      <td>Aalto University,Université de Montréal</td>\n",
              "      <td>Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho...</td>\n",
              "      <td>2013-12-20</td>\n",
              "      <td>How to Construct Deep Recurrent Neural Networks</td>\n",
              "      <td>https://arxiv.org/abs/1312.6026</td>\n",
              "      <td>1255.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KEPLER</td>\n",
              "      <td>Language</td>\n",
              "      <td>Tsinghua University,Mila- Quebec AI,University...</td>\n",
              "      <td>Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyu...</td>\n",
              "      <td>2020-11-23</td>\n",
              "      <td>KEPLER: A Unified Model for Knowledge Embeddin...</td>\n",
              "      <td>https://arxiv.org/abs/1911.06136</td>\n",
              "      <td>445.0</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>\"Experimental results show that KEPLER achieve...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DOC + Finetune∗ + Partial Shuffle (PTB)</td>\n",
              "      <td>Language</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-03-11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>ELMo</td>\n",
              "      <td>Language</td>\n",
              "      <td>University of Washington,Allen Institute for AI</td>\n",
              "      <td>ME Peters, M Neumann, M Iyyer, M Gardner</td>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>Deep contextualized word representations</td>\n",
              "      <td>https://arxiv.org/abs/1802.05365</td>\n",
              "      <td>10486.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1408</th>\n",
              "      <td>tsuzumi 7B</td>\n",
              "      <td>Language</td>\n",
              "      <td>NTT Communication Science Laboratories</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-12-01</td>\n",
              "      <td>NTT's Large Language Model \"tsuzumi\" is Here!</td>\n",
              "      <td>https://group.ntt/en/magazine/blog/tsuzumi/</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1409</th>\n",
              "      <td>VD-LSTM+REAL Small</td>\n",
              "      <td>Language</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-11-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1410</th>\n",
              "      <td>DLRM-12T</td>\n",
              "      <td>Recommendation</td>\n",
              "      <td>Meta AI,Carnegie Mellon University (CMU)</td>\n",
              "      <td>Dheevatsa Mudigere, Yuchen Hao, Jianyu Huang, ...</td>\n",
              "      <td>2021-04-12</td>\n",
              "      <td>Software-Hardware Co-design for Fast and Scala...</td>\n",
              "      <td>https://arxiv.org/abs/2104.05158</td>\n",
              "      <td>86.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>No training details provided.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No training details provided.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1411</th>\n",
              "      <td>FLAN 137B</td>\n",
              "      <td>Language</td>\n",
              "      <td>Google Research</td>\n",
              "      <td>Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kel...</td>\n",
              "      <td>2021-09-03</td>\n",
              "      <td>Finetuned Language Models Are Zero-Shot Learners</td>\n",
              "      <td>https://arxiv.org/abs/2109.01652</td>\n",
              "      <td>1802.0</td>\n",
              "      <td>Highly cited,SOTA improvement</td>\n",
              "      <td>Abstract: \\n\"FLAN substantially improves the p...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1412 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       System          Domain  \\\n",
              "0                Sparse digit recognition SVM          Vision   \n",
              "1                                 Karakuri LM        Language   \n",
              "2                                  DOT(S)-RNN        Language   \n",
              "3                                      KEPLER        Language   \n",
              "4     DOC + Finetune∗ + Partial Shuffle (PTB)        Language   \n",
              "...                                       ...             ...   \n",
              "1407                                     ELMo        Language   \n",
              "1408                               tsuzumi 7B        Language   \n",
              "1409                       VD-LSTM+REAL Small        Language   \n",
              "1410                                 DLRM-12T  Recommendation   \n",
              "1411                                FLAN 137B        Language   \n",
              "\n",
              "                                           Organization  \\\n",
              "0                                  University of Lubeck   \n",
              "1                                         KARAKURI Inc.   \n",
              "2               Aalto University,Université de Montréal   \n",
              "3     Tsinghua University,Mila- Quebec AI,University...   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "1407    University of Washington,Allen Institute for AI   \n",
              "1408             NTT Communication Science Laboratories   \n",
              "1409                                                NaN   \n",
              "1410           Meta AI,Carnegie Mellon University (CMU)   \n",
              "1411                                    Google Research   \n",
              "\n",
              "                                                Authors Publication date  \\\n",
              "0           Kai Labusch, Erhadt Barth, Thomas Martinetz       2008-11-19   \n",
              "1                                                   NaN       2024-01-26   \n",
              "2     Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho...       2013-12-20   \n",
              "3     Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyu...       2020-11-23   \n",
              "4                                                   NaN       2019-03-11   \n",
              "...                                                 ...              ...   \n",
              "1407           ME Peters, M Neumann, M Iyyer, M Gardner       2018-02-01   \n",
              "1408                                                NaN       2023-12-01   \n",
              "1409                                                NaN       2016-11-04   \n",
              "1410  Dheevatsa Mudigere, Yuchen Hao, Jianyu Huang, ...       2021-04-12   \n",
              "1411  Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kel...       2021-09-03   \n",
              "\n",
              "                                              Reference  \\\n",
              "0     Simple method for high-performance digit recog...   \n",
              "1                                           KARAKURI LM   \n",
              "2       How to Construct Deep Recurrent Neural Networks   \n",
              "3     KEPLER: A Unified Model for Knowledge Embeddin...   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "1407           Deep contextualized word representations   \n",
              "1408      NTT's Large Language Model \"tsuzumi\" is Here!   \n",
              "1409                                                NaN   \n",
              "1410  Software-Hardware Co-design for Fast and Scala...   \n",
              "1411   Finetuned Language Models Are Zero-Shot Learners   \n",
              "\n",
              "                                                   Link  Citations  \\\n",
              "0             https://pubmed.ncbi.nlm.nih.gov/19000969/      124.0   \n",
              "1     https://huggingface.co/karakuri-ai/karakuri-lm...        NaN   \n",
              "2                       https://arxiv.org/abs/1312.6026     1255.0   \n",
              "3                      https://arxiv.org/abs/1911.06136      445.0   \n",
              "4                                                   NaN        NaN   \n",
              "...                                                 ...        ...   \n",
              "1407                   https://arxiv.org/abs/1802.05365    10486.0   \n",
              "1408        https://group.ntt/en/magazine/blog/tsuzumi/        NaN   \n",
              "1409                                                NaN        NaN   \n",
              "1410                   https://arxiv.org/abs/2104.05158       86.0   \n",
              "1411                   https://arxiv.org/abs/2109.01652     1802.0   \n",
              "\n",
              "                Notability criteria  \\\n",
              "0                  SOTA improvement   \n",
              "1                               NaN   \n",
              "2                      Highly cited   \n",
              "3                  SOTA improvement   \n",
              "4                               NaN   \n",
              "...                             ...   \n",
              "1407                   Highly cited   \n",
              "1408                            NaN   \n",
              "1409                            NaN   \n",
              "1410                            NaN   \n",
              "1411  Highly cited,SOTA improvement   \n",
              "\n",
              "                              Notability criteria notes  ...  \\\n",
              "0     \"Finally, we train a support vector machine (S...  ...   \n",
              "1                                                   NaN  ...   \n",
              "2                                                   NaN  ...   \n",
              "3     \"Experimental results show that KEPLER achieve...  ...   \n",
              "4                                                   NaN  ...   \n",
              "...                                                 ...  ...   \n",
              "1407                                                NaN  ...   \n",
              "1408                                                NaN  ...   \n",
              "1409                                                NaN  ...   \n",
              "1410                                                NaN  ...   \n",
              "1411  Abstract: \\n\"FLAN substantially improves the p...  ...   \n",
              "\n",
              "                Training time notes Hardware quantity Hardware utilization  \\\n",
              "0                               NaN               NaN                  NaN   \n",
              "1                               NaN               NaN                  NaN   \n",
              "2                               NaN               NaN                  NaN   \n",
              "3                               NaN               NaN                  NaN   \n",
              "4                               NaN               NaN                  NaN   \n",
              "...                             ...               ...                  ...   \n",
              "1407                            NaN               NaN                  NaN   \n",
              "1408                            NaN               NaN                  NaN   \n",
              "1409                            NaN               NaN                  NaN   \n",
              "1410  No training details provided.               NaN                  NaN   \n",
              "1411                            NaN              64.0                  NaN   \n",
              "\n",
              "     Finetune compute (FLOP) Finetune compute notes Batch size  \\\n",
              "0                        NaN                    NaN        NaN   \n",
              "1                        NaN                    NaN        NaN   \n",
              "2                        NaN                    NaN        NaN   \n",
              "3                        NaN                    NaN        NaN   \n",
              "4                        NaN                    NaN        NaN   \n",
              "...                      ...                    ...        ...   \n",
              "1407                     NaN                    NaN        NaN   \n",
              "1408                     NaN                    NaN        NaN   \n",
              "1409                     NaN                    NaN        NaN   \n",
              "1410                     NaN                    NaN        NaN   \n",
              "1411                     NaN                    NaN        NaN   \n",
              "\n",
              "                 Compute cost notes Training cloud compute vendor  \\\n",
              "0                               NaN                           NaN   \n",
              "1                               NaN                           NaN   \n",
              "2                               NaN                           NaN   \n",
              "3                               NaN                           NaN   \n",
              "4                               NaN                           NaN   \n",
              "...                             ...                           ...   \n",
              "1407                            NaN                           NaN   \n",
              "1408                            NaN                           NaN   \n",
              "1409                            NaN                           NaN   \n",
              "1410  No training details provided.                           NaN   \n",
              "1411                            NaN                           NaN   \n",
              "\n",
              "     Batch size notes Training data center  \n",
              "0                 NaN                  NaN  \n",
              "1                 NaN                  NaN  \n",
              "2                 NaN                  NaN  \n",
              "3                 NaN                  NaN  \n",
              "4                 NaN                  NaN  \n",
              "...               ...                  ...  \n",
              "1407              NaN                  NaN  \n",
              "1408              NaN                  NaN  \n",
              "1409              NaN                  NaN  \n",
              "1410              NaN                  NaN  \n",
              "1411              NaN                  NaN  \n",
              "\n",
              "[1412 rows x 51 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcd_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XZ0FKyaZ3h_W"
      },
      "outputs": [],
      "source": [
        "pcd_df['Publication date'] = pd.to_datetime(pcd_df['Publication date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rcOYiwwg3oVY"
      },
      "outputs": [],
      "source": [
        "pcd_df.sort_values('Publication date', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QLUi4aysAXWr"
      },
      "outputs": [],
      "source": [
        "pcd_df.dropna(subset=['Publication date', 'Notability criteria', 'Training compute (FLOP)'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wGGuurmk4uZd",
        "outputId": "5d822c9c-67e5-4f2c-ff8b-9418f82d05e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Domain</th>\n",
              "      <th>Organization</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Publication date</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Link</th>\n",
              "      <th>Citations</th>\n",
              "      <th>Notability criteria</th>\n",
              "      <th>Notability criteria notes</th>\n",
              "      <th>...</th>\n",
              "      <th>Training time notes</th>\n",
              "      <th>Hardware quantity</th>\n",
              "      <th>Hardware utilization</th>\n",
              "      <th>Finetune compute (FLOP)</th>\n",
              "      <th>Finetune compute notes</th>\n",
              "      <th>Batch size</th>\n",
              "      <th>Compute cost notes</th>\n",
              "      <th>Training cloud compute vendor</th>\n",
              "      <th>Batch size notes</th>\n",
              "      <th>Training data center</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>Theseus</td>\n",
              "      <td>Robotics</td>\n",
              "      <td>Bell Laboratories</td>\n",
              "      <td>Claude Shannon</td>\n",
              "      <td>1950-07-02</td>\n",
              "      <td>Mighty Mouse</td>\n",
              "      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Historical significance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>Perceptron Mark I</td>\n",
              "      <td>Other</td>\n",
              "      <td>Cornell Aeronautical Laboratory,Cornell Univer...</td>\n",
              "      <td>F Rosenblatt</td>\n",
              "      <td>1957-01-01</td>\n",
              "      <td>The Perceptron—a perceiving and recognizing au...</td>\n",
              "      <td>https://blogs.umass.edu/brain-wars/files/2016/...</td>\n",
              "      <td>1610.0</td>\n",
              "      <td>Historical significance,Highly cited</td>\n",
              "      <td>First modern neural network</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>Pandemonium (morse)</td>\n",
              "      <td>Language</td>\n",
              "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
              "      <td>OG Selfridge</td>\n",
              "      <td>1959-02-01</td>\n",
              "      <td>Pandemonium: A Paradigm for Learning</td>\n",
              "      <td>https://aitopics.org/doc/classics:504E1BAC/</td>\n",
              "      <td>1453.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194</th>\n",
              "      <td>Samuel Neural Checkers</td>\n",
              "      <td>Games</td>\n",
              "      <td>IBM</td>\n",
              "      <td>Arthur L. Samuel</td>\n",
              "      <td>1959-07-01</td>\n",
              "      <td>Some studies in machine learning using the gam...</td>\n",
              "      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n",
              "      <td>4466.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>Perceptron (1960)</td>\n",
              "      <td>Vision</td>\n",
              "      <td>Cornell Aeronautical Laboratory</td>\n",
              "      <td>Frank Rosenblatt</td>\n",
              "      <td>1960-03-30</td>\n",
              "      <td>Perceptron Simulation Experiments</td>\n",
              "      <td>https://www.semanticscholar.org/paper/Perceptr...</td>\n",
              "      <td>394.0</td>\n",
              "      <td>Historical significance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1319</th>\n",
              "      <td>MultiBand Diffusion</td>\n",
              "      <td>Audio</td>\n",
              "      <td>Meta AI,Hebrew University of Jerusalem,LORIA</td>\n",
              "      <td>Robin San Roman, Yossi Adi, Antoine Deleforge,...</td>\n",
              "      <td>2023-11-08</td>\n",
              "      <td>From Discrete Tokens to High-Fidelity Audio Us...</td>\n",
              "      <td>https://arxiv.org/abs/2308.02560</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>\"At equal bit rate, the proposed approach outp...</td>\n",
              "      <td>...</td>\n",
              "      <td>around 2 days</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1129</th>\n",
              "      <td>Nemotron-3-8B</td>\n",
              "      <td>Language</td>\n",
              "      <td>NVIDIA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-11-15</td>\n",
              "      <td>NVIDIA AI Foundation Models: Build Custom Ente...</td>\n",
              "      <td>https://developer.nvidia.com/blog/nvidia-ai-fo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>\"The Nemotron-3-8B-QA model offers state-of-th...</td>\n",
              "      <td>...</td>\n",
              "      <td>19 days</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>0.34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>Inflection-2</td>\n",
              "      <td>Language</td>\n",
              "      <td>Inflection AI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-11-22</td>\n",
              "      <td>Inflection-2: The Next Step Up</td>\n",
              "      <td>https://inflection.ai/inflection-2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Significant use</td>\n",
              "      <td>Inflection-2 either already powers Pi or soon ...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Qwen-72B</td>\n",
              "      <td>Language</td>\n",
              "      <td>Alibaba</td>\n",
              "      <td>Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Ka...</td>\n",
              "      <td>2023-11-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>SOTA on several Chinese benchmarks, with highe...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4000000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Table 1 https://arxiv.org/abs/2309.16609\\n(thi...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>Gemini Ultra</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>Google DeepMind</td>\n",
              "      <td>Gemini Team</td>\n",
              "      <td>2023-12-06</td>\n",
              "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
              "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
              "      <td>252.0</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>\" Evaluation on a broad range of benchmarks sh...</td>\n",
              "      <td>...</td>\n",
              "      <td>Dylan Patel, author of SemiAnalysis, speculate...</td>\n",
              "      <td>55000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>349 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      System      Domain  \\\n",
              "1127                 Theseus    Robotics   \n",
              "626        Perceptron Mark I       Other   \n",
              "374      Pandemonium (morse)    Language   \n",
              "1194  Samuel Neural Checkers       Games   \n",
              "415        Perceptron (1960)      Vision   \n",
              "...                      ...         ...   \n",
              "1319     MultiBand Diffusion       Audio   \n",
              "1129           Nemotron-3-8B    Language   \n",
              "833             Inflection-2    Language   \n",
              "306                 Qwen-72B    Language   \n",
              "221             Gemini Ultra  Multimodal   \n",
              "\n",
              "                                           Organization  \\\n",
              "1127                                  Bell Laboratories   \n",
              "626   Cornell Aeronautical Laboratory,Cornell Univer...   \n",
              "374         Massachusetts Institute of Technology (MIT)   \n",
              "1194                                                IBM   \n",
              "415                     Cornell Aeronautical Laboratory   \n",
              "...                                                 ...   \n",
              "1319       Meta AI,Hebrew University of Jerusalem,LORIA   \n",
              "1129                                             NVIDIA   \n",
              "833                                       Inflection AI   \n",
              "306                                             Alibaba   \n",
              "221                                     Google DeepMind   \n",
              "\n",
              "                                                Authors Publication date  \\\n",
              "1127                                     Claude Shannon       1950-07-02   \n",
              "626                                        F Rosenblatt       1957-01-01   \n",
              "374                                        OG Selfridge       1959-02-01   \n",
              "1194                                   Arthur L. Samuel       1959-07-01   \n",
              "415                                    Frank Rosenblatt       1960-03-30   \n",
              "...                                                 ...              ...   \n",
              "1319  Robin San Roman, Yossi Adi, Antoine Deleforge,...       2023-11-08   \n",
              "1129                                                NaN       2023-11-15   \n",
              "833                                                 NaN       2023-11-22   \n",
              "306   Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Ka...       2023-11-30   \n",
              "221                                         Gemini Team       2023-12-06   \n",
              "\n",
              "                                              Reference  \\\n",
              "1127                                       Mighty Mouse   \n",
              "626   The Perceptron—a perceiving and recognizing au...   \n",
              "374                Pandemonium: A Paradigm for Learning   \n",
              "1194  Some studies in machine learning using the gam...   \n",
              "415                   Perceptron Simulation Experiments   \n",
              "...                                                 ...   \n",
              "1319  From Discrete Tokens to High-Fidelity Audio Us...   \n",
              "1129  NVIDIA AI Foundation Models: Build Custom Ente...   \n",
              "833                      Inflection-2: The Next Step Up   \n",
              "306                                                 NaN   \n",
              "221   Gemini: A Family of Highly Capable Multimodal ...   \n",
              "\n",
              "                                                   Link  Citations  \\\n",
              "1127  https://www.technologyreview.com/2018/12/19/13...        0.0   \n",
              "626   https://blogs.umass.edu/brain-wars/files/2016/...     1610.0   \n",
              "374         https://aitopics.org/doc/classics:504E1BAC/     1453.0   \n",
              "1194  https://ieeexplore.ieee.org/abstract/document/...     4466.0   \n",
              "415   https://www.semanticscholar.org/paper/Perceptr...      394.0   \n",
              "...                                                 ...        ...   \n",
              "1319                   https://arxiv.org/abs/2308.02560        1.0   \n",
              "1129  https://developer.nvidia.com/blog/nvidia-ai-fo...        NaN   \n",
              "833                  https://inflection.ai/inflection-2        NaN   \n",
              "306                https://huggingface.co/Qwen/Qwen-72B        NaN   \n",
              "221   https://storage.googleapis.com/deepmind-media/...      252.0   \n",
              "\n",
              "                       Notability criteria  \\\n",
              "1127               Historical significance   \n",
              "626   Historical significance,Highly cited   \n",
              "374                           Highly cited   \n",
              "1194                          Highly cited   \n",
              "415                Historical significance   \n",
              "...                                    ...   \n",
              "1319                      SOTA improvement   \n",
              "1129                      SOTA improvement   \n",
              "833                        Significant use   \n",
              "306                       SOTA improvement   \n",
              "221                       SOTA improvement   \n",
              "\n",
              "                              Notability criteria notes  ...  \\\n",
              "1127                                                NaN  ...   \n",
              "626                        First modern neural network   ...   \n",
              "374                                                 NaN  ...   \n",
              "1194                                                NaN  ...   \n",
              "415                                                 NaN  ...   \n",
              "...                                                 ...  ...   \n",
              "1319  \"At equal bit rate, the proposed approach outp...  ...   \n",
              "1129  \"The Nemotron-3-8B-QA model offers state-of-th...  ...   \n",
              "833   Inflection-2 either already powers Pi or soon ...  ...   \n",
              "306   SOTA on several Chinese benchmarks, with highe...  ...   \n",
              "221   \" Evaluation on a broad range of benchmarks sh...  ...   \n",
              "\n",
              "                                    Training time notes Hardware quantity  \\\n",
              "1127                                                NaN               NaN   \n",
              "626                                                 NaN               NaN   \n",
              "374                                                 NaN               NaN   \n",
              "1194                                                NaN               NaN   \n",
              "415                                                 NaN               NaN   \n",
              "...                                                 ...               ...   \n",
              "1319                                      around 2 days               NaN   \n",
              "1129                                            19 days            1024.0   \n",
              "833                                                 NaN            5000.0   \n",
              "306                                                 NaN               NaN   \n",
              "221   Dylan Patel, author of SemiAnalysis, speculate...           55000.0   \n",
              "\n",
              "     Hardware utilization Finetune compute (FLOP) Finetune compute notes  \\\n",
              "1127                  NaN                     NaN                    NaN   \n",
              "626                   NaN                     NaN                    NaN   \n",
              "374                   NaN                     NaN                    NaN   \n",
              "1194                  NaN                     NaN                    NaN   \n",
              "415                   NaN                     NaN                    NaN   \n",
              "...                   ...                     ...                    ...   \n",
              "1319                  NaN                     NaN                    NaN   \n",
              "1129                 0.34                     NaN                    NaN   \n",
              "833                   NaN                     NaN                    NaN   \n",
              "306                   NaN                     NaN                    NaN   \n",
              "221                   NaN                     NaN                    NaN   \n",
              "\n",
              "     Batch size  Compute cost notes Training cloud compute vendor  \\\n",
              "1127        NaN                 NaN                           NaN   \n",
              "626         NaN                 NaN                           NaN   \n",
              "374         NaN                 NaN                           NaN   \n",
              "1194        NaN                 NaN                           NaN   \n",
              "415         NaN                 NaN                           NaN   \n",
              "...         ...                 ...                           ...   \n",
              "1319        NaN                 NaN                           NaN   \n",
              "1129        NaN                 NaN                           NaN   \n",
              "833         NaN                 NaN                           NaN   \n",
              "306   4000000.0                 NaN                           NaN   \n",
              "221         NaN                 NaN                           NaN   \n",
              "\n",
              "                                       Batch size notes Training data center  \n",
              "1127                                                NaN                  NaN  \n",
              "626                                                 NaN                  NaN  \n",
              "374                                                 NaN                  NaN  \n",
              "1194                                                NaN                  NaN  \n",
              "415                                                 NaN                  NaN  \n",
              "...                                                 ...                  ...  \n",
              "1319                                                NaN                  NaN  \n",
              "1129                                                NaN                  NaN  \n",
              "833                                                 NaN                  NaN  \n",
              "306   Table 1 https://arxiv.org/abs/2309.16609\\n(thi...                  NaN  \n",
              "221                                                 NaN                  NaN  \n",
              "\n",
              "[349 rows x 51 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcd_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zFUQoG_01L8m"
      },
      "outputs": [],
      "source": [
        "outlier_window_size = 2  # years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_large_scale_era = '2015-09-01'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrayDGa4hK6X"
      },
      "source": [
        "# Default large scale systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ort2OjXauNI-"
      },
      "source": [
        "https://colab.research.google.com/drive/1PLGY5ErysqQMfy7Z08uIR2cTnnDgSaVR?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xo0BSLmQ4RpG"
      },
      "outputs": [],
      "source": [
        "high_outliers_z_value_threshold = 0.76"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sTTmucLNtU8l"
      },
      "outputs": [],
      "source": [
        "large_scale_idx = set()\n",
        "\n",
        "for index, row in pcd_df.iterrows():\n",
        "  # Filter entries in a 2-year window around the paper\n",
        "  window_size = pd.Timedelta(f'{outlier_window_size*52*7} days')\n",
        "  half_window_size = window_size / 2\n",
        "  mask = ( row['Publication date'] - half_window_size <= pcd_df['Publication date'] ) &\\\n",
        "        ( pcd_df['Publication date'] <= row['Publication date'] + half_window_size )\n",
        "  window_df = pcd_df[mask].copy()\n",
        "\n",
        "  if len(window_df) < 2: continue\n",
        "\n",
        "  window_df['Training compute (FLOP) z scores'] = stats.zscore(np.log10(window_df['Training compute (FLOP)'].values))\n",
        "  if window_df.loc[index, 'Training compute (FLOP) z scores'] > high_outliers_z_value_threshold:\n",
        "    large_scale_idx.add(index)\n",
        "\n",
        "large_scale_mask = pcd_df.index.isin(large_scale_idx) & (pcd_df['Publication date'] > start_large_scale_era)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w2HakL5g4iUq"
      },
      "outputs": [],
      "source": [
        "large_scale_df = pcd_df[large_scale_mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y4-TmYMQ7Iex",
        "outputId": "485901a3-4ccd-4956-bba8-e81f64bf5c0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Domain</th>\n",
              "      <th>Organization</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Publication date</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Link</th>\n",
              "      <th>Citations</th>\n",
              "      <th>Notability criteria</th>\n",
              "      <th>Notability criteria notes</th>\n",
              "      <th>...</th>\n",
              "      <th>Training time notes</th>\n",
              "      <th>Hardware quantity</th>\n",
              "      <th>Hardware utilization</th>\n",
              "      <th>Finetune compute (FLOP)</th>\n",
              "      <th>Finetune compute notes</th>\n",
              "      <th>Batch size</th>\n",
              "      <th>Compute cost notes</th>\n",
              "      <th>Training cloud compute vendor</th>\n",
              "      <th>Batch size notes</th>\n",
              "      <th>Training data center</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>AlphaGo Fan</td>\n",
              "      <td>Games</td>\n",
              "      <td>Google DeepMind</td>\n",
              "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
              "      <td>2015-10-01</td>\n",
              "      <td>Mastering the game of Go with deep neural netw...</td>\n",
              "      <td>https://www.nature.com/articles/nature24270.ep...</td>\n",
              "      <td>14733.0</td>\n",
              "      <td>Highly cited,SOTA improvement</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>AlphaGo Lee</td>\n",
              "      <td>Games</td>\n",
              "      <td>DeepMind</td>\n",
              "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
              "      <td>2016-01-27</td>\n",
              "      <td>Mastering the game of Go with deep neural netw...</td>\n",
              "      <td>https://www.nature.com/articles/nature16961</td>\n",
              "      <td>14733.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>GNMT</td>\n",
              "      <td>Language</td>\n",
              "      <td>Google</td>\n",
              "      <td>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...</td>\n",
              "      <td>2016-09-26</td>\n",
              "      <td>Google's Neural Machine Translation System: Br...</td>\n",
              "      <td>https://arxiv.org/abs/1609.08144</td>\n",
              "      <td>6105.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>96.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1217</th>\n",
              "      <td>Xception</td>\n",
              "      <td>Vision</td>\n",
              "      <td>Google</td>\n",
              "      <td>François Chollet</td>\n",
              "      <td>2016-10-07</td>\n",
              "      <td>Xception: Deep Learning with Depthwise Separab...</td>\n",
              "      <td>https://arxiv.org/abs/1610.02357</td>\n",
              "      <td>11338.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>\"while the JFT experiments took over one month...</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1291</th>\n",
              "      <td>NASv3 (CIFAR-10)</td>\n",
              "      <td>Vision</td>\n",
              "      <td>Google Brain</td>\n",
              "      <td>Barret Zoph, Quoc V. Le</td>\n",
              "      <td>2016-11-05</td>\n",
              "      <td>Neural Architecture Search with Reinforcement ...</td>\n",
              "      <td>https://arxiv.org/abs/1611.01578</td>\n",
              "      <td>4700.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>800.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>ChatGLM3</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>Zhipu AI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-10-27</td>\n",
              "      <td>Zhipu AI launches third-generation base model</td>\n",
              "      <td>https://www.zhipuai.cn/en/news/76</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>Aiming at GPT-4V, ChatGLM3 has implemented ite...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>Yi-34B</td>\n",
              "      <td>Language</td>\n",
              "      <td>01.AI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-11-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://github.com/01-ai/Yi</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Significant use</td>\n",
              "      <td>2nd most popular model on HuggingFace: https:/...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>Inflection-2</td>\n",
              "      <td>Language</td>\n",
              "      <td>Inflection AI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-11-22</td>\n",
              "      <td>Inflection-2: The Next Step Up</td>\n",
              "      <td>https://inflection.ai/inflection-2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Significant use</td>\n",
              "      <td>Inflection-2 either already powers Pi or soon ...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Qwen-72B</td>\n",
              "      <td>Language</td>\n",
              "      <td>Alibaba</td>\n",
              "      <td>Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Ka...</td>\n",
              "      <td>2023-11-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>SOTA on several Chinese benchmarks, with highe...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4000000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Table 1 https://arxiv.org/abs/2309.16609\\n(thi...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>Gemini Ultra</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>Google DeepMind</td>\n",
              "      <td>Gemini Team</td>\n",
              "      <td>2023-12-06</td>\n",
              "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
              "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
              "      <td>252.0</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>\" Evaluation on a broad range of benchmarks sh...</td>\n",
              "      <td>...</td>\n",
              "      <td>Dylan Patel, author of SemiAnalysis, speculate...</td>\n",
              "      <td>55000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                System      Domain     Organization  \\\n",
              "658        AlphaGo Fan       Games  Google DeepMind   \n",
              "1334       AlphaGo Lee       Games         DeepMind   \n",
              "479               GNMT    Language           Google   \n",
              "1217          Xception      Vision           Google   \n",
              "1291  NASv3 (CIFAR-10)      Vision     Google Brain   \n",
              "...                ...         ...              ...   \n",
              "1370          ChatGLM3  Multimodal         Zhipu AI   \n",
              "537             Yi-34B    Language            01.AI   \n",
              "833       Inflection-2    Language    Inflection AI   \n",
              "306           Qwen-72B    Language          Alibaba   \n",
              "221       Gemini Ultra  Multimodal  Google DeepMind   \n",
              "\n",
              "                                                Authors Publication date  \\\n",
              "658   David Silver, Aja Huang, Chris J. Maddison, Ar...       2015-10-01   \n",
              "1334  David Silver, Aja Huang, Chris J. Maddison, Ar...       2016-01-27   \n",
              "479   Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...       2016-09-26   \n",
              "1217                                   François Chollet       2016-10-07   \n",
              "1291                            Barret Zoph, Quoc V. Le       2016-11-05   \n",
              "...                                                 ...              ...   \n",
              "1370                                                NaN       2023-10-27   \n",
              "537                                                 NaN       2023-11-02   \n",
              "833                                                 NaN       2023-11-22   \n",
              "306   Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Ka...       2023-11-30   \n",
              "221                                         Gemini Team       2023-12-06   \n",
              "\n",
              "                                              Reference  \\\n",
              "658   Mastering the game of Go with deep neural netw...   \n",
              "1334  Mastering the game of Go with deep neural netw...   \n",
              "479   Google's Neural Machine Translation System: Br...   \n",
              "1217  Xception: Deep Learning with Depthwise Separab...   \n",
              "1291  Neural Architecture Search with Reinforcement ...   \n",
              "...                                                 ...   \n",
              "1370      Zhipu AI launches third-generation base model   \n",
              "537                                                 NaN   \n",
              "833                      Inflection-2: The Next Step Up   \n",
              "306                                                 NaN   \n",
              "221   Gemini: A Family of Highly Capable Multimodal ...   \n",
              "\n",
              "                                                   Link  Citations  \\\n",
              "658   https://www.nature.com/articles/nature24270.ep...    14733.0   \n",
              "1334        https://www.nature.com/articles/nature16961    14733.0   \n",
              "479                    https://arxiv.org/abs/1609.08144     6105.0   \n",
              "1217                   https://arxiv.org/abs/1610.02357    11338.0   \n",
              "1291                   https://arxiv.org/abs/1611.01578     4700.0   \n",
              "...                                                 ...        ...   \n",
              "1370                  https://www.zhipuai.cn/en/news/76        NaN   \n",
              "537                         https://github.com/01-ai/Yi        NaN   \n",
              "833                  https://inflection.ai/inflection-2        NaN   \n",
              "306                https://huggingface.co/Qwen/Qwen-72B        NaN   \n",
              "221   https://storage.googleapis.com/deepmind-media/...      252.0   \n",
              "\n",
              "                Notability criteria  \\\n",
              "658   Highly cited,SOTA improvement   \n",
              "1334                   Highly cited   \n",
              "479                    Highly cited   \n",
              "1217                   Highly cited   \n",
              "1291                   Highly cited   \n",
              "...                             ...   \n",
              "1370               SOTA improvement   \n",
              "537                 Significant use   \n",
              "833                 Significant use   \n",
              "306                SOTA improvement   \n",
              "221                SOTA improvement   \n",
              "\n",
              "                              Notability criteria notes  ...  \\\n",
              "658                                                 NaN  ...   \n",
              "1334                                                NaN  ...   \n",
              "479                                                 NaN  ...   \n",
              "1217                                                NaN  ...   \n",
              "1291                                                NaN  ...   \n",
              "...                                                 ...  ...   \n",
              "1370  Aiming at GPT-4V, ChatGLM3 has implemented ite...  ...   \n",
              "537   2nd most popular model on HuggingFace: https:/...  ...   \n",
              "833   Inflection-2 either already powers Pi or soon ...  ...   \n",
              "306   SOTA on several Chinese benchmarks, with highe...  ...   \n",
              "221   \" Evaluation on a broad range of benchmarks sh...  ...   \n",
              "\n",
              "                                    Training time notes Hardware quantity  \\\n",
              "658                                                 NaN               NaN   \n",
              "1334                                                NaN               NaN   \n",
              "479                                                 NaN              96.0   \n",
              "1217  \"while the JFT experiments took over one month...              60.0   \n",
              "1291                                                NaN             800.0   \n",
              "...                                                 ...               ...   \n",
              "1370                                                NaN               NaN   \n",
              "537                                                 NaN               NaN   \n",
              "833                                                 NaN            5000.0   \n",
              "306                                                 NaN               NaN   \n",
              "221   Dylan Patel, author of SemiAnalysis, speculate...           55000.0   \n",
              "\n",
              "     Hardware utilization Finetune compute (FLOP) Finetune compute notes  \\\n",
              "658                   NaN                     NaN                    NaN   \n",
              "1334                  NaN                     NaN                    NaN   \n",
              "479                   NaN                     NaN                    NaN   \n",
              "1217                  NaN                     NaN                    NaN   \n",
              "1291                  NaN                     NaN                    NaN   \n",
              "...                   ...                     ...                    ...   \n",
              "1370                  NaN                     NaN                    NaN   \n",
              "537                   NaN                     NaN                    NaN   \n",
              "833                   NaN                     NaN                    NaN   \n",
              "306                   NaN                     NaN                    NaN   \n",
              "221                   NaN                     NaN                    NaN   \n",
              "\n",
              "     Batch size  Compute cost notes Training cloud compute vendor  \\\n",
              "658         NaN                 NaN                           NaN   \n",
              "1334        NaN                 NaN                           NaN   \n",
              "479         NaN                 NaN                           NaN   \n",
              "1217        NaN                 NaN                           NaN   \n",
              "1291        NaN                 NaN                           NaN   \n",
              "...         ...                 ...                           ...   \n",
              "1370        NaN                 NaN                           NaN   \n",
              "537         NaN                 NaN                           NaN   \n",
              "833         NaN                 NaN                           NaN   \n",
              "306   4000000.0                 NaN                           NaN   \n",
              "221         NaN                 NaN                           NaN   \n",
              "\n",
              "                                       Batch size notes Training data center  \n",
              "658                                                 NaN                  NaN  \n",
              "1334                                                NaN                  NaN  \n",
              "479                                                 NaN                  NaN  \n",
              "1217                                                NaN                  NaN  \n",
              "1291                                                NaN                  NaN  \n",
              "...                                                 ...                  ...  \n",
              "1370                                                NaN                  NaN  \n",
              "537                                                 NaN                  NaN  \n",
              "833                                                 NaN                  NaN  \n",
              "306   Table 1 https://arxiv.org/abs/2309.16609\\n(thi...                  NaN  \n",
              "221                                                 NaN                  NaN  \n",
              "\n",
              "[77 rows x 51 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "large_scale_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ngeVX9J-1yx",
        "outputId": "949a42f5-e8c9-4c65-fcc9-c5ae79651d10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Ultra\n",
            "Qwen-72B\n",
            "Inflection-2\n",
            "Yi-34B\n",
            "ChatGLM3\n",
            "Falcon 180B\n",
            "Llama 2-70B\n",
            "Llama 2-34B\n",
            "Claude 2\n",
            "xTrimoPGLM -100B\n",
            "PaLM 2\n",
            "PanGu-Σ\n",
            "GPT-4\n",
            "LLaMA-65B\n",
            "ViT-22B\n",
            "GPT-3.5 (text-davinci-003)\n",
            "Galactica\n",
            "BLOOM-176B\n",
            "U-PaLM (540B)\n",
            "BlenderBot 3\n",
            "GLM-130B\n",
            "Minerva (540B)\n",
            "Parti\n",
            "UL2\n",
            "OPT-175B\n",
            "Flamingo\n",
            "PaLM (540B)\n",
            "Chinchilla\n",
            "LaMDA\n",
            "GPT-NeoX-20B\n",
            "AlphaCode\n",
            "ERNIE 3.0 Titan\n",
            "GLaM\n",
            "Gopher (280B)\n",
            "Yuan 1.0\n",
            "Megatron-Turing NLG 530B\n",
            "HyperCLOVA\n",
            "GOAT\n",
            "ByT5-XXL\n",
            "ProtT5-XXL\n",
            "PLUG\n",
            "Meta Pseudo Labels\n",
            "Switch\n",
            "DALL-E\n",
            "mT5-XXL\n",
            "GShard (dense)\n",
            "iGPT-XL\n",
            "GPT-3 175B (davinci)\n",
            "Turing-NLG\n",
            "Meena\n",
            "ContextNet + Noisy Student\n",
            "OpenAI Five Rerun\n",
            "OpenAI Five\n",
            "AlphaStar\n",
            "T5-11B\n",
            "Megatron-BERT\n",
            "Megatron-LM (8.3B)\n",
            "RoBERTa Large\n",
            "MnasNet-A1 + SSDLite\n",
            "MnasNet-A3\n",
            "GPT-2 (1.5B)\n",
            "BigGAN-deep 512x512\n",
            "FTW\n",
            "ResNeXt-101 32x48d\n",
            "IMPALA\n",
            "AmoebaNet-A (F=448)\n",
            "AlphaZero\n",
            "AlphaGo Zero\n",
            "OpenAI TI7 DOTA 1v1\n",
            "JFT\n",
            "AlphaGo Master\n",
            "Libratus\n",
            "NASv3 (CIFAR-10)\n",
            "Xception\n",
            "GNMT\n",
            "AlphaGo Lee\n",
            "AlphaGo Fan\n"
          ]
        }
      ],
      "source": [
        "for system in large_scale_df['System'][::-1]:\n",
        "  print(system)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1TTIzTQhPan"
      },
      "source": [
        "# Percentiles (CURRENT CHOICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-cxrNxPbW7r",
        "outputId": "1ab54428-dc65-4d79-e6a0-feff77ad6e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95\n",
            "90\n",
            "85\n",
            "80\n",
            "75\n",
            "70\n",
            "65\n",
            "60\n",
            "55\n",
            "50\n",
            "45\n",
            "40\n",
            "35\n",
            "30\n",
            "25\n",
            "20\n",
            "15\n",
            "10\n",
            "5\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "frontier_systems_by_percentile = {}\n",
        "percentile_interval = 5\n",
        "for percentile in range(95, -5, -percentile_interval):\n",
        "  print(percentile)\n",
        "  percentile_compute_low = np.zeros(len(pcd_df))\n",
        "  percentile_compute_high = np.zeros(len(pcd_df))\n",
        "  # Iterate through each row and calculate the 2-year moving average for each date\n",
        "  for i, (index, row) in enumerate(pcd_df.iterrows()):\n",
        "    # Define the 2-year window\n",
        "    start_date = row['Publication date'] - pd.DateOffset(years=outlier_window_size/2)\n",
        "    end_date = row['Publication date'] + pd.DateOffset(years=outlier_window_size/2)\n",
        "\n",
        "    # Filter the DataFrame for this window\n",
        "    window_df = pcd_df[(pcd_df['Publication date'] >= start_date) & (pcd_df['Publication date'] <= end_date)]\n",
        "\n",
        "    percentile_compute_low[i] = np.percentile(window_df['Training compute (FLOP)'], percentile)\n",
        "    percentile_compute_high[i] = np.percentile(window_df['Training compute (FLOP)'], percentile + percentile_interval)\n",
        "\n",
        "  frontier_systems_flag = pcd_df['Training compute (FLOP)'] > np.array(percentile_compute_low)\n",
        "  extra_frontier_systems_flag = pcd_df['Training compute (FLOP)'] <= np.array(percentile_compute_high)\n",
        "\n",
        "  # raise Exception(\"Edit the following line if you want to consider models released after 2023-12-31.\")\n",
        "  extra_frontier_systems = pcd_df['System'][frontier_systems_flag & extra_frontier_systems_flag & (pcd_df['Publication date'] > pd.to_datetime('2015-09-30'))].values\n",
        "\n",
        "  frontier_systems_by_percentile[percentile] = list(extra_frontier_systems)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGXo_vGde5mz",
        "outputId": "6684d0f4-3ec9-40ca-ff4a-94cd73c830d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{95: ['GNMT',\n",
              "  'AlphaGo Master',\n",
              "  'AlphaGo Zero',\n",
              "  'AlphaZero',\n",
              "  'ResNeXt-101 32x48d',\n",
              "  'Megatron-BERT',\n",
              "  'OpenAI Five',\n",
              "  'Meena',\n",
              "  'GPT-3 175B (davinci)',\n",
              "  'Megatron-Turing NLG 530B',\n",
              "  'ERNIE 3.0 Titan',\n",
              "  'PaLM (540B)',\n",
              "  'Minerva (540B)',\n",
              "  'GPT-4',\n",
              "  'PaLM 2',\n",
              "  'Inflection-2',\n",
              "  'Gemini Ultra'],\n",
              " 90: ['NASv3 (CIFAR-10)',\n",
              "  'FTW',\n",
              "  'T5-11B',\n",
              "  'AlphaStar',\n",
              "  'mT5-XXL',\n",
              "  'Switch',\n",
              "  'Gopher (280B)',\n",
              "  'Chinchilla',\n",
              "  'U-PaLM (540B)',\n",
              "  'GPT-3.5 (text-davinci-003)',\n",
              "  'Claude 2',\n",
              "  'Falcon 180B'],\n",
              " 85: ['AlphaGo Fan',\n",
              "  'AlphaGo Lee',\n",
              "  'BigGAN-deep 512x512',\n",
              "  'Megatron-LM (8.3B)',\n",
              "  'OpenAI Five Rerun',\n",
              "  'Turing-NLG',\n",
              "  'Yuan 1.0',\n",
              "  'GLaM',\n",
              "  'LaMDA',\n",
              "  'OPT-175B',\n",
              "  'Parti',\n",
              "  'Llama 2-70B',\n",
              "  'ChatGLM3',\n",
              "  'Qwen-72B'],\n",
              " 80: ['JFT',\n",
              "  'OpenAI TI7 DOTA 1v1',\n",
              "  'AmoebaNet-A (F=448)',\n",
              "  'GPT-2 (1.5B)',\n",
              "  'iGPT-XL',\n",
              "  'DALL-E',\n",
              "  'Meta Pseudo Labels',\n",
              "  'ByT5-XXL',\n",
              "  'GOAT',\n",
              "  'HyperCLOVA',\n",
              "  'AlphaCode',\n",
              "  'Flamingo',\n",
              "  'GLM-130B',\n",
              "  'BlenderBot 3',\n",
              "  'LLaMA-65B',\n",
              "  'PanGu-Σ',\n",
              "  'xTrimoPGLM -100B',\n",
              "  'Yi-34B'],\n",
              " 75: ['DeepSpeech2 (English)',\n",
              "  'Xception',\n",
              "  'Libratus',\n",
              "  'IMPALA',\n",
              "  'BERT-Large',\n",
              "  'RoBERTa Large',\n",
              "  'ContextNet + Noisy Student',\n",
              "  'GShard (dense)',\n",
              "  'ProtT5-XXL',\n",
              "  'GPT-NeoX-20B',\n",
              "  'UL2',\n",
              "  'BLOOM-176B',\n",
              "  'Galactica',\n",
              "  'ViT-22B',\n",
              "  'Llama 2-34B'],\n",
              " 70: ['Big Transformer for Back-Translation',\n",
              "  'MnasNet-A3',\n",
              "  'MnasNet-A1 + SSDLite',\n",
              "  'ALBERT-xxlarge',\n",
              "  'ELECTRA',\n",
              "  'iGPT-L',\n",
              "  'PLUG',\n",
              "  'ProtBERT-BFD',\n",
              "  'CoAtNet',\n",
              "  'FLAN 137B',\n",
              "  'AlexaTM 20B',\n",
              "  'Falcon-40B'],\n",
              " 65: ['ResNet-152 (ImageNet)',\n",
              "  'PolyNet',\n",
              "  'MoE',\n",
              "  'YOLOv3',\n",
              "  'Transformer (Adaptive Input Embeddings)',\n",
              "  'Mesh-TensorFlow Transformer 4.9B (language modelling)',\n",
              "  'BERT-Large-CAS (PTB+WT2+WT103)',\n",
              "  'Conformer + Wav2vec 2.0 + Noisy Student',\n",
              "  'CLIP (ViT L/14@336px)',\n",
              "  'ProtT5-XXL-BFD',\n",
              "  'CogView',\n",
              "  'ALIGN',\n",
              "  'Florence',\n",
              "  'Stable Diffusion (LDM-KL-8-G)',\n",
              "  'CoCa',\n",
              "  'BloombergGPT',\n",
              "  'StarCoder',\n",
              "  'Llama 2-13B',\n",
              "  'Skywork-13B'],\n",
              " 60: ['DeepStack',\n",
              "  'PNASNet-5',\n",
              "  'Population-based DRL',\n",
              "  'Mesh-TensorFlow Transformer 2.9B (translation)',\n",
              "  'Megatron-LM (355M)',\n",
              "  'T5-3B',\n",
              "  'CamemBERT',\n",
              "  'Noisy Student (L2)',\n",
              "  'Once for All',\n",
              "  'ERNIE 3.0',\n",
              "  'BASIC-L',\n",
              "  'XGLM-7.5B',\n",
              "  'ESM2-15B',\n",
              "  'PaLI',\n",
              "  'Taiyi-Stable Diffusion',\n",
              "  'Llama 2-7B',\n",
              "  'Nemotron-3-8B'],\n",
              " 55: ['LSTM (Hebbian, Cache, MbPA)',\n",
              "  'SciBERT',\n",
              "  'DD-PPO',\n",
              "  'ViT-Huge/14',\n",
              "  'MSA Transformer',\n",
              "  'M6-T',\n",
              "  'DeBERTa',\n",
              "  'T0-XXL',\n",
              "  'Whisper',\n",
              "  'XGen-7B'],\n",
              " 50: ['BIDAF',\n",
              "  'Transformer',\n",
              "  'GPT',\n",
              "  'GBERT-Large',\n",
              "  'wave2vec 2.0 LARGE',\n",
              "  'AlphaFold 2',\n",
              "  'HuBERT',\n",
              "  'Imagen',\n",
              "  'NLLB',\n",
              "  'ESM2-3B',\n",
              "  'LLaMA-7B',\n",
              "  'LLaMA-13B',\n",
              "  'WizardLM-7B',\n",
              "  'Pangu-Weather'],\n",
              " 45: ['RetinaNet-R101',\n",
              "  'Transformer + Simple Recurrent Unit',\n",
              "  'ProxylessNAS',\n",
              "  'Sandwich Transformer',\n",
              "  'German ELECTRA Large',\n",
              "  'CPM-Large',\n",
              "  'SEER',\n",
              "  'ProGen2-xlarge',\n",
              "  'OmegaPLM',\n",
              "  'Jais',\n",
              "  'CogVLM'],\n",
              " 40: ['Part-of-sentence tagging model',\n",
              "  'GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)',\n",
              "  'Transformer-XL Large',\n",
              "  'KataGo',\n",
              "  'MuZero',\n",
              "  'AlphaFold',\n",
              "  'DETR',\n",
              "  'ESM1-670M (UR50/S)',\n",
              "  'ESM1-670M (UR50/D)',\n",
              "  'ViT-G/14',\n",
              "  'AlphaFold-Multimer',\n",
              "  'NÜWA',\n",
              "  'Gato',\n",
              "  'Tranception',\n",
              "  'ESM2-650M',\n",
              "  'Nucleotide Transformer',\n",
              "  'VideoMAE V2',\n",
              "  'Segment Anything Model'],\n",
              " 35: ['Named Entity Recognition model',\n",
              "  'R-FCN',\n",
              "  'ObjectNet',\n",
              "  'Feedback Transformer',\n",
              "  'EMDR',\n",
              "  'ViT-G (model soup)',\n",
              "  'AudioGen',\n",
              "  'DINOv2',\n",
              "  'PeptideBERT'],\n",
              " 30: ['AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)',\n",
              "  'AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)',\n",
              "  'QRNN',\n",
              "  '(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)',\n",
              "  'TrellisNet',\n",
              "  'FAIRSEQ Adaptive Inputs',\n",
              "  'Transformer-XL Large + Phrase Induction',\n",
              "  'DistilBERT',\n",
              "  'ATLAS',\n",
              "  'ESM1-670M (UR100)',\n",
              "  'LUKE',\n",
              "  'ESM1b',\n",
              "  'ADM',\n",
              "  'CodeT5-base',\n",
              "  'CodeT5-large',\n",
              "  'EVA',\n",
              "  'Ankh_large'],\n",
              " 25: ['Zoneout + Variational LSTM (WT2)',\n",
              "  'VD-LSTM+REAL Large',\n",
              "  '4 layer QRNN (h=2500)',\n",
              "  'Big-Little Net (speech)',\n",
              "  'Hanabi 4 player',\n",
              "  'Tensorized Transformer (257M)',\n",
              "  'AlphaX-1',\n",
              "  'TaLK Convolution',\n",
              "  'ESM1-85M',\n",
              "  'KEPLER',\n",
              "  'ViT + DINO',\n",
              "  'ConSERT',\n",
              "  'Denoising Diffusion Probabilistic Models (LSUN Bedroom)',\n",
              "  'S4',\n",
              "  'Swin Transformer V2',\n",
              "  'PolyCoder',\n",
              "  'GenSLM',\n",
              "  'Ankh_base',\n",
              "  'Flan T5-XXL + BLIP-2',\n",
              "  'BLIP-2 (Q-Former)',\n",
              "  'Incoder-6.7B'],\n",
              " 20: ['Fraternal dropout + AWD-LSTM 3-layer (WT2)',\n",
              "  'Dropout-LSTM+Noise(Bernoulli) (WT2)',\n",
              "  'Decoupled weight decay regularization',\n",
              "  'Cross-lingual alignment',\n",
              "  'DLRM-2020',\n",
              "  'Base LM + kNN LM + Continuous Cache',\n",
              "  'ESM1-43M',\n",
              "  'ESM2-150M',\n",
              "  'AR-LDM',\n",
              "  'Hybrid H3-2.7B',\n",
              "  'DiT-XL/2'],\n",
              " 15: ['Variational (untied weights, MC) LSTM (Large)',\n",
              "  'Pointer Sentinel-LSTM (medium)',\n",
              "  'Neural Architecture Search with base 8 and shared embeddings',\n",
              "  'ENAS',\n",
              "  'aLSTM(depth-2)+RecurrentPolicy (WT2)',\n",
              "  'Transformer-XL DeFINE (141M)',\n",
              "  'DeLight',\n",
              "  'ERNIE-Doc (247M)',\n",
              "  'EfficientNetV2',\n",
              "  'Adaptive Input Transformer + RD',\n",
              "  'DNABERT',\n",
              "  'BERT-RBP',\n",
              "  'ESM2-35M',\n",
              "  'Fusion in Encoder',\n",
              "  'Discriminator Guidance',\n",
              "  'DDPM-IP (CelebA)',\n",
              "  'ONE-PEACE'],\n",
              " 10: ['EI-REHN-1000D',\n",
              "  'DARTS',\n",
              "  'AWD-LSTM-DRILL + dynamic evaluation† (WT2)',\n",
              "  'NAS+ESS (156M)',\n",
              "  'ProBERTa',\n",
              "  'SRU++ Large',\n",
              "  'ProteinBERT',\n",
              "  'DiffDock',\n",
              "  'LLaVA',\n",
              "  'LLaVA 1.5'],\n",
              " 5: ['VD-RHN',\n",
              "  'ISS',\n",
              "  'AWD-LSTM+WT+Cache+IOG (WT2)',\n",
              "  'AWD-LSTM + MoS + Partial Shuffled',\n",
              "  'UDSMProt',\n",
              "  'MMLSTM',\n",
              "  'Tensor-Transformer(1core)+PN (WT103)',\n",
              "  'Transformer local-attention (NesT-B)',\n",
              "  'Detic',\n",
              "  'Segatron-XL large, M=384 + HCP',\n",
              "  'Sparse all-MLP',\n",
              "  'ESM2-8M',\n",
              "  'CaLM',\n",
              "  'MultiBand Diffusion'],\n",
              " 0: ['2-layer-LSTM+Deep-Gradient-Compression',\n",
              "  'Fine-tuned-AWD-LSTM-DOC(fin)',\n",
              "  'Multi-cell LSTM',\n",
              "  'Pluribus',\n",
              "  'TransformerXL + spectrum control',\n",
              "  'DensePhrases',\n",
              "  'CT-MoS (WT2)',\n",
              "  'MedBERT',\n",
              "  'PermuteFormer',\n",
              "  'base LM+GNN+kNN',\n",
              "  'DITTO',\n",
              "  'Mogrifier RLSTM (WT2)',\n",
              "  'VALL-E',\n",
              "  'HyenaDNA',\n",
              "  'CODEFUSION (Python)']}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frontier_systems_by_percentile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to JSON\n",
        "with open('data/frontier_systems_by_window_percentile.json', 'w') as f:\n",
        "    json.dump(frontier_systems_by_percentile, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8pzY7skfxkV",
        "outputId": "195c3ec6-c885-4008-ba36-abb60e5dd645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95 to 100\n",
            "17 systems\n",
            "Total systems above 95th percentile: 17\n",
            "Gemini Ultra\n",
            "Inflection-2\n",
            "PaLM 2\n",
            "GPT-4\n",
            "Minerva (540B)\n",
            "PaLM (540B)\n",
            "ERNIE 3.0 Titan\n",
            "Megatron-Turing NLG 530B\n",
            "GPT-3 175B (davinci)\n",
            "Meena\n",
            "OpenAI Five\n",
            "Megatron-BERT\n",
            "ResNeXt-101 32x48d\n",
            "AlphaZero\n",
            "AlphaGo Zero\n",
            "AlphaGo Master\n",
            "GNMT\n",
            "\n",
            "90 to 95\n",
            "12 systems\n",
            "Total systems above 90th percentile: 29\n",
            "Falcon 180B\n",
            "Claude 2\n",
            "GPT-3.5 (text-davinci-003)\n",
            "U-PaLM (540B)\n",
            "Chinchilla\n",
            "Gopher (280B)\n",
            "Switch\n",
            "mT5-XXL\n",
            "AlphaStar\n",
            "T5-11B\n",
            "FTW\n",
            "NASv3 (CIFAR-10)\n",
            "\n",
            "85 to 90\n",
            "14 systems\n",
            "Total systems above 85th percentile: 43\n",
            "Qwen-72B\n",
            "ChatGLM3\n",
            "Llama 2-70B\n",
            "Parti\n",
            "OPT-175B\n",
            "LaMDA\n",
            "GLaM\n",
            "Yuan 1.0\n",
            "Turing-NLG\n",
            "OpenAI Five Rerun\n",
            "Megatron-LM (8.3B)\n",
            "BigGAN-deep 512x512\n",
            "AlphaGo Lee\n",
            "AlphaGo Fan\n",
            "\n",
            "80 to 85\n",
            "18 systems\n",
            "Total systems above 80th percentile: 61\n",
            "Yi-34B\n",
            "xTrimoPGLM -100B\n",
            "PanGu-Σ\n",
            "LLaMA-65B\n",
            "BlenderBot 3\n",
            "GLM-130B\n",
            "Flamingo\n",
            "AlphaCode\n",
            "HyperCLOVA\n",
            "GOAT\n",
            "ByT5-XXL\n",
            "Meta Pseudo Labels\n",
            "DALL-E\n",
            "iGPT-XL\n",
            "GPT-2 (1.5B)\n",
            "AmoebaNet-A (F=448)\n",
            "OpenAI TI7 DOTA 1v1\n",
            "JFT\n",
            "\n",
            "75 to 80\n",
            "15 systems\n",
            "Total systems above 75th percentile: 76\n",
            "Llama 2-34B\n",
            "ViT-22B\n",
            "Galactica\n",
            "BLOOM-176B\n",
            "UL2\n",
            "GPT-NeoX-20B\n",
            "ProtT5-XXL\n",
            "GShard (dense)\n",
            "ContextNet + Noisy Student\n",
            "RoBERTa Large\n",
            "BERT-Large\n",
            "IMPALA\n",
            "Libratus\n",
            "Xception\n",
            "DeepSpeech2 (English)\n",
            "\n",
            "70 to 75\n",
            "12 systems\n",
            "Total systems above 70th percentile: 88\n",
            "Falcon-40B\n",
            "AlexaTM 20B\n",
            "FLAN 137B\n",
            "CoAtNet\n",
            "ProtBERT-BFD\n",
            "PLUG\n",
            "iGPT-L\n",
            "ELECTRA\n",
            "ALBERT-xxlarge\n",
            "MnasNet-A1 + SSDLite\n",
            "MnasNet-A3\n",
            "Big Transformer for Back-Translation\n",
            "\n",
            "65 to 70\n",
            "19 systems\n",
            "Total systems above 65th percentile: 107\n",
            "Skywork-13B\n",
            "Llama 2-13B\n",
            "StarCoder\n",
            "BloombergGPT\n",
            "CoCa\n",
            "Stable Diffusion (LDM-KL-8-G)\n",
            "Florence\n",
            "ALIGN\n",
            "CogView\n",
            "ProtT5-XXL-BFD\n",
            "CLIP (ViT L/14@336px)\n",
            "Conformer + Wav2vec 2.0 + Noisy Student\n",
            "BERT-Large-CAS (PTB+WT2+WT103)\n",
            "Mesh-TensorFlow Transformer 4.9B (language modelling)\n",
            "Transformer (Adaptive Input Embeddings)\n",
            "YOLOv3\n",
            "MoE\n",
            "PolyNet\n",
            "ResNet-152 (ImageNet)\n",
            "\n",
            "60 to 65\n",
            "17 systems\n",
            "Total systems above 60th percentile: 124\n",
            "Nemotron-3-8B\n",
            "Llama 2-7B\n",
            "Taiyi-Stable Diffusion\n",
            "PaLI\n",
            "ESM2-15B\n",
            "XGLM-7.5B\n",
            "BASIC-L\n",
            "ERNIE 3.0\n",
            "Once for All\n",
            "Noisy Student (L2)\n",
            "CamemBERT\n",
            "T5-3B\n",
            "Megatron-LM (355M)\n",
            "Mesh-TensorFlow Transformer 2.9B (translation)\n",
            "Population-based DRL\n",
            "PNASNet-5\n",
            "DeepStack\n",
            "\n",
            "55 to 60\n",
            "10 systems\n",
            "Total systems above 55th percentile: 134\n",
            "XGen-7B\n",
            "Whisper\n",
            "T0-XXL\n",
            "DeBERTa\n",
            "M6-T\n",
            "MSA Transformer\n",
            "ViT-Huge/14\n",
            "DD-PPO\n",
            "SciBERT\n",
            "LSTM (Hebbian, Cache, MbPA)\n",
            "\n",
            "50 to 55\n",
            "14 systems\n",
            "Total systems above 50th percentile: 148\n",
            "Pangu-Weather\n",
            "WizardLM-7B\n",
            "LLaMA-13B\n",
            "LLaMA-7B\n",
            "ESM2-3B\n",
            "NLLB\n",
            "Imagen\n",
            "HuBERT\n",
            "AlphaFold 2\n",
            "wave2vec 2.0 LARGE\n",
            "GBERT-Large\n",
            "GPT\n",
            "Transformer\n",
            "BIDAF\n",
            "\n",
            "45 to 50\n",
            "11 systems\n",
            "Total systems above 45th percentile: 159\n",
            "CogVLM\n",
            "Jais\n",
            "OmegaPLM\n",
            "ProGen2-xlarge\n",
            "SEER\n",
            "CPM-Large\n",
            "German ELECTRA Large\n",
            "Sandwich Transformer\n",
            "ProxylessNAS\n",
            "Transformer + Simple Recurrent Unit\n",
            "RetinaNet-R101\n",
            "\n",
            "40 to 45\n",
            "18 systems\n",
            "Total systems above 40th percentile: 177\n",
            "Segment Anything Model\n",
            "VideoMAE V2\n",
            "Nucleotide Transformer\n",
            "ESM2-650M\n",
            "Tranception\n",
            "Gato\n",
            "NÜWA\n",
            "AlphaFold-Multimer\n",
            "ViT-G/14\n",
            "ESM1-670M (UR50/D)\n",
            "ESM1-670M (UR50/S)\n",
            "DETR\n",
            "AlphaFold\n",
            "MuZero\n",
            "KataGo\n",
            "Transformer-XL Large\n",
            "GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)\n",
            "Part-of-sentence tagging model\n",
            "\n",
            "35 to 40\n",
            "9 systems\n",
            "Total systems above 35th percentile: 186\n",
            "PeptideBERT\n",
            "DINOv2\n",
            "AudioGen\n",
            "ViT-G (model soup)\n",
            "EMDR\n",
            "Feedback Transformer\n",
            "ObjectNet\n",
            "R-FCN\n",
            "Named Entity Recognition model\n",
            "\n",
            "30 to 35\n",
            "17 systems\n",
            "Total systems above 30th percentile: 203\n",
            "Ankh_large\n",
            "EVA\n",
            "CodeT5-large\n",
            "CodeT5-base\n",
            "ADM\n",
            "ESM1b\n",
            "LUKE\n",
            "ESM1-670M (UR100)\n",
            "ATLAS\n",
            "DistilBERT\n",
            "Transformer-XL Large + Phrase Induction\n",
            "FAIRSEQ Adaptive Inputs\n",
            "TrellisNet\n",
            "(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)\n",
            "QRNN\n",
            "AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)\n",
            "AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)\n",
            "\n",
            "25 to 30\n",
            "21 systems\n",
            "Total systems above 25th percentile: 224\n",
            "Incoder-6.7B\n",
            "BLIP-2 (Q-Former)\n",
            "Flan T5-XXL + BLIP-2\n",
            "Ankh_base\n",
            "GenSLM\n",
            "PolyCoder\n",
            "Swin Transformer V2\n",
            "S4\n",
            "Denoising Diffusion Probabilistic Models (LSUN Bedroom)\n",
            "ConSERT\n",
            "ViT + DINO\n",
            "KEPLER\n",
            "ESM1-85M\n",
            "TaLK Convolution\n",
            "AlphaX-1\n",
            "Tensorized Transformer (257M)\n",
            "Hanabi 4 player\n",
            "Big-Little Net (speech)\n",
            "4 layer QRNN (h=2500)\n",
            "VD-LSTM+REAL Large\n",
            "Zoneout + Variational LSTM (WT2)\n",
            "\n",
            "20 to 25\n",
            "11 systems\n",
            "Total systems above 20th percentile: 235\n",
            "DiT-XL/2\n",
            "Hybrid H3-2.7B\n",
            "AR-LDM\n",
            "ESM2-150M\n",
            "ESM1-43M\n",
            "Base LM + kNN LM + Continuous Cache\n",
            "DLRM-2020\n",
            "Cross-lingual alignment\n",
            "Decoupled weight decay regularization\n",
            "Dropout-LSTM+Noise(Bernoulli) (WT2)\n",
            "Fraternal dropout + AWD-LSTM 3-layer (WT2)\n",
            "\n",
            "15 to 20\n",
            "17 systems\n",
            "Total systems above 15th percentile: 252\n",
            "ONE-PEACE\n",
            "DDPM-IP (CelebA)\n",
            "Discriminator Guidance\n",
            "Fusion in Encoder\n",
            "ESM2-35M\n",
            "BERT-RBP\n",
            "DNABERT\n",
            "Adaptive Input Transformer + RD\n",
            "EfficientNetV2\n",
            "ERNIE-Doc (247M)\n",
            "DeLight\n",
            "Transformer-XL DeFINE (141M)\n",
            "aLSTM(depth-2)+RecurrentPolicy (WT2)\n",
            "ENAS\n",
            "Neural Architecture Search with base 8 and shared embeddings\n",
            "Pointer Sentinel-LSTM (medium)\n",
            "Variational (untied weights, MC) LSTM (Large)\n",
            "\n",
            "10 to 15\n",
            "10 systems\n",
            "Total systems above 10th percentile: 262\n",
            "LLaVA 1.5\n",
            "LLaVA\n",
            "DiffDock\n",
            "ProteinBERT\n",
            "SRU++ Large\n",
            "ProBERTa\n",
            "NAS+ESS (156M)\n",
            "AWD-LSTM-DRILL + dynamic evaluation† (WT2)\n",
            "DARTS\n",
            "EI-REHN-1000D\n",
            "\n",
            "5 to 10\n",
            "14 systems\n",
            "Total systems above 5th percentile: 276\n",
            "MultiBand Diffusion\n",
            "CaLM\n",
            "ESM2-8M\n",
            "Sparse all-MLP\n",
            "Segatron-XL large, M=384 + HCP\n",
            "Detic\n",
            "Transformer local-attention (NesT-B)\n",
            "Tensor-Transformer(1core)+PN (WT103)\n",
            "MMLSTM\n",
            "UDSMProt\n",
            "AWD-LSTM + MoS + Partial Shuffled\n",
            "AWD-LSTM+WT+Cache+IOG (WT2)\n",
            "ISS\n",
            "VD-RHN\n",
            "\n",
            "0 to 5\n",
            "15 systems\n",
            "Total systems above 0th percentile: 291\n",
            "CODEFUSION (Python)\n",
            "HyenaDNA\n",
            "VALL-E\n",
            "Mogrifier RLSTM (WT2)\n",
            "DITTO\n",
            "base LM+GNN+kNN\n",
            "PermuteFormer\n",
            "MedBERT\n",
            "CT-MoS (WT2)\n",
            "DensePhrases\n",
            "TransformerXL + spectrum control\n",
            "Pluribus\n",
            "Multi-cell LSTM\n",
            "Fine-tuned-AWD-LSTM-DOC(fin)\n",
            "2-layer-LSTM+Deep-Gradient-Compression\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total_num_systems = 0\n",
        "for percentile, systems in frontier_systems_by_percentile.items():\n",
        "  total_num_systems += len(systems)\n",
        "  print(percentile, 'to', percentile + percentile_interval)\n",
        "  print(len(systems), \"systems\")\n",
        "  print(f'Total systems above {percentile}th percentile: {total_num_systems}')\n",
        "  for system in systems[::-1]:\n",
        "    print(system)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klMq2PP3f6Xw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TllyX8IqSiG2"
      },
      "source": [
        "# Distance from compute record at the time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC8_j5AASl0y"
      },
      "outputs": [],
      "source": [
        "ooms_from_frontier = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N395lGkYSoNU",
        "outputId": "ee6d6df7-3662-4dd8-ce41-b9490a33389a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4.00000000e+01, 6.94894938e+05, 6.00000000e+08, 6.00000000e+08,\n",
              "       7.20000000e+08, 7.20000000e+08, 7.20000000e+08, 7.20000000e+08,\n",
              "       2.83280026e+10, 2.83280026e+10, 2.83280026e+10, 4.33721175e+10,\n",
              "       8.11870414e+10, 1.82321576e+13, 1.82321576e+13, 1.82321576e+13,\n",
              "       2.10080000e+13, 2.10080000e+13, 6.30000000e+13, 1.30389876e+15,\n",
              "       1.30389876e+15, 1.30389876e+15, 1.30389876e+15, 1.30389876e+15,\n",
              "       3.41463600e+15, 6.14400000e+16, 6.14400000e+16, 2.73196800e+17,\n",
              "       2.73196800e+17, 2.73196800e+17, 6.00000000e+17, 6.00000000e+17,\n",
              "       6.00000000e+17, 6.00000000e+17, 6.00000000e+17, 6.00000000e+17,\n",
              "       6.00000000e+17, 1.34092800e+18, 1.34092800e+18, 1.34092800e+18,\n",
              "       1.34092800e+18, 1.34092800e+18, 3.41107200e+18, 3.41107200e+18,\n",
              "       3.41107200e+18, 9.25344000e+18, 9.25344000e+18, 5.60000000e+19,\n",
              "       5.60000000e+19, 5.60000000e+19, 5.60000000e+19, 5.60000000e+19,\n",
              "       5.60000000e+19, 5.60000000e+19, 5.60000000e+19, 3.80000000e+20,\n",
              "       3.80000000e+20, 3.80000000e+20, 3.80000000e+20, 1.90000000e+21,\n",
              "       1.90000000e+21, 1.90000000e+21, 1.90000000e+21, 1.90000000e+21,\n",
              "       1.90000000e+21, 1.90000000e+21, 6.90000000e+21, 6.90000000e+21,\n",
              "       6.90000000e+21, 6.90000000e+21, 6.90000000e+21, 6.90000000e+21,\n",
              "       6.90000000e+21, 6.90000000e+21, 1.50000000e+23, 1.50000000e+23,\n",
              "       1.50000000e+23, 1.50000000e+23, 1.50000000e+23, 1.50000000e+23,\n",
              "       1.50000000e+23, 1.50000000e+23, 1.50000000e+23, 1.50000000e+23,\n",
              "       1.50000000e+23, 1.50000000e+23, 1.50000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
              "       3.41000000e+23, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
              "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
              "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
              "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
              "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
              "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
              "       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n",
              "       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n",
              "       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n",
              "       2.52720000e+24, 2.52720000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
              "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
              "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
              "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
              "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
              "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
              "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
              "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
              "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
              "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
              "       5.00000000e+25])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_max = 0\n",
        "running_max = np.zeros(len(pcd_df))\n",
        "for i, compute in enumerate(pcd_df['Training compute (FLOP)']):\n",
        "  if compute > current_max:\n",
        "    running_max[i] = compute\n",
        "    current_max = compute\n",
        "  else:\n",
        "    running_max[i] = current_max\n",
        "running_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV1tpYgETmYT"
      },
      "outputs": [],
      "source": [
        "pcd_df['Frontier training compute (FLOP)'] = running_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WdpWpDvvTqOs",
        "outputId": "331ce3ef-cc47-4393-dc7f-98148184fd4c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pcd_df[['System', 'Frontier system']]\",\n  \"rows\": 349,\n  \"fields\": [\n    {\n      \"column\": \"System\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 349,\n        \"samples\": [\n          \"OpenAI Five Rerun\",\n          \"Yi-34B\",\n          \"VideoMAE V2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frontier system\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-15b478db-731c-435f-82c9-7f2e6d306dd8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Frontier system</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>Theseus</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>Perceptron Mark I</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>Pandemonium (morse)</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1193</th>\n",
              "      <td>Samuel Neural Checkers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>Perceptron (1960)</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1318</th>\n",
              "      <td>MultiBand Diffusion</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128</th>\n",
              "      <td>Nemotron-3-8B</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832</th>\n",
              "      <td>Inflection-2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Qwen-72B</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>Gemini Ultra</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>349 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15b478db-731c-435f-82c9-7f2e6d306dd8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15b478db-731c-435f-82c9-7f2e6d306dd8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15b478db-731c-435f-82c9-7f2e6d306dd8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c2f28f1-8b9f-4e07-8663-70fe78cef3f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c2f28f1-8b9f-4e07-8663-70fe78cef3f8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c2f28f1-8b9f-4e07-8663-70fe78cef3f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                      System  Frontier system\n",
              "1126                 Theseus            False\n",
              "625        Perceptron Mark I            False\n",
              "374      Pandemonium (morse)            False\n",
              "1193  Samuel Neural Checkers            False\n",
              "415        Perceptron (1960)            False\n",
              "...                      ...              ...\n",
              "1318     MultiBand Diffusion            False\n",
              "1128           Nemotron-3-8B            False\n",
              "832             Inflection-2             True\n",
              "306                 Qwen-72B             True\n",
              "221             Gemini Ultra             True\n",
              "\n",
              "[349 rows x 2 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pcd_df['Frontier system'] = (pcd_df['Publication date'] > start_large_scale_era) & (np.log10(pcd_df['Frontier training compute (FLOP)']) - np.log10(pcd_df['Training compute (FLOP)']) <= ooms_from_frontier)\n",
        "pcd_df[['System', 'Frontier system']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yrk0wu7LT6ZK",
        "outputId": "9d95a1fa-1ed8-4c4b-ae94-f9b42a8dddd8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "frontier_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-78999cec-4cd3-482e-9c29-8bc368d590bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Domain</th>\n",
              "      <th>Organization</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Publication date</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Link</th>\n",
              "      <th>Citations</th>\n",
              "      <th>Notability criteria</th>\n",
              "      <th>Notability criteria notes</th>\n",
              "      <th>...</th>\n",
              "      <th>Hardware utilization</th>\n",
              "      <th>Finetune compute (FLOP)</th>\n",
              "      <th>Finetune compute notes</th>\n",
              "      <th>Batch size</th>\n",
              "      <th>Compute cost notes</th>\n",
              "      <th>Training cloud compute vendor</th>\n",
              "      <th>Batch size notes</th>\n",
              "      <th>Training data center</th>\n",
              "      <th>Frontier training compute (FLOP)</th>\n",
              "      <th>Frontier system</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>657</th>\n",
              "      <td>AlphaGo Fan</td>\n",
              "      <td>Games</td>\n",
              "      <td>Google DeepMind</td>\n",
              "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
              "      <td>2015-10-01</td>\n",
              "      <td>Mastering the game of Go with deep neural netw...</td>\n",
              "      <td>https://www.nature.com/articles/nature24270.ep...</td>\n",
              "      <td>14733.0</td>\n",
              "      <td>Highly cited,SOTA improvement</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.800000e+20</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>DeepSpeech2 (English)</td>\n",
              "      <td>Speech</td>\n",
              "      <td>Baidu Research - Silicon Valley AI Lab</td>\n",
              "      <td>Dario Amodei, Rishita Anubhai, Eric Battenberg...</td>\n",
              "      <td>2015-12-08</td>\n",
              "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
              "      <td>https://arxiv.org/abs/1512.02595</td>\n",
              "      <td>2741.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.800000e+20</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>ResNet-152 (ImageNet)</td>\n",
              "      <td>Vision</td>\n",
              "      <td>Microsoft</td>\n",
              "      <td>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</td>\n",
              "      <td>2015-12-10</td>\n",
              "      <td>Deep Residual Learning for Image Recognition</td>\n",
              "      <td>https://arxiv.org/abs/1512.03385</td>\n",
              "      <td>154061.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.800000e+20</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>AlphaGo Lee</td>\n",
              "      <td>Games</td>\n",
              "      <td>DeepMind</td>\n",
              "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
              "      <td>2016-01-27</td>\n",
              "      <td>Mastering the game of Go with deep neural netw...</td>\n",
              "      <td>https://www.nature.com/articles/nature16961</td>\n",
              "      <td>14733.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.900000e+21</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>GNMT</td>\n",
              "      <td>Language</td>\n",
              "      <td>Google</td>\n",
              "      <td>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...</td>\n",
              "      <td>2016-09-26</td>\n",
              "      <td>Google's Neural Machine Translation System: Br...</td>\n",
              "      <td>https://arxiv.org/abs/1609.08144</td>\n",
              "      <td>6105.0</td>\n",
              "      <td>Highly cited</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.900000e+21</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1055</th>\n",
              "      <td>Skywork-13B</td>\n",
              "      <td>Language</td>\n",
              "      <td>Kunlun Inc.</td>\n",
              "      <td>Tianwen Wei, Liang Zhao, Lichang Zhang, Bo Zhu...</td>\n",
              "      <td>2023-10-30</td>\n",
              "      <td>Skywork: A More Open Bilingual Foundation Model</td>\n",
              "      <td>https://arxiv.org/abs/2310.19341</td>\n",
              "      <td>26.0</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>\"We show that our model not only excels on pop...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16000000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Table 3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.100000e+25</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>Yi-34B</td>\n",
              "      <td>Language</td>\n",
              "      <td>01.AI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-11-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://github.com/01-ai/Yi</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Significant use</td>\n",
              "      <td>2nd most popular model on HuggingFace: https:/...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.100000e+25</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832</th>\n",
              "      <td>Inflection-2</td>\n",
              "      <td>Language</td>\n",
              "      <td>Inflection AI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-11-22</td>\n",
              "      <td>Inflection-2: The Next Step Up</td>\n",
              "      <td>https://inflection.ai/inflection-2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Significant use</td>\n",
              "      <td>Inflection-2 either already powers Pi or soon ...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.100000e+25</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Qwen-72B</td>\n",
              "      <td>Language</td>\n",
              "      <td>Alibaba</td>\n",
              "      <td>Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Ka...</td>\n",
              "      <td>2023-11-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>SOTA on several Chinese benchmarks, with highe...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4000000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Table 1 https://arxiv.org/abs/2309.16609\\n(thi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.100000e+25</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>Gemini Ultra</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>Google DeepMind</td>\n",
              "      <td>Gemini Team</td>\n",
              "      <td>2023-12-06</td>\n",
              "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
              "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
              "      <td>252.0</td>\n",
              "      <td>SOTA improvement</td>\n",
              "      <td>\" Evaluation on a broad range of benchmarks sh...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.000000e+25</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105 rows × 53 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78999cec-4cd3-482e-9c29-8bc368d590bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78999cec-4cd3-482e-9c29-8bc368d590bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78999cec-4cd3-482e-9c29-8bc368d590bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-665f4544-1cd9-4852-af90-551bb915752e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-665f4544-1cd9-4852-af90-551bb915752e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-665f4544-1cd9-4852-af90-551bb915752e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                     System      Domain  \\\n",
              "657             AlphaGo Fan       Games   \n",
              "21    DeepSpeech2 (English)      Speech   \n",
              "359   ResNet-152 (ImageNet)      Vision   \n",
              "1333            AlphaGo Lee       Games   \n",
              "479                    GNMT    Language   \n",
              "...                     ...         ...   \n",
              "1055            Skywork-13B    Language   \n",
              "537                  Yi-34B    Language   \n",
              "832            Inflection-2    Language   \n",
              "306                Qwen-72B    Language   \n",
              "221            Gemini Ultra  Multimodal   \n",
              "\n",
              "                                Organization  \\\n",
              "657                          Google DeepMind   \n",
              "21    Baidu Research - Silicon Valley AI Lab   \n",
              "359                                Microsoft   \n",
              "1333                                DeepMind   \n",
              "479                                   Google   \n",
              "...                                      ...   \n",
              "1055                             Kunlun Inc.   \n",
              "537                                    01.AI   \n",
              "832                            Inflection AI   \n",
              "306                                  Alibaba   \n",
              "221                          Google DeepMind   \n",
              "\n",
              "                                                Authors Publication date  \\\n",
              "657   David Silver, Aja Huang, Chris J. Maddison, Ar...       2015-10-01   \n",
              "21    Dario Amodei, Rishita Anubhai, Eric Battenberg...       2015-12-08   \n",
              "359   Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun       2015-12-10   \n",
              "1333  David Silver, Aja Huang, Chris J. Maddison, Ar...       2016-01-27   \n",
              "479   Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...       2016-09-26   \n",
              "...                                                 ...              ...   \n",
              "1055  Tianwen Wei, Liang Zhao, Lichang Zhang, Bo Zhu...       2023-10-30   \n",
              "537                                                 NaN       2023-11-02   \n",
              "832                                                 NaN       2023-11-22   \n",
              "306   Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Ka...       2023-11-30   \n",
              "221                                         Gemini Team       2023-12-06   \n",
              "\n",
              "                                              Reference  \\\n",
              "657   Mastering the game of Go with deep neural netw...   \n",
              "21    Deep Speech 2: End-to-End Speech Recognition i...   \n",
              "359        Deep Residual Learning for Image Recognition   \n",
              "1333  Mastering the game of Go with deep neural netw...   \n",
              "479   Google's Neural Machine Translation System: Br...   \n",
              "...                                                 ...   \n",
              "1055    Skywork: A More Open Bilingual Foundation Model   \n",
              "537                                                 NaN   \n",
              "832                      Inflection-2: The Next Step Up   \n",
              "306                                                 NaN   \n",
              "221   Gemini: A Family of Highly Capable Multimodal ...   \n",
              "\n",
              "                                                   Link  Citations  \\\n",
              "657   https://www.nature.com/articles/nature24270.ep...    14733.0   \n",
              "21                     https://arxiv.org/abs/1512.02595     2741.0   \n",
              "359                    https://arxiv.org/abs/1512.03385   154061.0   \n",
              "1333        https://www.nature.com/articles/nature16961    14733.0   \n",
              "479                    https://arxiv.org/abs/1609.08144     6105.0   \n",
              "...                                                 ...        ...   \n",
              "1055                   https://arxiv.org/abs/2310.19341       26.0   \n",
              "537                         https://github.com/01-ai/Yi        NaN   \n",
              "832                  https://inflection.ai/inflection-2        NaN   \n",
              "306                https://huggingface.co/Qwen/Qwen-72B        NaN   \n",
              "221   https://storage.googleapis.com/deepmind-media/...      252.0   \n",
              "\n",
              "                Notability criteria  \\\n",
              "657   Highly cited,SOTA improvement   \n",
              "21                     Highly cited   \n",
              "359                    Highly cited   \n",
              "1333                   Highly cited   \n",
              "479                    Highly cited   \n",
              "...                             ...   \n",
              "1055               SOTA improvement   \n",
              "537                 Significant use   \n",
              "832                 Significant use   \n",
              "306                SOTA improvement   \n",
              "221                SOTA improvement   \n",
              "\n",
              "                              Notability criteria notes  ...  \\\n",
              "657                                                 NaN  ...   \n",
              "21                                                  NaN  ...   \n",
              "359                                                 NaN  ...   \n",
              "1333                                                NaN  ...   \n",
              "479                                                 NaN  ...   \n",
              "...                                                 ...  ...   \n",
              "1055  \"We show that our model not only excels on pop...  ...   \n",
              "537   2nd most popular model on HuggingFace: https:/...  ...   \n",
              "832   Inflection-2 either already powers Pi or soon ...  ...   \n",
              "306   SOTA on several Chinese benchmarks, with highe...  ...   \n",
              "221   \" Evaluation on a broad range of benchmarks sh...  ...   \n",
              "\n",
              "     Hardware utilization Finetune compute (FLOP) Finetune compute notes  \\\n",
              "657                   NaN                     NaN                    NaN   \n",
              "21                   0.45                     NaN                    NaN   \n",
              "359                   NaN                     NaN                    NaN   \n",
              "1333                  NaN                     NaN                    NaN   \n",
              "479                   NaN                     NaN                    NaN   \n",
              "...                   ...                     ...                    ...   \n",
              "1055                 0.46                     NaN                    NaN   \n",
              "537                   NaN                     NaN                    NaN   \n",
              "832                   NaN                     NaN                    NaN   \n",
              "306                   NaN                     NaN                    NaN   \n",
              "221                   NaN                     NaN                    NaN   \n",
              "\n",
              "      Batch size Compute cost notes Training cloud compute vendor  \\\n",
              "657          NaN                NaN                           NaN   \n",
              "21           NaN                NaN                           NaN   \n",
              "359          NaN                NaN                           NaN   \n",
              "1333         NaN                NaN                           NaN   \n",
              "479          NaN                NaN                           NaN   \n",
              "...          ...                ...                           ...   \n",
              "1055  16000000.0                NaN                           NaN   \n",
              "537          NaN                NaN                           NaN   \n",
              "832          NaN                NaN                           NaN   \n",
              "306    4000000.0                NaN                           NaN   \n",
              "221          NaN                NaN                           NaN   \n",
              "\n",
              "                                       Batch size notes Training data center  \\\n",
              "657                                                 NaN                  NaN   \n",
              "21                                                  NaN                  NaN   \n",
              "359                                                 NaN                  NaN   \n",
              "1333                                                NaN                  NaN   \n",
              "479                                                 NaN                  NaN   \n",
              "...                                                 ...                  ...   \n",
              "1055                                            Table 3                  NaN   \n",
              "537                                                 NaN                  NaN   \n",
              "832                                                 NaN                  NaN   \n",
              "306   Table 1 https://arxiv.org/abs/2309.16609\\n(thi...                  NaN   \n",
              "221                                                 NaN                  NaN   \n",
              "\n",
              "     Frontier training compute (FLOP) Frontier system  \n",
              "657                      3.800000e+20            True  \n",
              "21                       3.800000e+20            True  \n",
              "359                      3.800000e+20            True  \n",
              "1333                     1.900000e+21            True  \n",
              "479                      6.900000e+21            True  \n",
              "...                               ...             ...  \n",
              "1055                     2.100000e+25            True  \n",
              "537                      2.100000e+25            True  \n",
              "832                      2.100000e+25            True  \n",
              "306                      2.100000e+25            True  \n",
              "221                      5.000000e+25            True  \n",
              "\n",
              "[105 rows x 53 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frontier_df = pcd_df[pcd_df['Frontier system']]\n",
        "frontier_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjDaQcsVsyYz",
        "outputId": "7aa5fd43-3b36-45f5-997c-d57abd4a94d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Ultra\n",
            "Qwen-72B\n",
            "Inflection-2\n",
            "Yi-34B\n",
            "Skywork-13B\n",
            "ChatGLM3\n",
            "Falcon 180B\n",
            "Llama 2-34B\n",
            "Llama 2-70B\n",
            "Claude 2\n",
            "xTrimoPGLM -100B\n",
            "PaLM 2\n",
            "BloombergGPT\n",
            "PanGu-Σ\n",
            "Falcon-40B\n",
            "GPT-4\n",
            "LLaMA-13B\n",
            "LLaMA-65B\n",
            "LLaMA-7B\n",
            "ViT-22B\n",
            "GPT-3.5 (text-davinci-003)\n",
            "Galactica\n",
            "BLOOM-176B\n",
            "Taiyi-Stable Diffusion\n",
            "U-PaLM (540B)\n",
            "Whisper\n",
            "PaLI\n",
            "BlenderBot 3\n",
            "GLM-130B\n",
            "AlexaTM 20B\n",
            "ESM2-15B\n",
            "ESM2-3B\n",
            "Minerva (540B)\n",
            "Parti\n",
            "CoCa\n",
            "UL2\n",
            "OPT-175B\n",
            "Flamingo\n",
            "Stable Diffusion (LDM-KL-8-G)\n",
            "PaLM (540B)\n",
            "Chinchilla\n",
            "LaMDA\n",
            "GPT-NeoX-20B\n",
            "AlphaCode\n",
            "ERNIE 3.0 Titan\n",
            "XGLM-7.5B\n",
            "GLaM\n",
            "Gopher (280B)\n",
            "Florence\n",
            "BASIC-L\n",
            "T0-XXL\n",
            "Yuan 1.0\n",
            "Megatron-Turing NLG 530B\n",
            "AlphaFold-Multimer\n",
            "HyperCLOVA\n",
            "FLAN 137B\n",
            "SEER\n",
            "GOAT\n",
            "HuBERT\n",
            "ERNIE 3.0\n",
            "ALIGN\n",
            "DeBERTa\n",
            "CoAtNet\n",
            "ByT5-XXL\n",
            "CogView\n",
            "ProtBERT-BFD\n",
            "ProtT5-XXL\n",
            "ProtT5-XXL-BFD\n",
            "PLUG\n",
            "M6-T\n",
            "Meta Pseudo Labels\n",
            "MSA Transformer\n",
            "Switch\n",
            "CLIP (ViT L/14@336px)\n",
            "DALL-E\n",
            "ViT-Huge/14\n",
            "mT5-XXL\n",
            "Conformer + Wav2vec 2.0 + Noisy Student\n",
            "GShard (dense)\n",
            "iGPT-L\n",
            "iGPT-XL\n",
            "GPT-3 175B (davinci)\n",
            "Turing-NLG\n",
            "Meena\n",
            "ContextNet + Noisy Student\n",
            "OpenAI Five Rerun\n",
            "OpenAI Five\n",
            "AlphaStar\n",
            "T5-11B\n",
            "Megatron-BERT\n",
            "Megatron-LM (8.3B)\n",
            "RoBERTa Large\n",
            "GPT-2 (1.5B)\n",
            "FTW\n",
            "ResNeXt-101 32x48d\n",
            "AlphaZero\n",
            "AlphaGo Zero\n",
            "AlphaGo Master\n",
            "NASv3 (CIFAR-10)\n",
            "Xception\n",
            "GNMT\n",
            "AlphaGo Lee\n",
            "ResNet-152 (ImageNet)\n",
            "DeepSpeech2 (English)\n",
            "AlphaGo Fan\n"
          ]
        }
      ],
      "source": [
        "for system in frontier_df['System'][::-1]:\n",
        "  print(system)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ4rEiW4hW6_"
      },
      "source": [
        "# Constant threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8IgNL9shAZb"
      },
      "outputs": [],
      "source": [
        "compute_threshold = 1e23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGPWWQJ6hZCU"
      },
      "outputs": [],
      "source": [
        "above_threshold = pcd_df[pcd_df['Training compute (FLOP)'] > compute_threshold]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB6Qu1pBhd41",
        "outputId": "456309a2-7c4a-4f19-8e18-9922508807b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47 systems\n",
            "Gemini Ultra\n",
            "Qwen-72B\n",
            "Inflection-2\n",
            "Nemotron-3-8B\n",
            "Yi-34B\n",
            "Skywork-13B\n",
            "ChatGLM3\n",
            "Falcon 180B\n",
            "Llama 2-34B\n",
            "Llama 2-70B\n",
            "Llama 2-13B\n",
            "Claude 2\n",
            "xTrimoPGLM -100B\n",
            "PaLM 2\n",
            "StarCoder\n",
            "BloombergGPT\n",
            "PanGu-Σ\n",
            "Falcon-40B\n",
            "GPT-4\n",
            "LLaMA-65B\n",
            "ViT-22B\n",
            "GPT-3.5 (text-davinci-003)\n",
            "Galactica\n",
            "BLOOM-176B\n",
            "U-PaLM (540B)\n",
            "BlenderBot 3\n",
            "GLM-130B\n",
            "AlexaTM 20B\n",
            "Minerva (540B)\n",
            "Parti\n",
            "UL2\n",
            "OPT-175B\n",
            "Flamingo\n",
            "PaLM (540B)\n",
            "Chinchilla\n",
            "LaMDA\n",
            "AlphaCode\n",
            "ERNIE 3.0 Titan\n",
            "GLaM\n",
            "Gopher (280B)\n",
            "Yuan 1.0\n",
            "Megatron-Turing NLG 530B\n",
            "HyperCLOVA\n",
            "GPT-3 175B (davinci)\n",
            "Meena\n",
            "AlphaGo Zero\n",
            "AlphaGo Master\n"
          ]
        }
      ],
      "source": [
        "print(len(above_threshold), 'systems')\n",
        "for system in above_threshold['System'][::-1]:\n",
        "  print(system)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
