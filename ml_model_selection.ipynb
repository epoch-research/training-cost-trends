{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPSm37gghSrl"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:16.086433400Z",
     "start_time": "2024-05-21T21:31:13.561518800Z"
    },
    "id": "8Edmo7vA2Eg1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.210827700Z",
     "start_time": "2024-05-21T21:31:16.095336500Z"
    },
    "id": "fXBbtVKi2LmG"
   },
   "outputs": [],
   "source": [
    "data_url = 'https://epochai.org/data/epochdb/all_systems.csv'\n",
    "dtypes = {\n",
    "    'Training compute (FLOP)': np.float64,\n",
    "}\n",
    "pcd_df = pd.read_csv(data_url, dtype=dtypes)\n",
    "pcd_df['Decimal year'] = pd.to_datetime(pcd_df['Publication date']).dt.year + (pd.to_datetime(pcd_df['Publication date']).dt.month - 1) / 12 + (pd.to_datetime(pcd_df['Publication date']).dt.day - 1) / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.288846400Z",
     "start_time": "2024-05-21T21:31:17.210827700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yyQJeGOA2m7e",
    "outputId": "0fe58fa3-79c0-46d1-f5ff-00802616c0b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Parameters notes</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "      <th>Training compute notes</th>\n",
       "      <th>...</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Base model</th>\n",
       "      <th>Finetune compute notes</th>\n",
       "      <th>Training cloud compute vendor</th>\n",
       "      <th>Batch size notes</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Training compute upper bound</th>\n",
       "      <th>Archived links</th>\n",
       "      <th>Benchmark data</th>\n",
       "      <th>Decimal year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fugaku-LLM</td>\n",
       "      <td>Language</td>\n",
       "      <td>Tohoku University,CyberAgent,Tokyo Institute o...</td>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>Release of “Fugaku-LLM” – a large language mod...</td>\n",
       "      <td>https://www.fujitsu.com/global/about/resources...</td>\n",
       "      <td>1.300000e+10</td>\n",
       "      <td>\"Fugaku-LLM has 13 billion parameters (2)\"</td>\n",
       "      <td>2.964000e+22</td>\n",
       "      <td>https://www.wolframalpha.com/input?i=6+FLOP+*+...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.357991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gemini 1.5 Flash</td>\n",
       "      <td>Multimodal,Language,Vision,Audio</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>Gemini 1.5: Unlocking multimodal understanding...</td>\n",
       "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.357991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen 1.5 110B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>Qwen1.5-110B: The First 100B+ Model of the Qwe...</td>\n",
       "      <td>https://qwenlm.github.io/blog/qwen1.5-110b/?re...</td>\n",
       "      <td>1.100000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.315753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phi-3-medium 14B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>Phi-3 Technical Report: A Highly Capable Langu...</td>\n",
       "      <td>https://arxiv.org/abs/2404.14219</td>\n",
       "      <td>1.400000e+10</td>\n",
       "      <td>14B</td>\n",
       "      <td>4.032000e+23</td>\n",
       "      <td>counting operations: 6×4.8×10^12×14×10^9 ≈ 4.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.310274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SenseNova 5.0</td>\n",
       "      <td>Language</td>\n",
       "      <td>SenseTime</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://zhidx.com/p/421866.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.310274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>Sequence-based pattern recognition</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>1955-03-01</td>\n",
       "      <td>Pattern recognition and modern computers</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/1455292.1455310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1955.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Self Organizing System</td>\n",
       "      <td>Other</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>1955-03-01</td>\n",
       "      <td>Generalization of pattern recognition in a sel...</td>\n",
       "      <td>https://dl.acm.org/doi/10.1145/1455292.1455309</td>\n",
       "      <td>2.250000e+02</td>\n",
       "      <td>Figure 4 contains the learnt weight matrix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1955.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Genetic algorithm</td>\n",
       "      <td>Other</td>\n",
       "      <td>Institute for Advanced Study</td>\n",
       "      <td>1954-07-02</td>\n",
       "      <td>Numerical testing of evolution theories</td>\n",
       "      <td>https://link.springer.com/article/10.1007/BF01...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>266.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1954.502740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>SNARC</td>\n",
       "      <td>Robotics</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>1952-01-08</td>\n",
       "      <td>A Neural-Analogue Calculator Based upon a Prob...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stochastic_neura...</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>The link below seems to suggest the SNARC had ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1952.019178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Theseus</td>\n",
       "      <td>Robotics</td>\n",
       "      <td>Bell Laboratories</td>\n",
       "      <td>1950-07-02</td>\n",
       "      <td>Mighty Mouse</td>\n",
       "      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>The learned part is the maze configuration. Th...</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>The \"training\" consists on the mouse running a...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950.502740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1308 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  System                            Domain  \\\n",
       "0                             Fugaku-LLM                          Language   \n",
       "1                       Gemini 1.5 Flash  Multimodal,Language,Vision,Audio   \n",
       "2                          Qwen 1.5 110B                          Language   \n",
       "3                       phi-3-medium 14B                          Language   \n",
       "4                          SenseNova 5.0                          Language   \n",
       "...                                  ...                               ...   \n",
       "1303  Sequence-based pattern recognition                            Vision   \n",
       "1304              Self Organizing System                             Other   \n",
       "1305                   Genetic algorithm                             Other   \n",
       "1306                               SNARC                          Robotics   \n",
       "1307                             Theseus                          Robotics   \n",
       "\n",
       "                                           Organization Publication date  \\\n",
       "0     Tohoku University,CyberAgent,Tokyo Institute o...       2024-05-10   \n",
       "1                                       Google DeepMind       2024-05-10   \n",
       "2                                               Alibaba       2024-04-25   \n",
       "3                                             Microsoft       2024-04-23   \n",
       "4                                             SenseTime       2024-04-23   \n",
       "...                                                 ...              ...   \n",
       "1303        Massachusetts Institute of Technology (MIT)       1955-03-01   \n",
       "1304        Massachusetts Institute of Technology (MIT)       1955-03-01   \n",
       "1305                       Institute for Advanced Study       1954-07-02   \n",
       "1306                                 Harvard University       1952-01-08   \n",
       "1307                                  Bell Laboratories       1950-07-02   \n",
       "\n",
       "                                              Reference  \\\n",
       "0     Release of “Fugaku-LLM” – a large language mod...   \n",
       "1     Gemini 1.5: Unlocking multimodal understanding...   \n",
       "2     Qwen1.5-110B: The First 100B+ Model of the Qwe...   \n",
       "3     Phi-3 Technical Report: A Highly Capable Langu...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1303           Pattern recognition and modern computers   \n",
       "1304  Generalization of pattern recognition in a sel...   \n",
       "1305            Numerical testing of evolution theories   \n",
       "1306  A Neural-Analogue Calculator Based upon a Prob...   \n",
       "1307                                       Mighty Mouse   \n",
       "\n",
       "                                                   Link    Parameters  \\\n",
       "0     https://www.fujitsu.com/global/about/resources...  1.300000e+10   \n",
       "1     https://storage.googleapis.com/deepmind-media/...           NaN   \n",
       "2     https://qwenlm.github.io/blog/qwen1.5-110b/?re...  1.100000e+11   \n",
       "3                      https://arxiv.org/abs/2404.14219  1.400000e+10   \n",
       "4                       https://zhidx.com/p/421866.html           NaN   \n",
       "...                                                 ...           ...   \n",
       "1303     https://dl.acm.org/doi/10.1145/1455292.1455310           NaN   \n",
       "1304     https://dl.acm.org/doi/10.1145/1455292.1455309  2.250000e+02   \n",
       "1305  https://link.springer.com/article/10.1007/BF01...           NaN   \n",
       "1306  https://en.wikipedia.org/wiki/Stochastic_neura...  4.000000e+01   \n",
       "1307  https://www.technologyreview.com/2018/12/19/13...  4.000000e+01   \n",
       "\n",
       "                                       Parameters notes  \\\n",
       "0            \"Fugaku-LLM has 13 billion parameters (2)\"   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   14B   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1303                                                NaN   \n",
       "1304         Figure 4 contains the learnt weight matrix   \n",
       "1305                                                NaN   \n",
       "1306  The link below seems to suggest the SNARC had ...   \n",
       "1307  The learned part is the maze configuration. Th...   \n",
       "\n",
       "      Training compute (FLOP)  \\\n",
       "0                2.964000e+22   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                4.032000e+23   \n",
       "4                         NaN   \n",
       "...                       ...   \n",
       "1303                      NaN   \n",
       "1304                      NaN   \n",
       "1305                      NaN   \n",
       "1306                      NaN   \n",
       "1307             4.000000e+01   \n",
       "\n",
       "                                 Training compute notes  ... Citations  \\\n",
       "0     https://www.wolframalpha.com/input?i=6+FLOP+*+...  ...       NaN   \n",
       "1                                                   NaN  ...       NaN   \n",
       "2                                                   NaN  ...       NaN   \n",
       "3     counting operations: 6×4.8×10^12×14×10^9 ≈ 4.0...  ...       NaN   \n",
       "4                                                   NaN  ...       NaN   \n",
       "...                                                 ...  ...       ...   \n",
       "1303                                                NaN  ...     290.0   \n",
       "1304                                                NaN  ...      93.0   \n",
       "1305                                                NaN  ...     266.0   \n",
       "1306                                                NaN  ...      33.0   \n",
       "1307  The \"training\" consists on the mouse running a...  ...       0.0   \n",
       "\n",
       "      Base model Finetune compute notes Training cloud compute vendor  \\\n",
       "0            NaN                    NaN                           NaN   \n",
       "1            NaN                    NaN                           NaN   \n",
       "2            NaN                    NaN                           NaN   \n",
       "3            NaN                    NaN                           NaN   \n",
       "4            NaN                    NaN                           NaN   \n",
       "...          ...                    ...                           ...   \n",
       "1303         NaN                    NaN                           NaN   \n",
       "1304         NaN                    NaN                           NaN   \n",
       "1305         NaN                    NaN                           NaN   \n",
       "1306         NaN                    NaN                           NaN   \n",
       "1307         NaN                    NaN                           NaN   \n",
       "\n",
       "     Batch size notes Finetune compute (FLOP) Training compute upper bound  \\\n",
       "0                 NaN                     NaN                          NaN   \n",
       "1                 NaN                     NaN                          NaN   \n",
       "2                 NaN                     NaN                          NaN   \n",
       "3                 NaN                     NaN                          NaN   \n",
       "4                 NaN                     NaN                          NaN   \n",
       "...               ...                     ...                          ...   \n",
       "1303              NaN                     NaN                          NaN   \n",
       "1304              NaN                     NaN                          NaN   \n",
       "1305              NaN                     NaN                          NaN   \n",
       "1306              NaN                     NaN                          NaN   \n",
       "1307              NaN                     NaN                          NaN   \n",
       "\n",
       "     Archived links Benchmark data Decimal year  \n",
       "0               NaN            NaN  2024.357991  \n",
       "1               NaN            NaN  2024.357991  \n",
       "2               NaN            NaN  2024.315753  \n",
       "3               NaN            NaN  2024.310274  \n",
       "4               NaN            NaN  2024.310274  \n",
       "...             ...            ...          ...  \n",
       "1303            NaN            NaN  1955.166667  \n",
       "1304            NaN            NaN  1955.166667  \n",
       "1305            NaN            NaN  1954.502740  \n",
       "1306            NaN            NaN  1952.019178  \n",
       "1307            NaN            NaN  1950.502740  \n",
       "\n",
       "[1308 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.304527400Z",
     "start_time": "2024-05-21T21:31:17.288846400Z"
    },
    "id": "XZ0FKyaZ3h_W"
   },
   "outputs": [],
   "source": [
    "pcd_df['Publication date'] = pd.to_datetime(pcd_df['Publication date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.351750400Z",
     "start_time": "2024-05-21T21:31:17.304527400Z"
    },
    "id": "rcOYiwwg3oVY"
   },
   "outputs": [],
   "source": [
    "pcd_df.sort_values('Publication date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.414608800Z",
     "start_time": "2024-05-21T21:31:17.323609400Z"
    },
    "id": "QLUi4aysAXWr"
   },
   "outputs": [],
   "source": [
    "pcd_df.dropna(subset=['Publication date', 'Notability criteria', 'Training compute (FLOP)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.509956200Z",
     "start_time": "2024-05-21T21:31:17.351750400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wGGuurmk4uZd",
    "outputId": "5d822c9c-67e5-4f2c-ff8b-9418f82d05e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Parameters notes</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "      <th>Training compute notes</th>\n",
       "      <th>...</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Base model</th>\n",
       "      <th>Finetune compute notes</th>\n",
       "      <th>Training cloud compute vendor</th>\n",
       "      <th>Batch size notes</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Training compute upper bound</th>\n",
       "      <th>Archived links</th>\n",
       "      <th>Benchmark data</th>\n",
       "      <th>Decimal year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Theseus</td>\n",
       "      <td>Robotics</td>\n",
       "      <td>Bell Laboratories</td>\n",
       "      <td>1950-07-02</td>\n",
       "      <td>Mighty Mouse</td>\n",
       "      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>The learned part is the maze configuration. Th...</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>The \"training\" consists on the mouse running a...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950.502740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>Perceptron Mark I</td>\n",
       "      <td>Other</td>\n",
       "      <td>Cornell Aeronautical Laboratory,Cornell Univer...</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>The Perceptron—a perceiving and recognizing au...</td>\n",
       "      <td>https://blogs.umass.edu/brain-wars/files/2016/...</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>\"Figure 4.8 Illustration of the Mark 1 percept...</td>\n",
       "      <td>6.948949e+05</td>\n",
       "      <td>Extracted from AI and Compute (https://openai....</td>\n",
       "      <td>...</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1957.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Pandemonium (morse)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>1959-02-01</td>\n",
       "      <td>Pandemonium: A Paradigm for Learning</td>\n",
       "      <td>https://aitopics.org/doc/classics:504E1BAC/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The paper mentions 11 function types. Unclear ...</td>\n",
       "      <td>6.000000e+08</td>\n",
       "      <td>The paper mentions using an IBM 704, which can...</td>\n",
       "      <td>...</td>\n",
       "      <td>1453.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1959.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>Samuel Neural Checkers</td>\n",
       "      <td>Games</td>\n",
       "      <td>IBM</td>\n",
       "      <td>1959-07-01</td>\n",
       "      <td>Some studies in machine learning using the gam...</td>\n",
       "      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>\"with 16 terms for generalization learning\"\\n\\...</td>\n",
       "      <td>4.284000e+08</td>\n",
       "      <td>\"it can learn to do this in a remarkably short...</td>\n",
       "      <td>...</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1959.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>Perceptron (1960)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Cornell Aeronautical Laboratory</td>\n",
       "      <td>1960-03-30</td>\n",
       "      <td>Perceptron Simulation Experiments</td>\n",
       "      <td>https://www.semanticscholar.org/paper/Perceptr...</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>\" The first program was designed to handle\\nup...</td>\n",
       "      <td>7.200000e+08</td>\n",
       "      <td>4000 * 12000 * 15\\nfrom the text \"This program...</td>\n",
       "      <td>...</td>\n",
       "      <td>394.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960.246119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MegaScale (Production)</td>\n",
       "      <td>Language</td>\n",
       "      <td>ByteDance,Peking University</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>MegaScale: Scaling Large Language Model Traini...</td>\n",
       "      <td>https://arxiv.org/abs/2402.15627</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>Production run is stated to have \"hundreds of ...</td>\n",
       "      <td>1.200000e+25</td>\n",
       "      <td>Speculative. The model is stated to have train...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.143607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Inflection-2.5</td>\n",
       "      <td>Language</td>\n",
       "      <td>Inflection AI</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>Inflection-2.5: meet the world's best personal AI</td>\n",
       "      <td>https://inflection.ai/inflection-2-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000100e+25</td>\n",
       "      <td>\"Inflection-1 used approximately 4% the traini...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.183105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MM1-30B</td>\n",
       "      <td>Multimodal,Language,Vision</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>MM1: Methods, Analysis &amp; Insights from Multimo...</td>\n",
       "      <td>https://arxiv.org/abs/2403.09611</td>\n",
       "      <td>3.000000e+10</td>\n",
       "      <td>30B</td>\n",
       "      <td>4.860000e+23</td>\n",
       "      <td>Pre-trained on ~2B image-text pairs and 2T tok...</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.202283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mixture-of-Depths</td>\n",
       "      <td>Language</td>\n",
       "      <td>Google DeepMind,McGill University,Mila</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>Mixture-of-Depths: Dynamically allocating comp...</td>\n",
       "      <td>https://arxiv.org/abs/2404.02258</td>\n",
       "      <td>3.000000e+09</td>\n",
       "      <td>Figure 4: \"We used the 12.5% capacity MoD vari...</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>Figure 4: \"We used the 12.5% capacity MoD vari...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.252740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama 3-70B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>Introducing Meta Llama 3: The most capable ope...</td>\n",
       "      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n",
       "      <td>7.000000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.300000e+24</td>\n",
       "      <td>direct calculation\\n15000000000000 tokens*7000...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.296575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      System                      Domain  \\\n",
       "1307                 Theseus                    Robotics   \n",
       "1301       Perceptron Mark I                       Other   \n",
       "1300     Pandemonium (morse)                    Language   \n",
       "1299  Samuel Neural Checkers                       Games   \n",
       "1297       Perceptron (1960)                      Vision   \n",
       "...                      ...                         ...   \n",
       "30    MegaScale (Production)                    Language   \n",
       "21            Inflection-2.5                    Language   \n",
       "20                   MM1-30B  Multimodal,Language,Vision   \n",
       "13         Mixture-of-Depths                    Language   \n",
       "5                Llama 3-70B                    Language   \n",
       "\n",
       "                                           Organization Publication date  \\\n",
       "1307                                  Bell Laboratories       1950-07-02   \n",
       "1301  Cornell Aeronautical Laboratory,Cornell Univer...       1957-01-01   \n",
       "1300        Massachusetts Institute of Technology (MIT)       1959-02-01   \n",
       "1299                                                IBM       1959-07-01   \n",
       "1297                    Cornell Aeronautical Laboratory       1960-03-30   \n",
       "...                                                 ...              ...   \n",
       "30                          ByteDance,Peking University       2024-02-23   \n",
       "21                                        Inflection AI       2024-03-07   \n",
       "20                                                Apple       2024-03-14   \n",
       "13               Google DeepMind,McGill University,Mila       2024-04-02   \n",
       "5                                               Meta AI       2024-04-18   \n",
       "\n",
       "                                              Reference  \\\n",
       "1307                                       Mighty Mouse   \n",
       "1301  The Perceptron—a perceiving and recognizing au...   \n",
       "1300               Pandemonium: A Paradigm for Learning   \n",
       "1299  Some studies in machine learning using the gam...   \n",
       "1297                  Perceptron Simulation Experiments   \n",
       "...                                                 ...   \n",
       "30    MegaScale: Scaling Large Language Model Traini...   \n",
       "21    Inflection-2.5: meet the world's best personal AI   \n",
       "20    MM1: Methods, Analysis & Insights from Multimo...   \n",
       "13    Mixture-of-Depths: Dynamically allocating comp...   \n",
       "5     Introducing Meta Llama 3: The most capable ope...   \n",
       "\n",
       "                                                   Link    Parameters  \\\n",
       "1307  https://www.technologyreview.com/2018/12/19/13...  4.000000e+01   \n",
       "1301  https://blogs.umass.edu/brain-wars/files/2016/...  1.000000e+03   \n",
       "1300        https://aitopics.org/doc/classics:504E1BAC/           NaN   \n",
       "1299  https://ieeexplore.ieee.org/abstract/document/...  1.600000e+01   \n",
       "1297  https://www.semanticscholar.org/paper/Perceptr...  1.000000e+03   \n",
       "...                                                 ...           ...   \n",
       "30                     https://arxiv.org/abs/2402.15627  5.300000e+11   \n",
       "21                 https://inflection.ai/inflection-2-5           NaN   \n",
       "20                     https://arxiv.org/abs/2403.09611  3.000000e+10   \n",
       "13                     https://arxiv.org/abs/2404.02258  3.000000e+09   \n",
       "5     https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n",
       "\n",
       "                                       Parameters notes  \\\n",
       "1307  The learned part is the maze configuration. Th...   \n",
       "1301  \"Figure 4.8 Illustration of the Mark 1 percept...   \n",
       "1300  The paper mentions 11 function types. Unclear ...   \n",
       "1299  \"with 16 terms for generalization learning\"\\n\\...   \n",
       "1297  \" The first program was designed to handle\\nup...   \n",
       "...                                                 ...   \n",
       "30    Production run is stated to have \"hundreds of ...   \n",
       "21                                                  NaN   \n",
       "20                                                  30B   \n",
       "13    Figure 4: \"We used the 12.5% capacity MoD vari...   \n",
       "5                                                   NaN   \n",
       "\n",
       "      Training compute (FLOP)  \\\n",
       "1307             4.000000e+01   \n",
       "1301             6.948949e+05   \n",
       "1300             6.000000e+08   \n",
       "1299             4.284000e+08   \n",
       "1297             7.200000e+08   \n",
       "...                       ...   \n",
       "30               1.200000e+25   \n",
       "21               1.000100e+25   \n",
       "20               4.860000e+23   \n",
       "13               1.000000e+20   \n",
       "5                6.300000e+24   \n",
       "\n",
       "                                 Training compute notes  ... Citations  \\\n",
       "1307  The \"training\" consists on the mouse running a...  ...       0.0   \n",
       "1301  Extracted from AI and Compute (https://openai....  ...    1610.0   \n",
       "1300  The paper mentions using an IBM 704, which can...  ...    1453.0   \n",
       "1299  \"it can learn to do this in a remarkably short...  ...    4509.0   \n",
       "1297  4000 * 12000 * 15\\nfrom the text \"This program...  ...     394.0   \n",
       "...                                                 ...  ...       ...   \n",
       "30    Speculative. The model is stated to have train...  ...       1.0   \n",
       "21    \"Inflection-1 used approximately 4% the traini...  ...       NaN   \n",
       "20    Pre-trained on ~2B image-text pairs and 2T tok...  ...      11.0   \n",
       "13    Figure 4: \"We used the 12.5% capacity MoD vari...  ...       1.0   \n",
       "5     direct calculation\\n15000000000000 tokens*7000...  ...       NaN   \n",
       "\n",
       "      Base model Finetune compute notes Training cloud compute vendor  \\\n",
       "1307         NaN                    NaN                           NaN   \n",
       "1301         NaN                    NaN                           NaN   \n",
       "1300         NaN                    NaN                           NaN   \n",
       "1299         NaN                    NaN                           NaN   \n",
       "1297         NaN                    NaN                           NaN   \n",
       "...          ...                    ...                           ...   \n",
       "30           NaN                    NaN                           NaN   \n",
       "21           NaN                    NaN                           NaN   \n",
       "20           NaN                    NaN                           NaN   \n",
       "13           NaN                    NaN                           NaN   \n",
       "5            NaN                    NaN                           NaN   \n",
       "\n",
       "     Batch size notes Finetune compute (FLOP) Training compute upper bound  \\\n",
       "1307              NaN                     NaN                          NaN   \n",
       "1301              NaN                     NaN                          NaN   \n",
       "1300              NaN                     NaN                          NaN   \n",
       "1299              NaN                     NaN                          NaN   \n",
       "1297              NaN                     NaN                          NaN   \n",
       "...               ...                     ...                          ...   \n",
       "30                NaN                     NaN                          NaN   \n",
       "21                NaN                     NaN                          NaN   \n",
       "20                NaN                     NaN                          NaN   \n",
       "13                NaN                     NaN                          NaN   \n",
       "5                 NaN                     NaN                          NaN   \n",
       "\n",
       "     Archived links Benchmark data Decimal year  \n",
       "1307            NaN            NaN  1950.502740  \n",
       "1301            NaN            NaN  1957.000000  \n",
       "1300            NaN            NaN  1959.083333  \n",
       "1299            NaN            NaN  1959.500000  \n",
       "1297            NaN            NaN  1960.246119  \n",
       "...             ...            ...          ...  \n",
       "30              NaN            NaN  2024.143607  \n",
       "21              NaN            NaN  2024.183105  \n",
       "20              NaN            NaN  2024.202283  \n",
       "13              NaN            NaN  2024.252740  \n",
       "5               NaN            NaN  2024.296575  \n",
       "\n",
       "[368 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.557085700Z",
     "start_time": "2024-05-21T21:31:17.383067900Z"
    },
    "id": "zFUQoG_01L8m"
   },
   "outputs": [],
   "source": [
    "outlier_window_size = 2  # years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.557085700Z",
     "start_time": "2024-05-21T21:31:17.414608800Z"
    }
   },
   "outputs": [],
   "source": [
    "start_large_scale_era = '2015-10-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrayDGa4hK6X"
   },
   "source": [
    "# Top n all-time most compute-intensive (FIRST CHOICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.365327500Z",
     "start_time": "2024-05-21T21:31:17.414608800Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in range(1, 21):\n",
    "    # Add a column to mark the top n models\n",
    "    pcd_df[f'top_{n}_at_release'] = False\n",
    "    \n",
    "    for row, model in pcd_df.iterrows():\n",
    "        # Filter for models released through the model's release date\n",
    "        yearly_df = pcd_df[pcd_df['Decimal year'] <= model['Decimal year']]\n",
    "        # get the top n models by compute\n",
    "        top_n_models = yearly_df.nlargest(n, 'Training compute (FLOP)')\n",
    "        # mark these models in the original dataframe\n",
    "        pcd_df.loc[top_n_models.index, f'top_{n}_at_release'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.399202100Z",
     "start_time": "2024-05-21T21:31:30.366362100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['System', 'Domain', 'Organization', 'Publication date', 'Reference',\n",
       "       'Link', 'Parameters', 'Parameters notes', 'Training compute (FLOP)',\n",
       "       'Training compute notes', 'Training dataset notes',\n",
       "       'Training dataset size (datapoints)', 'Dataset size notes', 'Abstract',\n",
       "       'Confidence', 'Model accessibility', 'Last modified', 'Created By',\n",
       "       'Country (from Organization)', 'Organization categorization', 'Authors',\n",
       "       'Training time notes', 'Training hardware', 'Training dataset',\n",
       "       'Notability criteria', 'Notability criteria notes', 'Exclude',\n",
       "       'Hardware quantity', 'Hardware utilization', 'Training time (hours)',\n",
       "       'Batch size', 'Approach', 'Training compute lower bound', 'Epochs',\n",
       "       'Foundation model', 'Training data center', 'Citations', 'Base model',\n",
       "       'Finetune compute notes', 'Training cloud compute vendor',\n",
       "       'Batch size notes', 'Finetune compute (FLOP)',\n",
       "       'Training compute upper bound', 'Archived links', 'Benchmark data',\n",
       "       'Decimal year', 'top_1_at_release', 'top_2_at_release',\n",
       "       'top_3_at_release', 'top_4_at_release', 'top_5_at_release',\n",
       "       'top_6_at_release', 'top_7_at_release', 'top_8_at_release',\n",
       "       'top_9_at_release', 'top_10_at_release', 'top_11_at_release',\n",
       "       'top_12_at_release', 'top_13_at_release', 'top_14_at_release',\n",
       "       'top_15_at_release', 'top_16_at_release', 'top_17_at_release',\n",
       "       'top_18_at_release', 'top_19_at_release', 'top_20_at_release'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.446484200Z",
     "start_time": "2024-05-21T21:31:30.399202100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pcd_df['top_4_at_release'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.446484200Z",
     "start_time": "2024-05-21T21:31:30.430780900Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_df_n = pcd_df[(pcd_df['Decimal year'] > 2015.75) & (pcd_df['Decimal year'] < 2024)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.700498200Z",
     "start_time": "2024-05-21T21:31:30.446484200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_n = [np.sum(pcd_df_n[f'top_{n}_at_release']) for n in range(1, 21)]\n",
    "plt.scatter(range(1, 21), top_n)\n",
    "plt.xticks(ticks=range(1, 21))\n",
    "plt.xlabel('n-value for top n')\n",
    "plt.ylabel('Models which have ever been in the top n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.747327700Z",
     "start_time": "2024-05-21T21:31:30.700498200Z"
    }
   },
   "outputs": [],
   "source": [
    "top_n_models = {}\n",
    "for n in range(1, 21):\n",
    "    models = pcd_df_n[pcd_df_n[f'top_{n}_at_release']]['System'].values.tolist()\n",
    "    top_n_models[n] = set(models)\n",
    "\n",
    "for n in range(20, 1, -1):\n",
    "    top_n_models[n] = list(top_n_models[n].difference(top_n_models[n-1]))\n",
    "top_n_models[1] = list(top_n_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, 21):\n",
    "    top_n_models[n] = list(sorted(top_n_models[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.747327700Z",
     "start_time": "2024-05-21T21:31:30.731783700Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/frontier_systems_by_top_n.json', 'w') as f:\n",
    "    json.dump(top_n_models, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrayDGa4hK6X"
   },
   "source": [
    "# Default large scale systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ort2OjXauNI-"
   },
   "source": [
    "https://colab.research.google.com/drive/1PLGY5ErysqQMfy7Z08uIR2cTnnDgSaVR?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.762947700Z",
     "start_time": "2024-05-21T21:31:30.747327700Z"
    },
    "id": "Xo0BSLmQ4RpG"
   },
   "outputs": [],
   "source": [
    "high_outliers_z_value_threshold = 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:31.237076300Z",
     "start_time": "2024-05-21T21:31:30.762947700Z"
    },
    "id": "sTTmucLNtU8l"
   },
   "outputs": [],
   "source": [
    "large_scale_idx = set()\n",
    "\n",
    "for index, row in pcd_df.iterrows():\n",
    "  # Filter entries in a 2-year window around the paper\n",
    "  window_size = pd.Timedelta(f'{outlier_window_size*52*7} days')\n",
    "  half_window_size = window_size / 2\n",
    "  mask = ( row['Publication date'] - half_window_size <= pcd_df['Publication date'] ) &\\\n",
    "        ( pcd_df['Publication date'] <= row['Publication date'] + half_window_size )\n",
    "  window_df = pcd_df[mask].copy()\n",
    "\n",
    "  if len(window_df) < 2: continue\n",
    "\n",
    "  window_df['Training compute (FLOP) z scores'] = stats.zscore(np.log10(window_df['Training compute (FLOP)'].values))\n",
    "  if window_df.loc[index, 'Training compute (FLOP) z scores'] > high_outliers_z_value_threshold:\n",
    "    large_scale_idx.add(index)\n",
    "\n",
    "large_scale_mask = pcd_df.index.isin(large_scale_idx) & (pcd_df['Publication date'] > start_large_scale_era)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:31.252618300Z",
     "start_time": "2024-05-21T21:31:31.237076300Z"
    },
    "id": "w2HakL5g4iUq"
   },
   "outputs": [],
   "source": [
    "large_scale_df = pcd_df[large_scale_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:31.299553500Z",
     "start_time": "2024-05-21T21:31:31.252618300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y4-TmYMQ7Iex",
    "outputId": "485901a3-4ccd-4956-bba8-e81f64bf5c0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Parameters notes</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "      <th>Training compute notes</th>\n",
       "      <th>...</th>\n",
       "      <th>top_11_at_release</th>\n",
       "      <th>top_12_at_release</th>\n",
       "      <th>top_13_at_release</th>\n",
       "      <th>top_14_at_release</th>\n",
       "      <th>top_15_at_release</th>\n",
       "      <th>top_16_at_release</th>\n",
       "      <th>top_17_at_release</th>\n",
       "      <th>top_18_at_release</th>\n",
       "      <th>top_19_at_release</th>\n",
       "      <th>top_20_at_release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>https://www.nature.com/articles/nature16961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.900000e+21</td>\n",
       "      <td>This number is pretty uncertain. I expect it t...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>Language</td>\n",
       "      <td>Google</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>Google's Neural Machine Translation System: Br...</td>\n",
       "      <td>https://arxiv.org/abs/1609.08144</td>\n",
       "      <td>2.780000e+08</td>\n",
       "      <td>Table 5 in 'Outrageously Large Neural Networks...</td>\n",
       "      <td>6.900000e+21</td>\n",
       "      <td>sqrt(10 * 100) factor added because production...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>Xception</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Google</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>Xception: Deep Learning with Depthwise Separab...</td>\n",
       "      <td>https://arxiv.org/abs/1610.02357</td>\n",
       "      <td>2.285595e+07</td>\n",
       "      <td>Table 3</td>\n",
       "      <td>4.360000e+20</td>\n",
       "      <td>60 K80 GPUs * 30 days * 8.5 TFLOPS/GPU * 0.33 ...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Google Brain</td>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>Neural Architecture Search with Reinforcement ...</td>\n",
       "      <td>https://arxiv.org/abs/1611.01578</td>\n",
       "      <td>3.740000e+07</td>\n",
       "      <td>Table 1</td>\n",
       "      <td>2.200000e+21</td>\n",
       "      <td>50 epochs * 50,000 images * 10.0 GFLOPSs * 128...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Libratus</td>\n",
       "      <td>Games</td>\n",
       "      <td>Carnegie Mellon University (CMU)</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Libratus: The Superhuman AI for No-Limit Poker</td>\n",
       "      <td>https://www.cs.cmu.edu/~noamb/papers/17-IJCAI-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.510000e+20</td>\n",
       "      <td>\"In total, Libratus used about 25 million core...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Qwen-72B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n",
       "      <td>7.200000e+10</td>\n",
       "      <td>72B</td>\n",
       "      <td>1.300000e+24</td>\n",
       "      <td>72 billion params, 3 trillion tokens\\n72b * 3T...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Gemini 1.0 Ultra</td>\n",
       "      <td>Multimodal,Language,Vision</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>This number is an estimate based on limited ev...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MegaScale (Production)</td>\n",
       "      <td>Language</td>\n",
       "      <td>ByteDance,Peking University</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>MegaScale: Scaling Large Language Model Traini...</td>\n",
       "      <td>https://arxiv.org/abs/2402.15627</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>Production run is stated to have \"hundreds of ...</td>\n",
       "      <td>1.200000e+25</td>\n",
       "      <td>Speculative. The model is stated to have train...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Inflection-2.5</td>\n",
       "      <td>Language</td>\n",
       "      <td>Inflection AI</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>Inflection-2.5: meet the world's best personal AI</td>\n",
       "      <td>https://inflection.ai/inflection-2-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000100e+25</td>\n",
       "      <td>\"Inflection-1 used approximately 4% the traini...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama 3-70B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>Introducing Meta Llama 3: The most capable ope...</td>\n",
       "      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n",
       "      <td>7.000000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.300000e+24</td>\n",
       "      <td>direct calculation\\n15000000000000 tokens*7000...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      System                      Domain  \\\n",
       "1019             AlphaGo Lee                       Games   \n",
       "980                     GNMT                    Language   \n",
       "979                 Xception                      Vision   \n",
       "973         NASv3 (CIFAR-10)                      Vision   \n",
       "957                 Libratus                       Games   \n",
       "...                      ...                         ...   \n",
       "82                  Qwen-72B                    Language   \n",
       "74          Gemini 1.0 Ultra  Multimodal,Language,Vision   \n",
       "30    MegaScale (Production)                    Language   \n",
       "21            Inflection-2.5                    Language   \n",
       "5                Llama 3-70B                    Language   \n",
       "\n",
       "                          Organization Publication date  \\\n",
       "1019                          DeepMind       2016-01-27   \n",
       "980                             Google       2016-09-26   \n",
       "979                             Google       2016-10-07   \n",
       "973                       Google Brain       2016-11-05   \n",
       "957   Carnegie Mellon University (CMU)       2017-01-01   \n",
       "...                                ...              ...   \n",
       "82                             Alibaba       2023-11-30   \n",
       "74                     Google DeepMind       2023-12-06   \n",
       "30         ByteDance,Peking University       2024-02-23   \n",
       "21                       Inflection AI       2024-03-07   \n",
       "5                              Meta AI       2024-04-18   \n",
       "\n",
       "                                              Reference  \\\n",
       "1019  Mastering the game of Go with deep neural netw...   \n",
       "980   Google's Neural Machine Translation System: Br...   \n",
       "979   Xception: Deep Learning with Depthwise Separab...   \n",
       "973   Neural Architecture Search with Reinforcement ...   \n",
       "957      Libratus: The Superhuman AI for No-Limit Poker   \n",
       "...                                                 ...   \n",
       "82                                                  NaN   \n",
       "74    Gemini: A Family of Highly Capable Multimodal ...   \n",
       "30    MegaScale: Scaling Large Language Model Traini...   \n",
       "21    Inflection-2.5: meet the world's best personal AI   \n",
       "5     Introducing Meta Llama 3: The most capable ope...   \n",
       "\n",
       "                                                   Link    Parameters  \\\n",
       "1019        https://www.nature.com/articles/nature16961           NaN   \n",
       "980                    https://arxiv.org/abs/1609.08144  2.780000e+08   \n",
       "979                    https://arxiv.org/abs/1610.02357  2.285595e+07   \n",
       "973                    https://arxiv.org/abs/1611.01578  3.740000e+07   \n",
       "957   https://www.cs.cmu.edu/~noamb/papers/17-IJCAI-...           NaN   \n",
       "...                                                 ...           ...   \n",
       "82                 https://huggingface.co/Qwen/Qwen-72B  7.200000e+10   \n",
       "74    https://storage.googleapis.com/deepmind-media/...           NaN   \n",
       "30                     https://arxiv.org/abs/2402.15627  5.300000e+11   \n",
       "21                 https://inflection.ai/inflection-2-5           NaN   \n",
       "5     https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n",
       "\n",
       "                                       Parameters notes  \\\n",
       "1019                                                NaN   \n",
       "980   Table 5 in 'Outrageously Large Neural Networks...   \n",
       "979                                             Table 3   \n",
       "973                                             Table 1   \n",
       "957                                                 NaN   \n",
       "...                                                 ...   \n",
       "82                                                  72B   \n",
       "74                                                  NaN   \n",
       "30    Production run is stated to have \"hundreds of ...   \n",
       "21                                                  NaN   \n",
       "5                                                   NaN   \n",
       "\n",
       "      Training compute (FLOP)  \\\n",
       "1019             1.900000e+21   \n",
       "980              6.900000e+21   \n",
       "979              4.360000e+20   \n",
       "973              2.200000e+21   \n",
       "957              5.510000e+20   \n",
       "...                       ...   \n",
       "82               1.300000e+24   \n",
       "74               5.000000e+25   \n",
       "30               1.200000e+25   \n",
       "21               1.000100e+25   \n",
       "5                6.300000e+24   \n",
       "\n",
       "                                 Training compute notes  ...  \\\n",
       "1019  This number is pretty uncertain. I expect it t...  ...   \n",
       "980   sqrt(10 * 100) factor added because production...  ...   \n",
       "979   60 K80 GPUs * 30 days * 8.5 TFLOPS/GPU * 0.33 ...  ...   \n",
       "973   50 epochs * 50,000 images * 10.0 GFLOPSs * 128...  ...   \n",
       "957   \"In total, Libratus used about 25 million core...  ...   \n",
       "...                                                 ...  ...   \n",
       "82    72 billion params, 3 trillion tokens\\n72b * 3T...  ...   \n",
       "74    This number is an estimate based on limited ev...  ...   \n",
       "30    Speculative. The model is stated to have train...  ...   \n",
       "21    \"Inflection-1 used approximately 4% the traini...  ...   \n",
       "5     direct calculation\\n15000000000000 tokens*7000...  ...   \n",
       "\n",
       "     top_11_at_release  top_12_at_release top_13_at_release top_14_at_release  \\\n",
       "1019              True               True              True              True   \n",
       "980               True               True              True              True   \n",
       "979               True               True              True              True   \n",
       "973               True               True              True              True   \n",
       "957               True               True              True              True   \n",
       "...                ...                ...               ...               ...   \n",
       "82               False               True              True              True   \n",
       "74                True               True              True              True   \n",
       "30                True               True              True              True   \n",
       "21                True               True              True              True   \n",
       "5                 True               True              True              True   \n",
       "\n",
       "     top_15_at_release top_16_at_release top_17_at_release top_18_at_release  \\\n",
       "1019              True              True              True              True   \n",
       "980               True              True              True              True   \n",
       "979               True              True              True              True   \n",
       "973               True              True              True              True   \n",
       "957               True              True              True              True   \n",
       "...                ...               ...               ...               ...   \n",
       "82                True              True              True              True   \n",
       "74                True              True              True              True   \n",
       "30                True              True              True              True   \n",
       "21                True              True              True              True   \n",
       "5                 True              True              True              True   \n",
       "\n",
       "     top_19_at_release top_20_at_release  \n",
       "1019              True              True  \n",
       "980               True              True  \n",
       "979               True              True  \n",
       "973               True              True  \n",
       "957               True              True  \n",
       "...                ...               ...  \n",
       "82                True              True  \n",
       "74                True              True  \n",
       "30                True              True  \n",
       "21                True              True  \n",
       "5                 True              True  \n",
       "\n",
       "[74 rows x 66 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_scale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:31.330725700Z",
     "start_time": "2024-05-21T21:31:31.299553500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ngeVX9J-1yx",
    "outputId": "949a42f5-e8c9-4c65-fcc9-c5ae79651d10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3-70B\n",
      "Inflection-2.5\n",
      "MegaScale (Production)\n",
      "Gemini 1.0 Ultra\n",
      "Qwen-72B\n",
      "Inflection-2\n",
      "Grok-1\n",
      "ChatGLM3\n",
      "Falcon-180B\n",
      "Llama 2-70B\n",
      "Claude 2\n",
      "PaLM 2\n",
      "GPT-4\n",
      "LLaMA-65B\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Galactica\n",
      "BLOOM-176B\n",
      "Flan-PaLM 540B\n",
      "U-PaLM (540B)\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "Minerva (540B)\n",
      "Parti\n",
      "OPT-175B\n",
      "Flamingo\n",
      "PaLM (540B)\n",
      "Chinchilla\n",
      "ST-MoE\n",
      "LaMDA\n",
      "AlphaCode\n",
      "ERNIE 3.0 Titan\n",
      "GLaM\n",
      "Gopher (280B)\n",
      "Yuan 1.0\n",
      "Megatron-Turing NLG 530B\n",
      "GOAT\n",
      "ByT5-XXL\n",
      "ProtT5-XXL\n",
      "Meta Pseudo Labels\n",
      "Switch\n",
      "DALL-E\n",
      "mT5-XXL\n",
      "GShard (dense)\n",
      "iGPT-XL\n",
      "GPT-3 175B (davinci)\n",
      "Turing-NLG\n",
      "Meena\n",
      "ContextNet + Noisy Student\n",
      "OpenAI Five Rerun\n",
      "OpenAI Five\n",
      "AlphaStar\n",
      "T5-11B\n",
      "Megatron-LM (8.3B)\n",
      "Megatron-BERT\n",
      "RoBERTa Large\n",
      "XLNet\n",
      "MnasNet-A3\n",
      "MnasNet-A1 + SSDLite\n",
      "GPT-2 (1.5B)\n",
      "Transformer (Adaptive Input Embeddings)\n",
      "BigGAN-deep 512x512\n",
      "FTW\n",
      "ResNeXt-101 32x48d\n",
      "AmoebaNet-A (F=448)\n",
      "AlphaZero\n",
      "AlphaGo Zero\n",
      "OpenAI TI7 DOTA 1v1\n",
      "JFT\n",
      "AlphaGo Master\n",
      "Libratus\n",
      "NASv3 (CIFAR-10)\n",
      "Xception\n",
      "GNMT\n",
      "AlphaGo Lee\n"
     ]
    }
   ],
   "source": [
    "for system in large_scale_df['System'][::-1]:\n",
    "  print(system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1TTIzTQhPan"
   },
   "source": [
    "# Percentiles (SECOND CHOICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.615025800Z",
     "start_time": "2024-05-21T21:31:31.315133300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-cxrNxPbW7r",
    "outputId": "1ab54428-dc65-4d79-e6a0-feff77ad6e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "90\n",
      "85\n",
      "80\n",
      "75\n",
      "70\n",
      "65\n",
      "60\n",
      "55\n",
      "50\n",
      "45\n",
      "40\n",
      "35\n",
      "30\n",
      "25\n",
      "20\n",
      "15\n",
      "10\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "frontier_systems_by_percentile = {}\n",
    "percentile_interval = 5\n",
    "for percentile in range(95, -5, -percentile_interval):\n",
    "  print(percentile)\n",
    "  percentile_compute_low = np.zeros(len(pcd_df))\n",
    "  percentile_compute_high = np.zeros(len(pcd_df))\n",
    "  # Iterate through each row and calculate the 2-year moving average for each date\n",
    "  for i, (index, row) in enumerate(pcd_df.iterrows()):\n",
    "    # Define the 2-year window\n",
    "    start_date = row['Publication date'] - pd.DateOffset(years=outlier_window_size/2)\n",
    "    end_date = row['Publication date'] + pd.DateOffset(years=outlier_window_size/2)\n",
    "\n",
    "    # Filter the DataFrame for this window\n",
    "    window_df = pcd_df[(pcd_df['Publication date'] >= start_date) & (pcd_df['Publication date'] <= end_date)]\n",
    "\n",
    "    percentile_compute_low[i] = np.percentile(window_df['Training compute (FLOP)'], percentile)\n",
    "    percentile_compute_high[i] = np.percentile(window_df['Training compute (FLOP)'], percentile + percentile_interval)\n",
    "\n",
    "  frontier_systems_flag = pcd_df['Training compute (FLOP)'] > np.array(percentile_compute_low)\n",
    "  extra_frontier_systems_flag = pcd_df['Training compute (FLOP)'] <= np.array(percentile_compute_high)\n",
    "\n",
    "  # raise Exception(\"Edit the following line if you want to consider models released after 2023-12-31.\")\n",
    "  extra_frontier_systems = pcd_df['System'][frontier_systems_flag & extra_frontier_systems_flag & (pcd_df['Publication date'] > pd.to_datetime('2015-09-30')) & (pcd_df['Publication date'] < pd.to_datetime('2024-01-01'))].values\n",
    "\n",
    "  frontier_systems_by_percentile[percentile] = list(extra_frontier_systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.680790400Z",
     "start_time": "2024-05-21T21:31:39.620812500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGXo_vGde5mz",
    "outputId": "6684d0f4-3ec9-40ca-ff4a-94cd73c830d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95: ['GNMT',\n",
       "  'AlphaGo Master',\n",
       "  'AlphaGo Zero',\n",
       "  'AlphaZero',\n",
       "  'ResNeXt-101 32x48d',\n",
       "  'FTW',\n",
       "  'Megatron-BERT',\n",
       "  'OpenAI Five',\n",
       "  'Meena',\n",
       "  'GPT-3 175B (davinci)',\n",
       "  'Megatron-Turing NLG 530B',\n",
       "  'PaLM (540B)',\n",
       "  'Minerva (540B)',\n",
       "  'GPT-4',\n",
       "  'Gemini 1.0 Ultra'],\n",
       " 90: ['NASv3 (CIFAR-10)',\n",
       "  'T5-11B',\n",
       "  'AlphaStar',\n",
       "  'mT5-XXL',\n",
       "  'Switch',\n",
       "  'Gopher (280B)',\n",
       "  'ERNIE 3.0 Titan',\n",
       "  'Chinchilla',\n",
       "  'U-PaLM (540B)',\n",
       "  'Flan-PaLM 540B',\n",
       "  'GPT-3.5 (text-davinci-003)',\n",
       "  'PaLM 2',\n",
       "  'Claude 2',\n",
       "  'Inflection-2'],\n",
       " 85: ['AlphaGo Fan',\n",
       "  'AlphaGo Lee',\n",
       "  'JFT',\n",
       "  'Megatron-LM (8.3B)',\n",
       "  'OpenAI Five Rerun',\n",
       "  'Turing-NLG',\n",
       "  'Yuan 1.0',\n",
       "  'GLaM',\n",
       "  'LaMDA',\n",
       "  'OPT-175B',\n",
       "  'BLOOM-176B',\n",
       "  'Falcon-180B',\n",
       "  'Grok-1'],\n",
       " 80: ['OpenAI TI7 DOTA 1v1',\n",
       "  'AmoebaNet-A (F=448)',\n",
       "  'BigGAN-deep 512x512',\n",
       "  'GPT-2 (1.5B)',\n",
       "  'XLNet',\n",
       "  'iGPT-XL',\n",
       "  'DALL-E',\n",
       "  'Meta Pseudo Labels',\n",
       "  'ProtT5-XXL',\n",
       "  'ByT5-XXL',\n",
       "  'GOAT',\n",
       "  'AlphaCode',\n",
       "  'ST-MoE',\n",
       "  'Flamingo',\n",
       "  'Parti',\n",
       "  'BlenderBot 3',\n",
       "  'Llama 2-70B',\n",
       "  'ChatGLM3',\n",
       "  'Qwen-72B'],\n",
       " 75: ['DeepSpeech2 (English)',\n",
       "  'Xception',\n",
       "  'Libratus',\n",
       "  'IMPALA',\n",
       "  'Transformer (Adaptive Input Embeddings)',\n",
       "  'RoBERTa Large',\n",
       "  'ContextNet + Noisy Student',\n",
       "  'GPT-NeoX-20B',\n",
       "  'GLM-130B',\n",
       "  'ViT-22B',\n",
       "  'LLaMA-65B',\n",
       "  'PanGu-Σ',\n",
       "  'xTrimoPGLM -100B',\n",
       "  'Yi-34B'],\n",
       " 70: ['PolyNet',\n",
       "  'MoE',\n",
       "  'Big Transformer for Back-Translation',\n",
       "  'BERT-Large',\n",
       "  'MnasNet-A1 + SSDLite',\n",
       "  'MnasNet-A3',\n",
       "  'iGPT-L',\n",
       "  'GShard (dense)',\n",
       "  'ProtBERT-BFD',\n",
       "  'CoAtNet',\n",
       "  'FLAN 137B',\n",
       "  'UL2',\n",
       "  'AlexaTM 20B',\n",
       "  'Galactica'],\n",
       " 65: ['ResNet-152 (ImageNet)',\n",
       "  'ConvS2S (ensemble of 8 models)',\n",
       "  'YOLOv3',\n",
       "  'Mesh-TensorFlow Transformer 4.9B (language modelling)',\n",
       "  'BERT-Large-CAS (PTB+WT2+WT103)',\n",
       "  'ALBERT-xxlarge',\n",
       "  'ELECTRA',\n",
       "  'Conformer + Wav2vec 2.0 + Noisy Student',\n",
       "  'CLIP (ViT L/14@336px)',\n",
       "  'PLUG',\n",
       "  'ProtT5-XXL-BFD',\n",
       "  'Florence',\n",
       "  'Stable Diffusion (LDM-KL-8-G)',\n",
       "  'CoCa',\n",
       "  'Falcon-40B',\n",
       "  'BloombergGPT',\n",
       "  'Skywork-13B',\n",
       "  'FunSearch'],\n",
       " 60: ['PNASNet-5',\n",
       "  'Mesh-TensorFlow Transformer 2.9B (translation)',\n",
       "  'T5-3B',\n",
       "  'CogView',\n",
       "  'ALIGN',\n",
       "  'ERNIE 3.0',\n",
       "  'BASIC-L',\n",
       "  'XGLM-7.5B',\n",
       "  'ESM2-15B',\n",
       "  'PaLI',\n",
       "  'Nemotron-3-8B'],\n",
       " 55: ['DeepStack',\n",
       "  'LSTM (Hebbian, Cache, MbPA)',\n",
       "  'QT-Opt',\n",
       "  'Population-based DRL',\n",
       "  'SciBERT',\n",
       "  'CamemBERT',\n",
       "  'Noisy Student (L2)',\n",
       "  'Once for All',\n",
       "  'ViT-Huge/14',\n",
       "  'MSA Transformer',\n",
       "  'M6-T',\n",
       "  'Student of Games',\n",
       "  'Whisper',\n",
       "  'Taiyi-Stable Diffusion',\n",
       "  'StarCoder',\n",
       "  'WizardCoder-15.5B',\n",
       "  'Llama 2-7B',\n",
       "  'FinGPT-13B'],\n",
       " 50: ['BIDAF',\n",
       "  'Transformer',\n",
       "  'GPT',\n",
       "  'ProxylessNAS',\n",
       "  'DD-PPO',\n",
       "  'GBERT-Large',\n",
       "  'wave2vec 2.0 LARGE',\n",
       "  'AlphaFold 2',\n",
       "  'DeBERTa',\n",
       "  'HuBERT',\n",
       "  'XGLM',\n",
       "  'RETRO-7B',\n",
       "  'Imagen',\n",
       "  'NLLB',\n",
       "  'Flan-T5 11B',\n",
       "  'LLaMA-7B'],\n",
       " 45: ['RetinaNet-R101',\n",
       "  'Transformer + Simple Recurrent Unit',\n",
       "  'Sandwich Transformer',\n",
       "  'German ELECTRA Large',\n",
       "  'CPM-Large',\n",
       "  'SEER',\n",
       "  'ProGen2-xlarge',\n",
       "  'OmegaPLM',\n",
       "  'WizardLM-7B',\n",
       "  'Pangu-Weather',\n",
       "  'Jais'],\n",
       " 40: ['Part-of-sentence tagging model',\n",
       "  'GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)',\n",
       "  'Transformer-XL (257M)',\n",
       "  'KataGo',\n",
       "  'MuZero',\n",
       "  'AlphaFold',\n",
       "  'DETR',\n",
       "  'ESM1-670M (UR50/D)',\n",
       "  'ViT-G/14',\n",
       "  'AlphaFold-Multimer',\n",
       "  'NÜWA',\n",
       "  'Gato',\n",
       "  'Tranception',\n",
       "  'CogVLM',\n",
       "  'GraphCast',\n",
       "  'CogAgent'],\n",
       " 35: ['Named Entity Recognition model',\n",
       "  'R-FCN',\n",
       "  'ResNet-152 + ObjectNet',\n",
       "  'Feedback Transformer',\n",
       "  'EMDR',\n",
       "  'ViT-G (model soup)',\n",
       "  'Nucleotide Transformer',\n",
       "  'VideoMAE V2',\n",
       "  'Segment Anything Model',\n",
       "  'PeptideBERT'],\n",
       " 30: ['AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)',\n",
       "  'AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)',\n",
       "  'QRNN',\n",
       "  '(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)',\n",
       "  'TrellisNet',\n",
       "  'FAIRSEQ Adaptive Inputs',\n",
       "  'DistilBERT',\n",
       "  'TaLK Convolution',\n",
       "  'ATLAS',\n",
       "  'ERNIE-GEN (large)',\n",
       "  'LUKE',\n",
       "  'ADM',\n",
       "  'CodeT5-base',\n",
       "  'CodeT5-large',\n",
       "  'EVA-01',\n",
       "  'Ankh_large',\n",
       "  'AudioGen',\n",
       "  'DINOv2'],\n",
       " 25: ['VD-LSTM+REAL Large',\n",
       "  'ULM-FiT',\n",
       "  'Big-Little Net (speech)',\n",
       "  'Decoupled weight decay regularization',\n",
       "  'Hanabi 4 player',\n",
       "  'Transformer-XL Large + Phrase Induction',\n",
       "  'Tensorized Transformer (257M)',\n",
       "  'AlphaX-1',\n",
       "  'KEPLER',\n",
       "  'ViT + DINO',\n",
       "  'Denoising Diffusion Probabilistic Models (LSUN Bedroom)',\n",
       "  'T0-XXL',\n",
       "  'S4',\n",
       "  'Swin Transformer V2',\n",
       "  'PolyCoder',\n",
       "  'GenSLM',\n",
       "  'Ankh_base',\n",
       "  'Incoder-6.7B'],\n",
       " 20: ['Zoneout + Variational LSTM (WT2)',\n",
       "  'Fraternal dropout + AWD-LSTM 3-layer (WT2)',\n",
       "  '4 layer QRNN (h=2500)',\n",
       "  'Dropout-LSTM+Noise(Bernoulli) (WT2)',\n",
       "  'Cross-lingual alignment',\n",
       "  'DLRM-2020',\n",
       "  'Base LM + kNN LM + Continuous Cache',\n",
       "  'ConSERT',\n",
       "  'Masked Autoencoders',\n",
       "  'Hybrid H3-2.7B',\n",
       "  'Flan T5-XXL + BLIP-2',\n",
       "  'BLIP-2 (Q-Former)',\n",
       "  'DiT-XL/2'],\n",
       " 15: ['Variational (untied weights, MC) LSTM (Large)',\n",
       "  'Pointer Sentinel-LSTM (medium)',\n",
       "  'Neural Architecture Search with base 8 and shared embeddings',\n",
       "  'ENAS',\n",
       "  'aLSTM(depth-2)+RecurrentPolicy (WT2)',\n",
       "  'Transformer-XL DeFINE (141M)',\n",
       "  'DeLight',\n",
       "  'ERNIE-Doc (247M)',\n",
       "  'EfficientNetV2',\n",
       "  'Adaptive Input Transformer + RD',\n",
       "  'DNABERT',\n",
       "  'BERT-RBP',\n",
       "  'AR-LDM',\n",
       "  'Discriminator Guidance',\n",
       "  'DDPM-IP (CelebA)',\n",
       "  'ONE-PEACE'],\n",
       " 10: ['EI-REHN-1000D',\n",
       "  'DARTS',\n",
       "  'NAS+ESS (156M)',\n",
       "  'ProBERTa',\n",
       "  'SRU++ Large',\n",
       "  'Transformer local-attention (NesT-B)',\n",
       "  'ProteinBERT',\n",
       "  'BEIT-3',\n",
       "  'DiffDock',\n",
       "  'Fusion in Encoder',\n",
       "  'LLaVA 1.5'],\n",
       " 5: ['VD-RHN',\n",
       "  'ISS',\n",
       "  'AWD-LSTM+WT+Cache+IOG (WT2)',\n",
       "  'AWD-LSTM-DRILL + dynamic evaluation† (WT2)',\n",
       "  'AWD-LSTM + MoS + Partial Shuffled',\n",
       "  'UDSMProt',\n",
       "  'MMLSTM',\n",
       "  'TransformerXL + spectrum control',\n",
       "  'Tensor-Transformer(1core)+PN (WT103)',\n",
       "  'MedBERT',\n",
       "  'Detic',\n",
       "  'Segatron-XL large, M=384 + HCP',\n",
       "  'Sparse all-MLP',\n",
       "  'CaLM',\n",
       "  'LLaVA',\n",
       "  'MultiBand Diffusion'],\n",
       " 0: ['2-layer-LSTM+Deep-Gradient-Compression',\n",
       "  'Fine-tuned-AWD-LSTM-DOC(fin)',\n",
       "  'Multi-cell LSTM',\n",
       "  'Pluribus',\n",
       "  'DensePhrases',\n",
       "  'CT-MoS (WT2)',\n",
       "  'PermuteFormer',\n",
       "  'base LM+GNN+kNN',\n",
       "  'DITTO',\n",
       "  'Mogrifier RLSTM (WT2)',\n",
       "  'VALL-E',\n",
       "  'HyenaDNA',\n",
       "  'CODEFUSION (Python)']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_systems_by_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for percentile in range(95, -5, -percentile_interval):\n",
    "    frontier_systems_by_percentile[percentile] = list(sorted(frontier_systems_by_percentile[percentile]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.693769500Z",
     "start_time": "2024-05-21T21:31:39.681920900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "with open('data/frontier_systems_by_window_percentile.json', 'w') as f:\n",
    "    json.dump(frontier_systems_by_percentile, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.725023Z",
     "start_time": "2024-05-21T21:31:39.693769500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8pzY7skfxkV",
    "outputId": "195c3ec6-c885-4008-ba36-abb60e5dd645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 to 100\n",
      "15 systems\n",
      "Total systems above 95th percentile: 15\n",
      "ResNeXt-101 32x48d\n",
      "PaLM (540B)\n",
      "OpenAI Five\n",
      "Minerva (540B)\n",
      "Megatron-Turing NLG 530B\n",
      "Megatron-BERT\n",
      "Meena\n",
      "Gemini 1.0 Ultra\n",
      "GPT-4\n",
      "GPT-3 175B (davinci)\n",
      "GNMT\n",
      "FTW\n",
      "AlphaZero\n",
      "AlphaGo Zero\n",
      "AlphaGo Master\n",
      "\n",
      "90 to 95\n",
      "14 systems\n",
      "Total systems above 90th percentile: 29\n",
      "mT5-XXL\n",
      "U-PaLM (540B)\n",
      "T5-11B\n",
      "Switch\n",
      "PaLM 2\n",
      "NASv3 (CIFAR-10)\n",
      "Inflection-2\n",
      "Gopher (280B)\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Flan-PaLM 540B\n",
      "ERNIE 3.0 Titan\n",
      "Claude 2\n",
      "Chinchilla\n",
      "AlphaStar\n",
      "\n",
      "85 to 90\n",
      "13 systems\n",
      "Total systems above 85th percentile: 42\n",
      "Yuan 1.0\n",
      "Turing-NLG\n",
      "OpenAI Five Rerun\n",
      "OPT-175B\n",
      "Megatron-LM (8.3B)\n",
      "LaMDA\n",
      "JFT\n",
      "Grok-1\n",
      "GLaM\n",
      "Falcon-180B\n",
      "BLOOM-176B\n",
      "AlphaGo Lee\n",
      "AlphaGo Fan\n",
      "\n",
      "80 to 85\n",
      "19 systems\n",
      "Total systems above 80th percentile: 61\n",
      "iGPT-XL\n",
      "XLNet\n",
      "ST-MoE\n",
      "Qwen-72B\n",
      "ProtT5-XXL\n",
      "Parti\n",
      "OpenAI TI7 DOTA 1v1\n",
      "Meta Pseudo Labels\n",
      "Llama 2-70B\n",
      "GPT-2 (1.5B)\n",
      "GOAT\n",
      "Flamingo\n",
      "DALL-E\n",
      "ChatGLM3\n",
      "ByT5-XXL\n",
      "BlenderBot 3\n",
      "BigGAN-deep 512x512\n",
      "AmoebaNet-A (F=448)\n",
      "AlphaCode\n",
      "\n",
      "75 to 80\n",
      "14 systems\n",
      "Total systems above 75th percentile: 75\n",
      "xTrimoPGLM -100B\n",
      "Yi-34B\n",
      "Xception\n",
      "ViT-22B\n",
      "Transformer (Adaptive Input Embeddings)\n",
      "RoBERTa Large\n",
      "PanGu-Σ\n",
      "Libratus\n",
      "LLaMA-65B\n",
      "IMPALA\n",
      "GPT-NeoX-20B\n",
      "GLM-130B\n",
      "DeepSpeech2 (English)\n",
      "ContextNet + Noisy Student\n",
      "\n",
      "70 to 75\n",
      "14 systems\n",
      "Total systems above 70th percentile: 89\n",
      "iGPT-L\n",
      "UL2\n",
      "ProtBERT-BFD\n",
      "PolyNet\n",
      "MoE\n",
      "MnasNet-A3\n",
      "MnasNet-A1 + SSDLite\n",
      "Galactica\n",
      "GShard (dense)\n",
      "FLAN 137B\n",
      "CoAtNet\n",
      "Big Transformer for Back-Translation\n",
      "BERT-Large\n",
      "AlexaTM 20B\n",
      "\n",
      "65 to 70\n",
      "18 systems\n",
      "Total systems above 65th percentile: 107\n",
      "YOLOv3\n",
      "Stable Diffusion (LDM-KL-8-G)\n",
      "Skywork-13B\n",
      "ResNet-152 (ImageNet)\n",
      "ProtT5-XXL-BFD\n",
      "PLUG\n",
      "Mesh-TensorFlow Transformer 4.9B (language modelling)\n",
      "FunSearch\n",
      "Florence\n",
      "Falcon-40B\n",
      "ELECTRA\n",
      "ConvS2S (ensemble of 8 models)\n",
      "Conformer + Wav2vec 2.0 + Noisy Student\n",
      "CoCa\n",
      "CLIP (ViT L/14@336px)\n",
      "BloombergGPT\n",
      "BERT-Large-CAS (PTB+WT2+WT103)\n",
      "ALBERT-xxlarge\n",
      "\n",
      "60 to 65\n",
      "11 systems\n",
      "Total systems above 60th percentile: 118\n",
      "XGLM-7.5B\n",
      "T5-3B\n",
      "PaLI\n",
      "PNASNet-5\n",
      "Nemotron-3-8B\n",
      "Mesh-TensorFlow Transformer 2.9B (translation)\n",
      "ESM2-15B\n",
      "ERNIE 3.0\n",
      "CogView\n",
      "BASIC-L\n",
      "ALIGN\n",
      "\n",
      "55 to 60\n",
      "18 systems\n",
      "Total systems above 55th percentile: 136\n",
      "WizardCoder-15.5B\n",
      "Whisper\n",
      "ViT-Huge/14\n",
      "Taiyi-Stable Diffusion\n",
      "Student of Games\n",
      "StarCoder\n",
      "SciBERT\n",
      "QT-Opt\n",
      "Population-based DRL\n",
      "Once for All\n",
      "Noisy Student (L2)\n",
      "MSA Transformer\n",
      "M6-T\n",
      "Llama 2-7B\n",
      "LSTM (Hebbian, Cache, MbPA)\n",
      "FinGPT-13B\n",
      "DeepStack\n",
      "CamemBERT\n",
      "\n",
      "50 to 55\n",
      "16 systems\n",
      "Total systems above 50th percentile: 152\n",
      "wave2vec 2.0 LARGE\n",
      "XGLM\n",
      "Transformer\n",
      "RETRO-7B\n",
      "ProxylessNAS\n",
      "NLLB\n",
      "LLaMA-7B\n",
      "Imagen\n",
      "HuBERT\n",
      "GPT\n",
      "GBERT-Large\n",
      "Flan-T5 11B\n",
      "DeBERTa\n",
      "DD-PPO\n",
      "BIDAF\n",
      "AlphaFold 2\n",
      "\n",
      "45 to 50\n",
      "11 systems\n",
      "Total systems above 45th percentile: 163\n",
      "WizardLM-7B\n",
      "Transformer + Simple Recurrent Unit\n",
      "Sandwich Transformer\n",
      "SEER\n",
      "RetinaNet-R101\n",
      "ProGen2-xlarge\n",
      "Pangu-Weather\n",
      "OmegaPLM\n",
      "Jais\n",
      "German ELECTRA Large\n",
      "CPM-Large\n",
      "\n",
      "40 to 45\n",
      "16 systems\n",
      "Total systems above 40th percentile: 179\n",
      "ViT-G/14\n",
      "Transformer-XL (257M)\n",
      "Tranception\n",
      "Part-of-sentence tagging model\n",
      "NÜWA\n",
      "MuZero\n",
      "KataGo\n",
      "GraphCast\n",
      "Gato\n",
      "GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)\n",
      "ESM1-670M (UR50/D)\n",
      "DETR\n",
      "CogVLM\n",
      "CogAgent\n",
      "AlphaFold-Multimer\n",
      "AlphaFold\n",
      "\n",
      "35 to 40\n",
      "10 systems\n",
      "Total systems above 35th percentile: 189\n",
      "VideoMAE V2\n",
      "ViT-G (model soup)\n",
      "Segment Anything Model\n",
      "ResNet-152 + ObjectNet\n",
      "R-FCN\n",
      "PeptideBERT\n",
      "Nucleotide Transformer\n",
      "Named Entity Recognition model\n",
      "Feedback Transformer\n",
      "EMDR\n",
      "\n",
      "30 to 35\n",
      "18 systems\n",
      "Total systems above 30th percentile: 207\n",
      "TrellisNet\n",
      "TaLK Convolution\n",
      "QRNN\n",
      "LUKE\n",
      "FAIRSEQ Adaptive Inputs\n",
      "EVA-01\n",
      "ERNIE-GEN (large)\n",
      "DistilBERT\n",
      "DINOv2\n",
      "CodeT5-large\n",
      "CodeT5-base\n",
      "AudioGen\n",
      "Ankh_large\n",
      "AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)\n",
      "AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)\n",
      "ATLAS\n",
      "ADM\n",
      "(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)\n",
      "\n",
      "25 to 30\n",
      "18 systems\n",
      "Total systems above 25th percentile: 225\n",
      "ViT + DINO\n",
      "VD-LSTM+REAL Large\n",
      "ULM-FiT\n",
      "Transformer-XL Large + Phrase Induction\n",
      "Tensorized Transformer (257M)\n",
      "T0-XXL\n",
      "Swin Transformer V2\n",
      "S4\n",
      "PolyCoder\n",
      "KEPLER\n",
      "Incoder-6.7B\n",
      "Hanabi 4 player\n",
      "GenSLM\n",
      "Denoising Diffusion Probabilistic Models (LSUN Bedroom)\n",
      "Decoupled weight decay regularization\n",
      "Big-Little Net (speech)\n",
      "Ankh_base\n",
      "AlphaX-1\n",
      "\n",
      "20 to 25\n",
      "13 systems\n",
      "Total systems above 20th percentile: 238\n",
      "Zoneout + Variational LSTM (WT2)\n",
      "Masked Autoencoders\n",
      "Hybrid H3-2.7B\n",
      "Fraternal dropout + AWD-LSTM 3-layer (WT2)\n",
      "Flan T5-XXL + BLIP-2\n",
      "Dropout-LSTM+Noise(Bernoulli) (WT2)\n",
      "DiT-XL/2\n",
      "DLRM-2020\n",
      "Cross-lingual alignment\n",
      "ConSERT\n",
      "Base LM + kNN LM + Continuous Cache\n",
      "BLIP-2 (Q-Former)\n",
      "4 layer QRNN (h=2500)\n",
      "\n",
      "15 to 20\n",
      "16 systems\n",
      "Total systems above 15th percentile: 254\n",
      "aLSTM(depth-2)+RecurrentPolicy (WT2)\n",
      "Variational (untied weights, MC) LSTM (Large)\n",
      "Transformer-XL DeFINE (141M)\n",
      "Pointer Sentinel-LSTM (medium)\n",
      "ONE-PEACE\n",
      "Neural Architecture Search with base 8 and shared embeddings\n",
      "EfficientNetV2\n",
      "ERNIE-Doc (247M)\n",
      "ENAS\n",
      "Discriminator Guidance\n",
      "DeLight\n",
      "DNABERT\n",
      "DDPM-IP (CelebA)\n",
      "BERT-RBP\n",
      "Adaptive Input Transformer + RD\n",
      "AR-LDM\n",
      "\n",
      "10 to 15\n",
      "11 systems\n",
      "Total systems above 10th percentile: 265\n",
      "Transformer local-attention (NesT-B)\n",
      "SRU++ Large\n",
      "ProteinBERT\n",
      "ProBERTa\n",
      "NAS+ESS (156M)\n",
      "LLaVA 1.5\n",
      "Fusion in Encoder\n",
      "EI-REHN-1000D\n",
      "DiffDock\n",
      "DARTS\n",
      "BEIT-3\n",
      "\n",
      "5 to 10\n",
      "16 systems\n",
      "Total systems above 5th percentile: 281\n",
      "VD-RHN\n",
      "UDSMProt\n",
      "TransformerXL + spectrum control\n",
      "Tensor-Transformer(1core)+PN (WT103)\n",
      "Sparse all-MLP\n",
      "Segatron-XL large, M=384 + HCP\n",
      "MultiBand Diffusion\n",
      "MedBERT\n",
      "MMLSTM\n",
      "LLaVA\n",
      "ISS\n",
      "Detic\n",
      "CaLM\n",
      "AWD-LSTM-DRILL + dynamic evaluation† (WT2)\n",
      "AWD-LSTM+WT+Cache+IOG (WT2)\n",
      "AWD-LSTM + MoS + Partial Shuffled\n",
      "\n",
      "0 to 5\n",
      "13 systems\n",
      "Total systems above 0th percentile: 294\n",
      "base LM+GNN+kNN\n",
      "VALL-E\n",
      "Pluribus\n",
      "PermuteFormer\n",
      "Multi-cell LSTM\n",
      "Mogrifier RLSTM (WT2)\n",
      "HyenaDNA\n",
      "Fine-tuned-AWD-LSTM-DOC(fin)\n",
      "DensePhrases\n",
      "DITTO\n",
      "CT-MoS (WT2)\n",
      "CODEFUSION (Python)\n",
      "2-layer-LSTM+Deep-Gradient-Compression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_num_systems = 0\n",
    "for percentile, systems in frontier_systems_by_percentile.items():\n",
    "  total_num_systems += len(systems)\n",
    "  print(percentile, 'to', percentile + percentile_interval)\n",
    "  print(len(systems), \"systems\")\n",
    "  print(f'Total systems above {percentile}th percentile: {total_num_systems}')\n",
    "  for system in systems[::-1]:\n",
    "    print(system)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.725023Z",
     "start_time": "2024-05-21T21:31:39.709480700Z"
    },
    "id": "klMq2PP3f6Xw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TllyX8IqSiG2"
   },
   "source": [
    "# Distance from compute record at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.740645800Z",
     "start_time": "2024-05-21T21:31:39.725023Z"
    },
    "id": "CC8_j5AASl0y"
   },
   "outputs": [],
   "source": [
    "ooms_from_frontier = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.764574500Z",
     "start_time": "2024-05-21T21:31:39.747646Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N395lGkYSoNU",
    "outputId": "ee6d6df7-3662-4dd8-ce41-b9490a33389a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.00000000e+01, 6.94894938e+05, 6.00000000e+08, 6.00000000e+08,\n",
       "       7.20000000e+08, 7.20000000e+08, 7.20000000e+08, 7.20000000e+08,\n",
       "       7.20000000e+08, 7.20000000e+08, 7.20000000e+08, 7.20000000e+08,\n",
       "       7.20000000e+08, 2.83280026e+10, 2.83280026e+10, 2.83280026e+10,\n",
       "       1.81440000e+11, 1.81440000e+11, 1.81440000e+11, 1.81440000e+11,\n",
       "       1.81440000e+11, 1.81440000e+11, 1.82321576e+13, 1.82321576e+13,\n",
       "       1.82321576e+13, 1.82321576e+13, 2.10080000e+13, 2.10080000e+13,\n",
       "       6.30000000e+13, 1.30389876e+15, 1.30389876e+15, 1.30389876e+15,\n",
       "       1.30389876e+15, 1.30389876e+15, 3.41463600e+15, 6.14400000e+16,\n",
       "       6.14400000e+16, 2.73196800e+17, 2.73196800e+17, 2.73196800e+17,\n",
       "       6.00000000e+17, 6.00000000e+17, 6.00000000e+17, 6.00000000e+17,\n",
       "       6.00000000e+17, 6.00000000e+17, 6.00000000e+17, 1.34092800e+18,\n",
       "       1.34092800e+18, 1.34092800e+18, 1.34092800e+18, 1.34092800e+18,\n",
       "       3.41107200e+18, 3.41107200e+18, 3.41107200e+18, 9.25344000e+18,\n",
       "       9.25344000e+18, 5.60000000e+19, 5.60000000e+19, 5.60000000e+19,\n",
       "       5.60000000e+19, 5.60000000e+19, 5.60000000e+19, 5.60000000e+19,\n",
       "       5.60000000e+19, 3.80000000e+20, 3.80000000e+20, 3.80000000e+20,\n",
       "       3.80000000e+20, 1.90000000e+21, 1.90000000e+21, 1.90000000e+21,\n",
       "       1.90000000e+21, 1.90000000e+21, 1.90000000e+21, 6.90000000e+21,\n",
       "       6.90000000e+21, 6.90000000e+21, 6.90000000e+21, 6.90000000e+21,\n",
       "       6.90000000e+21, 6.90000000e+21, 6.90000000e+21, 6.90000000e+21,\n",
       "       6.90000000e+21, 2.00010000e+23, 2.00010000e+23, 2.00010000e+23,\n",
       "       2.00010000e+23, 2.00010000e+23, 2.00010000e+23, 2.00010000e+23,\n",
       "       2.00010000e+23, 2.00010000e+23, 2.00010000e+23, 2.00010000e+23,\n",
       "       2.00010000e+23, 2.00010000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n",
       "       3.41000000e+23, 3.41000000e+23, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n",
       "       1.17000000e+24, 1.17000000e+24, 2.52720000e+24, 2.52720000e+24,\n",
       "       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n",
       "       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n",
       "       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n",
       "       5.00000000e+25, 5.00000000e+25, 5.00000000e+25, 5.00000000e+25,\n",
       "       5.00000000e+25, 5.00000000e+25, 5.00000000e+25, 5.00000000e+25])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_max = 0\n",
    "running_max = np.zeros(len(pcd_df))\n",
    "for i, compute in enumerate(pcd_df['Training compute (FLOP)']):\n",
    "  if compute > current_max:\n",
    "    running_max[i] = compute\n",
    "    current_max = compute\n",
    "  else:\n",
    "    running_max[i] = current_max\n",
    "running_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.772581800Z",
     "start_time": "2024-05-21T21:31:39.764574500Z"
    },
    "id": "SV1tpYgETmYT"
   },
   "outputs": [],
   "source": [
    "pcd_df['Frontier training compute (FLOP)'] = running_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.794438900Z",
     "start_time": "2024-05-21T21:31:39.772581800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "WdpWpDvvTqOs",
    "outputId": "331ce3ef-cc47-4393-dc7f-98148184fd4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Frontier system</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Theseus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>Perceptron Mark I</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Pandemonium (morse)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>Samuel Neural Checkers</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>Perceptron (1960)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MegaScale (Production)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Inflection-2.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MM1-30B</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mixture-of-Depths</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama 3-70B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      System  Frontier system\n",
       "1307                 Theseus            False\n",
       "1301       Perceptron Mark I            False\n",
       "1300     Pandemonium (morse)            False\n",
       "1299  Samuel Neural Checkers            False\n",
       "1297       Perceptron (1960)            False\n",
       "...                      ...              ...\n",
       "30    MegaScale (Production)             True\n",
       "21            Inflection-2.5             True\n",
       "20                   MM1-30B            False\n",
       "13         Mixture-of-Depths            False\n",
       "5                Llama 3-70B             True\n",
       "\n",
       "[368 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df['Frontier system'] = (pcd_df['Publication date'] > start_large_scale_era) & (np.log10(pcd_df['Frontier training compute (FLOP)']) - np.log10(pcd_df['Training compute (FLOP)']) <= ooms_from_frontier)\n",
    "pcd_df[['System', 'Frontier system']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.871622100Z",
     "start_time": "2024-05-21T21:31:39.792281800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yrk0wu7LT6ZK",
    "outputId": "9d95a1fa-1ed8-4c4b-ae94-f9b42a8dddd8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Parameters notes</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "      <th>Training compute notes</th>\n",
       "      <th>...</th>\n",
       "      <th>top_13_at_release</th>\n",
       "      <th>top_14_at_release</th>\n",
       "      <th>top_15_at_release</th>\n",
       "      <th>top_16_at_release</th>\n",
       "      <th>top_17_at_release</th>\n",
       "      <th>top_18_at_release</th>\n",
       "      <th>top_19_at_release</th>\n",
       "      <th>top_20_at_release</th>\n",
       "      <th>Frontier training compute (FLOP)</th>\n",
       "      <th>Frontier system</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Baidu Research - Silicon Valley AI Lab</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
       "      <td>https://arxiv.org/abs/1512.02595</td>\n",
       "      <td>3.800000e+07</td>\n",
       "      <td>All networks have 38 million parameters.</td>\n",
       "      <td>2.600000e+19</td>\n",
       "      <td>1 timestep = (1280 hidden units)^2 * (7 RNN la...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.800000e+20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>https://arxiv.org/abs/1512.03385</td>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>Taken from https://arxiv.org/abs/1605.07146</td>\n",
       "      <td>1.210000e+19</td>\n",
       "      <td>(11.4 *10^9) mult-adds per forward pass\\n2 FLO...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.800000e+20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>https://www.nature.com/articles/nature16961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.900000e+21</td>\n",
       "      <td>This number is pretty uncertain. I expect it t...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.900000e+21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>Language</td>\n",
       "      <td>Google</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>Google's Neural Machine Translation System: Br...</td>\n",
       "      <td>https://arxiv.org/abs/1609.08144</td>\n",
       "      <td>2.780000e+08</td>\n",
       "      <td>Table 5 in 'Outrageously Large Neural Networks...</td>\n",
       "      <td>6.900000e+21</td>\n",
       "      <td>sqrt(10 * 100) factor added because production...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.900000e+21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>Xception</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Google</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>Xception: Deep Learning with Depthwise Separab...</td>\n",
       "      <td>https://arxiv.org/abs/1610.02357</td>\n",
       "      <td>2.285595e+07</td>\n",
       "      <td>Table 3</td>\n",
       "      <td>4.360000e+20</td>\n",
       "      <td>60 K80 GPUs * 30 days * 8.5 TFLOPS/GPU * 0.33 ...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.900000e+21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Qwen-72B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n",
       "      <td>7.200000e+10</td>\n",
       "      <td>72B</td>\n",
       "      <td>1.300000e+24</td>\n",
       "      <td>72 billion params, 3 trillion tokens\\n72b * 3T...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.100000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Gemini 1.0 Ultra</td>\n",
       "      <td>Multimodal,Language,Vision</td>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n",
       "      <td>https://storage.googleapis.com/deepmind-media/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>This number is an estimate based on limited ev...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MegaScale (Production)</td>\n",
       "      <td>Language</td>\n",
       "      <td>ByteDance,Peking University</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>MegaScale: Scaling Large Language Model Traini...</td>\n",
       "      <td>https://arxiv.org/abs/2402.15627</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>Production run is stated to have \"hundreds of ...</td>\n",
       "      <td>1.200000e+25</td>\n",
       "      <td>Speculative. The model is stated to have train...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Inflection-2.5</td>\n",
       "      <td>Language</td>\n",
       "      <td>Inflection AI</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>Inflection-2.5: meet the world's best personal AI</td>\n",
       "      <td>https://inflection.ai/inflection-2-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000100e+25</td>\n",
       "      <td>\"Inflection-1 used approximately 4% the traini...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama 3-70B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>Introducing Meta Llama 3: The most capable ope...</td>\n",
       "      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n",
       "      <td>7.000000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.300000e+24</td>\n",
       "      <td>direct calculation\\n15000000000000 tokens*7000...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.000000e+25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      System                      Domain  \\\n",
       "1025   DeepSpeech2 (English)                      Speech   \n",
       "1023   ResNet-152 (ImageNet)                      Vision   \n",
       "1019             AlphaGo Lee                       Games   \n",
       "980                     GNMT                    Language   \n",
       "979                 Xception                      Vision   \n",
       "...                      ...                         ...   \n",
       "82                  Qwen-72B                    Language   \n",
       "74          Gemini 1.0 Ultra  Multimodal,Language,Vision   \n",
       "30    MegaScale (Production)                    Language   \n",
       "21            Inflection-2.5                    Language   \n",
       "5                Llama 3-70B                    Language   \n",
       "\n",
       "                                Organization Publication date  \\\n",
       "1025  Baidu Research - Silicon Valley AI Lab       2015-12-08   \n",
       "1023                               Microsoft       2015-12-10   \n",
       "1019                                DeepMind       2016-01-27   \n",
       "980                                   Google       2016-09-26   \n",
       "979                                   Google       2016-10-07   \n",
       "...                                      ...              ...   \n",
       "82                                   Alibaba       2023-11-30   \n",
       "74                           Google DeepMind       2023-12-06   \n",
       "30               ByteDance,Peking University       2024-02-23   \n",
       "21                             Inflection AI       2024-03-07   \n",
       "5                                    Meta AI       2024-04-18   \n",
       "\n",
       "                                              Reference  \\\n",
       "1025  Deep Speech 2: End-to-End Speech Recognition i...   \n",
       "1023       Deep Residual Learning for Image Recognition   \n",
       "1019  Mastering the game of Go with deep neural netw...   \n",
       "980   Google's Neural Machine Translation System: Br...   \n",
       "979   Xception: Deep Learning with Depthwise Separab...   \n",
       "...                                                 ...   \n",
       "82                                                  NaN   \n",
       "74    Gemini: A Family of Highly Capable Multimodal ...   \n",
       "30    MegaScale: Scaling Large Language Model Traini...   \n",
       "21    Inflection-2.5: meet the world's best personal AI   \n",
       "5     Introducing Meta Llama 3: The most capable ope...   \n",
       "\n",
       "                                                   Link    Parameters  \\\n",
       "1025                   https://arxiv.org/abs/1512.02595  3.800000e+07   \n",
       "1023                   https://arxiv.org/abs/1512.03385  6.000000e+07   \n",
       "1019        https://www.nature.com/articles/nature16961           NaN   \n",
       "980                    https://arxiv.org/abs/1609.08144  2.780000e+08   \n",
       "979                    https://arxiv.org/abs/1610.02357  2.285595e+07   \n",
       "...                                                 ...           ...   \n",
       "82                 https://huggingface.co/Qwen/Qwen-72B  7.200000e+10   \n",
       "74    https://storage.googleapis.com/deepmind-media/...           NaN   \n",
       "30                     https://arxiv.org/abs/2402.15627  5.300000e+11   \n",
       "21                 https://inflection.ai/inflection-2-5           NaN   \n",
       "5     https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n",
       "\n",
       "                                       Parameters notes  \\\n",
       "1025           All networks have 38 million parameters.   \n",
       "1023        Taken from https://arxiv.org/abs/1605.07146   \n",
       "1019                                                NaN   \n",
       "980   Table 5 in 'Outrageously Large Neural Networks...   \n",
       "979                                             Table 3   \n",
       "...                                                 ...   \n",
       "82                                                  72B   \n",
       "74                                                  NaN   \n",
       "30    Production run is stated to have \"hundreds of ...   \n",
       "21                                                  NaN   \n",
       "5                                                   NaN   \n",
       "\n",
       "      Training compute (FLOP)  \\\n",
       "1025             2.600000e+19   \n",
       "1023             1.210000e+19   \n",
       "1019             1.900000e+21   \n",
       "980              6.900000e+21   \n",
       "979              4.360000e+20   \n",
       "...                       ...   \n",
       "82               1.300000e+24   \n",
       "74               5.000000e+25   \n",
       "30               1.200000e+25   \n",
       "21               1.000100e+25   \n",
       "5                6.300000e+24   \n",
       "\n",
       "                                 Training compute notes  ...  \\\n",
       "1025  1 timestep = (1280 hidden units)^2 * (7 RNN la...  ...   \n",
       "1023  (11.4 *10^9) mult-adds per forward pass\\n2 FLO...  ...   \n",
       "1019  This number is pretty uncertain. I expect it t...  ...   \n",
       "980   sqrt(10 * 100) factor added because production...  ...   \n",
       "979   60 K80 GPUs * 30 days * 8.5 TFLOPS/GPU * 0.33 ...  ...   \n",
       "...                                                 ...  ...   \n",
       "82    72 billion params, 3 trillion tokens\\n72b * 3T...  ...   \n",
       "74    This number is an estimate based on limited ev...  ...   \n",
       "30    Speculative. The model is stated to have train...  ...   \n",
       "21    \"Inflection-1 used approximately 4% the traini...  ...   \n",
       "5     direct calculation\\n15000000000000 tokens*7000...  ...   \n",
       "\n",
       "     top_13_at_release  top_14_at_release top_15_at_release top_16_at_release  \\\n",
       "1025              True               True              True              True   \n",
       "1023              True               True              True              True   \n",
       "1019              True               True              True              True   \n",
       "980               True               True              True              True   \n",
       "979               True               True              True              True   \n",
       "...                ...                ...               ...               ...   \n",
       "82                True               True              True              True   \n",
       "74                True               True              True              True   \n",
       "30                True               True              True              True   \n",
       "21                True               True              True              True   \n",
       "5                 True               True              True              True   \n",
       "\n",
       "     top_17_at_release top_18_at_release top_19_at_release top_20_at_release  \\\n",
       "1025              True              True              True              True   \n",
       "1023              True              True              True              True   \n",
       "1019              True              True              True              True   \n",
       "980               True              True              True              True   \n",
       "979               True              True              True              True   \n",
       "...                ...               ...               ...               ...   \n",
       "82                True              True              True              True   \n",
       "74                True              True              True              True   \n",
       "30                True              True              True              True   \n",
       "21                True              True              True              True   \n",
       "5                 True              True              True              True   \n",
       "\n",
       "     Frontier training compute (FLOP) Frontier system  \n",
       "1025                     3.800000e+20            True  \n",
       "1023                     3.800000e+20            True  \n",
       "1019                     1.900000e+21            True  \n",
       "980                      6.900000e+21            True  \n",
       "979                      6.900000e+21            True  \n",
       "...                               ...             ...  \n",
       "82                       2.100000e+25            True  \n",
       "74                       5.000000e+25            True  \n",
       "30                       5.000000e+25            True  \n",
       "21                       5.000000e+25            True  \n",
       "5                        5.000000e+25            True  \n",
       "\n",
       "[111 rows x 68 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_df = pcd_df[pcd_df['Frontier system']]\n",
    "frontier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.871622100Z",
     "start_time": "2024-05-21T21:31:39.828366800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjDaQcsVsyYz",
    "outputId": "7aa5fd43-3b36-45f5-997c-d57abd4a94d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3-70B\n",
      "Inflection-2.5\n",
      "MegaScale (Production)\n",
      "Gemini 1.0 Ultra\n",
      "Qwen-72B\n",
      "Inflection-2\n",
      "Grok-1\n",
      "Yi-34B\n",
      "Skywork-13B\n",
      "ChatGLM3\n",
      "Falcon-180B\n",
      "Llama 2-70B\n",
      "Claude 2\n",
      "xTrimoPGLM -100B\n",
      "PaLM 2\n",
      "BloombergGPT\n",
      "PanGu-Σ\n",
      "GPT-4\n",
      "Falcon-40B\n",
      "LLaMA-65B\n",
      "LLaMA-7B\n",
      "ViT-22B\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Galactica\n",
      "BLOOM-176B\n",
      "Taiyi-Stable Diffusion\n",
      "Flan-T5 11B\n",
      "Flan-PaLM 540B\n",
      "U-PaLM (540B)\n",
      "Whisper\n",
      "PaLI\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "AlexaTM 20B\n",
      "ESM2-15B\n",
      "Minerva (540B)\n",
      "Parti\n",
      "CoCa\n",
      "UL2\n",
      "OPT-175B\n",
      "Flamingo\n",
      "Stable Diffusion (LDM-KL-8-G)\n",
      "PaLM (540B)\n",
      "Chinchilla\n",
      "ST-MoE\n",
      "LaMDA\n",
      "GPT-NeoX-20B\n",
      "RETRO-7B\n",
      "AlphaCode\n",
      "ERNIE 3.0 Titan\n",
      "XGLM-7.5B\n",
      "XGLM\n",
      "GLaM\n",
      "Gopher (280B)\n",
      "Student of Games\n",
      "Florence\n",
      "BASIC-L\n",
      "Yuan 1.0\n",
      "Megatron-Turing NLG 530B\n",
      "AlphaFold-Multimer\n",
      "FLAN 137B\n",
      "SEER\n",
      "GOAT\n",
      "HuBERT\n",
      "ERNIE 3.0\n",
      "ALIGN\n",
      "DeBERTa\n",
      "CoAtNet\n",
      "ByT5-XXL\n",
      "CogView\n",
      "ProtT5-XXL-BFD\n",
      "ProtBERT-BFD\n",
      "ProtT5-XXL\n",
      "PLUG\n",
      "M6-T\n",
      "Meta Pseudo Labels\n",
      "MSA Transformer\n",
      "Switch\n",
      "DALL-E\n",
      "CLIP (ViT L/14@336px)\n",
      "ViT-Huge/14\n",
      "mT5-XXL\n",
      "Conformer + Wav2vec 2.0 + Noisy Student\n",
      "GShard (dense)\n",
      "iGPT-XL\n",
      "iGPT-L\n",
      "GPT-3 175B (davinci)\n",
      "Turing-NLG\n",
      "Meena\n",
      "ContextNet + Noisy Student\n",
      "OpenAI Five Rerun\n",
      "OpenAI Five\n",
      "AlphaStar\n",
      "T5-11B\n",
      "Megatron-LM (8.3B)\n",
      "Megatron-BERT\n",
      "RoBERTa Large\n",
      "XLNet\n",
      "GPT-2 (1.5B)\n",
      "FTW\n",
      "ResNeXt-101 32x48d\n",
      "AlphaZero\n",
      "AlphaGo Zero\n",
      "AlphaGo Master\n",
      "Libratus\n",
      "NASv3 (CIFAR-10)\n",
      "Xception\n",
      "GNMT\n",
      "AlphaGo Lee\n",
      "ResNet-152 (ImageNet)\n",
      "DeepSpeech2 (English)\n"
     ]
    }
   ],
   "source": [
    "for system in frontier_df['System'][::-1]:\n",
    "  print(system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ4rEiW4hW6_"
   },
   "source": [
    "# Constant threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.871622100Z",
     "start_time": "2024-05-21T21:31:39.840371400Z"
    },
    "id": "L8IgNL9shAZb"
   },
   "outputs": [],
   "source": [
    "compute_threshold = 1e23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.871622100Z",
     "start_time": "2024-05-21T21:31:39.856000900Z"
    },
    "id": "tGPWWQJ6hZCU"
   },
   "outputs": [],
   "source": [
    "above_threshold = pcd_df[pcd_df['Training compute (FLOP)'] > compute_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.903554700Z",
     "start_time": "2024-05-21T21:31:39.871622100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wB6Qu1pBhd41",
    "outputId": "456309a2-7c4a-4f19-8e18-9922508807b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 systems\n",
      "Llama 3-70B\n",
      "MM1-30B\n",
      "Inflection-2.5\n",
      "MegaScale (Production)\n",
      "FunSearch\n",
      "Gemini 1.0 Ultra\n",
      "Qwen-72B\n",
      "Inflection-2\n",
      "Nemotron-3-8B\n",
      "Grok-1\n",
      "Yi-34B\n",
      "Skywork-13B\n",
      "ChatGLM3\n",
      "FinGPT-13B\n",
      "Falcon-180B\n",
      "Llama 2-70B\n",
      "Claude 2\n",
      "xTrimoPGLM -100B\n",
      "WizardCoder-15.5B\n",
      "PaLM 2\n",
      "BloombergGPT\n",
      "PanGu-Σ\n",
      "GPT-4\n",
      "Falcon-40B\n",
      "LLaMA-65B\n",
      "ViT-22B\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Galactica\n",
      "BLOOM-176B\n",
      "Flan-PaLM 540B\n",
      "U-PaLM (540B)\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "AlexaTM 20B\n",
      "Minerva (540B)\n",
      "Parti\n",
      "UL2\n",
      "OPT-175B\n",
      "Flamingo\n",
      "PaLM (540B)\n",
      "Chinchilla\n",
      "ST-MoE\n",
      "LaMDA\n",
      "AlphaCode\n",
      "ERNIE 3.0 Titan\n",
      "GLaM\n",
      "Gopher (280B)\n",
      "Yuan 1.0\n",
      "Megatron-Turing NLG 530B\n",
      "GPT-3 175B (davinci)\n",
      "Meena\n",
      "AlphaGo Zero\n",
      "AlphaGo Master\n"
     ]
    }
   ],
   "source": [
    "print(len(above_threshold), 'systems')\n",
    "for system in above_threshold['System'][::-1]:\n",
    "  print(system)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
