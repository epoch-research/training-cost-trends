{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPSm37gghSrl"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8Edmo7vA2Eg1",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:16.086433400Z",
     "start_time": "2024-05-21T21:31:13.561518800Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fXBbtVKi2LmG",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.210827700Z",
     "start_time": "2024-05-21T21:31:16.095336500Z"
    }
   },
   "outputs": [],
   "source": [
    "data_url = 'https://epochai.org/data/epochdb/all_systems.csv'\n",
    "dtypes = {\n",
    "    'Training compute (FLOP)': np.float64,\n",
    "}\n",
    "pcd_df = pd.read_csv(data_url, dtype=dtypes)\n",
    "pcd_df['Decimal year'] = pd.to_datetime(pcd_df['Publication date']).dt.year + (pd.to_datetime(pcd_df['Publication date']).dt.month - 1) / 12 + (pd.to_datetime(pcd_df['Publication date']).dt.day - 1) / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yyQJeGOA2m7e",
    "outputId": "0fe58fa3-79c0-46d1-f5ff-00802616c0b0",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.288846400Z",
     "start_time": "2024-05-21T21:31:17.210827700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                  System                            Domain  \\\n0                             Fugaku-LLM                          Language   \n1                       Gemini 1.5 Flash  Multimodal,Language,Vision,Audio   \n2                          Qwen 1.5 110B                          Language   \n3                       phi-3-medium 14B                          Language   \n4                          SenseNova 5.0                          Language   \n...                                  ...                               ...   \n1303  Sequence-based pattern recognition                            Vision   \n1304              Self Organizing System                             Other   \n1305                   Genetic algorithm                             Other   \n1306                               SNARC                          Robotics   \n1307                             Theseus                          Robotics   \n\n                                           Organization Publication date  \\\n0     Tohoku University,CyberAgent,Tokyo Institute o...       2024-05-10   \n1                                       Google DeepMind       2024-05-10   \n2                                               Alibaba       2024-04-25   \n3                                             Microsoft       2024-04-23   \n4                                             SenseTime       2024-04-23   \n...                                                 ...              ...   \n1303        Massachusetts Institute of Technology (MIT)       1955-03-01   \n1304        Massachusetts Institute of Technology (MIT)       1955-03-01   \n1305                       Institute for Advanced Study       1954-07-02   \n1306                                 Harvard University       1952-01-08   \n1307                                  Bell Laboratories       1950-07-02   \n\n                                              Reference  \\\n0     Release of “Fugaku-LLM” – a large language mod...   \n1     Gemini 1.5: Unlocking multimodal understanding...   \n2     Qwen1.5-110B: The First 100B+ Model of the Qwe...   \n3     Phi-3 Technical Report: A Highly Capable Langu...   \n4                                                   NaN   \n...                                                 ...   \n1303           Pattern recognition and modern computers   \n1304  Generalization of pattern recognition in a sel...   \n1305            Numerical testing of evolution theories   \n1306  A Neural-Analogue Calculator Based upon a Prob...   \n1307                                       Mighty Mouse   \n\n                                                   Link    Parameters  \\\n0     https://www.fujitsu.com/global/about/resources...  1.300000e+10   \n1     https://storage.googleapis.com/deepmind-media/...           NaN   \n2     https://qwenlm.github.io/blog/qwen1.5-110b/?re...  1.100000e+11   \n3                      https://arxiv.org/abs/2404.14219  1.400000e+10   \n4                       https://zhidx.com/p/421866.html           NaN   \n...                                                 ...           ...   \n1303     https://dl.acm.org/doi/10.1145/1455292.1455310           NaN   \n1304     https://dl.acm.org/doi/10.1145/1455292.1455309  2.250000e+02   \n1305  https://link.springer.com/article/10.1007/BF01...           NaN   \n1306  https://en.wikipedia.org/wiki/Stochastic_neura...  4.000000e+01   \n1307  https://www.technologyreview.com/2018/12/19/13...  4.000000e+01   \n\n                                       Parameters notes  \\\n0            \"Fugaku-LLM has 13 billion parameters (2)\"   \n1                                                   NaN   \n2                                                   NaN   \n3                                                   14B   \n4                                                   NaN   \n...                                                 ...   \n1303                                                NaN   \n1304         Figure 4 contains the learnt weight matrix   \n1305                                                NaN   \n1306  The link below seems to suggest the SNARC had ...   \n1307  The learned part is the maze configuration. Th...   \n\n      Training compute (FLOP)  \\\n0                2.964000e+22   \n1                         NaN   \n2                         NaN   \n3                4.032000e+23   \n4                         NaN   \n...                       ...   \n1303                      NaN   \n1304                      NaN   \n1305                      NaN   \n1306                      NaN   \n1307             4.000000e+01   \n\n                                 Training compute notes  ... Citations  \\\n0     https://www.wolframalpha.com/input?i=6+FLOP+*+...  ...       NaN   \n1                                                   NaN  ...       NaN   \n2                                                   NaN  ...       NaN   \n3     counting operations: 6×4.8×10^12×14×10^9 ≈ 4.0...  ...       NaN   \n4                                                   NaN  ...       NaN   \n...                                                 ...  ...       ...   \n1303                                                NaN  ...     290.0   \n1304                                                NaN  ...      93.0   \n1305                                                NaN  ...     266.0   \n1306                                                NaN  ...      33.0   \n1307  The \"training\" consists on the mouse running a...  ...       0.0   \n\n      Base model Finetune compute notes Training cloud compute vendor  \\\n0            NaN                    NaN                           NaN   \n1            NaN                    NaN                           NaN   \n2            NaN                    NaN                           NaN   \n3            NaN                    NaN                           NaN   \n4            NaN                    NaN                           NaN   \n...          ...                    ...                           ...   \n1303         NaN                    NaN                           NaN   \n1304         NaN                    NaN                           NaN   \n1305         NaN                    NaN                           NaN   \n1306         NaN                    NaN                           NaN   \n1307         NaN                    NaN                           NaN   \n\n     Batch size notes Finetune compute (FLOP) Training compute upper bound  \\\n0                 NaN                     NaN                          NaN   \n1                 NaN                     NaN                          NaN   \n2                 NaN                     NaN                          NaN   \n3                 NaN                     NaN                          NaN   \n4                 NaN                     NaN                          NaN   \n...               ...                     ...                          ...   \n1303              NaN                     NaN                          NaN   \n1304              NaN                     NaN                          NaN   \n1305              NaN                     NaN                          NaN   \n1306              NaN                     NaN                          NaN   \n1307              NaN                     NaN                          NaN   \n\n     Archived links Benchmark data Decimal year  \n0               NaN            NaN  2024.357991  \n1               NaN            NaN  2024.357991  \n2               NaN            NaN  2024.315753  \n3               NaN            NaN  2024.310274  \n4               NaN            NaN  2024.310274  \n...             ...            ...          ...  \n1303            NaN            NaN  1955.166667  \n1304            NaN            NaN  1955.166667  \n1305            NaN            NaN  1954.502740  \n1306            NaN            NaN  1952.019178  \n1307            NaN            NaN  1950.502740  \n\n[1308 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>System</th>\n      <th>Domain</th>\n      <th>Organization</th>\n      <th>Publication date</th>\n      <th>Reference</th>\n      <th>Link</th>\n      <th>Parameters</th>\n      <th>Parameters notes</th>\n      <th>Training compute (FLOP)</th>\n      <th>Training compute notes</th>\n      <th>...</th>\n      <th>Citations</th>\n      <th>Base model</th>\n      <th>Finetune compute notes</th>\n      <th>Training cloud compute vendor</th>\n      <th>Batch size notes</th>\n      <th>Finetune compute (FLOP)</th>\n      <th>Training compute upper bound</th>\n      <th>Archived links</th>\n      <th>Benchmark data</th>\n      <th>Decimal year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fugaku-LLM</td>\n      <td>Language</td>\n      <td>Tohoku University,CyberAgent,Tokyo Institute o...</td>\n      <td>2024-05-10</td>\n      <td>Release of “Fugaku-LLM” – a large language mod...</td>\n      <td>https://www.fujitsu.com/global/about/resources...</td>\n      <td>1.300000e+10</td>\n      <td>\"Fugaku-LLM has 13 billion parameters (2)\"</td>\n      <td>2.964000e+22</td>\n      <td>https://www.wolframalpha.com/input?i=6+FLOP+*+...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.357991</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gemini 1.5 Flash</td>\n      <td>Multimodal,Language,Vision,Audio</td>\n      <td>Google DeepMind</td>\n      <td>2024-05-10</td>\n      <td>Gemini 1.5: Unlocking multimodal understanding...</td>\n      <td>https://storage.googleapis.com/deepmind-media/...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.357991</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Qwen 1.5 110B</td>\n      <td>Language</td>\n      <td>Alibaba</td>\n      <td>2024-04-25</td>\n      <td>Qwen1.5-110B: The First 100B+ Model of the Qwe...</td>\n      <td>https://qwenlm.github.io/blog/qwen1.5-110b/?re...</td>\n      <td>1.100000e+11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.315753</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>phi-3-medium 14B</td>\n      <td>Language</td>\n      <td>Microsoft</td>\n      <td>2024-04-23</td>\n      <td>Phi-3 Technical Report: A Highly Capable Langu...</td>\n      <td>https://arxiv.org/abs/2404.14219</td>\n      <td>1.400000e+10</td>\n      <td>14B</td>\n      <td>4.032000e+23</td>\n      <td>counting operations: 6×4.8×10^12×14×10^9 ≈ 4.0...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.310274</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SenseNova 5.0</td>\n      <td>Language</td>\n      <td>SenseTime</td>\n      <td>2024-04-23</td>\n      <td>NaN</td>\n      <td>https://zhidx.com/p/421866.html</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.310274</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1303</th>\n      <td>Sequence-based pattern recognition</td>\n      <td>Vision</td>\n      <td>Massachusetts Institute of Technology (MIT)</td>\n      <td>1955-03-01</td>\n      <td>Pattern recognition and modern computers</td>\n      <td>https://dl.acm.org/doi/10.1145/1455292.1455310</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>290.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1955.166667</td>\n    </tr>\n    <tr>\n      <th>1304</th>\n      <td>Self Organizing System</td>\n      <td>Other</td>\n      <td>Massachusetts Institute of Technology (MIT)</td>\n      <td>1955-03-01</td>\n      <td>Generalization of pattern recognition in a sel...</td>\n      <td>https://dl.acm.org/doi/10.1145/1455292.1455309</td>\n      <td>2.250000e+02</td>\n      <td>Figure 4 contains the learnt weight matrix</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>93.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1955.166667</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>Genetic algorithm</td>\n      <td>Other</td>\n      <td>Institute for Advanced Study</td>\n      <td>1954-07-02</td>\n      <td>Numerical testing of evolution theories</td>\n      <td>https://link.springer.com/article/10.1007/BF01...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>266.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1954.502740</td>\n    </tr>\n    <tr>\n      <th>1306</th>\n      <td>SNARC</td>\n      <td>Robotics</td>\n      <td>Harvard University</td>\n      <td>1952-01-08</td>\n      <td>A Neural-Analogue Calculator Based upon a Prob...</td>\n      <td>https://en.wikipedia.org/wiki/Stochastic_neura...</td>\n      <td>4.000000e+01</td>\n      <td>The link below seems to suggest the SNARC had ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1952.019178</td>\n    </tr>\n    <tr>\n      <th>1307</th>\n      <td>Theseus</td>\n      <td>Robotics</td>\n      <td>Bell Laboratories</td>\n      <td>1950-07-02</td>\n      <td>Mighty Mouse</td>\n      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n      <td>4.000000e+01</td>\n      <td>The learned part is the maze configuration. Th...</td>\n      <td>4.000000e+01</td>\n      <td>The \"training\" consists on the mouse running a...</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1950.502740</td>\n    </tr>\n  </tbody>\n</table>\n<p>1308 rows × 46 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XZ0FKyaZ3h_W",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.304527400Z",
     "start_time": "2024-05-21T21:31:17.288846400Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_df['Publication date'] = pd.to_datetime(pcd_df['Publication date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rcOYiwwg3oVY",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.351750400Z",
     "start_time": "2024-05-21T21:31:17.304527400Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_df.sort_values('Publication date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QLUi4aysAXWr",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.414608800Z",
     "start_time": "2024-05-21T21:31:17.323609400Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_df.dropna(subset=['Publication date', 'Notability criteria', 'Training compute (FLOP)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wGGuurmk4uZd",
    "outputId": "5d822c9c-67e5-4f2c-ff8b-9418f82d05e2",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.509956200Z",
     "start_time": "2024-05-21T21:31:17.351750400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                      System                      Domain  \\\n1307                 Theseus                    Robotics   \n1301       Perceptron Mark I                       Other   \n1300     Pandemonium (morse)                    Language   \n1299  Samuel Neural Checkers                       Games   \n1297       Perceptron (1960)                      Vision   \n...                      ...                         ...   \n30    MegaScale (Production)                    Language   \n21            Inflection-2.5                    Language   \n20                   MM1-30B  Multimodal,Language,Vision   \n13         Mixture-of-Depths                    Language   \n5                Llama 3-70B                    Language   \n\n                                           Organization Publication date  \\\n1307                                  Bell Laboratories       1950-07-02   \n1301  Cornell Aeronautical Laboratory,Cornell Univer...       1957-01-01   \n1300        Massachusetts Institute of Technology (MIT)       1959-02-01   \n1299                                                IBM       1959-07-01   \n1297                    Cornell Aeronautical Laboratory       1960-03-30   \n...                                                 ...              ...   \n30                          ByteDance,Peking University       2024-02-23   \n21                                        Inflection AI       2024-03-07   \n20                                                Apple       2024-03-14   \n13               Google DeepMind,McGill University,Mila       2024-04-02   \n5                                               Meta AI       2024-04-18   \n\n                                              Reference  \\\n1307                                       Mighty Mouse   \n1301  The Perceptron—a perceiving and recognizing au...   \n1300               Pandemonium: A Paradigm for Learning   \n1299  Some studies in machine learning using the gam...   \n1297                  Perceptron Simulation Experiments   \n...                                                 ...   \n30    MegaScale: Scaling Large Language Model Traini...   \n21    Inflection-2.5: meet the world's best personal AI   \n20    MM1: Methods, Analysis & Insights from Multimo...   \n13    Mixture-of-Depths: Dynamically allocating comp...   \n5     Introducing Meta Llama 3: The most capable ope...   \n\n                                                   Link    Parameters  \\\n1307  https://www.technologyreview.com/2018/12/19/13...  4.000000e+01   \n1301  https://blogs.umass.edu/brain-wars/files/2016/...  1.000000e+03   \n1300        https://aitopics.org/doc/classics:504E1BAC/           NaN   \n1299  https://ieeexplore.ieee.org/abstract/document/...  1.600000e+01   \n1297  https://www.semanticscholar.org/paper/Perceptr...  1.000000e+03   \n...                                                 ...           ...   \n30                     https://arxiv.org/abs/2402.15627  5.300000e+11   \n21                 https://inflection.ai/inflection-2-5           NaN   \n20                     https://arxiv.org/abs/2403.09611  3.000000e+10   \n13                     https://arxiv.org/abs/2404.02258  3.000000e+09   \n5     https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n\n                                       Parameters notes  \\\n1307  The learned part is the maze configuration. Th...   \n1301  \"Figure 4.8 Illustration of the Mark 1 percept...   \n1300  The paper mentions 11 function types. Unclear ...   \n1299  \"with 16 terms for generalization learning\"\\n\\...   \n1297  \" The first program was designed to handle\\nup...   \n...                                                 ...   \n30    Production run is stated to have \"hundreds of ...   \n21                                                  NaN   \n20                                                  30B   \n13    Figure 4: \"We used the 12.5% capacity MoD vari...   \n5                                                   NaN   \n\n      Training compute (FLOP)  \\\n1307             4.000000e+01   \n1301             6.948949e+05   \n1300             6.000000e+08   \n1299             4.284000e+08   \n1297             7.200000e+08   \n...                       ...   \n30               1.200000e+25   \n21               1.000100e+25   \n20               4.860000e+23   \n13               1.000000e+20   \n5                6.300000e+24   \n\n                                 Training compute notes  ... Citations  \\\n1307  The \"training\" consists on the mouse running a...  ...       0.0   \n1301  Extracted from AI and Compute (https://openai....  ...    1610.0   \n1300  The paper mentions using an IBM 704, which can...  ...    1453.0   \n1299  \"it can learn to do this in a remarkably short...  ...    4509.0   \n1297  4000 * 12000 * 15\\nfrom the text \"This program...  ...     394.0   \n...                                                 ...  ...       ...   \n30    Speculative. The model is stated to have train...  ...       1.0   \n21    \"Inflection-1 used approximately 4% the traini...  ...       NaN   \n20    Pre-trained on ~2B image-text pairs and 2T tok...  ...      11.0   \n13    Figure 4: \"We used the 12.5% capacity MoD vari...  ...       1.0   \n5     direct calculation\\n15000000000000 tokens*7000...  ...       NaN   \n\n      Base model Finetune compute notes Training cloud compute vendor  \\\n1307         NaN                    NaN                           NaN   \n1301         NaN                    NaN                           NaN   \n1300         NaN                    NaN                           NaN   \n1299         NaN                    NaN                           NaN   \n1297         NaN                    NaN                           NaN   \n...          ...                    ...                           ...   \n30           NaN                    NaN                           NaN   \n21           NaN                    NaN                           NaN   \n20           NaN                    NaN                           NaN   \n13           NaN                    NaN                           NaN   \n5            NaN                    NaN                           NaN   \n\n     Batch size notes Finetune compute (FLOP) Training compute upper bound  \\\n1307              NaN                     NaN                          NaN   \n1301              NaN                     NaN                          NaN   \n1300              NaN                     NaN                          NaN   \n1299              NaN                     NaN                          NaN   \n1297              NaN                     NaN                          NaN   \n...               ...                     ...                          ...   \n30                NaN                     NaN                          NaN   \n21                NaN                     NaN                          NaN   \n20                NaN                     NaN                          NaN   \n13                NaN                     NaN                          NaN   \n5                 NaN                     NaN                          NaN   \n\n     Archived links Benchmark data Decimal year  \n1307            NaN            NaN  1950.502740  \n1301            NaN            NaN  1957.000000  \n1300            NaN            NaN  1959.083333  \n1299            NaN            NaN  1959.500000  \n1297            NaN            NaN  1960.246119  \n...             ...            ...          ...  \n30              NaN            NaN  2024.143607  \n21              NaN            NaN  2024.183105  \n20              NaN            NaN  2024.202283  \n13              NaN            NaN  2024.252740  \n5               NaN            NaN  2024.296575  \n\n[368 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>System</th>\n      <th>Domain</th>\n      <th>Organization</th>\n      <th>Publication date</th>\n      <th>Reference</th>\n      <th>Link</th>\n      <th>Parameters</th>\n      <th>Parameters notes</th>\n      <th>Training compute (FLOP)</th>\n      <th>Training compute notes</th>\n      <th>...</th>\n      <th>Citations</th>\n      <th>Base model</th>\n      <th>Finetune compute notes</th>\n      <th>Training cloud compute vendor</th>\n      <th>Batch size notes</th>\n      <th>Finetune compute (FLOP)</th>\n      <th>Training compute upper bound</th>\n      <th>Archived links</th>\n      <th>Benchmark data</th>\n      <th>Decimal year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1307</th>\n      <td>Theseus</td>\n      <td>Robotics</td>\n      <td>Bell Laboratories</td>\n      <td>1950-07-02</td>\n      <td>Mighty Mouse</td>\n      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n      <td>4.000000e+01</td>\n      <td>The learned part is the maze configuration. Th...</td>\n      <td>4.000000e+01</td>\n      <td>The \"training\" consists on the mouse running a...</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1950.502740</td>\n    </tr>\n    <tr>\n      <th>1301</th>\n      <td>Perceptron Mark I</td>\n      <td>Other</td>\n      <td>Cornell Aeronautical Laboratory,Cornell Univer...</td>\n      <td>1957-01-01</td>\n      <td>The Perceptron—a perceiving and recognizing au...</td>\n      <td>https://blogs.umass.edu/brain-wars/files/2016/...</td>\n      <td>1.000000e+03</td>\n      <td>\"Figure 4.8 Illustration of the Mark 1 percept...</td>\n      <td>6.948949e+05</td>\n      <td>Extracted from AI and Compute (https://openai....</td>\n      <td>...</td>\n      <td>1610.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1957.000000</td>\n    </tr>\n    <tr>\n      <th>1300</th>\n      <td>Pandemonium (morse)</td>\n      <td>Language</td>\n      <td>Massachusetts Institute of Technology (MIT)</td>\n      <td>1959-02-01</td>\n      <td>Pandemonium: A Paradigm for Learning</td>\n      <td>https://aitopics.org/doc/classics:504E1BAC/</td>\n      <td>NaN</td>\n      <td>The paper mentions 11 function types. Unclear ...</td>\n      <td>6.000000e+08</td>\n      <td>The paper mentions using an IBM 704, which can...</td>\n      <td>...</td>\n      <td>1453.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1959.083333</td>\n    </tr>\n    <tr>\n      <th>1299</th>\n      <td>Samuel Neural Checkers</td>\n      <td>Games</td>\n      <td>IBM</td>\n      <td>1959-07-01</td>\n      <td>Some studies in machine learning using the gam...</td>\n      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n      <td>1.600000e+01</td>\n      <td>\"with 16 terms for generalization learning\"\\n\\...</td>\n      <td>4.284000e+08</td>\n      <td>\"it can learn to do this in a remarkably short...</td>\n      <td>...</td>\n      <td>4509.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1959.500000</td>\n    </tr>\n    <tr>\n      <th>1297</th>\n      <td>Perceptron (1960)</td>\n      <td>Vision</td>\n      <td>Cornell Aeronautical Laboratory</td>\n      <td>1960-03-30</td>\n      <td>Perceptron Simulation Experiments</td>\n      <td>https://www.semanticscholar.org/paper/Perceptr...</td>\n      <td>1.000000e+03</td>\n      <td>\" The first program was designed to handle\\nup...</td>\n      <td>7.200000e+08</td>\n      <td>4000 * 12000 * 15\\nfrom the text \"This program...</td>\n      <td>...</td>\n      <td>394.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1960.246119</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>MegaScale (Production)</td>\n      <td>Language</td>\n      <td>ByteDance,Peking University</td>\n      <td>2024-02-23</td>\n      <td>MegaScale: Scaling Large Language Model Traini...</td>\n      <td>https://arxiv.org/abs/2402.15627</td>\n      <td>5.300000e+11</td>\n      <td>Production run is stated to have \"hundreds of ...</td>\n      <td>1.200000e+25</td>\n      <td>Speculative. The model is stated to have train...</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.143607</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Inflection-2.5</td>\n      <td>Language</td>\n      <td>Inflection AI</td>\n      <td>2024-03-07</td>\n      <td>Inflection-2.5: meet the world's best personal AI</td>\n      <td>https://inflection.ai/inflection-2-5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000100e+25</td>\n      <td>\"Inflection-1 used approximately 4% the traini...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.183105</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>MM1-30B</td>\n      <td>Multimodal,Language,Vision</td>\n      <td>Apple</td>\n      <td>2024-03-14</td>\n      <td>MM1: Methods, Analysis &amp; Insights from Multimo...</td>\n      <td>https://arxiv.org/abs/2403.09611</td>\n      <td>3.000000e+10</td>\n      <td>30B</td>\n      <td>4.860000e+23</td>\n      <td>Pre-trained on ~2B image-text pairs and 2T tok...</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.202283</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Mixture-of-Depths</td>\n      <td>Language</td>\n      <td>Google DeepMind,McGill University,Mila</td>\n      <td>2024-04-02</td>\n      <td>Mixture-of-Depths: Dynamically allocating comp...</td>\n      <td>https://arxiv.org/abs/2404.02258</td>\n      <td>3.000000e+09</td>\n      <td>Figure 4: \"We used the 12.5% capacity MoD vari...</td>\n      <td>1.000000e+20</td>\n      <td>Figure 4: \"We used the 12.5% capacity MoD vari...</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.252740</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Llama 3-70B</td>\n      <td>Language</td>\n      <td>Meta AI</td>\n      <td>2024-04-18</td>\n      <td>Introducing Meta Llama 3: The most capable ope...</td>\n      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n      <td>7.000000e+10</td>\n      <td>NaN</td>\n      <td>6.300000e+24</td>\n      <td>direct calculation\\n15000000000000 tokens*7000...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2024.296575</td>\n    </tr>\n  </tbody>\n</table>\n<p>368 rows × 46 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zFUQoG_01L8m",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.557085700Z",
     "start_time": "2024-05-21T21:31:17.383067900Z"
    }
   },
   "outputs": [],
   "source": [
    "outlier_window_size = 2  # years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:17.557085700Z",
     "start_time": "2024-05-21T21:31:17.414608800Z"
    }
   },
   "outputs": [],
   "source": [
    "start_large_scale_era = '2015-10-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrayDGa4hK6X"
   },
   "source": [
    "# Top n all-time most compute-intensive (FIRST CHOICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.365327500Z",
     "start_time": "2024-05-21T21:31:17.414608800Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in range(1, 21):\n",
    "    # Add a column to mark the top n models\n",
    "    pcd_df[f'top_{n}_at_release'] = False\n",
    "    \n",
    "    for row, model in pcd_df.iterrows():\n",
    "        # Filter for models released through the model's release date\n",
    "        yearly_df = pcd_df[pcd_df['Decimal year'] <= model['Decimal year']]\n",
    "        # get the top n models by compute\n",
    "        top_n_models = yearly_df.nlargest(n, 'Training compute (FLOP)')\n",
    "        # mark these models in the original dataframe\n",
    "        pcd_df.loc[top_n_models.index, f'top_{n}_at_release'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.399202100Z",
     "start_time": "2024-05-21T21:31:30.366362100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['System', 'Domain', 'Organization', 'Publication date', 'Reference',\n       'Link', 'Parameters', 'Parameters notes', 'Training compute (FLOP)',\n       'Training compute notes', 'Training dataset notes',\n       'Training dataset size (datapoints)', 'Dataset size notes', 'Abstract',\n       'Confidence', 'Model accessibility', 'Last modified', 'Created By',\n       'Country (from Organization)', 'Organization categorization', 'Authors',\n       'Training time notes', 'Training hardware', 'Training dataset',\n       'Notability criteria', 'Notability criteria notes', 'Exclude',\n       'Hardware quantity', 'Hardware utilization', 'Training time (hours)',\n       'Batch size', 'Approach', 'Training compute lower bound', 'Epochs',\n       'Foundation model', 'Training data center', 'Citations', 'Base model',\n       'Finetune compute notes', 'Training cloud compute vendor',\n       'Batch size notes', 'Finetune compute (FLOP)',\n       'Training compute upper bound', 'Archived links', 'Benchmark data',\n       'Decimal year', 'top_1_at_release', 'top_2_at_release',\n       'top_3_at_release', 'top_4_at_release', 'top_5_at_release',\n       'top_6_at_release', 'top_7_at_release', 'top_8_at_release',\n       'top_9_at_release', 'top_10_at_release', 'top_11_at_release',\n       'top_12_at_release', 'top_13_at_release', 'top_14_at_release',\n       'top_15_at_release', 'top_16_at_release', 'top_17_at_release',\n       'top_18_at_release', 'top_19_at_release', 'top_20_at_release'],\n      dtype='object')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.446484200Z",
     "start_time": "2024-05-21T21:31:30.399202100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "75"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pcd_df['top_4_at_release'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.446484200Z",
     "start_time": "2024-05-21T21:31:30.430780900Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_df_n = pcd_df[(pcd_df['Decimal year'] > 2015.75) & (pcd_df['Decimal year'] < 2024)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.700498200Z",
     "start_time": "2024-05-21T21:31:30.446484200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_n = [np.sum(pcd_df_n[f'top_{n}_at_release']) for n in range(1, 21)]\n",
    "plt.scatter(range(1, 21), top_n)\n",
    "plt.xticks(ticks=range(1, 21))\n",
    "plt.xlabel('n-value for top n')\n",
    "plt.ylabel('Models which have ever been in the top n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.747327700Z",
     "start_time": "2024-05-21T21:31:30.700498200Z"
    }
   },
   "outputs": [],
   "source": [
    "top_n_models = {}\n",
    "for n in range(1, 21):\n",
    "    models = pcd_df_n[pcd_df_n[f'top_{n}_at_release']]['System'].values.tolist()\n",
    "    top_n_models[n] = set(models)\n",
    "\n",
    "for n in range(20, 1, -1):\n",
    "    top_n_models[n] = list(top_n_models[n].difference(top_n_models[n-1]))\n",
    "top_n_models[1] = list(top_n_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.747327700Z",
     "start_time": "2024-05-21T21:31:30.731783700Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/frontier_systems_by_top_n.json', 'w') as f:\n",
    "    json.dump(top_n_models, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrayDGa4hK6X"
   },
   "source": [
    "# Default large scale systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ort2OjXauNI-"
   },
   "source": [
    "https://colab.research.google.com/drive/1PLGY5ErysqQMfy7Z08uIR2cTnnDgSaVR?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Xo0BSLmQ4RpG",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:30.762947700Z",
     "start_time": "2024-05-21T21:31:30.747327700Z"
    }
   },
   "outputs": [],
   "source": [
    "high_outliers_z_value_threshold = 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sTTmucLNtU8l",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:31.237076300Z",
     "start_time": "2024-05-21T21:31:30.762947700Z"
    }
   },
   "outputs": [],
   "source": [
    "large_scale_idx = set()\n",
    "\n",
    "for index, row in pcd_df.iterrows():\n",
    "  # Filter entries in a 2-year window around the paper\n",
    "  window_size = pd.Timedelta(f'{outlier_window_size*52*7} days')\n",
    "  half_window_size = window_size / 2\n",
    "  mask = ( row['Publication date'] - half_window_size <= pcd_df['Publication date'] ) &\\\n",
    "        ( pcd_df['Publication date'] <= row['Publication date'] + half_window_size )\n",
    "  window_df = pcd_df[mask].copy()\n",
    "\n",
    "  if len(window_df) < 2: continue\n",
    "\n",
    "  window_df['Training compute (FLOP) z scores'] = stats.zscore(np.log10(window_df['Training compute (FLOP)'].values))\n",
    "  if window_df.loc[index, 'Training compute (FLOP) z scores'] > high_outliers_z_value_threshold:\n",
    "    large_scale_idx.add(index)\n",
    "\n",
    "large_scale_mask = pcd_df.index.isin(large_scale_idx) & (pcd_df['Publication date'] > start_large_scale_era)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "w2HakL5g4iUq",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:31.252618300Z",
     "start_time": "2024-05-21T21:31:31.237076300Z"
    }
   },
   "outputs": [],
   "source": [
    "large_scale_df = pcd_df[large_scale_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y4-TmYMQ7Iex",
    "outputId": "485901a3-4ccd-4956-bba8-e81f64bf5c0f",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:31.299553500Z",
     "start_time": "2024-05-21T21:31:31.252618300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                      System                      Domain  \\\n1019             AlphaGo Lee                       Games   \n980                     GNMT                    Language   \n979                 Xception                      Vision   \n973         NASv3 (CIFAR-10)                      Vision   \n957                 Libratus                       Games   \n...                      ...                         ...   \n82                  Qwen-72B                    Language   \n74          Gemini 1.0 Ultra  Multimodal,Language,Vision   \n30    MegaScale (Production)                    Language   \n21            Inflection-2.5                    Language   \n5                Llama 3-70B                    Language   \n\n                          Organization Publication date  \\\n1019                          DeepMind       2016-01-27   \n980                             Google       2016-09-26   \n979                             Google       2016-10-07   \n973                       Google Brain       2016-11-05   \n957   Carnegie Mellon University (CMU)       2017-01-01   \n...                                ...              ...   \n82                             Alibaba       2023-11-30   \n74                     Google DeepMind       2023-12-06   \n30         ByteDance,Peking University       2024-02-23   \n21                       Inflection AI       2024-03-07   \n5                              Meta AI       2024-04-18   \n\n                                              Reference  \\\n1019  Mastering the game of Go with deep neural netw...   \n980   Google's Neural Machine Translation System: Br...   \n979   Xception: Deep Learning with Depthwise Separab...   \n973   Neural Architecture Search with Reinforcement ...   \n957      Libratus: The Superhuman AI for No-Limit Poker   \n...                                                 ...   \n82                                                  NaN   \n74    Gemini: A Family of Highly Capable Multimodal ...   \n30    MegaScale: Scaling Large Language Model Traini...   \n21    Inflection-2.5: meet the world's best personal AI   \n5     Introducing Meta Llama 3: The most capable ope...   \n\n                                                   Link    Parameters  \\\n1019        https://www.nature.com/articles/nature16961           NaN   \n980                    https://arxiv.org/abs/1609.08144  2.780000e+08   \n979                    https://arxiv.org/abs/1610.02357  2.285595e+07   \n973                    https://arxiv.org/abs/1611.01578  3.740000e+07   \n957   https://www.cs.cmu.edu/~noamb/papers/17-IJCAI-...           NaN   \n...                                                 ...           ...   \n82                 https://huggingface.co/Qwen/Qwen-72B  7.200000e+10   \n74    https://storage.googleapis.com/deepmind-media/...           NaN   \n30                     https://arxiv.org/abs/2402.15627  5.300000e+11   \n21                 https://inflection.ai/inflection-2-5           NaN   \n5     https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n\n                                       Parameters notes  \\\n1019                                                NaN   \n980   Table 5 in 'Outrageously Large Neural Networks...   \n979                                             Table 3   \n973                                             Table 1   \n957                                                 NaN   \n...                                                 ...   \n82                                                  72B   \n74                                                  NaN   \n30    Production run is stated to have \"hundreds of ...   \n21                                                  NaN   \n5                                                   NaN   \n\n      Training compute (FLOP)  \\\n1019             1.900000e+21   \n980              6.900000e+21   \n979              4.360000e+20   \n973              2.200000e+21   \n957              5.510000e+20   \n...                       ...   \n82               1.300000e+24   \n74               5.000000e+25   \n30               1.200000e+25   \n21               1.000100e+25   \n5                6.300000e+24   \n\n                                 Training compute notes  ...  \\\n1019  This number is pretty uncertain. I expect it t...  ...   \n980   sqrt(10 * 100) factor added because production...  ...   \n979   60 K80 GPUs * 30 days * 8.5 TFLOPS/GPU * 0.33 ...  ...   \n973   50 epochs * 50,000 images * 10.0 GFLOPSs * 128...  ...   \n957   \"In total, Libratus used about 25 million core...  ...   \n...                                                 ...  ...   \n82    72 billion params, 3 trillion tokens\\n72b * 3T...  ...   \n74    This number is an estimate based on limited ev...  ...   \n30    Speculative. The model is stated to have train...  ...   \n21    \"Inflection-1 used approximately 4% the traini...  ...   \n5     direct calculation\\n15000000000000 tokens*7000...  ...   \n\n     top_11_at_release  top_12_at_release top_13_at_release top_14_at_release  \\\n1019              True               True              True              True   \n980               True               True              True              True   \n979               True               True              True              True   \n973               True               True              True              True   \n957               True               True              True              True   \n...                ...                ...               ...               ...   \n82               False               True              True              True   \n74                True               True              True              True   \n30                True               True              True              True   \n21                True               True              True              True   \n5                 True               True              True              True   \n\n     top_15_at_release top_16_at_release top_17_at_release top_18_at_release  \\\n1019              True              True              True              True   \n980               True              True              True              True   \n979               True              True              True              True   \n973               True              True              True              True   \n957               True              True              True              True   \n...                ...               ...               ...               ...   \n82                True              True              True              True   \n74                True              True              True              True   \n30                True              True              True              True   \n21                True              True              True              True   \n5                 True              True              True              True   \n\n     top_19_at_release top_20_at_release  \n1019              True              True  \n980               True              True  \n979               True              True  \n973               True              True  \n957               True              True  \n...                ...               ...  \n82                True              True  \n74                True              True  \n30                True              True  \n21                True              True  \n5                 True              True  \n\n[74 rows x 66 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>System</th>\n      <th>Domain</th>\n      <th>Organization</th>\n      <th>Publication date</th>\n      <th>Reference</th>\n      <th>Link</th>\n      <th>Parameters</th>\n      <th>Parameters notes</th>\n      <th>Training compute (FLOP)</th>\n      <th>Training compute notes</th>\n      <th>...</th>\n      <th>top_11_at_release</th>\n      <th>top_12_at_release</th>\n      <th>top_13_at_release</th>\n      <th>top_14_at_release</th>\n      <th>top_15_at_release</th>\n      <th>top_16_at_release</th>\n      <th>top_17_at_release</th>\n      <th>top_18_at_release</th>\n      <th>top_19_at_release</th>\n      <th>top_20_at_release</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1019</th>\n      <td>AlphaGo Lee</td>\n      <td>Games</td>\n      <td>DeepMind</td>\n      <td>2016-01-27</td>\n      <td>Mastering the game of Go with deep neural netw...</td>\n      <td>https://www.nature.com/articles/nature16961</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.900000e+21</td>\n      <td>This number is pretty uncertain. I expect it t...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>980</th>\n      <td>GNMT</td>\n      <td>Language</td>\n      <td>Google</td>\n      <td>2016-09-26</td>\n      <td>Google's Neural Machine Translation System: Br...</td>\n      <td>https://arxiv.org/abs/1609.08144</td>\n      <td>2.780000e+08</td>\n      <td>Table 5 in 'Outrageously Large Neural Networks...</td>\n      <td>6.900000e+21</td>\n      <td>sqrt(10 * 100) factor added because production...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>Xception</td>\n      <td>Vision</td>\n      <td>Google</td>\n      <td>2016-10-07</td>\n      <td>Xception: Deep Learning with Depthwise Separab...</td>\n      <td>https://arxiv.org/abs/1610.02357</td>\n      <td>2.285595e+07</td>\n      <td>Table 3</td>\n      <td>4.360000e+20</td>\n      <td>60 K80 GPUs * 30 days * 8.5 TFLOPS/GPU * 0.33 ...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>973</th>\n      <td>NASv3 (CIFAR-10)</td>\n      <td>Vision</td>\n      <td>Google Brain</td>\n      <td>2016-11-05</td>\n      <td>Neural Architecture Search with Reinforcement ...</td>\n      <td>https://arxiv.org/abs/1611.01578</td>\n      <td>3.740000e+07</td>\n      <td>Table 1</td>\n      <td>2.200000e+21</td>\n      <td>50 epochs * 50,000 images * 10.0 GFLOPSs * 128...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>957</th>\n      <td>Libratus</td>\n      <td>Games</td>\n      <td>Carnegie Mellon University (CMU)</td>\n      <td>2017-01-01</td>\n      <td>Libratus: The Superhuman AI for No-Limit Poker</td>\n      <td>https://www.cs.cmu.edu/~noamb/papers/17-IJCAI-...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.510000e+20</td>\n      <td>\"In total, Libratus used about 25 million core...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Qwen-72B</td>\n      <td>Language</td>\n      <td>Alibaba</td>\n      <td>2023-11-30</td>\n      <td>NaN</td>\n      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n      <td>7.200000e+10</td>\n      <td>72B</td>\n      <td>1.300000e+24</td>\n      <td>72 billion params, 3 trillion tokens\\n72b * 3T...</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Gemini 1.0 Ultra</td>\n      <td>Multimodal,Language,Vision</td>\n      <td>Google DeepMind</td>\n      <td>2023-12-06</td>\n      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n      <td>https://storage.googleapis.com/deepmind-media/...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.000000e+25</td>\n      <td>This number is an estimate based on limited ev...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>MegaScale (Production)</td>\n      <td>Language</td>\n      <td>ByteDance,Peking University</td>\n      <td>2024-02-23</td>\n      <td>MegaScale: Scaling Large Language Model Traini...</td>\n      <td>https://arxiv.org/abs/2402.15627</td>\n      <td>5.300000e+11</td>\n      <td>Production run is stated to have \"hundreds of ...</td>\n      <td>1.200000e+25</td>\n      <td>Speculative. The model is stated to have train...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Inflection-2.5</td>\n      <td>Language</td>\n      <td>Inflection AI</td>\n      <td>2024-03-07</td>\n      <td>Inflection-2.5: meet the world's best personal AI</td>\n      <td>https://inflection.ai/inflection-2-5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000100e+25</td>\n      <td>\"Inflection-1 used approximately 4% the traini...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Llama 3-70B</td>\n      <td>Language</td>\n      <td>Meta AI</td>\n      <td>2024-04-18</td>\n      <td>Introducing Meta Llama 3: The most capable ope...</td>\n      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n      <td>7.000000e+10</td>\n      <td>NaN</td>\n      <td>6.300000e+24</td>\n      <td>direct calculation\\n15000000000000 tokens*7000...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>74 rows × 66 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_scale_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ngeVX9J-1yx",
    "outputId": "949a42f5-e8c9-4c65-fcc9-c5ae79651d10",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:31.330725700Z",
     "start_time": "2024-05-21T21:31:31.299553500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3-70B\n",
      "Inflection-2.5\n",
      "MegaScale (Production)\n",
      "Gemini 1.0 Ultra\n",
      "Qwen-72B\n",
      "Inflection-2\n",
      "Grok-1\n",
      "ChatGLM3\n",
      "Falcon-180B\n",
      "Llama 2-70B\n",
      "Claude 2\n",
      "PaLM 2\n",
      "GPT-4\n",
      "LLaMA-65B\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Galactica\n",
      "BLOOM-176B\n",
      "Flan-PaLM 540B\n",
      "U-PaLM (540B)\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "Minerva (540B)\n",
      "Parti\n",
      "OPT-175B\n",
      "Flamingo\n",
      "PaLM (540B)\n",
      "Chinchilla\n",
      "ST-MoE\n",
      "LaMDA\n",
      "AlphaCode\n",
      "ERNIE 3.0 Titan\n",
      "GLaM\n",
      "Gopher (280B)\n",
      "Yuan 1.0\n",
      "Megatron-Turing NLG 530B\n",
      "GOAT\n",
      "ByT5-XXL\n",
      "ProtT5-XXL\n",
      "Meta Pseudo Labels\n",
      "Switch\n",
      "DALL-E\n",
      "mT5-XXL\n",
      "GShard (dense)\n",
      "iGPT-XL\n",
      "GPT-3 175B (davinci)\n",
      "Turing-NLG\n",
      "Meena\n",
      "ContextNet + Noisy Student\n",
      "OpenAI Five Rerun\n",
      "OpenAI Five\n",
      "AlphaStar\n",
      "T5-11B\n",
      "Megatron-LM (8.3B)\n",
      "Megatron-BERT\n",
      "RoBERTa Large\n",
      "XLNet\n",
      "MnasNet-A3\n",
      "MnasNet-A1 + SSDLite\n",
      "GPT-2 (1.5B)\n",
      "Transformer (Adaptive Input Embeddings)\n",
      "BigGAN-deep 512x512\n",
      "FTW\n",
      "ResNeXt-101 32x48d\n",
      "AmoebaNet-A (F=448)\n",
      "AlphaZero\n",
      "AlphaGo Zero\n",
      "OpenAI TI7 DOTA 1v1\n",
      "JFT\n",
      "AlphaGo Master\n",
      "Libratus\n",
      "NASv3 (CIFAR-10)\n",
      "Xception\n",
      "GNMT\n",
      "AlphaGo Lee\n"
     ]
    }
   ],
   "source": [
    "for system in large_scale_df['System'][::-1]:\n",
    "  print(system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1TTIzTQhPan"
   },
   "source": [
    "# Percentiles (SECOND CHOICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-cxrNxPbW7r",
    "outputId": "1ab54428-dc65-4d79-e6a0-feff77ad6e1d",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.615025800Z",
     "start_time": "2024-05-21T21:31:31.315133300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "90\n",
      "85\n",
      "80\n",
      "75\n",
      "70\n",
      "65\n",
      "60\n",
      "55\n",
      "50\n",
      "45\n",
      "40\n",
      "35\n",
      "30\n",
      "25\n",
      "20\n",
      "15\n",
      "10\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "frontier_systems_by_percentile = {}\n",
    "percentile_interval = 5\n",
    "for percentile in range(95, -5, -percentile_interval):\n",
    "  print(percentile)\n",
    "  percentile_compute_low = np.zeros(len(pcd_df))\n",
    "  percentile_compute_high = np.zeros(len(pcd_df))\n",
    "  # Iterate through each row and calculate the 2-year moving average for each date\n",
    "  for i, (index, row) in enumerate(pcd_df.iterrows()):\n",
    "    # Define the 2-year window\n",
    "    start_date = row['Publication date'] - pd.DateOffset(years=outlier_window_size/2)\n",
    "    end_date = row['Publication date'] + pd.DateOffset(years=outlier_window_size/2)\n",
    "\n",
    "    # Filter the DataFrame for this window\n",
    "    window_df = pcd_df[(pcd_df['Publication date'] >= start_date) & (pcd_df['Publication date'] <= end_date)]\n",
    "\n",
    "    percentile_compute_low[i] = np.percentile(window_df['Training compute (FLOP)'], percentile)\n",
    "    percentile_compute_high[i] = np.percentile(window_df['Training compute (FLOP)'], percentile + percentile_interval)\n",
    "\n",
    "  frontier_systems_flag = pcd_df['Training compute (FLOP)'] > np.array(percentile_compute_low)\n",
    "  extra_frontier_systems_flag = pcd_df['Training compute (FLOP)'] <= np.array(percentile_compute_high)\n",
    "\n",
    "  # raise Exception(\"Edit the following line if you want to consider models released after 2023-12-31.\")\n",
    "  extra_frontier_systems = pcd_df['System'][frontier_systems_flag & extra_frontier_systems_flag & (pcd_df['Publication date'] > pd.to_datetime('2015-09-30')) & (pcd_df['Publication date'] < pd.to_datetime('2024-01-01'))].values\n",
    "\n",
    "  frontier_systems_by_percentile[percentile] = list(extra_frontier_systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGXo_vGde5mz",
    "outputId": "6684d0f4-3ec9-40ca-ff4a-94cd73c830d7",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.680790400Z",
     "start_time": "2024-05-21T21:31:39.620812500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{95: ['GNMT',\n  'AlphaGo Master',\n  'AlphaGo Zero',\n  'AlphaZero',\n  'ResNeXt-101 32x48d',\n  'FTW',\n  'Megatron-BERT',\n  'OpenAI Five',\n  'Meena',\n  'GPT-3 175B (davinci)',\n  'Megatron-Turing NLG 530B',\n  'PaLM (540B)',\n  'Minerva (540B)',\n  'GPT-4',\n  'Gemini 1.0 Ultra'],\n 90: ['NASv3 (CIFAR-10)',\n  'T5-11B',\n  'AlphaStar',\n  'mT5-XXL',\n  'Switch',\n  'Gopher (280B)',\n  'ERNIE 3.0 Titan',\n  'Chinchilla',\n  'U-PaLM (540B)',\n  'Flan-PaLM 540B',\n  'GPT-3.5 (text-davinci-003)',\n  'PaLM 2',\n  'Claude 2',\n  'Inflection-2'],\n 85: ['AlphaGo Fan',\n  'AlphaGo Lee',\n  'JFT',\n  'Megatron-LM (8.3B)',\n  'OpenAI Five Rerun',\n  'Turing-NLG',\n  'Yuan 1.0',\n  'GLaM',\n  'LaMDA',\n  'OPT-175B',\n  'BLOOM-176B',\n  'Falcon-180B',\n  'Grok-1'],\n 80: ['OpenAI TI7 DOTA 1v1',\n  'AmoebaNet-A (F=448)',\n  'BigGAN-deep 512x512',\n  'GPT-2 (1.5B)',\n  'XLNet',\n  'iGPT-XL',\n  'DALL-E',\n  'Meta Pseudo Labels',\n  'ProtT5-XXL',\n  'ByT5-XXL',\n  'GOAT',\n  'AlphaCode',\n  'ST-MoE',\n  'Flamingo',\n  'Parti',\n  'BlenderBot 3',\n  'Llama 2-70B',\n  'ChatGLM3',\n  'Qwen-72B'],\n 75: ['DeepSpeech2 (English)',\n  'Xception',\n  'Libratus',\n  'IMPALA',\n  'Transformer (Adaptive Input Embeddings)',\n  'RoBERTa Large',\n  'ContextNet + Noisy Student',\n  'GPT-NeoX-20B',\n  'GLM-130B',\n  'ViT-22B',\n  'LLaMA-65B',\n  'PanGu-Σ',\n  'xTrimoPGLM -100B',\n  'Yi-34B'],\n 70: ['PolyNet',\n  'MoE',\n  'Big Transformer for Back-Translation',\n  'BERT-Large',\n  'MnasNet-A1 + SSDLite',\n  'MnasNet-A3',\n  'iGPT-L',\n  'GShard (dense)',\n  'ProtBERT-BFD',\n  'CoAtNet',\n  'FLAN 137B',\n  'UL2',\n  'AlexaTM 20B',\n  'Galactica'],\n 65: ['ResNet-152 (ImageNet)',\n  'ConvS2S (ensemble of 8 models)',\n  'YOLOv3',\n  'Mesh-TensorFlow Transformer 4.9B (language modelling)',\n  'BERT-Large-CAS (PTB+WT2+WT103)',\n  'ALBERT-xxlarge',\n  'ELECTRA',\n  'Conformer + Wav2vec 2.0 + Noisy Student',\n  'CLIP (ViT L/14@336px)',\n  'PLUG',\n  'ProtT5-XXL-BFD',\n  'Florence',\n  'Stable Diffusion (LDM-KL-8-G)',\n  'CoCa',\n  'Falcon-40B',\n  'BloombergGPT',\n  'Skywork-13B',\n  'FunSearch'],\n 60: ['PNASNet-5',\n  'Mesh-TensorFlow Transformer 2.9B (translation)',\n  'T5-3B',\n  'CogView',\n  'ALIGN',\n  'ERNIE 3.0',\n  'BASIC-L',\n  'XGLM-7.5B',\n  'ESM2-15B',\n  'PaLI',\n  'Nemotron-3-8B'],\n 55: ['DeepStack',\n  'LSTM (Hebbian, Cache, MbPA)',\n  'QT-Opt',\n  'Population-based DRL',\n  'SciBERT',\n  'CamemBERT',\n  'Noisy Student (L2)',\n  'Once for All',\n  'ViT-Huge/14',\n  'MSA Transformer',\n  'M6-T',\n  'Student of Games',\n  'Whisper',\n  'Taiyi-Stable Diffusion',\n  'StarCoder',\n  'WizardCoder-15.5B',\n  'Llama 2-7B',\n  'FinGPT-13B'],\n 50: ['BIDAF',\n  'Transformer',\n  'GPT',\n  'ProxylessNAS',\n  'DD-PPO',\n  'GBERT-Large',\n  'wave2vec 2.0 LARGE',\n  'AlphaFold 2',\n  'DeBERTa',\n  'HuBERT',\n  'XGLM',\n  'RETRO-7B',\n  'Imagen',\n  'NLLB',\n  'Flan-T5 11B',\n  'LLaMA-7B'],\n 45: ['RetinaNet-R101',\n  'Transformer + Simple Recurrent Unit',\n  'Sandwich Transformer',\n  'German ELECTRA Large',\n  'CPM-Large',\n  'SEER',\n  'ProGen2-xlarge',\n  'OmegaPLM',\n  'WizardLM-7B',\n  'Pangu-Weather',\n  'Jais'],\n 40: ['Part-of-sentence tagging model',\n  'GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)',\n  'Transformer-XL (257M)',\n  'KataGo',\n  'MuZero',\n  'AlphaFold',\n  'DETR',\n  'ESM1-670M (UR50/D)',\n  'ViT-G/14',\n  'AlphaFold-Multimer',\n  'NÜWA',\n  'Gato',\n  'Tranception',\n  'CogVLM',\n  'GraphCast',\n  'CogAgent'],\n 35: ['Named Entity Recognition model',\n  'R-FCN',\n  'ResNet-152 + ObjectNet',\n  'Feedback Transformer',\n  'EMDR',\n  'ViT-G (model soup)',\n  'Nucleotide Transformer',\n  'VideoMAE V2',\n  'Segment Anything Model',\n  'PeptideBERT'],\n 30: ['AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)',\n  'AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)',\n  'QRNN',\n  '(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)',\n  'TrellisNet',\n  'FAIRSEQ Adaptive Inputs',\n  'DistilBERT',\n  'TaLK Convolution',\n  'ATLAS',\n  'ERNIE-GEN (large)',\n  'LUKE',\n  'ADM',\n  'CodeT5-base',\n  'CodeT5-large',\n  'EVA-01',\n  'Ankh_large',\n  'AudioGen',\n  'DINOv2'],\n 25: ['VD-LSTM+REAL Large',\n  'ULM-FiT',\n  'Big-Little Net (speech)',\n  'Decoupled weight decay regularization',\n  'Hanabi 4 player',\n  'Transformer-XL Large + Phrase Induction',\n  'Tensorized Transformer (257M)',\n  'AlphaX-1',\n  'KEPLER',\n  'ViT + DINO',\n  'Denoising Diffusion Probabilistic Models (LSUN Bedroom)',\n  'T0-XXL',\n  'S4',\n  'Swin Transformer V2',\n  'PolyCoder',\n  'GenSLM',\n  'Ankh_base',\n  'Incoder-6.7B'],\n 20: ['Zoneout + Variational LSTM (WT2)',\n  'Fraternal dropout + AWD-LSTM 3-layer (WT2)',\n  '4 layer QRNN (h=2500)',\n  'Dropout-LSTM+Noise(Bernoulli) (WT2)',\n  'Cross-lingual alignment',\n  'DLRM-2020',\n  'Base LM + kNN LM + Continuous Cache',\n  'ConSERT',\n  'Masked Autoencoders',\n  'Hybrid H3-2.7B',\n  'Flan T5-XXL + BLIP-2',\n  'BLIP-2 (Q-Former)',\n  'DiT-XL/2'],\n 15: ['Variational (untied weights, MC) LSTM (Large)',\n  'Pointer Sentinel-LSTM (medium)',\n  'Neural Architecture Search with base 8 and shared embeddings',\n  'ENAS',\n  'aLSTM(depth-2)+RecurrentPolicy (WT2)',\n  'Transformer-XL DeFINE (141M)',\n  'DeLight',\n  'ERNIE-Doc (247M)',\n  'EfficientNetV2',\n  'Adaptive Input Transformer + RD',\n  'DNABERT',\n  'BERT-RBP',\n  'AR-LDM',\n  'Discriminator Guidance',\n  'DDPM-IP (CelebA)',\n  'ONE-PEACE'],\n 10: ['EI-REHN-1000D',\n  'DARTS',\n  'NAS+ESS (156M)',\n  'ProBERTa',\n  'SRU++ Large',\n  'Transformer local-attention (NesT-B)',\n  'ProteinBERT',\n  'BEIT-3',\n  'DiffDock',\n  'Fusion in Encoder',\n  'LLaVA 1.5'],\n 5: ['VD-RHN',\n  'ISS',\n  'AWD-LSTM+WT+Cache+IOG (WT2)',\n  'AWD-LSTM-DRILL + dynamic evaluation† (WT2)',\n  'AWD-LSTM + MoS + Partial Shuffled',\n  'UDSMProt',\n  'MMLSTM',\n  'TransformerXL + spectrum control',\n  'Tensor-Transformer(1core)+PN (WT103)',\n  'MedBERT',\n  'Detic',\n  'Segatron-XL large, M=384 + HCP',\n  'Sparse all-MLP',\n  'CaLM',\n  'LLaVA',\n  'MultiBand Diffusion'],\n 0: ['2-layer-LSTM+Deep-Gradient-Compression',\n  'Fine-tuned-AWD-LSTM-DOC(fin)',\n  'Multi-cell LSTM',\n  'Pluribus',\n  'DensePhrases',\n  'CT-MoS (WT2)',\n  'PermuteFormer',\n  'base LM+GNN+kNN',\n  'DITTO',\n  'Mogrifier RLSTM (WT2)',\n  'VALL-E',\n  'HyenaDNA',\n  'CODEFUSION (Python)']}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_systems_by_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.693769500Z",
     "start_time": "2024-05-21T21:31:39.681920900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "with open('data/frontier_systems_by_window_percentile.json', 'w') as f:\n",
    "    json.dump(frontier_systems_by_percentile, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8pzY7skfxkV",
    "outputId": "195c3ec6-c885-4008-ba36-abb60e5dd645",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.725023Z",
     "start_time": "2024-05-21T21:31:39.693769500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 to 100\n",
      "15 systems\n",
      "Total systems above 95th percentile: 15\n",
      "Gemini 1.0 Ultra\n",
      "GPT-4\n",
      "Minerva (540B)\n",
      "PaLM (540B)\n",
      "Megatron-Turing NLG 530B\n",
      "GPT-3 175B (davinci)\n",
      "Meena\n",
      "OpenAI Five\n",
      "Megatron-BERT\n",
      "FTW\n",
      "ResNeXt-101 32x48d\n",
      "AlphaZero\n",
      "AlphaGo Zero\n",
      "AlphaGo Master\n",
      "GNMT\n",
      "\n",
      "90 to 95\n",
      "14 systems\n",
      "Total systems above 90th percentile: 29\n",
      "Inflection-2\n",
      "Claude 2\n",
      "PaLM 2\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Flan-PaLM 540B\n",
      "U-PaLM (540B)\n",
      "Chinchilla\n",
      "ERNIE 3.0 Titan\n",
      "Gopher (280B)\n",
      "Switch\n",
      "mT5-XXL\n",
      "AlphaStar\n",
      "T5-11B\n",
      "NASv3 (CIFAR-10)\n",
      "\n",
      "85 to 90\n",
      "13 systems\n",
      "Total systems above 85th percentile: 42\n",
      "Grok-1\n",
      "Falcon-180B\n",
      "BLOOM-176B\n",
      "OPT-175B\n",
      "LaMDA\n",
      "GLaM\n",
      "Yuan 1.0\n",
      "Turing-NLG\n",
      "OpenAI Five Rerun\n",
      "Megatron-LM (8.3B)\n",
      "JFT\n",
      "AlphaGo Lee\n",
      "AlphaGo Fan\n",
      "\n",
      "80 to 85\n",
      "19 systems\n",
      "Total systems above 80th percentile: 61\n",
      "Qwen-72B\n",
      "ChatGLM3\n",
      "Llama 2-70B\n",
      "BlenderBot 3\n",
      "Parti\n",
      "Flamingo\n",
      "ST-MoE\n",
      "AlphaCode\n",
      "GOAT\n",
      "ByT5-XXL\n",
      "ProtT5-XXL\n",
      "Meta Pseudo Labels\n",
      "DALL-E\n",
      "iGPT-XL\n",
      "XLNet\n",
      "GPT-2 (1.5B)\n",
      "BigGAN-deep 512x512\n",
      "AmoebaNet-A (F=448)\n",
      "OpenAI TI7 DOTA 1v1\n",
      "\n",
      "75 to 80\n",
      "14 systems\n",
      "Total systems above 75th percentile: 75\n",
      "Yi-34B\n",
      "xTrimoPGLM -100B\n",
      "PanGu-Σ\n",
      "LLaMA-65B\n",
      "ViT-22B\n",
      "GLM-130B\n",
      "GPT-NeoX-20B\n",
      "ContextNet + Noisy Student\n",
      "RoBERTa Large\n",
      "Transformer (Adaptive Input Embeddings)\n",
      "IMPALA\n",
      "Libratus\n",
      "Xception\n",
      "DeepSpeech2 (English)\n",
      "\n",
      "70 to 75\n",
      "14 systems\n",
      "Total systems above 70th percentile: 89\n",
      "Galactica\n",
      "AlexaTM 20B\n",
      "UL2\n",
      "FLAN 137B\n",
      "CoAtNet\n",
      "ProtBERT-BFD\n",
      "GShard (dense)\n",
      "iGPT-L\n",
      "MnasNet-A3\n",
      "MnasNet-A1 + SSDLite\n",
      "BERT-Large\n",
      "Big Transformer for Back-Translation\n",
      "MoE\n",
      "PolyNet\n",
      "\n",
      "65 to 70\n",
      "18 systems\n",
      "Total systems above 65th percentile: 107\n",
      "FunSearch\n",
      "Skywork-13B\n",
      "BloombergGPT\n",
      "Falcon-40B\n",
      "CoCa\n",
      "Stable Diffusion (LDM-KL-8-G)\n",
      "Florence\n",
      "ProtT5-XXL-BFD\n",
      "PLUG\n",
      "CLIP (ViT L/14@336px)\n",
      "Conformer + Wav2vec 2.0 + Noisy Student\n",
      "ELECTRA\n",
      "ALBERT-xxlarge\n",
      "BERT-Large-CAS (PTB+WT2+WT103)\n",
      "Mesh-TensorFlow Transformer 4.9B (language modelling)\n",
      "YOLOv3\n",
      "ConvS2S (ensemble of 8 models)\n",
      "ResNet-152 (ImageNet)\n",
      "\n",
      "60 to 65\n",
      "11 systems\n",
      "Total systems above 60th percentile: 118\n",
      "Nemotron-3-8B\n",
      "PaLI\n",
      "ESM2-15B\n",
      "XGLM-7.5B\n",
      "BASIC-L\n",
      "ERNIE 3.0\n",
      "ALIGN\n",
      "CogView\n",
      "T5-3B\n",
      "Mesh-TensorFlow Transformer 2.9B (translation)\n",
      "PNASNet-5\n",
      "\n",
      "55 to 60\n",
      "18 systems\n",
      "Total systems above 55th percentile: 136\n",
      "FinGPT-13B\n",
      "Llama 2-7B\n",
      "WizardCoder-15.5B\n",
      "StarCoder\n",
      "Taiyi-Stable Diffusion\n",
      "Whisper\n",
      "Student of Games\n",
      "M6-T\n",
      "MSA Transformer\n",
      "ViT-Huge/14\n",
      "Once for All\n",
      "Noisy Student (L2)\n",
      "CamemBERT\n",
      "SciBERT\n",
      "Population-based DRL\n",
      "QT-Opt\n",
      "LSTM (Hebbian, Cache, MbPA)\n",
      "DeepStack\n",
      "\n",
      "50 to 55\n",
      "16 systems\n",
      "Total systems above 50th percentile: 152\n",
      "LLaMA-7B\n",
      "Flan-T5 11B\n",
      "NLLB\n",
      "Imagen\n",
      "RETRO-7B\n",
      "XGLM\n",
      "HuBERT\n",
      "DeBERTa\n",
      "AlphaFold 2\n",
      "wave2vec 2.0 LARGE\n",
      "GBERT-Large\n",
      "DD-PPO\n",
      "ProxylessNAS\n",
      "GPT\n",
      "Transformer\n",
      "BIDAF\n",
      "\n",
      "45 to 50\n",
      "11 systems\n",
      "Total systems above 45th percentile: 163\n",
      "Jais\n",
      "Pangu-Weather\n",
      "WizardLM-7B\n",
      "OmegaPLM\n",
      "ProGen2-xlarge\n",
      "SEER\n",
      "CPM-Large\n",
      "German ELECTRA Large\n",
      "Sandwich Transformer\n",
      "Transformer + Simple Recurrent Unit\n",
      "RetinaNet-R101\n",
      "\n",
      "40 to 45\n",
      "16 systems\n",
      "Total systems above 40th percentile: 179\n",
      "CogAgent\n",
      "GraphCast\n",
      "CogVLM\n",
      "Tranception\n",
      "Gato\n",
      "NÜWA\n",
      "AlphaFold-Multimer\n",
      "ViT-G/14\n",
      "ESM1-670M (UR50/D)\n",
      "DETR\n",
      "AlphaFold\n",
      "MuZero\n",
      "KataGo\n",
      "Transformer-XL (257M)\n",
      "GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)\n",
      "Part-of-sentence tagging model\n",
      "\n",
      "35 to 40\n",
      "10 systems\n",
      "Total systems above 35th percentile: 189\n",
      "PeptideBERT\n",
      "Segment Anything Model\n",
      "VideoMAE V2\n",
      "Nucleotide Transformer\n",
      "ViT-G (model soup)\n",
      "EMDR\n",
      "Feedback Transformer\n",
      "ResNet-152 + ObjectNet\n",
      "R-FCN\n",
      "Named Entity Recognition model\n",
      "\n",
      "30 to 35\n",
      "18 systems\n",
      "Total systems above 30th percentile: 207\n",
      "DINOv2\n",
      "AudioGen\n",
      "Ankh_large\n",
      "EVA-01\n",
      "CodeT5-large\n",
      "CodeT5-base\n",
      "ADM\n",
      "LUKE\n",
      "ERNIE-GEN (large)\n",
      "ATLAS\n",
      "TaLK Convolution\n",
      "DistilBERT\n",
      "FAIRSEQ Adaptive Inputs\n",
      "TrellisNet\n",
      "(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)\n",
      "QRNN\n",
      "AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)\n",
      "AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)\n",
      "\n",
      "25 to 30\n",
      "18 systems\n",
      "Total systems above 25th percentile: 225\n",
      "Incoder-6.7B\n",
      "Ankh_base\n",
      "GenSLM\n",
      "PolyCoder\n",
      "Swin Transformer V2\n",
      "S4\n",
      "T0-XXL\n",
      "Denoising Diffusion Probabilistic Models (LSUN Bedroom)\n",
      "ViT + DINO\n",
      "KEPLER\n",
      "AlphaX-1\n",
      "Tensorized Transformer (257M)\n",
      "Transformer-XL Large + Phrase Induction\n",
      "Hanabi 4 player\n",
      "Decoupled weight decay regularization\n",
      "Big-Little Net (speech)\n",
      "ULM-FiT\n",
      "VD-LSTM+REAL Large\n",
      "\n",
      "20 to 25\n",
      "13 systems\n",
      "Total systems above 20th percentile: 238\n",
      "DiT-XL/2\n",
      "BLIP-2 (Q-Former)\n",
      "Flan T5-XXL + BLIP-2\n",
      "Hybrid H3-2.7B\n",
      "Masked Autoencoders\n",
      "ConSERT\n",
      "Base LM + kNN LM + Continuous Cache\n",
      "DLRM-2020\n",
      "Cross-lingual alignment\n",
      "Dropout-LSTM+Noise(Bernoulli) (WT2)\n",
      "4 layer QRNN (h=2500)\n",
      "Fraternal dropout + AWD-LSTM 3-layer (WT2)\n",
      "Zoneout + Variational LSTM (WT2)\n",
      "\n",
      "15 to 20\n",
      "16 systems\n",
      "Total systems above 15th percentile: 254\n",
      "ONE-PEACE\n",
      "DDPM-IP (CelebA)\n",
      "Discriminator Guidance\n",
      "AR-LDM\n",
      "BERT-RBP\n",
      "DNABERT\n",
      "Adaptive Input Transformer + RD\n",
      "EfficientNetV2\n",
      "ERNIE-Doc (247M)\n",
      "DeLight\n",
      "Transformer-XL DeFINE (141M)\n",
      "aLSTM(depth-2)+RecurrentPolicy (WT2)\n",
      "ENAS\n",
      "Neural Architecture Search with base 8 and shared embeddings\n",
      "Pointer Sentinel-LSTM (medium)\n",
      "Variational (untied weights, MC) LSTM (Large)\n",
      "\n",
      "10 to 15\n",
      "11 systems\n",
      "Total systems above 10th percentile: 265\n",
      "LLaVA 1.5\n",
      "Fusion in Encoder\n",
      "DiffDock\n",
      "BEIT-3\n",
      "ProteinBERT\n",
      "Transformer local-attention (NesT-B)\n",
      "SRU++ Large\n",
      "ProBERTa\n",
      "NAS+ESS (156M)\n",
      "DARTS\n",
      "EI-REHN-1000D\n",
      "\n",
      "5 to 10\n",
      "16 systems\n",
      "Total systems above 5th percentile: 281\n",
      "MultiBand Diffusion\n",
      "LLaVA\n",
      "CaLM\n",
      "Sparse all-MLP\n",
      "Segatron-XL large, M=384 + HCP\n",
      "Detic\n",
      "MedBERT\n",
      "Tensor-Transformer(1core)+PN (WT103)\n",
      "TransformerXL + spectrum control\n",
      "MMLSTM\n",
      "UDSMProt\n",
      "AWD-LSTM + MoS + Partial Shuffled\n",
      "AWD-LSTM-DRILL + dynamic evaluation† (WT2)\n",
      "AWD-LSTM+WT+Cache+IOG (WT2)\n",
      "ISS\n",
      "VD-RHN\n",
      "\n",
      "0 to 5\n",
      "13 systems\n",
      "Total systems above 0th percentile: 294\n",
      "CODEFUSION (Python)\n",
      "HyenaDNA\n",
      "VALL-E\n",
      "Mogrifier RLSTM (WT2)\n",
      "DITTO\n",
      "base LM+GNN+kNN\n",
      "PermuteFormer\n",
      "CT-MoS (WT2)\n",
      "DensePhrases\n",
      "Pluribus\n",
      "Multi-cell LSTM\n",
      "Fine-tuned-AWD-LSTM-DOC(fin)\n",
      "2-layer-LSTM+Deep-Gradient-Compression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_num_systems = 0\n",
    "for percentile, systems in frontier_systems_by_percentile.items():\n",
    "  total_num_systems += len(systems)\n",
    "  print(percentile, 'to', percentile + percentile_interval)\n",
    "  print(len(systems), \"systems\")\n",
    "  print(f'Total systems above {percentile}th percentile: {total_num_systems}')\n",
    "  for system in systems[::-1]:\n",
    "    print(system)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "klMq2PP3f6Xw",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.725023Z",
     "start_time": "2024-05-21T21:31:39.709480700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TllyX8IqSiG2"
   },
   "source": [
    "# Distance from compute record at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CC8_j5AASl0y",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.740645800Z",
     "start_time": "2024-05-21T21:31:39.725023Z"
    }
   },
   "outputs": [],
   "source": [
    "ooms_from_frontier = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N395lGkYSoNU",
    "outputId": "ee6d6df7-3662-4dd8-ce41-b9490a33389a",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.764574500Z",
     "start_time": "2024-05-21T21:31:39.747646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([4.00000000e+01, 6.94894938e+05, 6.00000000e+08, 6.00000000e+08,\n       7.20000000e+08, 7.20000000e+08, 7.20000000e+08, 7.20000000e+08,\n       7.20000000e+08, 7.20000000e+08, 7.20000000e+08, 7.20000000e+08,\n       7.20000000e+08, 2.83280026e+10, 2.83280026e+10, 2.83280026e+10,\n       1.81440000e+11, 1.81440000e+11, 1.81440000e+11, 1.81440000e+11,\n       1.81440000e+11, 1.81440000e+11, 1.82321576e+13, 1.82321576e+13,\n       1.82321576e+13, 1.82321576e+13, 2.10080000e+13, 2.10080000e+13,\n       6.30000000e+13, 1.30389876e+15, 1.30389876e+15, 1.30389876e+15,\n       1.30389876e+15, 1.30389876e+15, 3.41463600e+15, 6.14400000e+16,\n       6.14400000e+16, 2.73196800e+17, 2.73196800e+17, 2.73196800e+17,\n       6.00000000e+17, 6.00000000e+17, 6.00000000e+17, 6.00000000e+17,\n       6.00000000e+17, 6.00000000e+17, 6.00000000e+17, 1.34092800e+18,\n       1.34092800e+18, 1.34092800e+18, 1.34092800e+18, 1.34092800e+18,\n       3.41107200e+18, 3.41107200e+18, 3.41107200e+18, 9.25344000e+18,\n       9.25344000e+18, 5.60000000e+19, 5.60000000e+19, 5.60000000e+19,\n       5.60000000e+19, 5.60000000e+19, 5.60000000e+19, 5.60000000e+19,\n       5.60000000e+19, 3.80000000e+20, 3.80000000e+20, 3.80000000e+20,\n       3.80000000e+20, 1.90000000e+21, 1.90000000e+21, 1.90000000e+21,\n       1.90000000e+21, 1.90000000e+21, 1.90000000e+21, 6.90000000e+21,\n       6.90000000e+21, 6.90000000e+21, 6.90000000e+21, 6.90000000e+21,\n       6.90000000e+21, 6.90000000e+21, 6.90000000e+21, 6.90000000e+21,\n       6.90000000e+21, 2.00010000e+23, 2.00010000e+23, 2.00010000e+23,\n       2.00010000e+23, 2.00010000e+23, 2.00010000e+23, 2.00010000e+23,\n       2.00010000e+23, 2.00010000e+23, 2.00010000e+23, 2.00010000e+23,\n       2.00010000e+23, 2.00010000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 3.41000000e+23, 3.41000000e+23,\n       3.41000000e+23, 3.41000000e+23, 1.17000000e+24, 1.17000000e+24,\n       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n       1.17000000e+24, 1.17000000e+24, 1.17000000e+24, 1.17000000e+24,\n       1.17000000e+24, 1.17000000e+24, 2.52720000e+24, 2.52720000e+24,\n       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n       2.52720000e+24, 2.52720000e+24, 2.52720000e+24, 2.52720000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.74150000e+24, 2.74150000e+24, 2.74150000e+24, 2.74150000e+24,\n       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n       2.10000000e+25, 2.10000000e+25, 2.10000000e+25, 2.10000000e+25,\n       5.00000000e+25, 5.00000000e+25, 5.00000000e+25, 5.00000000e+25,\n       5.00000000e+25, 5.00000000e+25, 5.00000000e+25, 5.00000000e+25])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_max = 0\n",
    "running_max = np.zeros(len(pcd_df))\n",
    "for i, compute in enumerate(pcd_df['Training compute (FLOP)']):\n",
    "  if compute > current_max:\n",
    "    running_max[i] = compute\n",
    "    current_max = compute\n",
    "  else:\n",
    "    running_max[i] = current_max\n",
    "running_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SV1tpYgETmYT",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.772581800Z",
     "start_time": "2024-05-21T21:31:39.764574500Z"
    }
   },
   "outputs": [],
   "source": [
    "pcd_df['Frontier training compute (FLOP)'] = running_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "WdpWpDvvTqOs",
    "outputId": "331ce3ef-cc47-4393-dc7f-98148184fd4c",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.794438900Z",
     "start_time": "2024-05-21T21:31:39.772581800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                      System  Frontier system\n1307                 Theseus            False\n1301       Perceptron Mark I            False\n1300     Pandemonium (morse)            False\n1299  Samuel Neural Checkers            False\n1297       Perceptron (1960)            False\n...                      ...              ...\n30    MegaScale (Production)             True\n21            Inflection-2.5             True\n20                   MM1-30B            False\n13         Mixture-of-Depths            False\n5                Llama 3-70B             True\n\n[368 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>System</th>\n      <th>Frontier system</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1307</th>\n      <td>Theseus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1301</th>\n      <td>Perceptron Mark I</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1300</th>\n      <td>Pandemonium (morse)</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1299</th>\n      <td>Samuel Neural Checkers</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1297</th>\n      <td>Perceptron (1960)</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>MegaScale (Production)</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Inflection-2.5</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>MM1-30B</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Mixture-of-Depths</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Llama 3-70B</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>368 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_df['Frontier system'] = (pcd_df['Publication date'] > start_large_scale_era) & (np.log10(pcd_df['Frontier training compute (FLOP)']) - np.log10(pcd_df['Training compute (FLOP)']) <= ooms_from_frontier)\n",
    "pcd_df[['System', 'Frontier system']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yrk0wu7LT6ZK",
    "outputId": "9d95a1fa-1ed8-4c4b-ae94-f9b42a8dddd8",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.871622100Z",
     "start_time": "2024-05-21T21:31:39.792281800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                      System                      Domain  \\\n1025   DeepSpeech2 (English)                      Speech   \n1023   ResNet-152 (ImageNet)                      Vision   \n1019             AlphaGo Lee                       Games   \n980                     GNMT                    Language   \n979                 Xception                      Vision   \n...                      ...                         ...   \n82                  Qwen-72B                    Language   \n74          Gemini 1.0 Ultra  Multimodal,Language,Vision   \n30    MegaScale (Production)                    Language   \n21            Inflection-2.5                    Language   \n5                Llama 3-70B                    Language   \n\n                                Organization Publication date  \\\n1025  Baidu Research - Silicon Valley AI Lab       2015-12-08   \n1023                               Microsoft       2015-12-10   \n1019                                DeepMind       2016-01-27   \n980                                   Google       2016-09-26   \n979                                   Google       2016-10-07   \n...                                      ...              ...   \n82                                   Alibaba       2023-11-30   \n74                           Google DeepMind       2023-12-06   \n30               ByteDance,Peking University       2024-02-23   \n21                             Inflection AI       2024-03-07   \n5                                    Meta AI       2024-04-18   \n\n                                              Reference  \\\n1025  Deep Speech 2: End-to-End Speech Recognition i...   \n1023       Deep Residual Learning for Image Recognition   \n1019  Mastering the game of Go with deep neural netw...   \n980   Google's Neural Machine Translation System: Br...   \n979   Xception: Deep Learning with Depthwise Separab...   \n...                                                 ...   \n82                                                  NaN   \n74    Gemini: A Family of Highly Capable Multimodal ...   \n30    MegaScale: Scaling Large Language Model Traini...   \n21    Inflection-2.5: meet the world's best personal AI   \n5     Introducing Meta Llama 3: The most capable ope...   \n\n                                                   Link    Parameters  \\\n1025                   https://arxiv.org/abs/1512.02595  3.800000e+07   \n1023                   https://arxiv.org/abs/1512.03385  6.000000e+07   \n1019        https://www.nature.com/articles/nature16961           NaN   \n980                    https://arxiv.org/abs/1609.08144  2.780000e+08   \n979                    https://arxiv.org/abs/1610.02357  2.285595e+07   \n...                                                 ...           ...   \n82                 https://huggingface.co/Qwen/Qwen-72B  7.200000e+10   \n74    https://storage.googleapis.com/deepmind-media/...           NaN   \n30                     https://arxiv.org/abs/2402.15627  5.300000e+11   \n21                 https://inflection.ai/inflection-2-5           NaN   \n5     https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...  7.000000e+10   \n\n                                       Parameters notes  \\\n1025           All networks have 38 million parameters.   \n1023        Taken from https://arxiv.org/abs/1605.07146   \n1019                                                NaN   \n980   Table 5 in 'Outrageously Large Neural Networks...   \n979                                             Table 3   \n...                                                 ...   \n82                                                  72B   \n74                                                  NaN   \n30    Production run is stated to have \"hundreds of ...   \n21                                                  NaN   \n5                                                   NaN   \n\n      Training compute (FLOP)  \\\n1025             2.600000e+19   \n1023             1.210000e+19   \n1019             1.900000e+21   \n980              6.900000e+21   \n979              4.360000e+20   \n...                       ...   \n82               1.300000e+24   \n74               5.000000e+25   \n30               1.200000e+25   \n21               1.000100e+25   \n5                6.300000e+24   \n\n                                 Training compute notes  ...  \\\n1025  1 timestep = (1280 hidden units)^2 * (7 RNN la...  ...   \n1023  (11.4 *10^9) mult-adds per forward pass\\n2 FLO...  ...   \n1019  This number is pretty uncertain. I expect it t...  ...   \n980   sqrt(10 * 100) factor added because production...  ...   \n979   60 K80 GPUs * 30 days * 8.5 TFLOPS/GPU * 0.33 ...  ...   \n...                                                 ...  ...   \n82    72 billion params, 3 trillion tokens\\n72b * 3T...  ...   \n74    This number is an estimate based on limited ev...  ...   \n30    Speculative. The model is stated to have train...  ...   \n21    \"Inflection-1 used approximately 4% the traini...  ...   \n5     direct calculation\\n15000000000000 tokens*7000...  ...   \n\n     top_13_at_release  top_14_at_release top_15_at_release top_16_at_release  \\\n1025              True               True              True              True   \n1023              True               True              True              True   \n1019              True               True              True              True   \n980               True               True              True              True   \n979               True               True              True              True   \n...                ...                ...               ...               ...   \n82                True               True              True              True   \n74                True               True              True              True   \n30                True               True              True              True   \n21                True               True              True              True   \n5                 True               True              True              True   \n\n     top_17_at_release top_18_at_release top_19_at_release top_20_at_release  \\\n1025              True              True              True              True   \n1023              True              True              True              True   \n1019              True              True              True              True   \n980               True              True              True              True   \n979               True              True              True              True   \n...                ...               ...               ...               ...   \n82                True              True              True              True   \n74                True              True              True              True   \n30                True              True              True              True   \n21                True              True              True              True   \n5                 True              True              True              True   \n\n     Frontier training compute (FLOP) Frontier system  \n1025                     3.800000e+20            True  \n1023                     3.800000e+20            True  \n1019                     1.900000e+21            True  \n980                      6.900000e+21            True  \n979                      6.900000e+21            True  \n...                               ...             ...  \n82                       2.100000e+25            True  \n74                       5.000000e+25            True  \n30                       5.000000e+25            True  \n21                       5.000000e+25            True  \n5                        5.000000e+25            True  \n\n[111 rows x 68 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>System</th>\n      <th>Domain</th>\n      <th>Organization</th>\n      <th>Publication date</th>\n      <th>Reference</th>\n      <th>Link</th>\n      <th>Parameters</th>\n      <th>Parameters notes</th>\n      <th>Training compute (FLOP)</th>\n      <th>Training compute notes</th>\n      <th>...</th>\n      <th>top_13_at_release</th>\n      <th>top_14_at_release</th>\n      <th>top_15_at_release</th>\n      <th>top_16_at_release</th>\n      <th>top_17_at_release</th>\n      <th>top_18_at_release</th>\n      <th>top_19_at_release</th>\n      <th>top_20_at_release</th>\n      <th>Frontier training compute (FLOP)</th>\n      <th>Frontier system</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1025</th>\n      <td>DeepSpeech2 (English)</td>\n      <td>Speech</td>\n      <td>Baidu Research - Silicon Valley AI Lab</td>\n      <td>2015-12-08</td>\n      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n      <td>https://arxiv.org/abs/1512.02595</td>\n      <td>3.800000e+07</td>\n      <td>All networks have 38 million parameters.</td>\n      <td>2.600000e+19</td>\n      <td>1 timestep = (1280 hidden units)^2 * (7 RNN la...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>3.800000e+20</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1023</th>\n      <td>ResNet-152 (ImageNet)</td>\n      <td>Vision</td>\n      <td>Microsoft</td>\n      <td>2015-12-10</td>\n      <td>Deep Residual Learning for Image Recognition</td>\n      <td>https://arxiv.org/abs/1512.03385</td>\n      <td>6.000000e+07</td>\n      <td>Taken from https://arxiv.org/abs/1605.07146</td>\n      <td>1.210000e+19</td>\n      <td>(11.4 *10^9) mult-adds per forward pass\\n2 FLO...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>3.800000e+20</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1019</th>\n      <td>AlphaGo Lee</td>\n      <td>Games</td>\n      <td>DeepMind</td>\n      <td>2016-01-27</td>\n      <td>Mastering the game of Go with deep neural netw...</td>\n      <td>https://www.nature.com/articles/nature16961</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.900000e+21</td>\n      <td>This number is pretty uncertain. I expect it t...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>1.900000e+21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>980</th>\n      <td>GNMT</td>\n      <td>Language</td>\n      <td>Google</td>\n      <td>2016-09-26</td>\n      <td>Google's Neural Machine Translation System: Br...</td>\n      <td>https://arxiv.org/abs/1609.08144</td>\n      <td>2.780000e+08</td>\n      <td>Table 5 in 'Outrageously Large Neural Networks...</td>\n      <td>6.900000e+21</td>\n      <td>sqrt(10 * 100) factor added because production...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>6.900000e+21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>Xception</td>\n      <td>Vision</td>\n      <td>Google</td>\n      <td>2016-10-07</td>\n      <td>Xception: Deep Learning with Depthwise Separab...</td>\n      <td>https://arxiv.org/abs/1610.02357</td>\n      <td>2.285595e+07</td>\n      <td>Table 3</td>\n      <td>4.360000e+20</td>\n      <td>60 K80 GPUs * 30 days * 8.5 TFLOPS/GPU * 0.33 ...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>6.900000e+21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Qwen-72B</td>\n      <td>Language</td>\n      <td>Alibaba</td>\n      <td>2023-11-30</td>\n      <td>NaN</td>\n      <td>https://huggingface.co/Qwen/Qwen-72B</td>\n      <td>7.200000e+10</td>\n      <td>72B</td>\n      <td>1.300000e+24</td>\n      <td>72 billion params, 3 trillion tokens\\n72b * 3T...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2.100000e+25</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Gemini 1.0 Ultra</td>\n      <td>Multimodal,Language,Vision</td>\n      <td>Google DeepMind</td>\n      <td>2023-12-06</td>\n      <td>Gemini: A Family of Highly Capable Multimodal ...</td>\n      <td>https://storage.googleapis.com/deepmind-media/...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.000000e+25</td>\n      <td>This number is an estimate based on limited ev...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>5.000000e+25</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>MegaScale (Production)</td>\n      <td>Language</td>\n      <td>ByteDance,Peking University</td>\n      <td>2024-02-23</td>\n      <td>MegaScale: Scaling Large Language Model Traini...</td>\n      <td>https://arxiv.org/abs/2402.15627</td>\n      <td>5.300000e+11</td>\n      <td>Production run is stated to have \"hundreds of ...</td>\n      <td>1.200000e+25</td>\n      <td>Speculative. The model is stated to have train...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>5.000000e+25</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Inflection-2.5</td>\n      <td>Language</td>\n      <td>Inflection AI</td>\n      <td>2024-03-07</td>\n      <td>Inflection-2.5: meet the world's best personal AI</td>\n      <td>https://inflection.ai/inflection-2-5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000100e+25</td>\n      <td>\"Inflection-1 used approximately 4% the traini...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>5.000000e+25</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Llama 3-70B</td>\n      <td>Language</td>\n      <td>Meta AI</td>\n      <td>2024-04-18</td>\n      <td>Introducing Meta Llama 3: The most capable ope...</td>\n      <td>https://ai.meta.com/blog/meta-llama-3/\\n\\nhttp...</td>\n      <td>7.000000e+10</td>\n      <td>NaN</td>\n      <td>6.300000e+24</td>\n      <td>direct calculation\\n15000000000000 tokens*7000...</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>5.000000e+25</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>111 rows × 68 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_df = pcd_df[pcd_df['Frontier system']]\n",
    "frontier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjDaQcsVsyYz",
    "outputId": "7aa5fd43-3b36-45f5-997c-d57abd4a94d3",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.871622100Z",
     "start_time": "2024-05-21T21:31:39.828366800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3-70B\n",
      "Inflection-2.5\n",
      "MegaScale (Production)\n",
      "Gemini 1.0 Ultra\n",
      "Qwen-72B\n",
      "Inflection-2\n",
      "Grok-1\n",
      "Yi-34B\n",
      "Skywork-13B\n",
      "ChatGLM3\n",
      "Falcon-180B\n",
      "Llama 2-70B\n",
      "Claude 2\n",
      "xTrimoPGLM -100B\n",
      "PaLM 2\n",
      "BloombergGPT\n",
      "PanGu-Σ\n",
      "GPT-4\n",
      "Falcon-40B\n",
      "LLaMA-65B\n",
      "LLaMA-7B\n",
      "ViT-22B\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Galactica\n",
      "BLOOM-176B\n",
      "Taiyi-Stable Diffusion\n",
      "Flan-T5 11B\n",
      "Flan-PaLM 540B\n",
      "U-PaLM (540B)\n",
      "Whisper\n",
      "PaLI\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "AlexaTM 20B\n",
      "ESM2-15B\n",
      "Minerva (540B)\n",
      "Parti\n",
      "CoCa\n",
      "UL2\n",
      "OPT-175B\n",
      "Flamingo\n",
      "Stable Diffusion (LDM-KL-8-G)\n",
      "PaLM (540B)\n",
      "Chinchilla\n",
      "ST-MoE\n",
      "LaMDA\n",
      "GPT-NeoX-20B\n",
      "RETRO-7B\n",
      "AlphaCode\n",
      "ERNIE 3.0 Titan\n",
      "XGLM-7.5B\n",
      "XGLM\n",
      "GLaM\n",
      "Gopher (280B)\n",
      "Student of Games\n",
      "Florence\n",
      "BASIC-L\n",
      "Yuan 1.0\n",
      "Megatron-Turing NLG 530B\n",
      "AlphaFold-Multimer\n",
      "FLAN 137B\n",
      "SEER\n",
      "GOAT\n",
      "HuBERT\n",
      "ERNIE 3.0\n",
      "ALIGN\n",
      "DeBERTa\n",
      "CoAtNet\n",
      "ByT5-XXL\n",
      "CogView\n",
      "ProtT5-XXL-BFD\n",
      "ProtBERT-BFD\n",
      "ProtT5-XXL\n",
      "PLUG\n",
      "M6-T\n",
      "Meta Pseudo Labels\n",
      "MSA Transformer\n",
      "Switch\n",
      "DALL-E\n",
      "CLIP (ViT L/14@336px)\n",
      "ViT-Huge/14\n",
      "mT5-XXL\n",
      "Conformer + Wav2vec 2.0 + Noisy Student\n",
      "GShard (dense)\n",
      "iGPT-XL\n",
      "iGPT-L\n",
      "GPT-3 175B (davinci)\n",
      "Turing-NLG\n",
      "Meena\n",
      "ContextNet + Noisy Student\n",
      "OpenAI Five Rerun\n",
      "OpenAI Five\n",
      "AlphaStar\n",
      "T5-11B\n",
      "Megatron-LM (8.3B)\n",
      "Megatron-BERT\n",
      "RoBERTa Large\n",
      "XLNet\n",
      "GPT-2 (1.5B)\n",
      "FTW\n",
      "ResNeXt-101 32x48d\n",
      "AlphaZero\n",
      "AlphaGo Zero\n",
      "AlphaGo Master\n",
      "Libratus\n",
      "NASv3 (CIFAR-10)\n",
      "Xception\n",
      "GNMT\n",
      "AlphaGo Lee\n",
      "ResNet-152 (ImageNet)\n",
      "DeepSpeech2 (English)\n"
     ]
    }
   ],
   "source": [
    "for system in frontier_df['System'][::-1]:\n",
    "  print(system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ4rEiW4hW6_"
   },
   "source": [
    "# Constant threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "L8IgNL9shAZb",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.871622100Z",
     "start_time": "2024-05-21T21:31:39.840371400Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_threshold = 1e23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tGPWWQJ6hZCU",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.871622100Z",
     "start_time": "2024-05-21T21:31:39.856000900Z"
    }
   },
   "outputs": [],
   "source": [
    "above_threshold = pcd_df[pcd_df['Training compute (FLOP)'] > compute_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wB6Qu1pBhd41",
    "outputId": "456309a2-7c4a-4f19-8e18-9922508807b5",
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:39.903554700Z",
     "start_time": "2024-05-21T21:31:39.871622100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 systems\n",
      "Llama 3-70B\n",
      "MM1-30B\n",
      "Inflection-2.5\n",
      "MegaScale (Production)\n",
      "FunSearch\n",
      "Gemini 1.0 Ultra\n",
      "Qwen-72B\n",
      "Inflection-2\n",
      "Nemotron-3-8B\n",
      "Grok-1\n",
      "Yi-34B\n",
      "Skywork-13B\n",
      "ChatGLM3\n",
      "FinGPT-13B\n",
      "Falcon-180B\n",
      "Llama 2-70B\n",
      "Claude 2\n",
      "xTrimoPGLM -100B\n",
      "WizardCoder-15.5B\n",
      "PaLM 2\n",
      "BloombergGPT\n",
      "PanGu-Σ\n",
      "GPT-4\n",
      "Falcon-40B\n",
      "LLaMA-65B\n",
      "ViT-22B\n",
      "GPT-3.5 (text-davinci-003)\n",
      "Galactica\n",
      "BLOOM-176B\n",
      "Flan-PaLM 540B\n",
      "U-PaLM (540B)\n",
      "BlenderBot 3\n",
      "GLM-130B\n",
      "AlexaTM 20B\n",
      "Minerva (540B)\n",
      "Parti\n",
      "UL2\n",
      "OPT-175B\n",
      "Flamingo\n",
      "PaLM (540B)\n",
      "Chinchilla\n",
      "ST-MoE\n",
      "LaMDA\n",
      "AlphaCode\n",
      "ERNIE 3.0 Titan\n",
      "GLaM\n",
      "Gopher (280B)\n",
      "Yuan 1.0\n",
      "Megatron-Turing NLG 530B\n",
      "GPT-3 175B (davinci)\n",
      "Meena\n",
      "AlphaGo Zero\n",
      "AlphaGo Master\n"
     ]
    }
   ],
   "source": [
    "print(len(above_threshold), 'systems')\n",
    "for system in above_threshold['System'][::-1]:\n",
    "  print(system)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
