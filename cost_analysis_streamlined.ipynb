{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:49.691298800Z",
     "start_time": "2024-03-08T01:54:49.634206900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:56.468786200Z",
     "start_time": "2024-03-08T01:54:49.695864500Z"
    },
    "id": "qltoZ7TbdkHZ"
   },
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from cost import *\n",
    "from plotting import *\n",
    "from prices import *\n",
    "from inflation import *\n",
    "from regression import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:56.578403700Z",
     "start_time": "2024-03-08T01:54:56.468786200Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_threshold_method = 'top_n'  # top_n, window_percentile\n",
    "compute_threshold = 10  # e.g. 10 to select top 10; 75 to select top 25%\n",
    "variant = '2025-03-17_exclude_finetunes_at_threshold_stage'  # whatever else distinguishes this run, e.g. 'excluding-AlphaGo'\n",
    "exclude_models_containing = []  # ['GNMT', 'AlphaZero', 'AlphaGo Master', 'AlphaGo Zero']\n",
    "\n",
    "# Run all three cost estimation methods\n",
    "estimation_methods = ['hardware-capex-energy', 'hardware-acquisition', 'cloud']\n",
    "estimation_method_lookup = {\n",
    "    'hardware-capex-energy': estimate_hardware_capex_energy,\n",
    "    'hardware-acquisition': estimate_hardware_acquisition_cost,\n",
    "    'cloud': estimate_cloud_costs,\n",
    "}\n",
    "\n",
    "results_dir = f'results/all-methods-{compute_threshold_method}={compute_threshold}-{variant}/'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:57.129865300Z",
     "start_time": "2024-03-08T01:54:56.872275900Z"
    }
   },
   "outputs": [],
   "source": [
    "frontier_pcd_df, hardware_df, price_df = load_data_for_cost_estimation(\n",
    "    compute_threshold_method=compute_threshold_method, compute_threshold=compute_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:57.278230500Z",
     "start_time": "2024-03-08T01:54:57.129865300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 5775, 590)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frontier_pcd_df), len(hardware_df), len(price_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:57.807954200Z",
     "start_time": "2024-03-08T01:54:57.278230500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running hardware-capex-energy estimation ===\n",
      "\n",
      "=== Running hardware-acquisition estimation ===\n",
      "\n",
      "=== Running cloud estimation ===\n",
      "\n",
      "Cost estimation completed for all methods\n"
     ]
    }
   ],
   "source": [
    "# Run all three cost estimation methods\n",
    "cost_dfs = {}\n",
    "component_cost_df = None\n",
    "\n",
    "for estimation_method in estimation_methods:\n",
    "    print(f\"\\n=== Running {estimation_method} estimation ===\")\n",
    "    cost_estimation_function = estimation_method_lookup[estimation_method]\n",
    "    \n",
    "    with open(f'{results_dir}/cost_estimation_{estimation_method}.out', 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            cost_df = cost_estimation_function(frontier_pcd_df.copy(), hardware_df, price_df)\n",
    "    \n",
    "    cost_dfs[estimation_method] = cost_df\n",
    "    \n",
    "    # Create component cost breakdown only for hardware-capex-energy method\n",
    "    if estimation_method == 'hardware-capex-energy':\n",
    "        frontier_pcd_df_copy = frontier_pcd_df.copy()\n",
    "        with open(f'{results_dir}/component_cost_estimation.out', 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                component_cost_df = cost_estimation_function(frontier_pcd_df_copy, hardware_df, price_df, separate_components=True)\n",
    "\n",
    "print(f\"\\nCost estimation completed for all methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== hardware-capex-energy results ===\n",
      "Total models: 89\n",
      "Models with cost estimates: 61\n",
      "Models with training time: 40\n",
      "Models with hardware utilization: 22\n",
      "Cost range: $185 - $301454771\n",
      "\n",
      "\n",
      "=== hardware-acquisition results ===\n",
      "Total models: 89\n",
      "Models with cost estimates: 43\n",
      "Models with training time: 37\n",
      "Models with hardware utilization: 22\n",
      "Cost range: $32363 - $5492577778\n",
      "\n",
      "\n",
      "=== cloud results ===\n",
      "Total models: 89\n",
      "Models with cost estimates: 56\n",
      "Models with training time: 36\n",
      "Models with hardware utilization: 21\n",
      "Cost range: $10175 - $1166400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the old conditional component cost creation since it's now handled in the loop above\n",
    "# Display results for each method\n",
    "for method, df in cost_dfs.items():\n",
    "    print(f\"\\n=== {method} results ===\")\n",
    "    print(f\"Total models: {len(df)}\")\n",
    "    print(f\"Models with cost estimates: {df['Cost'].notna().sum()}\")\n",
    "    print(f\"Models with training time: {df.dropna(subset=['Cost'])['Training time (hours)'].notna().sum()}\")\n",
    "    print(f\"Models with hardware utilization: {df.dropna(subset=['Cost'])['Hardware utilization'].notna().sum()}\")\n",
    "    print(f\"Cost range: ${df['Cost'].min():.0f} - ${df['Cost'].max():.0f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:57.967995500Z",
     "start_time": "2024-03-08T01:54:57.807954200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Notability criteria</th>\n",
       "      <th>...</th>\n",
       "      <th>Organization categorization (from Organization)</th>\n",
       "      <th>Training compute cost (2023 USD)</th>\n",
       "      <th>Utilization notes</th>\n",
       "      <th>Numerical format</th>\n",
       "      <th>Training power draw (W)</th>\n",
       "      <th>Training compute estimation method</th>\n",
       "      <th>Hugging Face developer id</th>\n",
       "      <th>Post-training compute (FLOP)</th>\n",
       "      <th>Post-training compute notes</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Llama 4 Behemoth (preview)</td>\n",
       "      <td>Multimodal,Language,Vision</td>\n",
       "      <td>Chat,Code generation,Visual question answering...</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>The Llama 4 herd: The beginning of a new era o...</td>\n",
       "      <td>https://ai.meta.com/blog/llama-4-multimodal-in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Operation counting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>GPT-4.5</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Foundational contributors\\r\\nAlex Paino, Ali K...</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>Introducing GPT-4.5</td>\n",
       "      <td>https://openai.com/index/introducing-gpt-4-5/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>https://www.anthropic.com/news/claude-3-7-sonnet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Grok-3</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Chat,Language modeling/generation,Question ans...</td>\n",
       "      <td>xAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Grok 3 Beta — The Age of Reasoning Agents</td>\n",
       "      <td>https://x.ai/blog/grok-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.374358e+08</td>\n",
       "      <td>Hardware,Comparison with other models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.014548e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Doubao-pro</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>ByteDance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>Doubao General Model Pro (Doubao-pro)</td>\n",
       "      <td>https://www.volcengine.com/docs/6360/1264663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Training cost</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Operation counting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>ResNet-200</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Microsoft Research Asia</td>\n",
       "      <td>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>Identity Mappings in Deep Residual Networks</td>\n",
       "      <td>https://link.springer.com/chapter/10.1007/978-...</td>\n",
       "      <td>9621.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>David Silver, Aja Huang, Chris J. Maddison, Ar...</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>https://www.nature.com/articles/nature16961</td>\n",
       "      <td>16057.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comparison with other models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>https://arxiv.org/abs/1512.03385</td>\n",
       "      <td>175697.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FP32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Operation counting,Third-party estimation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech recognition</td>\n",
       "      <td>Baidu Research - Silicon Valley AI Lab</td>\n",
       "      <td>Dario Amodei, Rishita Anubhai, Eric Battenberg...</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
       "      <td>https://arxiv.org/abs/1512.02595</td>\n",
       "      <td>2853.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>$206.31</td>\n",
       "      <td>\"Overall the system sustains approximately 50 ...</td>\n",
       "      <td>FP32</td>\n",
       "      <td>8.463468e+03</td>\n",
       "      <td>Operation counting,Third-party estimation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.854566e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>Inception v3</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Google,University College London (UCL)</td>\n",
       "      <td>Christian Szegedy, Vincent Vanhoucke, Sergey I...</td>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>Rethinking the inception architecture for comp...</td>\n",
       "      <td>https://arxiv.org/abs/1512.00567</td>\n",
       "      <td>25401.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>Industry,Academia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Third-party estimation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model                      Domain  \\\n",
       "52    Llama 4 Behemoth (preview)  Multimodal,Language,Vision   \n",
       "87                       GPT-4.5  Language,Vision,Multimodal   \n",
       "94             Claude 3.7 Sonnet  Language,Vision,Multimodal   \n",
       "101                       Grok-3  Language,Vision,Multimodal   \n",
       "206                   Doubao-pro                    Language   \n",
       "...                          ...                         ...   \n",
       "1632                  ResNet-200                      Vision   \n",
       "1660                 AlphaGo Lee                       Games   \n",
       "1664       ResNet-152 (ImageNet)                      Vision   \n",
       "1665       DeepSpeech2 (English)                      Speech   \n",
       "1667                Inception v3                      Vision   \n",
       "\n",
       "                                                   Task  \\\n",
       "52    Chat,Code generation,Visual question answering...   \n",
       "87    Language modeling/generation,Question answerin...   \n",
       "94    Language modeling/generation,Question answerin...   \n",
       "101   Chat,Language modeling/generation,Question ans...   \n",
       "206   Language modeling/generation,Question answerin...   \n",
       "...                                                 ...   \n",
       "1632                               Image classification   \n",
       "1660                                                 Go   \n",
       "1664                               Image classification   \n",
       "1665                                 Speech recognition   \n",
       "1667                               Image classification   \n",
       "\n",
       "                                Organization  \\\n",
       "52                                   Meta AI   \n",
       "87                                    OpenAI   \n",
       "94                                 Anthropic   \n",
       "101                                      xAI   \n",
       "206                                ByteDance   \n",
       "...                                      ...   \n",
       "1632                 Microsoft Research Asia   \n",
       "1660                                DeepMind   \n",
       "1664                               Microsoft   \n",
       "1665  Baidu Research - Silicon Valley AI Lab   \n",
       "1667  Google,University College London (UCL)   \n",
       "\n",
       "                                                Authors Publication date  \\\n",
       "52                                                  NaN       2025-04-05   \n",
       "87    Foundational contributors\\r\\nAlex Paino, Ali K...       2025-02-27   \n",
       "94                                                  NaN       2025-02-24   \n",
       "101                                                 NaN       2025-02-17   \n",
       "206                                                 NaN       2024-10-28   \n",
       "...                                                 ...              ...   \n",
       "1632  Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun       2016-09-17   \n",
       "1660  David Silver, Aja Huang, Chris J. Maddison, Ar...       2016-01-27   \n",
       "1664  Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun       2015-12-10   \n",
       "1665  Dario Amodei, Rishita Anubhai, Eric Battenberg...       2015-12-08   \n",
       "1667  Christian Szegedy, Vincent Vanhoucke, Sergey I...       2015-12-02   \n",
       "\n",
       "                                              Reference  \\\n",
       "52    The Llama 4 herd: The beginning of a new era o...   \n",
       "87                                  Introducing GPT-4.5   \n",
       "94                                    Claude 3.7 Sonnet   \n",
       "101           Grok 3 Beta — The Age of Reasoning Agents   \n",
       "206               Doubao General Model Pro (Doubao-pro)   \n",
       "...                                                 ...   \n",
       "1632        Identity Mappings in Deep Residual Networks   \n",
       "1660  Mastering the game of Go with deep neural netw...   \n",
       "1664       Deep Residual Learning for Image Recognition   \n",
       "1665  Deep Speech 2: End-to-End Speech Recognition i...   \n",
       "1667  Rethinking the inception architecture for comp...   \n",
       "\n",
       "                                                   Link  Citations  \\\n",
       "52    https://ai.meta.com/blog/llama-4-multimodal-in...        NaN   \n",
       "87        https://openai.com/index/introducing-gpt-4-5/        NaN   \n",
       "94     https://www.anthropic.com/news/claude-3-7-sonnet        NaN   \n",
       "101                            https://x.ai/blog/grok-3        NaN   \n",
       "206        https://www.volcengine.com/docs/6360/1264663        NaN   \n",
       "...                                                 ...        ...   \n",
       "1632  https://link.springer.com/chapter/10.1007/978-...     9621.0   \n",
       "1660        https://www.nature.com/articles/nature16961    16057.0   \n",
       "1664                   https://arxiv.org/abs/1512.03385   175697.0   \n",
       "1665                   https://arxiv.org/abs/1512.02595     2853.0   \n",
       "1667                   https://arxiv.org/abs/1512.00567    25401.0   \n",
       "\n",
       "     Notability criteria  ... Organization categorization (from Organization)  \\\n",
       "52         Training cost  ...                                        Industry   \n",
       "87         Training cost  ...                                        Industry   \n",
       "94         Training cost  ...                                        Industry   \n",
       "101        Training cost  ...                                        Industry   \n",
       "206        Training cost  ...                                        Industry   \n",
       "...                  ...  ...                                             ...   \n",
       "1632        Highly cited  ...                                        Industry   \n",
       "1660        Highly cited  ...                                        Industry   \n",
       "1664        Highly cited  ...                                        Industry   \n",
       "1665        Highly cited  ...                                        Industry   \n",
       "1667        Highly cited  ...                               Industry,Academia   \n",
       "\n",
       "      Training compute cost (2023 USD)  \\\n",
       "52                                 NaN   \n",
       "87                                 NaN   \n",
       "94                                 NaN   \n",
       "101                                NaN   \n",
       "206                                NaN   \n",
       "...                                ...   \n",
       "1632                               NaN   \n",
       "1660                               NaN   \n",
       "1664                               NaN   \n",
       "1665                           $206.31   \n",
       "1667                               NaN   \n",
       "\n",
       "                                      Utilization notes  Numerical format  \\\n",
       "52                                                  NaN               NaN   \n",
       "87                                                  NaN               NaN   \n",
       "94                                                  NaN               NaN   \n",
       "101                                                 NaN               NaN   \n",
       "206                                                 NaN               NaN   \n",
       "...                                                 ...               ...   \n",
       "1632                                                NaN               NaN   \n",
       "1660                                                NaN               NaN   \n",
       "1664                                                NaN              FP32   \n",
       "1665  \"Overall the system sustains approximately 50 ...              FP32   \n",
       "1667                                                NaN               NaN   \n",
       "\n",
       "     Training power draw (W)         Training compute estimation method  \\\n",
       "52                       NaN                         Operation counting   \n",
       "87                       NaN                                 Benchmarks   \n",
       "94                       NaN                                        NaN   \n",
       "101             1.374358e+08      Hardware,Comparison with other models   \n",
       "206                      NaN                         Operation counting   \n",
       "...                      ...                                        ...   \n",
       "1632                     NaN                                   Hardware   \n",
       "1660                     NaN               Comparison with other models   \n",
       "1664                     NaN  Operation counting,Third-party estimation   \n",
       "1665            8.463468e+03  Operation counting,Third-party estimation   \n",
       "1667                     NaN                     Third-party estimation   \n",
       "\n",
       "     Hugging Face developer id  Post-training compute (FLOP)  \\\n",
       "52                         NaN                           NaN   \n",
       "87                         NaN                           NaN   \n",
       "94                         NaN                           NaN   \n",
       "101                        NaN                           NaN   \n",
       "206                        NaN                           NaN   \n",
       "...                        ...                           ...   \n",
       "1632                       NaN                           NaN   \n",
       "1660                       NaN                           NaN   \n",
       "1664                       NaN                           NaN   \n",
       "1665                       NaN                           NaN   \n",
       "1667                       NaN                           NaN   \n",
       "\n",
       "     Post-training compute notes          Cost  \n",
       "52                           NaN           NaN  \n",
       "87                           NaN           NaN  \n",
       "94                           NaN           NaN  \n",
       "101                          NaN  3.014548e+08  \n",
       "206                          NaN           NaN  \n",
       "...                          ...           ...  \n",
       "1632                         NaN           NaN  \n",
       "1660                         NaN           NaN  \n",
       "1664                         NaN           NaN  \n",
       "1665                         NaN  1.854566e+02  \n",
       "1667                         NaN           NaN  \n",
       "\n",
       "[89 rows x 57 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use hardware-capex-energy results as the base for further analysis\n",
    "cost_df = cost_dfs['hardware-capex-energy']\n",
    "cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:58.104807Z",
     "start_time": "2024-03-08T01:54:57.967995500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Cost'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df.dropna(subset=['Cost'])['Training time (hours)'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df.dropna(subset=['Cost'])['Hardware utilization'].notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>2017-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>AlphaGo Zero</td>\n",
       "      <td>2017-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>Libratus</td>\n",
       "      <td>2017-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>2017-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>JFT</td>\n",
       "      <td>2017-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>MoE-Multi</td>\n",
       "      <td>2017-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>PolyNet</td>\n",
       "      <td>2016-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>2016-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Xception</td>\n",
       "      <td>2016-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>2016-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>ResNet-200</td>\n",
       "      <td>2016-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>2016-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>2015-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>2015-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>Inception v3</td>\n",
       "      <td>2015-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Publication date\n",
       "1566         AlphaGo Master       2017-10-19\n",
       "1567           AlphaGo Zero       2017-10-18\n",
       "1572               Libratus       2017-08-19\n",
       "1577    OpenAI TI7 DOTA 1v1       2017-08-11\n",
       "1584                    JFT       2017-07-10\n",
       "1604              MoE-Multi       2017-01-23\n",
       "1615                PolyNet       2016-11-17\n",
       "1617       NASv3 (CIFAR-10)       2016-11-05\n",
       "1623               Xception       2016-10-07\n",
       "1624                   GNMT       2016-09-26\n",
       "1632             ResNet-200       2016-09-17\n",
       "1660            AlphaGo Lee       2016-01-27\n",
       "1664  ResNet-152 (ImageNet)       2015-12-10\n",
       "1665  DeepSpeech2 (English)       2015-12-08\n",
       "1667           Inception v3       2015-12-02"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df[['Model', 'Publication date']].tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>2017-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>AlphaGo Zero</td>\n",
       "      <td>2017-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>Libratus</td>\n",
       "      <td>2017-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>2017-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>JFT</td>\n",
       "      <td>2017-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>MoE-Multi</td>\n",
       "      <td>2017-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>PolyNet</td>\n",
       "      <td>2016-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>NASv3 (CIFAR-10)</td>\n",
       "      <td>2016-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Xception</td>\n",
       "      <td>2016-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>2016-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>ResNet-200</td>\n",
       "      <td>2016-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>2016-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>2015-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>2015-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>Inception v3</td>\n",
       "      <td>2015-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Publication date\n",
       "1566         AlphaGo Master       2017-10-19\n",
       "1567           AlphaGo Zero       2017-10-18\n",
       "1572               Libratus       2017-08-19\n",
       "1577    OpenAI TI7 DOTA 1v1       2017-08-11\n",
       "1584                    JFT       2017-07-10\n",
       "1604              MoE-Multi       2017-01-23\n",
       "1615                PolyNet       2016-11-17\n",
       "1617       NASv3 (CIFAR-10)       2016-11-05\n",
       "1623               Xception       2016-10-07\n",
       "1624                   GNMT       2016-09-26\n",
       "1632             ResNet-200       2016-09-17\n",
       "1660            AlphaGo Lee       2016-01-27\n",
       "1664  ResNet-152 (ImageNet)       2015-12-10\n",
       "1665  DeepSpeech2 (English)       2015-12-08\n",
       "1667           Inception v3       2015-12-02"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply exclusions to all cost dataframes\n",
    "for method in estimation_methods:\n",
    "    for kw in exclude_models_containing:\n",
    "        cost_dfs[method] = cost_dfs[method][cost_dfs[method]['Model'].str.contains(kw) == False]\n",
    "\n",
    "# Show the models after exclusion (using hardware-capex-energy as reference)\n",
    "cost_dfs['hardware-capex-energy'][['Model', 'Publication date']].tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below to check data availability for specific systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:58.418907200Z",
     "start_time": "2024-03-08T01:54:58.109807800Z"
    }
   },
   "outputs": [],
   "source": [
    "# system = 'WizardLM-7B'\n",
    "# row = cost_df.loc[cost_df['Model'] == system]\n",
    "# print('Cost:', row['Cost'].values[0])\n",
    "# print('Training hardware:', row['Training hardware'].values[0])\n",
    "# print('Training time (hours):', row['Training time (hours)'].values[0])\n",
    "# print('Hardware quantity:', row['Hardware quantity'].values[0])\n",
    "# print('Hardware utilization:', row['Hardware utilization'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply inflation adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101     3.014548e+08\n",
       "366     3.060541e+07\n",
       "403     5.126034e+07\n",
       "448     2.057972e+07\n",
       "612     1.179460e+07\n",
       "            ...     \n",
       "1604    3.538189e+03\n",
       "1615    5.635997e+02\n",
       "1623    1.155451e+04\n",
       "1624    1.774592e+05\n",
       "1665    1.854566e+02\n",
       "Name: Cost, Length: 61, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show costs before inflation adjustment (using hardware-capex-energy)\n",
    "cost_dfs['hardware-capex-energy']['Cost'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.049781600Z",
     "start_time": "2024-03-08T01:54:58.881981400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply inflation adjustment to all cost dataframes\n",
    "for method in estimation_methods:\n",
    "    cost_dfs[method] = adjust_column_for_inflation(cost_dfs[method], 'Cost', 'data/PCU518210518210.csv', '2024-12-01')\n",
    "\n",
    "# Update the main cost_df reference\n",
    "cost_df = cost_dfs['hardware-capex-energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.177190500Z",
     "start_time": "2024-03-08T01:54:59.049781600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101     3.008724e+08\n",
       "366     3.049986e+07\n",
       "403     5.104052e+07\n",
       "448     2.052898e+07\n",
       "612     1.180459e+07\n",
       "            ...     \n",
       "1604    3.874123e+03\n",
       "1615    6.171107e+02\n",
       "1623    1.265155e+04\n",
       "1624    1.943081e+05\n",
       "1665    2.068604e+02\n",
       "Name: Cost (inflation-adjusted), Length: 61, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df['Cost (inflation-adjusted)'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.344452300Z",
     "start_time": "2024-03-08T01:54:59.182457200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Equal number of non-null values\n",
    "assert cost_df['Cost (inflation-adjusted)'].notna().sum() == cost_df['Cost'].notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.490722200Z",
     "start_time": "2024-03-08T01:54:59.337705700Z"
    }
   },
   "outputs": [],
   "source": [
    "cost_df['Publication date (float)'] = datetime_to_float_year(pd.to_datetime(cost_df['Publication date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:54:59.700207700Z",
     "start_time": "2024-03-08T01:54:59.462346300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   142.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 04 Jul 2025</td> <th>  Prob (F-statistic):</th> <td>2.36e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:51:19</td>     <th>  Log-Likelihood:    </th> <td> -62.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    61</td>      <th>  AIC:               </th> <td>   128.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    59</td>      <th>  BIC:               </th> <td>   132.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -887.9037</td> <td>   74.944</td> <td>  -11.848</td> <td> 0.000</td> <td>-1037.867</td> <td> -737.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4421</td> <td>    0.037</td> <td>   11.923</td> <td> 0.000</td> <td>    0.368</td> <td>    0.516</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.397</td> <th>  Durbin-Watson:     </th> <td>   1.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.111</td> <th>  Jarque-Bera (JB):  </th> <td>   4.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.630</td> <th>  Prob(JB):          </th> <td>   0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.962</td> <th>  Cond. No.          </th> <td>1.73e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.73e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.707   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.702   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     142.1   \\\\\n",
       "\\textbf{Date:}             & Fri, 04 Jul 2025 & \\textbf{  Prob (F-statistic):} &  2.36e-17   \\\\\n",
       "\\textbf{Time:}             &     12:51:19     & \\textbf{  Log-Likelihood:    } &   -62.231   \\\\\n",
       "\\textbf{No. Observations:} &          61      & \\textbf{  AIC:               } &     128.5   \\\\\n",
       "\\textbf{Df Residuals:}     &          59      & \\textbf{  BIC:               } &     132.7   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    -887.9037  &       74.944     &   -11.848  &         0.000        &    -1037.867    &     -737.940     \\\\\n",
       "\\textbf{x1}    &       0.4421  &        0.037     &    11.923  &         0.000        &        0.368    &        0.516     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  4.397 & \\textbf{  Durbin-Watson:     } &    1.406  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.111 & \\textbf{  Jarque-Bera (JB):  } &    4.037  \\\\\n",
       "\\textbf{Skew:}          &  0.630 & \\textbf{  Prob(JB):          } &    0.133  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.962 & \\textbf{  Cond. No.          } & 1.73e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.73e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.707\n",
       "Model:                            OLS   Adj. R-squared:                  0.702\n",
       "Method:                 Least Squares   F-statistic:                     142.1\n",
       "Date:                Fri, 04 Jul 2025   Prob (F-statistic):           2.36e-17\n",
       "Time:                        12:51:19   Log-Likelihood:                -62.231\n",
       "No. Observations:                  61   AIC:                             128.5\n",
       "Df Residuals:                      59   BIC:                             132.7\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -887.9037     74.944    -11.848      0.000   -1037.867    -737.940\n",
       "x1             0.4421      0.037     11.923      0.000       0.368       0.516\n",
       "==============================================================================\n",
       "Omnibus:                        4.397   Durbin-Watson:                   1.406\n",
       "Prob(Omnibus):                  0.111   Jarque-Bera (JB):                4.037\n",
       "Skew:                           0.630   Prob(JB):                        0.133\n",
       "Kurtosis:                       2.962   Cond. No.                     1.73e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.73e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_results = fit_ols_regression(cost_df, ['Publication date (float)'], 'Cost (inflation-adjusted)', logy=True)\n",
    "reg_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:55:00.548785500Z",
     "start_time": "2024-03-08T01:54:59.700207700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=61.0\n",
      "R^2=0.71\n",
      "0.44209 OOMs/year (90% CI: 0.38012, 0.50405)\n",
      "2.76748x/year (90% CI: 2.3995x, 3.1919x)\n",
      "doubling time of 8.17119 months (90% CI: 7.16669, 9.50317)\n"
     ]
    }
   ],
   "source": [
    "with open(f'{results_dir}/regression_results.out', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        print_growth_rates(reg_results, round_digits=None)\n",
    "print_growth_rates(reg_results, ci=90, round_digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:55:00.548785500Z",
     "start_time": "2024-03-08T01:54:59.809703300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication date (float)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.10101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.20202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.30303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.40404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2024.59596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2024.69697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2024.79798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2024.89899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2025.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Publication date (float)\n",
       "0                 2015.00000\n",
       "1                 2015.10101\n",
       "2                 2015.20202\n",
       "3                 2015.30303\n",
       "4                 2015.40404\n",
       "..                       ...\n",
       "95                2024.59596\n",
       "96                2024.69697\n",
       "97                2024.79798\n",
       "98                2024.89899\n",
       "99                2025.00000\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_start_year = 2015\n",
    "pred_end_year = 2025\n",
    "pred_start_date = f'{pred_start_year}-01-01'\n",
    "pred_end_date = f'{pred_end_year}-01-01'\n",
    "\n",
    "pred_years = pd.DataFrame({'Publication date (float)': np.linspace(pred_start_year, pred_end_year, 100)})\n",
    "pred_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T01:55:00.564420400Z",
     "start_time": "2024-03-08T01:54:59.920051200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "      <th>Publication date (float)</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.897729</td>\n",
       "      <td>0.244884</td>\n",
       "      <td>2.488505</td>\n",
       "      <td>3.306952</td>\n",
       "      <td>1.686120</td>\n",
       "      <td>4.109338</td>\n",
       "      <td>2015.00000</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.942384</td>\n",
       "      <td>0.241388</td>\n",
       "      <td>2.539001</td>\n",
       "      <td>3.345767</td>\n",
       "      <td>1.732736</td>\n",
       "      <td>4.152032</td>\n",
       "      <td>2015.10101</td>\n",
       "      <td>2015-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.987039</td>\n",
       "      <td>0.237901</td>\n",
       "      <td>2.589484</td>\n",
       "      <td>3.384594</td>\n",
       "      <td>1.779322</td>\n",
       "      <td>4.194756</td>\n",
       "      <td>2015.20202</td>\n",
       "      <td>2015-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.031694</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>2.639954</td>\n",
       "      <td>3.423434</td>\n",
       "      <td>1.825878</td>\n",
       "      <td>4.237510</td>\n",
       "      <td>2015.30303</td>\n",
       "      <td>2015-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.076349</td>\n",
       "      <td>0.230950</td>\n",
       "      <td>2.690410</td>\n",
       "      <td>3.462288</td>\n",
       "      <td>1.872405</td>\n",
       "      <td>4.280293</td>\n",
       "      <td>2015.40404</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7.139960</td>\n",
       "      <td>0.154196</td>\n",
       "      <td>6.882284</td>\n",
       "      <td>7.397636</td>\n",
       "      <td>5.970802</td>\n",
       "      <td>8.309117</td>\n",
       "      <td>2024.59596</td>\n",
       "      <td>2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7.184615</td>\n",
       "      <td>0.157296</td>\n",
       "      <td>6.921758</td>\n",
       "      <td>7.447472</td>\n",
       "      <td>6.014305</td>\n",
       "      <td>8.354925</td>\n",
       "      <td>2024.69697</td>\n",
       "      <td>2024-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.229270</td>\n",
       "      <td>0.160424</td>\n",
       "      <td>6.961186</td>\n",
       "      <td>7.497354</td>\n",
       "      <td>6.057775</td>\n",
       "      <td>8.400765</td>\n",
       "      <td>2024.79798</td>\n",
       "      <td>2024-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7.273925</td>\n",
       "      <td>0.163578</td>\n",
       "      <td>7.000571</td>\n",
       "      <td>7.547279</td>\n",
       "      <td>6.101212</td>\n",
       "      <td>8.446637</td>\n",
       "      <td>2024.89899</td>\n",
       "      <td>2024-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7.318580</td>\n",
       "      <td>0.166756</td>\n",
       "      <td>7.039914</td>\n",
       "      <td>7.597245</td>\n",
       "      <td>6.144618</td>\n",
       "      <td>8.492542</td>\n",
       "      <td>2025.00000</td>\n",
       "      <td>2025-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0   2.897729  0.244884       2.488505       3.306952      1.686120   \n",
       "1   2.942384  0.241388       2.539001       3.345767      1.732736   \n",
       "2   2.987039  0.237901       2.589484       3.384594      1.779322   \n",
       "3   3.031694  0.234421       2.639954       3.423434      1.825878   \n",
       "4   3.076349  0.230950       2.690410       3.462288      1.872405   \n",
       "..       ...       ...            ...            ...           ...   \n",
       "95  7.139960  0.154196       6.882284       7.397636      5.970802   \n",
       "96  7.184615  0.157296       6.921758       7.447472      6.014305   \n",
       "97  7.229270  0.160424       6.961186       7.497354      6.057775   \n",
       "98  7.273925  0.163578       7.000571       7.547279      6.101212   \n",
       "99  7.318580  0.166756       7.039914       7.597245      6.144618   \n",
       "\n",
       "    obs_ci_upper  Publication date (float) Publication date  \n",
       "0       4.109338                2015.00000       2015-01-01  \n",
       "1       4.152032                2015.10101       2015-02-06  \n",
       "2       4.194756                2015.20202       2015-03-15  \n",
       "3       4.237510                2015.30303       2015-04-21  \n",
       "4       4.280293                2015.40404       2015-05-28  \n",
       "..           ...                       ...              ...  \n",
       "95      8.309117                2024.59596       2024-08-06  \n",
       "96      8.354925                2024.69697       2024-09-12  \n",
       "97      8.400765                2024.79798       2024-10-19  \n",
       "98      8.446637                2024.89899       2024-11-25  \n",
       "99      8.492542                2025.00000       2025-01-01  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predicted_cost_df = get_predictions(reg_results, pred_years, ['Publication date (float)'])\n",
    "predicted_cost_df['Publication date'] = predicted_cost_df['Publication date (float)'].apply(float_year_to_datetime)\n",
    "predicted_cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction dataset - this uses hardware-capex-energy method for regression\n",
    "predicted_cost_df.to_csv(results_dir + 'predicted_cost_dataset_hardware_capex_energy.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost comparison across methods:\n",
      "                      Model  hardware_capex_energy_cost  \\\n",
      "101                  Grok-3                3.008724e+08   \n",
      "403          Llama 3.1-405B                5.104052e+07   \n",
      "448         Nemotron-4 340B                2.052898e+07   \n",
      "635  MegaScale (Production)                2.614019e+06   \n",
      "725        Gemini 1.0 Ultra                2.830960e+07   \n",
      "748            Inflection-2                1.299155e+07   \n",
      "831            Amazon Titan                7.656705e+06   \n",
      "856             Falcon-180B                1.036871e+07   \n",
      "908             Llama 2-70B                1.102561e+06   \n",
      "927        xTrimoPGLM -100B                1.823415e+06   \n",
      "\n",
      "     hardware_acquisition_cost    cloud_cost  \n",
      "101               5.481967e+09  1.164147e+09  \n",
      "403               8.960449e+08  1.698280e+08  \n",
      "448               3.366319e+08  6.552968e+07  \n",
      "635               3.768262e+08  8.967297e+06  \n",
      "725               5.979132e+08  1.919146e+08  \n",
      "748               2.760095e+08  3.660518e+07  \n",
      "831               4.263257e+08  2.318910e+07  \n",
      "856               1.269063e+08  2.588551e+07  \n",
      "908               3.096779e+07  3.139930e+06  \n",
      "927               2.378326e+07  4.120322e+06  \n",
      "\n",
      "Saved cost_dataset_3_estimates.csv with 89 models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Model accessibility</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "      <th>Training dataset size (datapoints)</th>\n",
       "      <th>...</th>\n",
       "      <th>Training time (hours)</th>\n",
       "      <th>Training hardware</th>\n",
       "      <th>Base model</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Hardware quantity</th>\n",
       "      <th>Hardware utilization</th>\n",
       "      <th>Training cloud compute vendor</th>\n",
       "      <th>Training data center</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Cost (inflation-adjusted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Llama 4 Behemoth (preview)</td>\n",
       "      <td>Multimodal,Language,Vision</td>\n",
       "      <td>Chat,Code generation,Visual question answering...</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>The Llama 4 herd: The beginning of a new era o...</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2.000000e+12</td>\n",
       "      <td>5.184000e+25</td>\n",
       "      <td>3.000000e+13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>GPT-4.5</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>API access</td>\n",
       "      <td>Introducing GPT-4.5</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.100000e+26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Azure AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>API access</td>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.350000e+25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Grok-3</td>\n",
       "      <td>Language,Vision,Multimodal</td>\n",
       "      <td>Chat,Language modeling/generation,Question ans...</td>\n",
       "      <td>Hosted access (no API)</td>\n",
       "      <td>Grok 3 Beta — The Age of Reasoning Agents</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>xAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.640000e+26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>NVIDIA H100 SXM5 80GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xAI Memphis Colossus</td>\n",
       "      <td>3.014548e+08</td>\n",
       "      <td>3.008724e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Doubao-pro</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modeling/generation,Question answerin...</td>\n",
       "      <td>API access</td>\n",
       "      <td>Doubao General Model Pro (Doubao-pro)</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>ByteDance</td>\n",
       "      <td>5.000000e+11</td>\n",
       "      <td>2.505000e+25</td>\n",
       "      <td>8.350000e+12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There is no paper to reference, also no inform...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>ResNet-200</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>Identity Mappings in Deep Residual Networks</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>Microsoft Research Asia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.974164e+19</td>\n",
       "      <td>1.281167e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>AlphaGo Lee</td>\n",
       "      <td>Games</td>\n",
       "      <td>Go</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.900000e+21</td>\n",
       "      <td>2.940000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>ResNet-152 (ImageNet)</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>6.020000e+07</td>\n",
       "      <td>1.041408e+19</td>\n",
       "      <td>1.280000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech recognition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>Baidu Research - Silicon Valley AI Lab</td>\n",
       "      <td>3.800000e+07</td>\n",
       "      <td>2.600000e+19</td>\n",
       "      <td>1.633392e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NVIDIA GeForce GTX TITAN X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.854566e+02</td>\n",
       "      <td>2.068604e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>Inception v3</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rethinking the inception architecture for comp...</td>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>Google,University College London (UCL)</td>\n",
       "      <td>2.362673e+07</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model                      Domain  \\\n",
       "52    Llama 4 Behemoth (preview)  Multimodal,Language,Vision   \n",
       "87                       GPT-4.5  Language,Vision,Multimodal   \n",
       "94             Claude 3.7 Sonnet  Language,Vision,Multimodal   \n",
       "101                       Grok-3  Language,Vision,Multimodal   \n",
       "206                   Doubao-pro                    Language   \n",
       "...                          ...                         ...   \n",
       "1632                  ResNet-200                      Vision   \n",
       "1660                 AlphaGo Lee                       Games   \n",
       "1664       ResNet-152 (ImageNet)                      Vision   \n",
       "1665       DeepSpeech2 (English)                      Speech   \n",
       "1667                Inception v3                      Vision   \n",
       "\n",
       "                                                   Task  \\\n",
       "52    Chat,Code generation,Visual question answering...   \n",
       "87    Language modeling/generation,Question answerin...   \n",
       "94    Language modeling/generation,Question answerin...   \n",
       "101   Chat,Language modeling/generation,Question ans...   \n",
       "206   Language modeling/generation,Question answerin...   \n",
       "...                                                 ...   \n",
       "1632                               Image classification   \n",
       "1660                                                 Go   \n",
       "1664                               Image classification   \n",
       "1665                                 Speech recognition   \n",
       "1667                               Image classification   \n",
       "\n",
       "         Model accessibility  \\\n",
       "52                Unreleased   \n",
       "87                API access   \n",
       "94                API access   \n",
       "101   Hosted access (no API)   \n",
       "206               API access   \n",
       "...                      ...   \n",
       "1632              Unreleased   \n",
       "1660              Unreleased   \n",
       "1664                     NaN   \n",
       "1665                     NaN   \n",
       "1667                     NaN   \n",
       "\n",
       "                                              Reference Publication date  \\\n",
       "52    The Llama 4 herd: The beginning of a new era o...       2025-04-05   \n",
       "87                                  Introducing GPT-4.5       2025-02-27   \n",
       "94                                    Claude 3.7 Sonnet       2025-02-24   \n",
       "101           Grok 3 Beta — The Age of Reasoning Agents       2025-02-17   \n",
       "206               Doubao General Model Pro (Doubao-pro)       2024-10-28   \n",
       "...                                                 ...              ...   \n",
       "1632        Identity Mappings in Deep Residual Networks       2016-09-17   \n",
       "1660  Mastering the game of Go with deep neural netw...       2016-01-27   \n",
       "1664       Deep Residual Learning for Image Recognition       2015-12-10   \n",
       "1665  Deep Speech 2: End-to-End Speech Recognition i...       2015-12-08   \n",
       "1667  Rethinking the inception architecture for comp...       2015-12-02   \n",
       "\n",
       "                                Organization    Parameters  \\\n",
       "52                                   Meta AI  2.000000e+12   \n",
       "87                                    OpenAI           NaN   \n",
       "94                                 Anthropic           NaN   \n",
       "101                                      xAI           NaN   \n",
       "206                                ByteDance  5.000000e+11   \n",
       "...                                      ...           ...   \n",
       "1632                 Microsoft Research Asia           NaN   \n",
       "1660                                DeepMind           NaN   \n",
       "1664                               Microsoft  6.020000e+07   \n",
       "1665  Baidu Research - Silicon Valley AI Lab  3.800000e+07   \n",
       "1667  Google,University College London (UCL)  2.362673e+07   \n",
       "\n",
       "      Training compute (FLOP)  Training dataset size (datapoints)  ...  \\\n",
       "52               5.184000e+25                        3.000000e+13  ...   \n",
       "87               2.100000e+26                                 NaN  ...   \n",
       "94               3.350000e+25                                 NaN  ...   \n",
       "101              4.640000e+26                                 NaN  ...   \n",
       "206              2.505000e+25                        8.350000e+12  ...   \n",
       "...                       ...                                 ...  ...   \n",
       "1632             2.974164e+19                        1.281167e+06  ...   \n",
       "1660             1.900000e+21                        2.940000e+07  ...   \n",
       "1664             1.041408e+19                        1.280000e+06  ...   \n",
       "1665             2.600000e+19                        1.633392e+08  ...   \n",
       "1667             1.000000e+20                        1.200000e+06  ...   \n",
       "\n",
       "      Training time (hours)           Training hardware Base model  \\\n",
       "52                      NaN                         NaN        NaN   \n",
       "87                      NaN                         NaN        NaN   \n",
       "94                      NaN                         NaN        NaN   \n",
       "101                  2400.0       NVIDIA H100 SXM5 80GB        NaN   \n",
       "206                     NaN                         NaN        NaN   \n",
       "...                     ...                         ...        ...   \n",
       "1632                  500.0                         NaN        NaN   \n",
       "1660                  696.0                         NaN        NaN   \n",
       "1664                    NaN                         NaN        NaN   \n",
       "1665                  120.0  NVIDIA GeForce GTX TITAN X        NaN   \n",
       "1667                    NaN                         NaN        NaN   \n",
       "\n",
       "     Finetune compute (FLOP) Hardware quantity  Hardware utilization  \\\n",
       "52                       NaN           32000.0                   NaN   \n",
       "87                       NaN               NaN                   NaN   \n",
       "94                       NaN               NaN                   NaN   \n",
       "101                      NaN          100000.0                   NaN   \n",
       "206                      NaN               NaN                   NaN   \n",
       "...                      ...               ...                   ...   \n",
       "1632                     NaN               NaN                   NaN   \n",
       "1660                     NaN               NaN                   NaN   \n",
       "1664                     NaN               NaN                   NaN   \n",
       "1665                     NaN              16.0                0.4484   \n",
       "1667                     NaN               NaN                   NaN   \n",
       "\n",
       "      Training cloud compute vendor  \\\n",
       "52                              NaN   \n",
       "87                         Azure AI   \n",
       "94                              NaN   \n",
       "101                             NaN   \n",
       "206                             NaN   \n",
       "...                             ...   \n",
       "1632                            NaN   \n",
       "1660                            NaN   \n",
       "1664                            NaN   \n",
       "1665                            NaN   \n",
       "1667                            NaN   \n",
       "\n",
       "                                   Training data center          Cost  \\\n",
       "52                                                  NaN           NaN   \n",
       "87                                                  NaN           NaN   \n",
       "94                                                  NaN           NaN   \n",
       "101                                xAI Memphis Colossus  3.014548e+08   \n",
       "206   There is no paper to reference, also no inform...           NaN   \n",
       "...                                                 ...           ...   \n",
       "1632                                                NaN           NaN   \n",
       "1660                                                NaN           NaN   \n",
       "1664                                                NaN           NaN   \n",
       "1665                                                NaN  1.854566e+02   \n",
       "1667                                                NaN           NaN   \n",
       "\n",
       "      Cost (inflation-adjusted)  \n",
       "52                          NaN  \n",
       "87                          NaN  \n",
       "94                          NaN  \n",
       "101                3.008724e+08  \n",
       "206                         NaN  \n",
       "...                         ...  \n",
       "1632                        NaN  \n",
       "1660                        NaN  \n",
       "1664                        NaN  \n",
       "1665               2.068604e+02  \n",
       "1667                        NaN  \n",
       "\n",
       "[89 rows x 21 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create cost_dataset_3_estimates.csv with Model + 3 cost columns\n",
    "cost_comparison_df = pd.DataFrame()\n",
    "cost_comparison_df['Model'] = cost_dfs['hardware-capex-energy']['Model']\n",
    "\n",
    "# Add inflation-adjusted costs from each method\n",
    "for method in estimation_methods:\n",
    "    method_df = cost_dfs[method]\n",
    "    # Apply inflation adjustment to each method's costs\n",
    "    method_df = adjust_column_for_inflation(method_df, 'Cost', 'data/PCU518210518210.csv', '2024-12-01')\n",
    "    cost_comparison_df[f'{method.replace(\"-\", \"_\")}_cost'] = method_df['Cost (inflation-adjusted)']\n",
    "\n",
    "# Display the comparison\n",
    "print(\"Cost comparison across methods:\")\n",
    "print(cost_comparison_df.dropna().head(10))\n",
    "\n",
    "# Save the 3-method comparison dataset\n",
    "cost_comparison_df.to_csv(results_dir + 'cost_dataset_3_estimates.csv', index=False)\n",
    "print(f\"\\nSaved cost_dataset_3_estimates.csv with {len(cost_comparison_df)} models\")\n",
    "\n",
    "# Also keep the original detailed export for the hardware-capex-energy method\n",
    "keep_cols = [\n",
    "    'Model',\n",
    "    'Domain',\n",
    "    'Task',\n",
    "    'Model accessibility',\n",
    "    'Reference',\n",
    "    'Publication date',\n",
    "    'Organization',\n",
    "    'Parameters',\n",
    "    'Training compute (FLOP)',\n",
    "    'Training dataset size (datapoints)',\n",
    "    'Epochs',\n",
    "    'Training time (hours)',\n",
    "    'Training hardware',\n",
    "    'Base model',\n",
    "    'Finetune compute (FLOP)',\n",
    "    'Hardware quantity',\n",
    "    'Hardware utilization',\n",
    "    'Training cloud compute vendor',\n",
    "    'Training data center',\n",
    "    'Cost',\n",
    "    'Cost (inflation-adjusted)',\n",
    "]\n",
    "cost_df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the detailed export for the hardware-capex-energy method\n",
    "cost_df[keep_cols].to_csv(results_dir + 'cost_dataset_detailed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_component_names = [\n",
    "    'AI accelerator chip cost',\n",
    "    'Other server components cost',\n",
    "    'Cluster-level interconnect cost',\n",
    "    'Energy cost',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52            NaN\n",
       "87            NaN\n",
       "94            NaN\n",
       "101     45.507920\n",
       "206           NaN\n",
       "          ...    \n",
       "1632          NaN\n",
       "1660          NaN\n",
       "1664          NaN\n",
       "1665    34.484219\n",
       "1667          NaN\n",
       "Name: AI accelerator chip cost (%), Length: 89, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in cost_component_names:\n",
    "    component_cost_df[f\"{key} (%)\"] = component_cost_df[key] / component_cost_df['Cost'] * 100\n",
    "component_cost_df['AI accelerator chip cost (%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_component_pc_names = [name + ' (%)' for name in cost_component_names]\n",
    "filtered_component_cost_df = component_cost_df.dropna(subset=cost_component_pc_names).sort_values(by='Publication date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Notability criteria</th>\n",
       "      <th>...</th>\n",
       "      <th>Post-training compute notes</th>\n",
       "      <th>AI accelerator chip cost</th>\n",
       "      <th>Other server components cost</th>\n",
       "      <th>Cluster-level interconnect cost</th>\n",
       "      <th>Energy cost</th>\n",
       "      <th>Cost</th>\n",
       "      <th>AI accelerator chip cost (%)</th>\n",
       "      <th>Other server components cost (%)</th>\n",
       "      <th>Cluster-level interconnect cost (%)</th>\n",
       "      <th>Energy cost (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>DeepSpeech2 (English)</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech recognition</td>\n",
       "      <td>Baidu Research - Silicon Valley AI Lab</td>\n",
       "      <td>Dario Amodei, Rishita Anubhai, Eric Battenberg...</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>Deep Speech 2: End-to-End Speech Recognition i...</td>\n",
       "      <td>https://arxiv.org/abs/1512.02595</td>\n",
       "      <td>2853.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.953273</td>\n",
       "      <td>40.930095</td>\n",
       "      <td>24.602271</td>\n",
       "      <td>55.971000</td>\n",
       "      <td>185.456639</td>\n",
       "      <td>34.484219</td>\n",
       "      <td>22.069900</td>\n",
       "      <td>13.265781</td>\n",
       "      <td>30.180101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>Language</td>\n",
       "      <td>Translation</td>\n",
       "      <td>Google</td>\n",
       "      <td>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>Google's Neural Machine Translation System: Br...</td>\n",
       "      <td>https://arxiv.org/abs/1609.08144</td>\n",
       "      <td>6483.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77894.044829</td>\n",
       "      <td>49852.188691</td>\n",
       "      <td>29965.165887</td>\n",
       "      <td>19747.833534</td>\n",
       "      <td>177459.232941</td>\n",
       "      <td>43.894050</td>\n",
       "      <td>28.092192</td>\n",
       "      <td>16.885662</td>\n",
       "      <td>11.128096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Xception</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Google</td>\n",
       "      <td>François Chollet</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>Xception: Deep Learning with Depthwise Separab...</td>\n",
       "      <td>https://arxiv.org/abs/1610.02357</td>\n",
       "      <td>13038.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5064.230483</td>\n",
       "      <td>3241.107509</td>\n",
       "      <td>1948.165702</td>\n",
       "      <td>1301.002560</td>\n",
       "      <td>11554.506253</td>\n",
       "      <td>43.829051</td>\n",
       "      <td>28.050593</td>\n",
       "      <td>16.860657</td>\n",
       "      <td>11.259698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>PolyNet</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Chinese University of Hong Kong (CUHK)</td>\n",
       "      <td>X Zhang, Z Li, C Change Loy</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>PolyNet: A Pursuit of Structural Diversity in ...</td>\n",
       "      <td>https://arxiv.org/abs/1611.05725</td>\n",
       "      <td>282.0</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.564122</td>\n",
       "      <td>114.281038</td>\n",
       "      <td>68.692074</td>\n",
       "      <td>202.062472</td>\n",
       "      <td>563.599706</td>\n",
       "      <td>31.682792</td>\n",
       "      <td>20.276987</td>\n",
       "      <td>12.188096</td>\n",
       "      <td>35.852125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>MoE-Multi</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modeling,Translation</td>\n",
       "      <td>Jagiellonian University,Google Brain</td>\n",
       "      <td>N Shazeer, A Mirhoseini, K Maziarz, A Davis</td>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>Outrageously Large Neural Networks: The Sparse...</td>\n",
       "      <td>https://arxiv.org/abs/1701.06538</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1519.646471</td>\n",
       "      <td>972.573741</td>\n",
       "      <td>584.594865</td>\n",
       "      <td>461.374341</td>\n",
       "      <td>3538.189418</td>\n",
       "      <td>42.949834</td>\n",
       "      <td>27.487894</td>\n",
       "      <td>16.522430</td>\n",
       "      <td>13.039843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model    Domain                           Task  \\\n",
       "1665  DeepSpeech2 (English)    Speech             Speech recognition   \n",
       "1624                   GNMT  Language                    Translation   \n",
       "1623               Xception    Vision           Image classification   \n",
       "1615                PolyNet    Vision           Image classification   \n",
       "1604              MoE-Multi  Language  Language modeling,Translation   \n",
       "\n",
       "                                Organization  \\\n",
       "1665  Baidu Research - Silicon Valley AI Lab   \n",
       "1624                                  Google   \n",
       "1623                                  Google   \n",
       "1615  Chinese University of Hong Kong (CUHK)   \n",
       "1604    Jagiellonian University,Google Brain   \n",
       "\n",
       "                                                Authors Publication date  \\\n",
       "1665  Dario Amodei, Rishita Anubhai, Eric Battenberg...       2015-12-08   \n",
       "1624  Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc ...       2016-09-26   \n",
       "1623                                   François Chollet       2016-10-07   \n",
       "1615                        X Zhang, Z Li, C Change Loy       2016-11-17   \n",
       "1604        N Shazeer, A Mirhoseini, K Maziarz, A Davis       2017-01-23   \n",
       "\n",
       "                                              Reference  \\\n",
       "1665  Deep Speech 2: End-to-End Speech Recognition i...   \n",
       "1624  Google's Neural Machine Translation System: Br...   \n",
       "1623  Xception: Deep Learning with Depthwise Separab...   \n",
       "1615  PolyNet: A Pursuit of Structural Diversity in ...   \n",
       "1604  Outrageously Large Neural Networks: The Sparse...   \n",
       "\n",
       "                                  Link  Citations  \\\n",
       "1665  https://arxiv.org/abs/1512.02595     2853.0   \n",
       "1624  https://arxiv.org/abs/1609.08144     6483.0   \n",
       "1623  https://arxiv.org/abs/1610.02357    13038.0   \n",
       "1615  https://arxiv.org/abs/1611.05725      282.0   \n",
       "1604  https://arxiv.org/abs/1701.06538     2037.0   \n",
       "\n",
       "                Notability criteria  ... Post-training compute notes  \\\n",
       "1665                   Highly cited  ...                         NaN   \n",
       "1624                   Highly cited  ...                         NaN   \n",
       "1623                   Highly cited  ...                         NaN   \n",
       "1615               SOTA improvement  ...                         NaN   \n",
       "1604  Highly cited,SOTA improvement  ...                         NaN   \n",
       "\n",
       "      AI accelerator chip cost Other server components cost  \\\n",
       "1665                 63.953273                    40.930095   \n",
       "1624              77894.044829                 49852.188691   \n",
       "1623               5064.230483                  3241.107509   \n",
       "1615                178.564122                   114.281038   \n",
       "1604               1519.646471                   972.573741   \n",
       "\n",
       "      Cluster-level interconnect cost   Energy cost           Cost  \\\n",
       "1665                        24.602271     55.971000     185.456639   \n",
       "1624                     29965.165887  19747.833534  177459.232941   \n",
       "1623                      1948.165702   1301.002560   11554.506253   \n",
       "1615                        68.692074    202.062472     563.599706   \n",
       "1604                       584.594865    461.374341    3538.189418   \n",
       "\n",
       "     AI accelerator chip cost (%)  Other server components cost (%)  \\\n",
       "1665                    34.484219                         22.069900   \n",
       "1624                    43.894050                         28.092192   \n",
       "1623                    43.829051                         28.050593   \n",
       "1615                    31.682792                         20.276987   \n",
       "1604                    42.949834                         27.487894   \n",
       "\n",
       "     Cluster-level interconnect cost (%)  Energy cost (%)  \n",
       "1665                           13.265781        30.180101  \n",
       "1624                           16.885662        11.128096  \n",
       "1623                           16.860657        11.259698  \n",
       "1615                           12.188096        35.852125  \n",
       "1604                           16.522430        13.039843  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_component_cost_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_component_cost_df.to_csv(results_dir + 'cost_components.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AI accelerator chip cost (%)           45.618313\n",
       "Other server components cost (%)       29.544045\n",
       "Cluster-level interconnect cost (%)    17.630677\n",
       "Energy cost (%)                         7.206965\n",
       "dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average percentage for each component\n",
    "filtered_component_cost_df[cost_component_pc_names].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Model', 'Domain', 'Task', 'Organization', 'Authors',\n",
       "       'Publication date', 'Reference', 'Link', 'Citations',\n",
       "       'Notability criteria', 'Notability criteria notes', 'Parameters',\n",
       "       'Parameters notes', 'Training compute (FLOP)', 'Training compute notes',\n",
       "       'Training dataset', 'Training dataset notes',\n",
       "       'Training dataset size (datapoints)', 'Dataset size notes',\n",
       "       'Training time (hours)', 'Training time notes', 'Training hardware',\n",
       "       'Approach', 'Confidence', 'Abstract', 'Epochs', 'Benchmark data',\n",
       "       'Model accessibility', 'Country (of organization)', 'Base model',\n",
       "       'Finetune compute (FLOP)', 'Finetune compute notes',\n",
       "       'Hardware quantity', 'Hardware utilization', 'Last modified',\n",
       "       'Training cloud compute vendor', 'Training data center',\n",
       "       'Archived links', 'Batch size', 'Batch size notes',\n",
       "       'Organization categorization', 'Foundation model',\n",
       "       'Training compute lower bound', 'Training compute upper bound',\n",
       "       'Training chip-hours', 'Training code accessibility',\n",
       "       'Accessibility notes',\n",
       "       'Organization categorization (from Organization)',\n",
       "       'Training compute cost (2023 USD)', 'Utilization notes',\n",
       "       'Numerical format', 'Training power draw (W)',\n",
       "       'Training compute estimation method', 'Hugging Face developer id',\n",
       "       'Post-training compute (FLOP)', 'Post-training compute notes',\n",
       "       'AI accelerator chip cost', 'Other server components cost',\n",
       "       'Cluster-level interconnect cost', 'Energy cost', 'Cost',\n",
       "       'AI accelerator chip cost (%)', 'Other server components cost (%)',\n",
       "       'Cluster-level interconnect cost (%)', 'Energy cost (%)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_component_cost_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_component_cost_df = filtered_component_cost_df.dropna(subset=['Training hardware'])\n",
    "power_col = 'Power capacity for final training run (kW)'\n",
    "filtered_component_cost_df.loc[:, power_col] = [\n",
    "    cluster_power_capacity(row['Training hardware'], row['Hardware quantity'], hardware_df, row['Organization'])\n",
    "    for _, row in filtered_component_cost_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_component_cost_df['Publication date (float)'] = datetime_to_float_year(\n",
    "    pd.to_datetime(filtered_component_cost_df['Publication date'])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
